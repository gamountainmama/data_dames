{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOq/sBzs8C/WqTtVz+QEtS1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KellyPared/dash_dashboard/blob/main/Grade_Level_Predictions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Private School Fort Lauderdale"
      ],
      "metadata": {
        "id": "WFMLIvHEyzzr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NN Model - Dropping Math Courses\n",
        "\n",
        "1/41 [==============================] - 0s \n",
        "\n",
        "Loss: 2.519768238067627, \n",
        "\n",
        "Accuracy: 0.48012471199035645"
      ],
      "metadata": {
        "id": "XZA69vaewPoa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "7e9tgr_9dt7n"
      },
      "outputs": [],
      "source": [
        "# Import our dependencies\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import pandas as pd \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load the data\n",
        "df = pd.read_csv('Data_Set_9-12.csv')\n",
        "\n",
        "# Check the shape of the DataFrame\n",
        "print(df.shape)\n",
        "\n",
        "# Check the first few rows of the DataFrame\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C736F297d0qK",
        "outputId": "a9fedf8c-d4f7-4415-9a91-451ae0fd8a2f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5131, 4)\n",
            "  StudentID                          Course  Grade  Section_Grade\n",
            "0    STU711                English I Honors      9          96.67\n",
            "1    STU711                French II Honors      9          87.92\n",
            "2    STU711  Computer Science Principles AP      9          86.02\n",
            "3    STU711                       Chemistry      9          88.89\n",
            "4    STU711              Human Geography AP      9          88.49\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "new_df = df.copy()\n",
        "\n",
        "keywords_to_course_type = {\n",
        "    'french spanish german latin chinese': 'Foreign Language',\n",
        "    'math algebra statistics geometry calculus': 'Math',\n",
        "    'english writers literature shakespeare': 'English',\n",
        "    'human government world history microeconomics': 'Humanities',\n",
        "    'science astronomy biology physics anatomy chemistry': 'Science',\n",
        "    'data computer artificial': \"Computer Science\",\n",
        "    'capstone': \"Research\",\n",
        "    'visual arts art music': 'Arts',\n",
        "    'psychology great decisions': 'Psychology',\n",
        "    'entrepreneurship': 'Entrepreneurship',\n",
        "    'constitutional international politics':'Law and Politics'\n",
        "}\n",
        "\n",
        "def get_course_type(course):\n",
        "    '''find words in keywords and assign'''\n",
        "    for keyword, course_type in keywords_to_course_type.items():\n",
        "        if any(word in course.lower() for word in keyword.split()):\n",
        "            return course_type\n",
        "    return 'unknown'\n",
        "\n",
        "# apply the function to the 'Course' column to create a new 'Course_Type' column\n",
        "new_df['Course_Type'] = new_df['Course'].apply(get_course_type)\n",
        "\n",
        "# display the updated dataframe\n",
        "new_df.head(100)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 537
        },
        "id": "3_BxSn7HNllW",
        "outputId": "2ff0444e-81e0-438b-d533-3730049bef54"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   StudentID                          Course  Grade  Section_Grade  \\\n",
              "0     STU711                English I Honors      9          96.67   \n",
              "1     STU711                French II Honors      9          87.92   \n",
              "2     STU711  Computer Science Principles AP      9          86.02   \n",
              "3     STU711                       Chemistry      9          88.89   \n",
              "4     STU711              Human Geography AP      9          88.49   \n",
              "..       ...                             ...    ...            ...   \n",
              "95    STU348  Computer Science Principles AP      9          98.83   \n",
              "96    STU348                Chemistry Honors      9          93.57   \n",
              "97    STU348                World History AP      9          98.98   \n",
              "98    STU735                English I Honors      9          94.60   \n",
              "99    STU735               Chinese II Honors      9          97.60   \n",
              "\n",
              "         Course_Type  \n",
              "0            English  \n",
              "1   Foreign Language  \n",
              "2            Science  \n",
              "3            Science  \n",
              "4         Humanities  \n",
              "..               ...  \n",
              "95           Science  \n",
              "96           Science  \n",
              "97        Humanities  \n",
              "98           English  \n",
              "99  Foreign Language  \n",
              "\n",
              "[100 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1251f853-38c2-4c02-a94f-5ad19ba395ba\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>StudentID</th>\n",
              "      <th>Course</th>\n",
              "      <th>Grade</th>\n",
              "      <th>Section_Grade</th>\n",
              "      <th>Course_Type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>STU711</td>\n",
              "      <td>English I Honors</td>\n",
              "      <td>9</td>\n",
              "      <td>96.67</td>\n",
              "      <td>English</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>STU711</td>\n",
              "      <td>French II Honors</td>\n",
              "      <td>9</td>\n",
              "      <td>87.92</td>\n",
              "      <td>Foreign Language</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>STU711</td>\n",
              "      <td>Computer Science Principles AP</td>\n",
              "      <td>9</td>\n",
              "      <td>86.02</td>\n",
              "      <td>Science</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>STU711</td>\n",
              "      <td>Chemistry</td>\n",
              "      <td>9</td>\n",
              "      <td>88.89</td>\n",
              "      <td>Science</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>STU711</td>\n",
              "      <td>Human Geography AP</td>\n",
              "      <td>9</td>\n",
              "      <td>88.49</td>\n",
              "      <td>Humanities</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>STU348</td>\n",
              "      <td>Computer Science Principles AP</td>\n",
              "      <td>9</td>\n",
              "      <td>98.83</td>\n",
              "      <td>Science</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>STU348</td>\n",
              "      <td>Chemistry Honors</td>\n",
              "      <td>9</td>\n",
              "      <td>93.57</td>\n",
              "      <td>Science</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>STU348</td>\n",
              "      <td>World History AP</td>\n",
              "      <td>9</td>\n",
              "      <td>98.98</td>\n",
              "      <td>Humanities</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>STU735</td>\n",
              "      <td>English I Honors</td>\n",
              "      <td>9</td>\n",
              "      <td>94.60</td>\n",
              "      <td>English</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>STU735</td>\n",
              "      <td>Chinese II Honors</td>\n",
              "      <td>9</td>\n",
              "      <td>97.60</td>\n",
              "      <td>Foreign Language</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1251f853-38c2-4c02-a94f-5ad19ba395ba')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1251f853-38c2-4c02-a94f-5ad19ba395ba button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1251f853-38c2-4c02-a94f-5ad19ba395ba');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_df.to_csv('new_PC_data.csv')\n"
      ],
      "metadata": {
        "id": "kTW4iT99-999"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# find unknown data strings in the 'col1' column\n",
        "# unknowns = new_df[new_df['Course_Type'] == 'unknown']\n",
        "# print(unknowns)"
      ],
      "metadata": {
        "id": "fnHLPCUMZPDD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop the non-beneficial columns.\n",
        "df = df.drop(columns='StudentID', axis=1)"
      ],
      "metadata": {
        "id": "NrPINnjFphc0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_df.dtypes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5E4OYBkrrMRS",
        "outputId": "ff607228-5496-4fdf-89e3-38a52a634ebb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Course            object\n",
              "Grade              int64\n",
              "Section_Grade    float64\n",
              "Course_Type       object\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_df[\"Course_Type\"].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o77kLyDVVloy",
        "outputId": "4cb814be-0fb4-4f7c-80b8-187b2aaf82ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['English', 'Foreign Language', 'Science', 'Humanities', 'Math',\n",
              "       'Psychology', 'Arts', 'Law and Politics', 'Entrepreneurship',\n",
              "       'Computer Science', 'Research'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate the average grade per course\n",
        "avg_grades = new_df.groupby('Course')['Section_Grade'].mean()\n",
        "\n",
        "# print the result\n",
        "print(avg_grades)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q9Tl0_pcfKXO",
        "outputId": "d81afb14-6c2b-4213-ca4e-f5d9122fdf2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Course\n",
            "AP Research (Capstone Year 2)          97.055000\n",
            "AP Seminar (Capstone Year 1)           90.933333\n",
            "Algebra II                             86.140000\n",
            "Algebra II Honors                      90.570000\n",
            "Anatomy and Physiology Honors          91.059403\n",
            "                                         ...    \n",
            "Talented Writers Program III Honors    90.171429\n",
            "United States History AP               90.253567\n",
            "United States History Honors           89.568125\n",
            "Women Writers Post-AP                  95.564667\n",
            "World History AP                       95.681765\n",
            "Name: Section_Grade, Length: 105, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert categorical data to numeric with `pd.get_dummies`\n",
        "cat_data = pd.get_dummies(new_df)\n",
        "cat_data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352
        },
        "id": "hIWBR4-kt_gA",
        "outputId": "7d2ad228-8ff6-4eaa-aca1-c416d8a4c3ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Grade  Section_Grade  Course_AP Research (Capstone Year 2)  \\\n",
              "0      9          96.67                                     0   \n",
              "1      9          87.92                                     0   \n",
              "2      9          86.02                                     0   \n",
              "3      9          88.89                                     0   \n",
              "4      9          88.49                                     0   \n",
              "\n",
              "   Course_AP Seminar (Capstone Year 1)  Course_Algebra II  \\\n",
              "0                                    0                  0   \n",
              "1                                    0                  0   \n",
              "2                                    0                  0   \n",
              "3                                    0                  0   \n",
              "4                                    0                  0   \n",
              "\n",
              "   Course_Algebra II Honors  Course_Anatomy and Physiology Honors  \\\n",
              "0                         0                                     0   \n",
              "1                         0                                     0   \n",
              "2                         0                                     0   \n",
              "3                         0                                     0   \n",
              "4                         0                                     0   \n",
              "\n",
              "   Course_Art History AP  Course_Artificial Intelligence Post-AP  \\\n",
              "0                      0                                       0   \n",
              "1                      0                                       0   \n",
              "2                      0                                       0   \n",
              "3                      0                                       0   \n",
              "4                      0                                       0   \n",
              "\n",
              "   Course_Astronomy Honors  ...  Course_Type_Computer Science  \\\n",
              "0                        0  ...                             0   \n",
              "1                        0  ...                             0   \n",
              "2                        0  ...                             0   \n",
              "3                        0  ...                             0   \n",
              "4                        0  ...                             0   \n",
              "\n",
              "   Course_Type_English  Course_Type_Entrepreneurship  \\\n",
              "0                    1                             0   \n",
              "1                    0                             0   \n",
              "2                    0                             0   \n",
              "3                    0                             0   \n",
              "4                    0                             0   \n",
              "\n",
              "   Course_Type_Foreign Language  Course_Type_Humanities  \\\n",
              "0                             0                       0   \n",
              "1                             1                       0   \n",
              "2                             0                       0   \n",
              "3                             0                       0   \n",
              "4                             0                       1   \n",
              "\n",
              "   Course_Type_Law and Politics  Course_Type_Math  Course_Type_Psychology  \\\n",
              "0                             0                 0                       0   \n",
              "1                             0                 0                       0   \n",
              "2                             0                 0                       0   \n",
              "3                             0                 0                       0   \n",
              "4                             0                 0                       0   \n",
              "\n",
              "   Course_Type_Research  Course_Type_Science  \n",
              "0                     0                    0  \n",
              "1                     0                    0  \n",
              "2                     0                    1  \n",
              "3                     0                    1  \n",
              "4                     0                    0  \n",
              "\n",
              "[5 rows x 118 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f1c37ac7-2557-44f3-8346-b4de45dd1ebf\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Grade</th>\n",
              "      <th>Section_Grade</th>\n",
              "      <th>Course_AP Research (Capstone Year 2)</th>\n",
              "      <th>Course_AP Seminar (Capstone Year 1)</th>\n",
              "      <th>Course_Algebra II</th>\n",
              "      <th>Course_Algebra II Honors</th>\n",
              "      <th>Course_Anatomy and Physiology Honors</th>\n",
              "      <th>Course_Art History AP</th>\n",
              "      <th>Course_Artificial Intelligence Post-AP</th>\n",
              "      <th>Course_Astronomy Honors</th>\n",
              "      <th>...</th>\n",
              "      <th>Course_Type_Computer Science</th>\n",
              "      <th>Course_Type_English</th>\n",
              "      <th>Course_Type_Entrepreneurship</th>\n",
              "      <th>Course_Type_Foreign Language</th>\n",
              "      <th>Course_Type_Humanities</th>\n",
              "      <th>Course_Type_Law and Politics</th>\n",
              "      <th>Course_Type_Math</th>\n",
              "      <th>Course_Type_Psychology</th>\n",
              "      <th>Course_Type_Research</th>\n",
              "      <th>Course_Type_Science</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>9</td>\n",
              "      <td>96.67</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>9</td>\n",
              "      <td>87.92</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>9</td>\n",
              "      <td>86.02</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9</td>\n",
              "      <td>88.89</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9</td>\n",
              "      <td>88.49</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 118 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f1c37ac7-2557-44f3-8346-b4de45dd1ebf')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f1c37ac7-2557-44f3-8346-b4de45dd1ebf button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f1c37ac7-2557-44f3-8346-b4de45dd1ebf');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cat_data.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WzmM8J50ulzJ",
        "outputId": "1c257f5f-3f82-412b-f91d-8eaa911377a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Grade', 'Section_Grade', 'Course_AP Research (Capstone Year 2)',\n",
              "       'Course_AP Seminar (Capstone Year 1)', 'Course_Algebra II',\n",
              "       'Course_Algebra II Honors', 'Course_Anatomy and Physiology Honors',\n",
              "       'Course_Art History AP', 'Course_Artificial Intelligence Post-AP',\n",
              "       'Course_Astronomy Honors',\n",
              "       ...\n",
              "       'Course_Type_Computer Science', 'Course_Type_English',\n",
              "       'Course_Type_Entrepreneurship', 'Course_Type_Foreign Language',\n",
              "       'Course_Type_Humanities', 'Course_Type_Law and Politics',\n",
              "       'Course_Type_Math', 'Course_Type_Psychology', 'Course_Type_Research',\n",
              "       'Course_Type_Science'],\n",
              "      dtype='object', length=118)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split our preprocessed data into our features and target arrays\n",
        "X = cat_data.drop('Course_Type_Math', axis=1).values\n",
        "y = cat_data['Course_Type_Math'].values\n",
        "\n",
        "# Split the preprocessed data into a training and testing dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=13)"
      ],
      "metadata": {
        "id": "QA-gnjHCuM9V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a StandardScaler instances\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit the StandardScaler\n",
        "X_scaler = scaler.fit(X_train)\n",
        "\n",
        "# Scale the data\n",
        "X_train_scaled = X_scaler.transform(X_train)\n",
        "X_test_scaled = X_scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "OuSh79R_uxDp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Compile, Train and Evaluate the Model\n",
        "\n",
        "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
        "input = X_train_scaled.shape[1]\n",
        "nn = tf.keras.models.Sequential()\n",
        "\n",
        "# First hidden layer\n",
        "nn.add(tf.keras.layers.Dense(units=5, activation=\"relu\", input_dim=input))\n",
        "\n",
        "# Check the structure of the model\n",
        "nn.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vmV-xclduzJi",
        "outputId": "13e49cc2-8f64-479b-fb5f-49773dfe4aa7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 5)                 590       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 590\n",
            "Trainable params: 590\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "nn.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "Tmo4LobQu962"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "checkpoint = ModelCheckpoint(\"best_model.hdf5\", monitor='accuracy', verbose=1,\n",
        "    save_best_only=True, mode='auto', save_freq=5)\n",
        "\n",
        "fit_model = nn.fit(X_train_scaled, y_train, epochs=100, verbose=1, callbacks=[checkpoint])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fjQbnq_Iu_W8",
        "outputId": "34f94a43-6bf6-4e74-f8a5-f7f43fe36fa3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Epoch 1: accuracy improved from 0.26151 to 0.26438, saving model to best_model.hdf5\n",
            "\n",
            "Epoch 1: accuracy improved from 0.26438 to 0.27054, saving model to best_model.hdf5\n",
            "105/121 [=========================>....] - ETA: 0s - loss: 3.5321 - accuracy: 0.2705\n",
            "Epoch 1: accuracy improved from 0.27054 to 0.27443, saving model to best_model.hdf5\n",
            "\n",
            "Epoch 1: accuracy improved from 0.27443 to 0.27554, saving model to best_model.hdf5\n",
            "115/121 [===========================>..] - ETA: 0s - loss: 3.5250 - accuracy: 0.2755\n",
            "Epoch 1: accuracy improved from 0.27554 to 0.27682, saving model to best_model.hdf5\n",
            "121/121 [==============================] - 2s 4ms/step - loss: 3.5100 - accuracy: 0.2765\n",
            "Epoch 2/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.9429 - accuracy: 0.5312\n",
            "Epoch 2: accuracy improved from 0.27682 to 0.34375, saving model to best_model.hdf5\n",
            "\n",
            "Epoch 2: accuracy did not improve from 0.34375\n",
            "\n",
            "Epoch 2: accuracy improved from 0.34375 to 0.36830, saving model to best_model.hdf5\n",
            " 14/121 [==>...........................] - ETA: 0s - loss: 3.4194 - accuracy: 0.3683\n",
            "Epoch 2: accuracy did not improve from 0.36830\n",
            "\n",
            "Epoch 2: accuracy did not improve from 0.36830\n",
            "\n",
            "Epoch 2: accuracy did not improve from 0.36830\n",
            "\n",
            "Epoch 2: accuracy did not improve from 0.36830\n",
            " 34/121 [=======>......................] - ETA: 0s - loss: 3.3015 - accuracy: 0.3640\n",
            "Epoch 2: accuracy did not improve from 0.36830\n",
            "\n",
            "Epoch 2: accuracy improved from 0.36830 to 0.37926, saving model to best_model.hdf5\n",
            "\n",
            "Epoch 2: accuracy did not improve from 0.37926\n",
            " 49/121 [===========>..................] - ETA: 0s - loss: 3.2938 - accuracy: 0.3756\n",
            "Epoch 2: accuracy did not improve from 0.37926\n",
            "\n",
            "Epoch 2: accuracy improved from 0.37926 to 0.38453, saving model to best_model.hdf5\n",
            "\n",
            "Epoch 2: accuracy did not improve from 0.38453\n",
            " 64/121 [==============>...............] - ETA: 0s - loss: 3.3104 - accuracy: 0.3818\n",
            "Epoch 2: accuracy improved from 0.38453 to 0.38496, saving model to best_model.hdf5\n",
            "\n",
            "Epoch 2: accuracy improved from 0.38496 to 0.38978, saving model to best_model.hdf5\n",
            " 74/121 [=================>............] - ETA: 0s - loss: 3.3198 - accuracy: 0.3898\n",
            "Epoch 2: accuracy improved from 0.38978 to 0.39241, saving model to best_model.hdf5\n",
            "\n",
            "Epoch 2: accuracy improved from 0.39241 to 0.39435, saving model to best_model.hdf5\n",
            " 88/121 [====================>.........] - ETA: 0s - loss: 3.3127 - accuracy: 0.3981\n",
            "Epoch 2: accuracy improved from 0.39435 to 0.39817, saving model to best_model.hdf5\n",
            "\n",
            "Epoch 2: accuracy did not improve from 0.39817\n",
            "\n",
            "Epoch 2: accuracy did not improve from 0.39817\n",
            "102/121 [========================>.....] - ETA: 0s - loss: 3.3547 - accuracy: 0.4004\n",
            "Epoch 2: accuracy improved from 0.39817 to 0.40445, saving model to best_model.hdf5\n",
            "\n",
            "Epoch 2: accuracy improved from 0.40445 to 0.40711, saving model to best_model.hdf5\n",
            "109/121 [==========================>...] - ETA: 0s - loss: 3.3185 - accuracy: 0.4071\n",
            "Epoch 2: accuracy did not improve from 0.40711\n",
            "\n",
            "Epoch 2: accuracy improved from 0.40711 to 0.40730, saving model to best_model.hdf5\n",
            "121/121 [==============================] - 0s 4ms/step - loss: 3.2987 - accuracy: 0.4059\n",
            "Epoch 3/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 3.4707 - accuracy: 0.5625\n",
            "Epoch 3: accuracy improved from 0.40730 to 0.52083, saving model to best_model.hdf5\n",
            "\n",
            "Epoch 3: accuracy did not improve from 0.52083\n",
            "\n",
            "Epoch 3: accuracy did not improve from 0.52083\n",
            "\n",
            "Epoch 3: accuracy did not improve from 0.52083\n",
            " 18/121 [===>..........................] - ETA: 0s - loss: 3.1755 - accuracy: 0.4531\n",
            "Epoch 3: accuracy did not improve from 0.52083\n",
            "\n",
            "Epoch 3: accuracy did not improve from 0.52083\n",
            "\n",
            "Epoch 3: accuracy did not improve from 0.52083\n",
            " 34/121 [=======>......................] - ETA: 0s - loss: 3.2233 - accuracy: 0.4586\n",
            "Epoch 3: accuracy did not improve from 0.52083\n",
            "\n",
            "Epoch 3: accuracy did not improve from 0.52083\n",
            "\n",
            "Epoch 3: accuracy did not improve from 0.52083\n",
            " 49/121 [===========>..................] - ETA: 0s - loss: 3.2725 - accuracy: 0.4630\n",
            "Epoch 3: accuracy did not improve from 0.52083\n",
            "\n",
            "Epoch 3: accuracy did not improve from 0.52083\n",
            "\n",
            "Epoch 3: accuracy did not improve from 0.52083\n",
            "\n",
            "Epoch 3: accuracy did not improve from 0.52083\n",
            " 69/121 [================>.............] - ETA: 0s - loss: 3.3078 - accuracy: 0.4574\n",
            "Epoch 3: accuracy did not improve from 0.52083\n",
            "\n",
            "Epoch 3: accuracy did not improve from 0.52083\n",
            "\n",
            "Epoch 3: accuracy did not improve from 0.52083\n",
            "\n",
            "Epoch 3: accuracy did not improve from 0.52083\n",
            " 89/121 [=====================>........] - ETA: 0s - loss: 3.2682 - accuracy: 0.4610\n",
            "Epoch 3: accuracy did not improve from 0.52083\n",
            "\n",
            "Epoch 3: accuracy did not improve from 0.52083\n",
            "\n",
            "Epoch 3: accuracy did not improve from 0.52083\n",
            "\n",
            "Epoch 3: accuracy did not improve from 0.52083\n",
            "108/121 [=========================>....] - ETA: 0s - loss: 3.2430 - accuracy: 0.4638\n",
            "Epoch 3: accuracy did not improve from 0.52083\n",
            "\n",
            "Epoch 3: accuracy did not improve from 0.52083\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 3.2705 - accuracy: 0.4589\n",
            "Epoch 4/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.0057 - accuracy: 0.5312\n",
            "Epoch 4: accuracy improved from 0.52083 to 0.54688, saving model to best_model.hdf5\n",
            "\n",
            "Epoch 4: accuracy did not improve from 0.54688\n",
            "\n",
            "Epoch 4: accuracy did not improve from 0.54688\n",
            " 16/121 [==>...........................] - ETA: 0s - loss: 3.2608 - accuracy: 0.4531\n",
            "Epoch 4: accuracy did not improve from 0.54688\n",
            "\n",
            "Epoch 4: accuracy did not improve from 0.54688\n",
            "\n",
            "Epoch 4: accuracy did not improve from 0.54688\n",
            "\n",
            "Epoch 4: accuracy did not improve from 0.54688\n",
            " 34/121 [=======>......................] - ETA: 0s - loss: 3.3250 - accuracy: 0.4596\n",
            "Epoch 4: accuracy did not improve from 0.54688\n",
            "\n",
            "Epoch 4: accuracy did not improve from 0.54688\n",
            "\n",
            "Epoch 4: accuracy did not improve from 0.54688\n",
            "\n",
            "Epoch 4: accuracy did not improve from 0.54688\n",
            " 53/121 [============>.................] - ETA: 0s - loss: 3.2482 - accuracy: 0.4617\n",
            "Epoch 4: accuracy did not improve from 0.54688\n",
            "\n",
            "Epoch 4: accuracy did not improve from 0.54688\n",
            "\n",
            "Epoch 4: accuracy did not improve from 0.54688\n",
            " 71/121 [================>.............] - ETA: 0s - loss: 3.2566 - accuracy: 0.4648\n",
            "Epoch 4: accuracy did not improve from 0.54688\n",
            "\n",
            "Epoch 4: accuracy did not improve from 0.54688\n",
            "\n",
            "Epoch 4: accuracy did not improve from 0.54688\n",
            "\n",
            "Epoch 4: accuracy did not improve from 0.54688\n",
            " 88/121 [====================>.........] - ETA: 0s - loss: 3.2278 - accuracy: 0.4677\n",
            "Epoch 4: accuracy did not improve from 0.54688\n",
            "\n",
            "Epoch 4: accuracy did not improve from 0.54688\n",
            "\n",
            "Epoch 4: accuracy did not improve from 0.54688\n",
            "103/121 [========================>.....] - ETA: 0s - loss: 3.2305 - accuracy: 0.4748\n",
            "Epoch 4: accuracy did not improve from 0.54688\n",
            "\n",
            "Epoch 4: accuracy did not improve from 0.54688\n",
            "\n",
            "Epoch 4: accuracy did not improve from 0.54688\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 3.2598 - accuracy: 0.4717\n",
            "Epoch 5/100\n",
            "\n",
            "Epoch 5: accuracy did not improve from 0.54688\n",
            "  1/121 [..............................] - ETA: 0s - loss: 3.0687 - accuracy: 0.4688\n",
            "Epoch 5: accuracy did not improve from 0.54688\n",
            "\n",
            "Epoch 5: accuracy did not improve from 0.54688\n",
            "\n",
            "Epoch 5: accuracy did not improve from 0.54688\n",
            " 17/121 [===>..........................] - ETA: 0s - loss: 3.2909 - accuracy: 0.4577\n",
            "Epoch 5: accuracy did not improve from 0.54688\n",
            "\n",
            "Epoch 5: accuracy did not improve from 0.54688\n",
            "\n",
            "Epoch 5: accuracy did not improve from 0.54688\n",
            "\n",
            "Epoch 5: accuracy did not improve from 0.54688\n",
            " 37/121 [========>.....................] - ETA: 0s - loss: 3.2953 - accuracy: 0.4696\n",
            "Epoch 5: accuracy did not improve from 0.54688\n",
            "\n",
            "Epoch 5: accuracy did not improve from 0.54688\n",
            "\n",
            "Epoch 5: accuracy did not improve from 0.54688\n",
            " 54/121 [============>.................] - ETA: 0s - loss: 3.2598 - accuracy: 0.4844\n",
            "Epoch 5: accuracy did not improve from 0.54688\n",
            "\n",
            "Epoch 5: accuracy did not improve from 0.54688\n",
            "\n",
            "Epoch 5: accuracy did not improve from 0.54688\n",
            " 68/121 [===============>..............] - ETA: 0s - loss: 3.2370 - accuracy: 0.4913\n",
            "Epoch 5: accuracy did not improve from 0.54688\n",
            "\n",
            "Epoch 5: accuracy did not improve from 0.54688\n",
            "\n",
            "Epoch 5: accuracy did not improve from 0.54688\n",
            " 84/121 [===================>..........] - ETA: 0s - loss: 3.2165 - accuracy: 0.4944\n",
            "Epoch 5: accuracy did not improve from 0.54688\n",
            "\n",
            "Epoch 5: accuracy did not improve from 0.54688\n",
            "\n",
            "Epoch 5: accuracy did not improve from 0.54688\n",
            " 99/121 [=======================>......] - ETA: 0s - loss: 3.2625 - accuracy: 0.4915\n",
            "Epoch 5: accuracy did not improve from 0.54688\n",
            "\n",
            "Epoch 5: accuracy did not improve from 0.54688\n",
            "\n",
            "Epoch 5: accuracy did not improve from 0.54688\n",
            "111/121 [==========================>...] - ETA: 0s - loss: 3.2837 - accuracy: 0.4930\n",
            "Epoch 5: accuracy did not improve from 0.54688\n",
            "\n",
            "Epoch 5: accuracy did not improve from 0.54688\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 3.2535 - accuracy: 0.4974\n",
            "Epoch 6/100\n",
            "  1/121 [..............................] - ETA: 1s - loss: 3.0637 - accuracy: 0.5000\n",
            "Epoch 6: accuracy did not improve from 0.54688\n",
            "\n",
            "Epoch 6: accuracy did not improve from 0.54688\n",
            "\n",
            "Epoch 6: accuracy did not improve from 0.54688\n",
            " 15/121 [==>...........................] - ETA: 0s - loss: 3.3804 - accuracy: 0.4917\n",
            "Epoch 6: accuracy did not improve from 0.54688\n",
            "\n",
            "Epoch 6: accuracy did not improve from 0.54688\n",
            "\n",
            "Epoch 6: accuracy did not improve from 0.54688\n",
            " 30/121 [======>.......................] - ETA: 0s - loss: 3.2596 - accuracy: 0.5208\n",
            "Epoch 6: accuracy did not improve from 0.54688\n",
            "\n",
            "Epoch 6: accuracy did not improve from 0.54688\n",
            "\n",
            "Epoch 6: accuracy did not improve from 0.54688\n",
            " 45/121 [==========>...................] - ETA: 0s - loss: 3.2565 - accuracy: 0.5306\n",
            "Epoch 6: accuracy did not improve from 0.54688\n",
            "\n",
            "Epoch 6: accuracy did not improve from 0.54688\n",
            " 59/121 [=============>................] - ETA: 0s - loss: 3.2627 - accuracy: 0.5238\n",
            "Epoch 6: accuracy did not improve from 0.54688\n",
            "\n",
            "Epoch 6: accuracy did not improve from 0.54688\n",
            "\n",
            "Epoch 6: accuracy did not improve from 0.54688\n",
            " 74/121 [=================>............] - ETA: 0s - loss: 3.2420 - accuracy: 0.5317\n",
            "Epoch 6: accuracy did not improve from 0.54688\n",
            "\n",
            "Epoch 6: accuracy did not improve from 0.54688\n",
            "\n",
            "Epoch 6: accuracy did not improve from 0.54688\n",
            "\n",
            "Epoch 6: accuracy did not improve from 0.54688\n",
            " 90/121 [=====================>........] - ETA: 0s - loss: 3.2424 - accuracy: 0.5306\n",
            "Epoch 6: accuracy did not improve from 0.54688\n",
            "\n",
            "Epoch 6: accuracy did not improve from 0.54688\n",
            "\n",
            "Epoch 6: accuracy did not improve from 0.54688\n",
            "105/121 [=========================>....] - ETA: 0s - loss: 3.2411 - accuracy: 0.5318\n",
            "Epoch 6: accuracy did not improve from 0.54688\n",
            "\n",
            "Epoch 6: accuracy did not improve from 0.54688\n",
            "\n",
            "Epoch 6: accuracy did not improve from 0.54688\n",
            "121/121 [==============================] - 0s 4ms/step - loss: 3.2504 - accuracy: 0.5338\n",
            "Epoch 7/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 3.1595 - accuracy: 0.4062\n",
            "Epoch 7: accuracy did not improve from 0.54688\n",
            "\n",
            "Epoch 7: accuracy did not improve from 0.54688\n",
            "\n",
            "Epoch 7: accuracy did not improve from 0.54688\n",
            " 14/121 [==>...........................] - ETA: 0s - loss: 3.3343 - accuracy: 0.5156\n",
            "Epoch 7: accuracy did not improve from 0.54688\n",
            "\n",
            "Epoch 7: accuracy did not improve from 0.54688\n",
            " 28/121 [=====>........................] - ETA: 0s - loss: 3.3430 - accuracy: 0.5234\n",
            "Epoch 7: accuracy did not improve from 0.54688\n",
            "\n",
            "Epoch 7: accuracy did not improve from 0.54688\n",
            "\n",
            "Epoch 7: accuracy did not improve from 0.54688\n",
            " 43/121 [=========>....................] - ETA: 0s - loss: 3.2371 - accuracy: 0.5385\n",
            "Epoch 7: accuracy did not improve from 0.54688\n",
            "\n",
            "Epoch 7: accuracy did not improve from 0.54688\n",
            "\n",
            "Epoch 7: accuracy did not improve from 0.54688\n",
            " 58/121 [=============>................] - ETA: 0s - loss: 3.2294 - accuracy: 0.5426\n",
            "Epoch 7: accuracy did not improve from 0.54688\n",
            "\n",
            "Epoch 7: accuracy did not improve from 0.54688\n",
            "\n",
            "Epoch 7: accuracy did not improve from 0.54688\n",
            "\n",
            "Epoch 7: accuracy did not improve from 0.54688\n",
            " 74/121 [=================>............] - ETA: 0s - loss: 3.2569 - accuracy: 0.5405\n",
            "Epoch 7: accuracy did not improve from 0.54688\n",
            "\n",
            "Epoch 7: accuracy did not improve from 0.54688\n",
            "\n",
            "Epoch 7: accuracy did not improve from 0.54688\n",
            " 89/121 [=====================>........] - ETA: 0s - loss: 3.2456 - accuracy: 0.5411\n",
            "Epoch 7: accuracy did not improve from 0.54688\n",
            "\n",
            "Epoch 7: accuracy did not improve from 0.54688\n",
            "103/121 [========================>.....] - ETA: 0s - loss: 3.2686 - accuracy: 0.5455\n",
            "Epoch 7: accuracy did not improve from 0.54688\n",
            "\n",
            "Epoch 7: accuracy did not improve from 0.54688\n",
            "\n",
            "Epoch 7: accuracy did not improve from 0.54688\n",
            "\n",
            "Epoch 7: accuracy did not improve from 0.54688\n",
            "121/121 [==============================] - 0s 4ms/step - loss: 3.2489 - accuracy: 0.5455\n",
            "Epoch 8/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 3.3567 - accuracy: 0.4375\n",
            "Epoch 8: accuracy did not improve from 0.54688\n",
            "\n",
            "Epoch 8: accuracy did not improve from 0.54688\n",
            "\n",
            "Epoch 8: accuracy improved from 0.54688 to 0.55048, saving model to best_model.hdf5\n",
            " 13/121 [==>...........................] - ETA: 0s - loss: 3.3009 - accuracy: 0.5505\n",
            "Epoch 8: accuracy did not improve from 0.55048\n",
            "\n",
            "Epoch 8: accuracy improved from 0.55048 to 0.55842, saving model to best_model.hdf5\n",
            " 26/121 [=====>........................] - ETA: 0s - loss: 3.2034 - accuracy: 0.5565\n",
            "Epoch 8: accuracy improved from 0.55842 to 0.56027, saving model to best_model.hdf5\n",
            "\n",
            "Epoch 8: accuracy did not improve from 0.56027\n",
            "\n",
            "Epoch 8: accuracy did not improve from 0.56027\n",
            " 38/121 [========>.....................] - ETA: 0s - loss: 3.2573 - accuracy: 0.5428\n",
            "Epoch 8: accuracy did not improve from 0.56027\n",
            "\n",
            "Epoch 8: accuracy did not improve from 0.56027\n",
            "\n",
            "Epoch 8: accuracy did not improve from 0.56027\n",
            " 55/121 [============>.................] - ETA: 0s - loss: 3.3190 - accuracy: 0.5398\n",
            "Epoch 8: accuracy did not improve from 0.56027\n",
            "\n",
            "Epoch 8: accuracy did not improve from 0.56027\n",
            "\n",
            "Epoch 8: accuracy did not improve from 0.56027\n",
            " 72/121 [================>.............] - ETA: 0s - loss: 3.2983 - accuracy: 0.5399\n",
            "Epoch 8: accuracy did not improve from 0.56027\n",
            "\n",
            "Epoch 8: accuracy did not improve from 0.56027\n",
            "\n",
            "Epoch 8: accuracy did not improve from 0.56027\n",
            "\n",
            "Epoch 8: accuracy did not improve from 0.56027\n",
            " 89/121 [=====================>........] - ETA: 0s - loss: 3.2383 - accuracy: 0.5474\n",
            "Epoch 8: accuracy did not improve from 0.56027\n",
            "\n",
            "Epoch 8: accuracy did not improve from 0.56027\n",
            "\n",
            "Epoch 8: accuracy did not improve from 0.56027\n",
            "107/121 [=========================>....] - ETA: 0s - loss: 3.2429 - accuracy: 0.5467\n",
            "Epoch 8: accuracy did not improve from 0.56027\n",
            "\n",
            "Epoch 8: accuracy did not improve from 0.56027\n",
            "\n",
            "Epoch 8: accuracy did not improve from 0.56027\n",
            "121/121 [==============================] - 0s 4ms/step - loss: 3.2481 - accuracy: 0.5452\n",
            "Epoch 9/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 3.5387 - accuracy: 0.6250\n",
            "Epoch 9: accuracy improved from 0.56027 to 0.59375, saving model to best_model.hdf5\n",
            "\n",
            "Epoch 9: accuracy did not improve from 0.59375\n",
            "\n",
            "Epoch 9: accuracy did not improve from 0.59375\n",
            " 13/121 [==>...........................] - ETA: 0s - loss: 3.2910 - accuracy: 0.5264\n",
            "Epoch 9: accuracy did not improve from 0.59375\n",
            "\n",
            "Epoch 9: accuracy did not improve from 0.59375\n",
            "\n",
            "Epoch 9: accuracy did not improve from 0.59375\n",
            "\n",
            "Epoch 9: accuracy did not improve from 0.59375\n",
            " 32/121 [======>.......................] - ETA: 0s - loss: 3.3504 - accuracy: 0.5303\n",
            "Epoch 9: accuracy did not improve from 0.59375\n",
            "\n",
            "Epoch 9: accuracy did not improve from 0.59375\n",
            "\n",
            "Epoch 9: accuracy did not improve from 0.59375\n",
            " 51/121 [===========>..................] - ETA: 0s - loss: 3.2382 - accuracy: 0.5404\n",
            "Epoch 9: accuracy did not improve from 0.59375\n",
            "\n",
            "Epoch 9: accuracy did not improve from 0.59375\n",
            "\n",
            "Epoch 9: accuracy did not improve from 0.59375\n",
            "\n",
            "Epoch 9: accuracy did not improve from 0.59375\n",
            " 68/121 [===============>..............] - ETA: 0s - loss: 3.2318 - accuracy: 0.5437\n",
            "Epoch 9: accuracy did not improve from 0.59375\n",
            "\n",
            "Epoch 9: accuracy did not improve from 0.59375\n",
            "\n",
            "Epoch 9: accuracy did not improve from 0.59375\n",
            " 86/121 [====================>.........] - ETA: 0s - loss: 3.2284 - accuracy: 0.5436\n",
            "Epoch 9: accuracy did not improve from 0.59375\n",
            "\n",
            "Epoch 9: accuracy did not improve from 0.59375\n",
            "\n",
            "Epoch 9: accuracy did not improve from 0.59375\n",
            "\n",
            "Epoch 9: accuracy did not improve from 0.59375\n",
            "103/121 [========================>.....] - ETA: 0s - loss: 3.2077 - accuracy: 0.5473\n",
            "Epoch 9: accuracy did not improve from 0.59375\n",
            "\n",
            "Epoch 9: accuracy did not improve from 0.59375\n",
            "\n",
            "Epoch 9: accuracy did not improve from 0.59375\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 3.2475 - accuracy: 0.5491\n",
            "Epoch 10/100\n",
            "\n",
            "Epoch 10: accuracy did not improve from 0.59375\n",
            "  1/121 [..............................] - ETA: 0s - loss: 3.5486 - accuracy: 0.5938\n",
            "Epoch 10: accuracy did not improve from 0.59375\n",
            "\n",
            "Epoch 10: accuracy did not improve from 0.59375\n",
            "\n",
            "Epoch 10: accuracy did not improve from 0.59375\n",
            " 17/121 [===>..........................] - ETA: 0s - loss: 3.0682 - accuracy: 0.5643\n",
            "Epoch 10: accuracy did not improve from 0.59375\n",
            "\n",
            "Epoch 10: accuracy did not improve from 0.59375\n",
            "\n",
            "Epoch 10: accuracy did not improve from 0.59375\n",
            " 34/121 [=======>......................] - ETA: 0s - loss: 3.1893 - accuracy: 0.5533\n",
            "Epoch 10: accuracy did not improve from 0.59375\n",
            "\n",
            "Epoch 10: accuracy did not improve from 0.59375\n",
            "\n",
            "Epoch 10: accuracy did not improve from 0.59375\n",
            "\n",
            "Epoch 10: accuracy did not improve from 0.59375\n",
            " 51/121 [===========>..................] - ETA: 0s - loss: 3.1152 - accuracy: 0.5643\n",
            "Epoch 10: accuracy did not improve from 0.59375\n",
            "\n",
            "Epoch 10: accuracy did not improve from 0.59375\n",
            "\n",
            "Epoch 10: accuracy did not improve from 0.59375\n",
            " 69/121 [================>.............] - ETA: 0s - loss: 3.1861 - accuracy: 0.5684\n",
            "Epoch 10: accuracy did not improve from 0.59375\n",
            "\n",
            "Epoch 10: accuracy did not improve from 0.59375\n",
            "\n",
            "Epoch 10: accuracy did not improve from 0.59375\n",
            " 84/121 [===================>..........] - ETA: 0s - loss: 3.2178 - accuracy: 0.5592\n",
            "Epoch 10: accuracy did not improve from 0.59375\n",
            "\n",
            "Epoch 10: accuracy did not improve from 0.59375\n",
            "\n",
            "Epoch 10: accuracy did not improve from 0.59375\n",
            "\n",
            "Epoch 10: accuracy did not improve from 0.59375\n",
            "101/121 [========================>.....] - ETA: 0s - loss: 3.2147 - accuracy: 0.5566\n",
            "Epoch 10: accuracy did not improve from 0.59375\n",
            "\n",
            "Epoch 10: accuracy did not improve from 0.59375\n",
            "\n",
            "Epoch 10: accuracy did not improve from 0.59375\n",
            "118/121 [============================>.] - ETA: 0s - loss: 3.2473 - accuracy: 0.5575\n",
            "Epoch 10: accuracy did not improve from 0.59375\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 3.2471 - accuracy: 0.5590\n",
            "Epoch 11/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.7694 - accuracy: 0.5938\n",
            "Epoch 11: accuracy did not improve from 0.59375\n",
            "\n",
            "Epoch 11: accuracy did not improve from 0.59375\n",
            " 14/121 [==>...........................] - ETA: 0s - loss: 3.4653 - accuracy: 0.5714\n",
            "Epoch 11: accuracy did not improve from 0.59375\n",
            "\n",
            "Epoch 11: accuracy did not improve from 0.59375\n",
            "\n",
            "Epoch 11: accuracy did not improve from 0.59375\n",
            " 29/121 [======>.......................] - ETA: 0s - loss: 3.3137 - accuracy: 0.5905\n",
            "Epoch 11: accuracy did not improve from 0.59375\n",
            "\n",
            "Epoch 11: accuracy did not improve from 0.59375\n",
            "\n",
            "Epoch 11: accuracy did not improve from 0.59375\n",
            "\n",
            "Epoch 11: accuracy did not improve from 0.59375\n",
            " 46/121 [==========>...................] - ETA: 0s - loss: 3.3264 - accuracy: 0.5761\n",
            "Epoch 11: accuracy did not improve from 0.59375\n",
            "\n",
            "Epoch 11: accuracy did not improve from 0.59375\n",
            "\n",
            "Epoch 11: accuracy did not improve from 0.59375\n",
            " 62/121 [==============>...............] - ETA: 0s - loss: 3.3183 - accuracy: 0.5640\n",
            "Epoch 11: accuracy did not improve from 0.59375\n",
            "\n",
            "Epoch 11: accuracy did not improve from 0.59375\n",
            "\n",
            "Epoch 11: accuracy did not improve from 0.59375\n",
            " 79/121 [==================>...........] - ETA: 0s - loss: 3.2913 - accuracy: 0.5688\n",
            "Epoch 11: accuracy did not improve from 0.59375\n",
            "\n",
            "Epoch 11: accuracy did not improve from 0.59375\n",
            "\n",
            "Epoch 11: accuracy did not improve from 0.59375\n",
            "\n",
            "Epoch 11: accuracy did not improve from 0.59375\n",
            " 95/121 [======================>.......] - ETA: 0s - loss: 3.2729 - accuracy: 0.5681\n",
            "Epoch 11: accuracy did not improve from 0.59375\n",
            "\n",
            "Epoch 11: accuracy did not improve from 0.59375\n",
            "\n",
            "Epoch 11: accuracy did not improve from 0.59375\n",
            "111/121 [==========================>...] - ETA: 0s - loss: 3.2529 - accuracy: 0.5667\n",
            "Epoch 11: accuracy did not improve from 0.59375\n",
            "\n",
            "Epoch 11: accuracy did not improve from 0.59375\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 3.2470 - accuracy: 0.5686\n",
            "Epoch 12/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.7672 - accuracy: 0.5938\n",
            "Epoch 12: accuracy did not improve from 0.59375\n",
            "\n",
            "Epoch 12: accuracy did not improve from 0.59375\n",
            "\n",
            "Epoch 12: accuracy did not improve from 0.59375\n",
            " 15/121 [==>...........................] - ETA: 0s - loss: 3.2916 - accuracy: 0.5708\n",
            "Epoch 12: accuracy did not improve from 0.59375\n",
            "\n",
            "Epoch 12: accuracy did not improve from 0.59375\n",
            "\n",
            "Epoch 12: accuracy did not improve from 0.59375\n",
            " 29/121 [======>.......................] - ETA: 0s - loss: 3.2113 - accuracy: 0.5593\n",
            "Epoch 12: accuracy did not improve from 0.59375\n",
            "\n",
            "Epoch 12: accuracy did not improve from 0.59375\n",
            "\n",
            "Epoch 12: accuracy did not improve from 0.59375\n",
            " 47/121 [==========>...................] - ETA: 0s - loss: 3.1425 - accuracy: 0.5698\n",
            "Epoch 12: accuracy did not improve from 0.59375\n",
            "\n",
            "Epoch 12: accuracy did not improve from 0.59375\n",
            "\n",
            "Epoch 12: accuracy did not improve from 0.59375\n",
            " 61/121 [==============>...............] - ETA: 0s - loss: 3.1380 - accuracy: 0.5753\n",
            "Epoch 12: accuracy did not improve from 0.59375\n",
            "\n",
            "Epoch 12: accuracy did not improve from 0.59375\n",
            "\n",
            "Epoch 12: accuracy did not improve from 0.59375\n",
            " 74/121 [=================>............] - ETA: 0s - loss: 3.1247 - accuracy: 0.5785\n",
            "Epoch 12: accuracy did not improve from 0.59375\n",
            "\n",
            "Epoch 12: accuracy did not improve from 0.59375\n",
            "\n",
            "Epoch 12: accuracy did not improve from 0.59375\n",
            " 91/121 [=====================>........] - ETA: 0s - loss: 3.1974 - accuracy: 0.5749\n",
            "Epoch 12: accuracy did not improve from 0.59375\n",
            "\n",
            "Epoch 12: accuracy did not improve from 0.59375\n",
            "\n",
            "Epoch 12: accuracy did not improve from 0.59375\n",
            "107/121 [=========================>....] - ETA: 0s - loss: 3.2026 - accuracy: 0.5724\n",
            "Epoch 12: accuracy did not improve from 0.59375\n",
            "\n",
            "Epoch 12: accuracy did not improve from 0.59375\n",
            "\n",
            "Epoch 12: accuracy did not improve from 0.59375\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 3.2469 - accuracy: 0.5720\n",
            "Epoch 13/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 3.7346 - accuracy: 0.5000\n",
            "Epoch 13: accuracy did not improve from 0.59375\n",
            "\n",
            "Epoch 13: accuracy did not improve from 0.59375\n",
            "\n",
            "Epoch 13: accuracy did not improve from 0.59375\n",
            " 14/121 [==>...........................] - ETA: 0s - loss: 3.5155 - accuracy: 0.5603\n",
            "Epoch 13: accuracy did not improve from 0.59375\n",
            "\n",
            "Epoch 13: accuracy did not improve from 0.59375\n",
            "\n",
            "Epoch 13: accuracy did not improve from 0.59375\n",
            " 31/121 [======>.......................] - ETA: 0s - loss: 3.3797 - accuracy: 0.5575\n",
            "Epoch 13: accuracy did not improve from 0.59375\n",
            "\n",
            "Epoch 13: accuracy did not improve from 0.59375\n",
            "\n",
            "Epoch 13: accuracy did not improve from 0.59375\n",
            "\n",
            "Epoch 13: accuracy did not improve from 0.59375\n",
            " 49/121 [===========>..................] - ETA: 0s - loss: 3.3883 - accuracy: 0.5529\n",
            "Epoch 13: accuracy did not improve from 0.59375\n",
            "\n",
            "Epoch 13: accuracy did not improve from 0.59375\n",
            "\n",
            "Epoch 13: accuracy did not improve from 0.59375\n",
            " 67/121 [===============>..............] - ETA: 0s - loss: 3.3423 - accuracy: 0.5639\n",
            "Epoch 13: accuracy did not improve from 0.59375\n",
            "\n",
            "Epoch 13: accuracy did not improve from 0.59375\n",
            "\n",
            "Epoch 13: accuracy did not improve from 0.59375\n",
            "\n",
            "Epoch 13: accuracy did not improve from 0.59375\n",
            " 84/121 [===================>..........] - ETA: 0s - loss: 3.3252 - accuracy: 0.5647\n",
            "Epoch 13: accuracy did not improve from 0.59375\n",
            "\n",
            "Epoch 13: accuracy did not improve from 0.59375\n",
            "\n",
            "Epoch 13: accuracy did not improve from 0.59375\n",
            "102/121 [========================>.....] - ETA: 0s - loss: 3.2998 - accuracy: 0.5656\n",
            "Epoch 13: accuracy did not improve from 0.59375\n",
            "\n",
            "Epoch 13: accuracy did not improve from 0.59375\n",
            "\n",
            "Epoch 13: accuracy did not improve from 0.59375\n",
            "116/121 [===========================>..] - ETA: 0s - loss: 3.2570 - accuracy: 0.5735\n",
            "Epoch 13: accuracy did not improve from 0.59375\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 3.2469 - accuracy: 0.5725\n",
            "Epoch 14/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 3.7313 - accuracy: 0.5938\n",
            "Epoch 14: accuracy did not improve from 0.59375\n",
            "\n",
            "Epoch 14: accuracy improved from 0.59375 to 0.59821, saving model to best_model.hdf5\n",
            " 11/121 [=>............................] - ETA: 0s - loss: 3.2275 - accuracy: 0.5966\n",
            "Epoch 14: accuracy improved from 0.59821 to 0.60417, saving model to best_model.hdf5\n",
            "\n",
            "Epoch 14: accuracy did not improve from 0.60417\n",
            " 20/121 [===>..........................] - ETA: 0s - loss: 3.1629 - accuracy: 0.5984\n",
            "Epoch 14: accuracy did not improve from 0.60417\n",
            "\n",
            "Epoch 14: accuracy did not improve from 0.60417\n",
            "\n",
            "Epoch 14: accuracy did not improve from 0.60417\n",
            " 34/121 [=======>......................] - ETA: 0s - loss: 3.1722 - accuracy: 0.5790\n",
            "Epoch 14: accuracy did not improve from 0.60417\n",
            "\n",
            "Epoch 14: accuracy did not improve from 0.60417\n",
            "\n",
            "Epoch 14: accuracy did not improve from 0.60417\n",
            "\n",
            "Epoch 14: accuracy did not improve from 0.60417\n",
            " 52/121 [===========>..................] - ETA: 0s - loss: 3.2446 - accuracy: 0.5679\n",
            "Epoch 14: accuracy did not improve from 0.60417\n",
            "\n",
            "Epoch 14: accuracy did not improve from 0.60417\n",
            "\n",
            "Epoch 14: accuracy did not improve from 0.60417\n",
            " 69/121 [================>.............] - ETA: 0s - loss: 3.2138 - accuracy: 0.5729\n",
            "Epoch 14: accuracy did not improve from 0.60417\n",
            "\n",
            "Epoch 14: accuracy did not improve from 0.60417\n",
            "\n",
            "Epoch 14: accuracy did not improve from 0.60417\n",
            " 85/121 [====================>.........] - ETA: 0s - loss: 3.2066 - accuracy: 0.5794\n",
            "Epoch 14: accuracy did not improve from 0.60417\n",
            "\n",
            "Epoch 14: accuracy did not improve from 0.60417\n",
            "\n",
            "Epoch 14: accuracy did not improve from 0.60417\n",
            " 98/121 [=======================>......] - ETA: 0s - loss: 3.2098 - accuracy: 0.5765\n",
            "Epoch 14: accuracy did not improve from 0.60417\n",
            "\n",
            "Epoch 14: accuracy did not improve from 0.60417\n",
            "\n",
            "Epoch 14: accuracy did not improve from 0.60417\n",
            "114/121 [===========================>..] - ETA: 0s - loss: 3.2326 - accuracy: 0.5704\n",
            "Epoch 14: accuracy did not improve from 0.60417\n",
            "121/121 [==============================] - 0s 4ms/step - loss: 3.2469 - accuracy: 0.5733\n",
            "Epoch 15/100\n",
            "\n",
            "Epoch 15: accuracy did not improve from 0.60417\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.9655 - accuracy: 0.5312\n",
            "Epoch 15: accuracy did not improve from 0.60417\n",
            "\n",
            "Epoch 15: accuracy did not improve from 0.60417\n",
            "\n",
            "Epoch 15: accuracy did not improve from 0.60417\n",
            " 19/121 [===>..........................] - ETA: 0s - loss: 3.2144 - accuracy: 0.5526\n",
            "Epoch 15: accuracy did not improve from 0.60417\n",
            "\n",
            "Epoch 15: accuracy did not improve from 0.60417\n",
            "\n",
            "Epoch 15: accuracy did not improve from 0.60417\n",
            "\n",
            "Epoch 15: accuracy did not improve from 0.60417\n",
            " 36/121 [=======>......................] - ETA: 0s - loss: 3.1928 - accuracy: 0.5712\n",
            "Epoch 15: accuracy did not improve from 0.60417\n",
            "\n",
            "Epoch 15: accuracy did not improve from 0.60417\n",
            "\n",
            "Epoch 15: accuracy did not improve from 0.60417\n",
            " 54/121 [============>.................] - ETA: 0s - loss: 3.1877 - accuracy: 0.5735\n",
            "Epoch 15: accuracy did not improve from 0.60417\n",
            "\n",
            "Epoch 15: accuracy did not improve from 0.60417\n",
            "\n",
            "Epoch 15: accuracy did not improve from 0.60417\n",
            " 70/121 [================>.............] - ETA: 0s - loss: 3.2100 - accuracy: 0.5737\n",
            "Epoch 15: accuracy did not improve from 0.60417\n",
            "\n",
            "Epoch 15: accuracy did not improve from 0.60417\n",
            "\n",
            "Epoch 15: accuracy did not improve from 0.60417\n",
            " 82/121 [===================>..........] - ETA: 0s - loss: 3.1873 - accuracy: 0.5812\n",
            "Epoch 15: accuracy did not improve from 0.60417\n",
            "\n",
            "Epoch 15: accuracy did not improve from 0.60417\n",
            "\n",
            "Epoch 15: accuracy did not improve from 0.60417\n",
            " 97/121 [=======================>......] - ETA: 0s - loss: 3.2254 - accuracy: 0.5799\n",
            "Epoch 15: accuracy did not improve from 0.60417\n",
            "\n",
            "Epoch 15: accuracy did not improve from 0.60417\n",
            "\n",
            "Epoch 15: accuracy did not improve from 0.60417\n",
            "111/121 [==========================>...] - ETA: 0s - loss: 3.2494 - accuracy: 0.5760\n",
            "Epoch 15: accuracy did not improve from 0.60417\n",
            "\n",
            "Epoch 15: accuracy did not improve from 0.60417\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 3.2469 - accuracy: 0.5738\n",
            "Epoch 16/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.6708 - accuracy: 0.5938\n",
            "Epoch 16: accuracy did not improve from 0.60417\n",
            "\n",
            "Epoch 16: accuracy did not improve from 0.60417\n",
            "\n",
            "Epoch 16: accuracy did not improve from 0.60417\n",
            "\n",
            "Epoch 16: accuracy did not improve from 0.60417\n",
            " 20/121 [===>..........................] - ETA: 0s - loss: 3.3486 - accuracy: 0.5625\n",
            "Epoch 16: accuracy did not improve from 0.60417\n",
            "\n",
            "Epoch 16: accuracy did not improve from 0.60417\n",
            "\n",
            "Epoch 16: accuracy did not improve from 0.60417\n",
            " 39/121 [========>.....................] - ETA: 0s - loss: 3.2113 - accuracy: 0.5785\n",
            "Epoch 16: accuracy did not improve from 0.60417\n",
            "\n",
            "Epoch 16: accuracy did not improve from 0.60417\n",
            "\n",
            "Epoch 16: accuracy did not improve from 0.60417\n",
            " 54/121 [============>.................] - ETA: 0s - loss: 3.2342 - accuracy: 0.5804\n",
            "Epoch 16: accuracy did not improve from 0.60417\n",
            "\n",
            "Epoch 16: accuracy did not improve from 0.60417\n",
            "\n",
            "Epoch 16: accuracy did not improve from 0.60417\n",
            " 66/121 [===============>..............] - ETA: 0s - loss: 3.2109 - accuracy: 0.5838\n",
            "Epoch 16: accuracy did not improve from 0.60417\n",
            "\n",
            "Epoch 16: accuracy did not improve from 0.60417\n",
            "\n",
            "Epoch 16: accuracy did not improve from 0.60417\n",
            " 80/121 [==================>...........] - ETA: 0s - loss: 3.2090 - accuracy: 0.5805\n",
            "Epoch 16: accuracy did not improve from 0.60417\n",
            "\n",
            "Epoch 16: accuracy did not improve from 0.60417\n",
            "\n",
            "Epoch 16: accuracy did not improve from 0.60417\n",
            "\n",
            "Epoch 16: accuracy did not improve from 0.60417\n",
            "101/121 [========================>.....] - ETA: 0s - loss: 3.2329 - accuracy: 0.5792\n",
            "Epoch 16: accuracy did not improve from 0.60417\n",
            "\n",
            "Epoch 16: accuracy did not improve from 0.60417\n",
            "\n",
            "Epoch 16: accuracy did not improve from 0.60417\n",
            "115/121 [===========================>..] - ETA: 0s - loss: 3.2462 - accuracy: 0.5753\n",
            "Epoch 16: accuracy did not improve from 0.60417\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 3.2469 - accuracy: 0.5743\n",
            "Epoch 17/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.7672 - accuracy: 0.6562\n",
            "Epoch 17: accuracy did not improve from 0.60417\n",
            "\n",
            "Epoch 17: accuracy did not improve from 0.60417\n",
            "\n",
            "Epoch 17: accuracy did not improve from 0.60417\n",
            " 17/121 [===>..........................] - ETA: 0s - loss: 3.3872 - accuracy: 0.5680\n",
            "Epoch 17: accuracy did not improve from 0.60417\n",
            "\n",
            "Epoch 17: accuracy did not improve from 0.60417\n",
            "\n",
            "Epoch 17: accuracy did not improve from 0.60417\n",
            " 33/121 [=======>......................] - ETA: 0s - loss: 3.4979 - accuracy: 0.5492\n",
            "Epoch 17: accuracy did not improve from 0.60417\n",
            "\n",
            "Epoch 17: accuracy did not improve from 0.60417\n",
            "\n",
            "Epoch 17: accuracy did not improve from 0.60417\n",
            " 48/121 [==========>...................] - ETA: 0s - loss: 3.3721 - accuracy: 0.5716\n",
            "Epoch 17: accuracy did not improve from 0.60417\n",
            "\n",
            "Epoch 17: accuracy did not improve from 0.60417\n",
            "\n",
            "Epoch 17: accuracy did not improve from 0.60417\n",
            "\n",
            "Epoch 17: accuracy did not improve from 0.60417\n",
            " 65/121 [===============>..............] - ETA: 0s - loss: 3.3105 - accuracy: 0.5731\n",
            "Epoch 17: accuracy did not improve from 0.60417\n",
            "\n",
            "Epoch 17: accuracy did not improve from 0.60417\n",
            "\n",
            "Epoch 17: accuracy did not improve from 0.60417\n",
            " 82/121 [===================>..........] - ETA: 0s - loss: 3.2719 - accuracy: 0.5770\n",
            "Epoch 17: accuracy did not improve from 0.60417\n",
            "\n",
            "Epoch 17: accuracy did not improve from 0.60417\n",
            "\n",
            "Epoch 17: accuracy did not improve from 0.60417\n",
            "\n",
            "Epoch 17: accuracy did not improve from 0.60417\n",
            " 99/121 [=======================>......] - ETA: 0s - loss: 3.2609 - accuracy: 0.5761\n",
            "Epoch 17: accuracy did not improve from 0.60417\n",
            "\n",
            "Epoch 17: accuracy did not improve from 0.60417\n",
            "\n",
            "Epoch 17: accuracy did not improve from 0.60417\n",
            "116/121 [===========================>..] - ETA: 0s - loss: 3.2694 - accuracy: 0.5727\n",
            "Epoch 17: accuracy did not improve from 0.60417\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 3.2469 - accuracy: 0.5746\n",
            "Epoch 18/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.8680 - accuracy: 0.5312\n",
            "Epoch 18: accuracy did not improve from 0.60417\n",
            "\n",
            "Epoch 18: accuracy did not improve from 0.60417\n",
            "\n",
            "Epoch 18: accuracy did not improve from 0.60417\n",
            "\n",
            "Epoch 18: accuracy did not improve from 0.60417\n",
            " 19/121 [===>..........................] - ETA: 0s - loss: 3.4661 - accuracy: 0.5757\n",
            "Epoch 18: accuracy did not improve from 0.60417\n",
            "\n",
            "Epoch 18: accuracy did not improve from 0.60417\n",
            "\n",
            "Epoch 18: accuracy did not improve from 0.60417\n",
            " 36/121 [=======>......................] - ETA: 0s - loss: 3.3498 - accuracy: 0.5660\n",
            "Epoch 18: accuracy did not improve from 0.60417\n",
            "\n",
            "Epoch 18: accuracy did not improve from 0.60417\n",
            "\n",
            "Epoch 18: accuracy did not improve from 0.60417\n",
            "\n",
            "Epoch 18: accuracy did not improve from 0.60417\n",
            " 54/121 [============>.................] - ETA: 0s - loss: 3.2928 - accuracy: 0.5810\n",
            "Epoch 18: accuracy did not improve from 0.60417\n",
            "\n",
            "Epoch 18: accuracy did not improve from 0.60417\n",
            "\n",
            "Epoch 18: accuracy did not improve from 0.60417\n",
            "\n",
            "Epoch 18: accuracy did not improve from 0.60417\n",
            " 73/121 [=================>............] - ETA: 0s - loss: 3.3122 - accuracy: 0.5762\n",
            "Epoch 18: accuracy did not improve from 0.60417\n",
            "\n",
            "Epoch 18: accuracy did not improve from 0.60417\n",
            "\n",
            "Epoch 18: accuracy did not improve from 0.60417\n",
            " 91/121 [=====================>........] - ETA: 0s - loss: 3.3041 - accuracy: 0.5742\n",
            "Epoch 18: accuracy did not improve from 0.60417\n",
            "\n",
            "Epoch 18: accuracy did not improve from 0.60417\n",
            "\n",
            "Epoch 18: accuracy did not improve from 0.60417\n",
            "\n",
            "Epoch 18: accuracy did not improve from 0.60417\n",
            "\n",
            "Epoch 18: accuracy did not improve from 0.60417\n",
            "113/121 [===========================>..] - ETA: 0s - loss: 3.2555 - accuracy: 0.5788\n",
            "Epoch 18: accuracy did not improve from 0.60417\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 3.2469 - accuracy: 0.5746\n",
            "Epoch 19/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 3.2558 - accuracy: 0.5312\n",
            "Epoch 19: accuracy did not improve from 0.60417\n",
            "\n",
            "Epoch 19: accuracy did not improve from 0.60417\n",
            "\n",
            "Epoch 19: accuracy did not improve from 0.60417\n",
            "\n",
            "Epoch 19: accuracy did not improve from 0.60417\n",
            " 17/121 [===>..........................] - ETA: 0s - loss: 3.3656 - accuracy: 0.5662\n",
            "Epoch 19: accuracy did not improve from 0.60417\n",
            "\n",
            "Epoch 19: accuracy did not improve from 0.60417\n",
            "\n",
            "Epoch 19: accuracy did not improve from 0.60417\n",
            " 33/121 [=======>......................] - ETA: 0s - loss: 3.3584 - accuracy: 0.5739\n",
            "Epoch 19: accuracy did not improve from 0.60417\n",
            "\n",
            "Epoch 19: accuracy did not improve from 0.60417\n",
            "\n",
            "Epoch 19: accuracy did not improve from 0.60417\n",
            "\n",
            "Epoch 19: accuracy did not improve from 0.60417\n",
            " 52/121 [===========>..................] - ETA: 0s - loss: 3.3517 - accuracy: 0.5715\n",
            "Epoch 19: accuracy did not improve from 0.60417\n",
            "\n",
            "Epoch 19: accuracy did not improve from 0.60417\n",
            "\n",
            "Epoch 19: accuracy did not improve from 0.60417\n",
            "\n",
            "Epoch 19: accuracy did not improve from 0.60417\n",
            " 72/121 [================>.............] - ETA: 0s - loss: 3.3390 - accuracy: 0.5703\n",
            "Epoch 19: accuracy did not improve from 0.60417\n",
            "\n",
            "Epoch 19: accuracy did not improve from 0.60417\n",
            "\n",
            "Epoch 19: accuracy did not improve from 0.60417\n",
            " 89/121 [=====================>........] - ETA: 0s - loss: 3.2857 - accuracy: 0.5734\n",
            "Epoch 19: accuracy did not improve from 0.60417\n",
            "\n",
            "Epoch 19: accuracy did not improve from 0.60417\n",
            "100/121 [=======================>......] - ETA: 0s - loss: 3.2582 - accuracy: 0.5722\n",
            "Epoch 19: accuracy did not improve from 0.60417\n",
            "\n",
            "Epoch 19: accuracy did not improve from 0.60417\n",
            "\n",
            "Epoch 19: accuracy did not improve from 0.60417\n",
            "\n",
            "Epoch 19: accuracy did not improve from 0.60417\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 3.2469 - accuracy: 0.5748\n",
            "Epoch 20/100\n",
            "\n",
            "Epoch 20: accuracy improved from 0.60417 to 0.65625, saving model to best_model.hdf5\n",
            "  1/121 [..............................] - ETA: 2s - loss: 2.2984 - accuracy: 0.6562\n",
            "Epoch 20: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 20: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 20: accuracy did not improve from 0.65625\n",
            " 18/121 [===>..........................] - ETA: 0s - loss: 3.0144 - accuracy: 0.5972\n",
            "Epoch 20: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 20: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 20: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 20: accuracy did not improve from 0.65625\n",
            " 36/121 [=======>......................] - ETA: 0s - loss: 3.1925 - accuracy: 0.5729\n",
            "Epoch 20: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 20: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 20: accuracy did not improve from 0.65625\n",
            " 54/121 [============>.................] - ETA: 0s - loss: 3.2630 - accuracy: 0.5758\n",
            "Epoch 20: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 20: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 20: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 20: accuracy did not improve from 0.65625\n",
            " 73/121 [=================>............] - ETA: 0s - loss: 3.2568 - accuracy: 0.5736\n",
            "Epoch 20: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 20: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 20: accuracy did not improve from 0.65625\n",
            " 87/121 [====================>.........] - ETA: 0s - loss: 3.2508 - accuracy: 0.5715\n",
            "Epoch 20: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 20: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 20: accuracy did not improve from 0.65625\n",
            "104/121 [========================>.....] - ETA: 0s - loss: 3.2325 - accuracy: 0.5733\n",
            "Epoch 20: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 20: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 20: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 20: accuracy did not improve from 0.65625\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 3.2469 - accuracy: 0.5746\n",
            "Epoch 21/100\n",
            "  1/121 [..............................] - ETA: 1s - loss: 3.4432 - accuracy: 0.5625\n",
            "Epoch 21: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 21: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 21: accuracy did not improve from 0.65625\n",
            " 16/121 [==>...........................] - ETA: 0s - loss: 3.3903 - accuracy: 0.5566\n",
            "Epoch 21: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 21: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 21: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 21: accuracy did not improve from 0.65625\n",
            " 37/121 [========>.....................] - ETA: 0s - loss: 3.3281 - accuracy: 0.5617\n",
            "Epoch 21: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 21: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 21: accuracy did not improve from 0.65625\n",
            " 54/121 [============>.................] - ETA: 0s - loss: 3.3331 - accuracy: 0.5631\n",
            "Epoch 21: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 21: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 21: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 21: accuracy did not improve from 0.65625\n",
            " 70/121 [================>.............] - ETA: 0s - loss: 3.2927 - accuracy: 0.5683\n",
            "Epoch 21: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 21: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 21: accuracy did not improve from 0.65625\n",
            " 89/121 [=====================>........] - ETA: 0s - loss: 3.2308 - accuracy: 0.5713\n",
            "Epoch 21: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 21: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 21: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 21: accuracy did not improve from 0.65625\n",
            "105/121 [=========================>....] - ETA: 0s - loss: 3.2435 - accuracy: 0.5729\n",
            "Epoch 21: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 21: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 21: accuracy did not improve from 0.65625\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 3.2469 - accuracy: 0.5746\n",
            "Epoch 22/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.5788 - accuracy: 0.6250\n",
            "Epoch 22: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 22: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 22: accuracy did not improve from 0.65625\n",
            " 15/121 [==>...........................] - ETA: 0s - loss: 3.2327 - accuracy: 0.5729\n",
            "Epoch 22: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 22: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 22: accuracy did not improve from 0.65625\n",
            " 29/121 [======>.......................] - ETA: 0s - loss: 3.1741 - accuracy: 0.5797\n",
            "Epoch 22: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 22: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 22: accuracy did not improve from 0.65625\n",
            " 45/121 [==========>...................] - ETA: 0s - loss: 3.1772 - accuracy: 0.5785\n",
            "Epoch 22: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 22: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 22: accuracy did not improve from 0.65625\n",
            " 63/121 [==============>...............] - ETA: 0s - loss: 3.1759 - accuracy: 0.5764\n",
            "Epoch 22: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 22: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 22: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 22: accuracy did not improve from 0.65625\n",
            " 82/121 [===================>..........] - ETA: 0s - loss: 3.2464 - accuracy: 0.5686\n",
            "Epoch 22: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 22: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 22: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 22: accuracy did not improve from 0.65625\n",
            " 99/121 [=======================>......] - ETA: 0s - loss: 3.2399 - accuracy: 0.5717\n",
            "Epoch 22: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 22: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 22: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 22: accuracy did not improve from 0.65625\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 3.2469 - accuracy: 0.5748\n",
            "Epoch 23/100\n",
            "  1/121 [..............................] - ETA: 1s - loss: 3.4388 - accuracy: 0.4375\n",
            "Epoch 23: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 23: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 23: accuracy did not improve from 0.65625\n",
            " 16/121 [==>...........................] - ETA: 0s - loss: 3.4461 - accuracy: 0.5664\n",
            "Epoch 23: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 23: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 23: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 23: accuracy did not improve from 0.65625\n",
            " 33/121 [=======>......................] - ETA: 0s - loss: 3.3670 - accuracy: 0.5653\n",
            "Epoch 23: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 23: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 23: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 23: accuracy did not improve from 0.65625\n",
            " 56/121 [============>.................] - ETA: 0s - loss: 3.2998 - accuracy: 0.5681\n",
            "Epoch 23: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 23: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 23: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 23: accuracy did not improve from 0.65625\n",
            " 74/121 [=================>............] - ETA: 0s - loss: 3.2950 - accuracy: 0.5680\n",
            "Epoch 23: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 23: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 23: accuracy did not improve from 0.65625\n",
            " 92/121 [=====================>........] - ETA: 0s - loss: 3.2681 - accuracy: 0.5673\n",
            "Epoch 23: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 23: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 23: accuracy did not improve from 0.65625\n",
            "105/121 [=========================>....] - ETA: 0s - loss: 3.2516 - accuracy: 0.5753\n",
            "Epoch 23: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 23: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 23: accuracy did not improve from 0.65625\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 3.2469 - accuracy: 0.5748\n",
            "Epoch 24/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 3.7324 - accuracy: 0.5625\n",
            "Epoch 24: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 24: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 24: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 24: accuracy did not improve from 0.65625\n",
            " 17/121 [===>..........................] - ETA: 0s - loss: 3.0969 - accuracy: 0.5754\n",
            "Epoch 24: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 24: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 24: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 24: accuracy did not improve from 0.65625\n",
            " 37/121 [========>.....................] - ETA: 0s - loss: 3.0671 - accuracy: 0.5794\n",
            "Epoch 24: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 24: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 24: accuracy did not improve from 0.65625\n",
            " 53/121 [============>.................] - ETA: 0s - loss: 3.1886 - accuracy: 0.5725\n",
            "Epoch 24: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 24: accuracy did not improve from 0.65625\n",
            " 66/121 [===============>..............] - ETA: 0s - loss: 3.1972 - accuracy: 0.5729\n",
            "Epoch 24: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 24: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 24: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 24: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 24: accuracy did not improve from 0.65625\n",
            " 87/121 [====================>.........] - ETA: 0s - loss: 3.2227 - accuracy: 0.5783\n",
            "Epoch 24: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 24: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 24: accuracy did not improve from 0.65625\n",
            "104/121 [========================>.....] - ETA: 0s - loss: 3.2536 - accuracy: 0.5766\n",
            "Epoch 24: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 24: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 24: accuracy did not improve from 0.65625\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 3.2469 - accuracy: 0.5751\n",
            "Epoch 25/100\n",
            "\n",
            "Epoch 25: accuracy did not improve from 0.65625\n",
            "  1/121 [..............................] - ETA: 1s - loss: 2.5766 - accuracy: 0.6250\n",
            "Epoch 25: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 25: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 25: accuracy did not improve from 0.65625\n",
            " 19/121 [===>..........................] - ETA: 0s - loss: 3.0073 - accuracy: 0.5970\n",
            "Epoch 25: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 25: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 25: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 25: accuracy did not improve from 0.65625\n",
            " 37/121 [========>.....................] - ETA: 0s - loss: 3.1041 - accuracy: 0.5904\n",
            "Epoch 25: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 25: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 25: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 25: accuracy did not improve from 0.65625\n",
            " 56/121 [============>.................] - ETA: 0s - loss: 3.1774 - accuracy: 0.5848\n",
            "Epoch 25: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 25: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 25: accuracy did not improve from 0.65625\n",
            " 72/121 [================>.............] - ETA: 0s - loss: 3.2155 - accuracy: 0.5825\n",
            "Epoch 25: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 25: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 25: accuracy did not improve from 0.65625\n",
            " 89/121 [=====================>........] - ETA: 0s - loss: 3.2228 - accuracy: 0.5755\n",
            "Epoch 25: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 25: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 25: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 25: accuracy did not improve from 0.65625\n",
            "106/121 [=========================>....] - ETA: 0s - loss: 3.2502 - accuracy: 0.5775\n",
            "Epoch 25: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 25: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 25: accuracy did not improve from 0.65625\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 3.2469 - accuracy: 0.5751\n",
            "Epoch 26/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.3937 - accuracy: 0.6875\n",
            "Epoch 26: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 26: accuracy did not improve from 0.65625\n",
            " 14/121 [==>...........................] - ETA: 0s - loss: 3.2111 - accuracy: 0.5915\n",
            "Epoch 26: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 26: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 26: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 26: accuracy did not improve from 0.65625\n",
            " 32/121 [======>.......................] - ETA: 0s - loss: 3.1278 - accuracy: 0.5850\n",
            "Epoch 26: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 26: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 26: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 26: accuracy did not improve from 0.65625\n",
            " 53/121 [============>.................] - ETA: 0s - loss: 3.1756 - accuracy: 0.5825\n",
            "Epoch 26: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 26: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 26: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 26: accuracy did not improve from 0.65625\n",
            " 70/121 [================>.............] - ETA: 0s - loss: 3.2535 - accuracy: 0.5701\n",
            "Epoch 26: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 26: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 26: accuracy did not improve from 0.65625\n",
            " 88/121 [====================>.........] - ETA: 0s - loss: 3.2492 - accuracy: 0.5742\n",
            "Epoch 26: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 26: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 26: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 26: accuracy did not improve from 0.65625\n",
            "106/121 [=========================>....] - ETA: 0s - loss: 3.2164 - accuracy: 0.5755\n",
            "Epoch 26: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 26: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 26: accuracy did not improve from 0.65625\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 3.2469 - accuracy: 0.5751\n",
            "Epoch 27/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 3.1572 - accuracy: 0.6875\n",
            "Epoch 27: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 27: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 27: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 27: accuracy did not improve from 0.65625\n",
            " 19/121 [===>..........................] - ETA: 0s - loss: 3.4242 - accuracy: 0.5526\n",
            "Epoch 27: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 27: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 27: accuracy did not improve from 0.65625\n",
            " 38/121 [========>.....................] - ETA: 0s - loss: 3.2982 - accuracy: 0.5584\n",
            "Epoch 27: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 27: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 27: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 27: accuracy did not improve from 0.65625\n",
            " 56/121 [============>.................] - ETA: 0s - loss: 3.2956 - accuracy: 0.5636\n",
            "Epoch 27: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 27: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 27: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 27: accuracy did not improve from 0.65625\n",
            " 75/121 [=================>............] - ETA: 0s - loss: 3.2509 - accuracy: 0.5733\n",
            "Epoch 27: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 27: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 27: accuracy did not improve from 0.65625\n",
            " 91/121 [=====================>........] - ETA: 0s - loss: 3.2810 - accuracy: 0.5721\n",
            "Epoch 27: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 27: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 27: accuracy did not improve from 0.65625\n",
            "105/121 [=========================>....] - ETA: 0s - loss: 3.2536 - accuracy: 0.5753\n",
            "Epoch 27: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 27: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 27: accuracy did not improve from 0.65625\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 3.2469 - accuracy: 0.5751\n",
            "Epoch 28/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 3.1649 - accuracy: 0.5625\n",
            "Epoch 28: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 28: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 28: accuracy did not improve from 0.65625\n",
            " 17/121 [===>..........................] - ETA: 0s - loss: 3.2308 - accuracy: 0.5533\n",
            "Epoch 28: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 28: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 28: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 28: accuracy did not improve from 0.65625\n",
            " 35/121 [=======>......................] - ETA: 0s - loss: 3.2666 - accuracy: 0.5580\n",
            "Epoch 28: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 28: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 28: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 28: accuracy did not improve from 0.65625\n",
            " 53/121 [============>.................] - ETA: 0s - loss: 3.2676 - accuracy: 0.5660\n",
            "Epoch 28: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 28: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 28: accuracy did not improve from 0.65625\n",
            " 71/121 [================>.............] - ETA: 0s - loss: 3.2820 - accuracy: 0.5695\n",
            "Epoch 28: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 28: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 28: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 28: accuracy did not improve from 0.65625\n",
            " 88/121 [====================>.........] - ETA: 0s - loss: 3.2316 - accuracy: 0.5717\n",
            "Epoch 28: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 28: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 28: accuracy did not improve from 0.65625\n",
            "105/121 [=========================>....] - ETA: 0s - loss: 3.2334 - accuracy: 0.5735\n",
            "Epoch 28: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 28: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 28: accuracy did not improve from 0.65625\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 3.2469 - accuracy: 0.5751\n",
            "Epoch 29/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.6719 - accuracy: 0.5625\n",
            "Epoch 29: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 29: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 29: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 29: accuracy did not improve from 0.65625\n",
            " 17/121 [===>..........................] - ETA: 0s - loss: 3.2082 - accuracy: 0.5699\n",
            "Epoch 29: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 29: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 29: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 29: accuracy did not improve from 0.65625\n",
            " 37/121 [========>.....................] - ETA: 0s - loss: 3.2021 - accuracy: 0.5769\n",
            "Epoch 29: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 29: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 29: accuracy did not improve from 0.65625\n",
            " 56/121 [============>.................] - ETA: 0s - loss: 3.1890 - accuracy: 0.5848\n",
            "Epoch 29: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 29: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 29: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 29: accuracy did not improve from 0.65625\n",
            " 76/121 [=================>............] - ETA: 0s - loss: 3.2259 - accuracy: 0.5843\n",
            "Epoch 29: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 29: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 29: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 29: accuracy did not improve from 0.65625\n",
            " 96/121 [======================>.......] - ETA: 0s - loss: 3.2245 - accuracy: 0.5765\n",
            "Epoch 29: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 29: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 29: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 29: accuracy did not improve from 0.65625\n",
            "116/121 [===========================>..] - ETA: 0s - loss: 3.2569 - accuracy: 0.5741\n",
            "Epoch 29: accuracy did not improve from 0.65625\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 3.2469 - accuracy: 0.5748\n",
            "Epoch 30/100\n",
            "\n",
            "Epoch 30: accuracy improved from 0.65625 to 0.68750, saving model to best_model.hdf5\n",
            "  1/121 [..............................] - ETA: 2s - loss: 3.0674 - accuracy: 0.6875\n",
            "Epoch 30: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 30: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 30: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 30: accuracy did not improve from 0.68750\n",
            " 21/121 [====>.........................] - ETA: 0s - loss: 3.1401 - accuracy: 0.5952\n",
            "Epoch 30: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 30: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 30: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 30: accuracy did not improve from 0.68750\n",
            " 42/121 [=========>....................] - ETA: 0s - loss: 3.2172 - accuracy: 0.5841\n",
            "Epoch 30: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 30: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 30: accuracy did not improve from 0.68750\n",
            " 57/121 [=============>................] - ETA: 0s - loss: 3.2253 - accuracy: 0.5833\n",
            "Epoch 30: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 30: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 30: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 30: accuracy did not improve from 0.68750\n",
            " 77/121 [==================>...........] - ETA: 0s - loss: 3.2224 - accuracy: 0.5747\n",
            "Epoch 30: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 30: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 30: accuracy did not improve from 0.68750\n",
            " 92/121 [=====================>........] - ETA: 0s - loss: 3.2370 - accuracy: 0.5774\n",
            "Epoch 30: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 30: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 30: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 30: accuracy did not improve from 0.68750\n",
            "111/121 [==========================>...] - ETA: 0s - loss: 3.2418 - accuracy: 0.5766\n",
            "Epoch 30: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 30: accuracy did not improve from 0.68750\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 3.2469 - accuracy: 0.5754\n",
            "Epoch 31/100\n",
            "  1/121 [..............................] - ETA: 1s - loss: 2.8746 - accuracy: 0.6875\n",
            "Epoch 31: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 31: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 31: accuracy did not improve from 0.68750\n",
            " 16/121 [==>...........................] - ETA: 0s - loss: 3.2738 - accuracy: 0.5938\n",
            "Epoch 31: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 31: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 31: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 31: accuracy did not improve from 0.68750\n",
            " 35/121 [=======>......................] - ETA: 0s - loss: 3.2239 - accuracy: 0.5821\n",
            "Epoch 31: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 31: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 31: accuracy did not improve from 0.68750\n",
            " 50/121 [===========>..................] - ETA: 0s - loss: 3.1989 - accuracy: 0.5869\n",
            "Epoch 31: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 31: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 31: accuracy did not improve from 0.68750\n",
            " 69/121 [================>.............] - ETA: 0s - loss: 3.2472 - accuracy: 0.5802\n",
            "Epoch 31: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 31: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 31: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 31: accuracy did not improve from 0.68750\n",
            " 86/121 [====================>.........] - ETA: 0s - loss: 3.2430 - accuracy: 0.5799\n",
            "Epoch 31: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 31: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 31: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 31: accuracy did not improve from 0.68750\n",
            "106/121 [=========================>....] - ETA: 0s - loss: 3.2429 - accuracy: 0.5764\n",
            "Epoch 31: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 31: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 31: accuracy did not improve from 0.68750\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 3.2469 - accuracy: 0.5754\n",
            "Epoch 32/100\n",
            "  1/121 [..............................] - ETA: 1s - loss: 3.5363 - accuracy: 0.4062\n",
            "Epoch 32: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 32: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 32: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 32: accuracy did not improve from 0.68750\n",
            " 19/121 [===>..........................] - ETA: 0s - loss: 3.2792 - accuracy: 0.5724\n",
            "Epoch 32: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 32: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 32: accuracy did not improve from 0.68750\n",
            " 36/121 [=======>......................] - ETA: 0s - loss: 3.2086 - accuracy: 0.5686\n",
            "Epoch 32: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 32: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 32: accuracy did not improve from 0.68750\n",
            " 49/121 [===========>..................] - ETA: 0s - loss: 3.2580 - accuracy: 0.5727\n",
            "Epoch 32: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 32: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 32: accuracy did not improve from 0.68750\n",
            " 68/121 [===============>..............] - ETA: 0s - loss: 3.2299 - accuracy: 0.5790\n",
            "Epoch 32: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 32: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 32: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 32: accuracy did not improve from 0.68750\n",
            " 86/121 [====================>.........] - ETA: 0s - loss: 3.2672 - accuracy: 0.5741\n",
            "Epoch 32: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 32: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 32: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 32: accuracy did not improve from 0.68750\n",
            "104/121 [========================>.....] - ETA: 0s - loss: 3.2527 - accuracy: 0.5754\n",
            "Epoch 32: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 32: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 32: accuracy did not improve from 0.68750\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 3.2469 - accuracy: 0.5754\n",
            "Epoch 33/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.3838 - accuracy: 0.6875\n",
            "Epoch 33: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 33: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 33: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 33: accuracy did not improve from 0.68750\n",
            " 18/121 [===>..........................] - ETA: 0s - loss: 3.1359 - accuracy: 0.5747\n",
            "Epoch 33: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 33: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 33: accuracy did not improve from 0.68750\n",
            " 37/121 [========>.....................] - ETA: 0s - loss: 3.1762 - accuracy: 0.5887\n",
            "Epoch 33: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 33: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 33: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 33: accuracy did not improve from 0.68750\n",
            " 54/121 [============>.................] - ETA: 0s - loss: 3.1995 - accuracy: 0.5874\n",
            "Epoch 33: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 33: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 33: accuracy did not improve from 0.68750\n",
            " 71/121 [================>.............] - ETA: 0s - loss: 3.1985 - accuracy: 0.5775\n",
            "Epoch 33: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 33: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 33: accuracy did not improve from 0.68750\n",
            " 87/121 [====================>.........] - ETA: 0s - loss: 3.2078 - accuracy: 0.5826\n",
            "Epoch 33: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 33: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 33: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 33: accuracy did not improve from 0.68750\n",
            "104/121 [========================>.....] - ETA: 0s - loss: 3.2465 - accuracy: 0.5751\n",
            "Epoch 33: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 33: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 33: accuracy did not improve from 0.68750\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 3.2469 - accuracy: 0.5754\n",
            "Epoch 34/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 3.7269 - accuracy: 0.4688\n",
            "Epoch 34: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 34: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 34: accuracy did not improve from 0.68750\n",
            " 16/121 [==>...........................] - ETA: 0s - loss: 3.1934 - accuracy: 0.6074\n",
            "Epoch 34: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 34: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 34: accuracy did not improve from 0.68750\n",
            " 31/121 [======>.......................] - ETA: 0s - loss: 3.1821 - accuracy: 0.5907\n",
            "Epoch 34: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 34: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 34: accuracy did not improve from 0.68750\n",
            " 46/121 [==========>...................] - ETA: 0s - loss: 3.1846 - accuracy: 0.5836\n",
            "Epoch 34: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 34: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 34: accuracy did not improve from 0.68750\n",
            " 59/121 [=============>................] - ETA: 0s - loss: 3.2468 - accuracy: 0.5768\n",
            "Epoch 34: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 34: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 34: accuracy did not improve from 0.68750\n",
            " 73/121 [=================>............] - ETA: 0s - loss: 3.2598 - accuracy: 0.5758\n",
            "Epoch 34: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 34: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 34: accuracy did not improve from 0.68750\n",
            " 90/121 [=====================>........] - ETA: 0s - loss: 3.2388 - accuracy: 0.5757\n",
            "Epoch 34: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 34: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 34: accuracy did not improve from 0.68750\n",
            "103/121 [========================>.....] - ETA: 0s - loss: 3.2743 - accuracy: 0.5731\n",
            "Epoch 34: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 34: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 34: accuracy did not improve from 0.68750\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 3.2469 - accuracy: 0.5754\n",
            "Epoch 35/100\n",
            "\n",
            "Epoch 35: accuracy did not improve from 0.68750\n",
            "  1/121 [..............................] - ETA: 1s - loss: 2.1954 - accuracy: 0.6875\n",
            "Epoch 35: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 35: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 35: accuracy did not improve from 0.68750\n",
            " 20/121 [===>..........................] - ETA: 0s - loss: 3.1508 - accuracy: 0.5719\n",
            "Epoch 35: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 35: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 35: accuracy did not improve from 0.68750\n",
            " 35/121 [=======>......................] - ETA: 0s - loss: 3.2133 - accuracy: 0.5705\n",
            "Epoch 35: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 35: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 35: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 35: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 35: accuracy did not improve from 0.68750\n",
            " 56/121 [============>.................] - ETA: 0s - loss: 3.2114 - accuracy: 0.5748\n",
            "Epoch 35: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 35: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 35: accuracy did not improve from 0.68750\n",
            " 74/121 [=================>............] - ETA: 0s - loss: 3.2554 - accuracy: 0.5743\n",
            "Epoch 35: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 35: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 35: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 35: accuracy did not improve from 0.68750\n",
            " 93/121 [======================>.......] - ETA: 0s - loss: 3.1699 - accuracy: 0.5780\n",
            "Epoch 35: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 35: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 35: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 35: accuracy did not improve from 0.68750\n",
            "112/121 [==========================>...] - ETA: 0s - loss: 3.2314 - accuracy: 0.5745\n",
            "Epoch 35: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 35: accuracy did not improve from 0.68750\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 3.2469 - accuracy: 0.5754\n",
            "Epoch 36/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 3.3511 - accuracy: 0.4062\n",
            "Epoch 36: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 36: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 36: accuracy did not improve from 0.68750\n",
            " 18/121 [===>..........................] - ETA: 0s - loss: 3.3750 - accuracy: 0.5156\n",
            "Epoch 36: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 36: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 36: accuracy did not improve from 0.68750\n",
            " 32/121 [======>.......................] - ETA: 0s - loss: 3.3161 - accuracy: 0.5459\n",
            "Epoch 36: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 36: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 36: accuracy did not improve from 0.68750\n",
            " 48/121 [==========>...................] - ETA: 0s - loss: 3.2609 - accuracy: 0.5534\n",
            "Epoch 36: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 36: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 36: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 36: accuracy did not improve from 0.68750\n",
            " 65/121 [===============>..............] - ETA: 0s - loss: 3.2427 - accuracy: 0.5611\n",
            "Epoch 36: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 36: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 36: accuracy did not improve from 0.68750\n",
            " 82/121 [===================>..........] - ETA: 0s - loss: 3.2465 - accuracy: 0.5682\n",
            "Epoch 36: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 36: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 36: accuracy did not improve from 0.68750\n",
            " 98/121 [=======================>......] - ETA: 0s - loss: 3.2633 - accuracy: 0.5702\n",
            "Epoch 36: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 36: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 36: accuracy did not improve from 0.68750\n",
            "113/121 [===========================>..] - ETA: 0s - loss: 3.2392 - accuracy: 0.5752\n",
            "Epoch 36: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 36: accuracy did not improve from 0.68750\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 3.2469 - accuracy: 0.5754\n",
            "Epoch 37/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 3.8354 - accuracy: 0.5625\n",
            "Epoch 37: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 37: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 37: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 37: accuracy did not improve from 0.68750\n",
            " 21/121 [====>.........................] - ETA: 0s - loss: 3.3125 - accuracy: 0.5283\n",
            "Epoch 37: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 37: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 37: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 37: accuracy did not improve from 0.68750\n",
            " 40/121 [========>.....................] - ETA: 0s - loss: 3.3344 - accuracy: 0.5578\n",
            "Epoch 37: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 37: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 37: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 37: accuracy did not improve from 0.68750\n",
            " 59/121 [=============>................] - ETA: 0s - loss: 3.2972 - accuracy: 0.5588\n",
            "Epoch 37: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 37: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 37: accuracy did not improve from 0.68750\n",
            " 78/121 [==================>...........] - ETA: 0s - loss: 3.2439 - accuracy: 0.5665\n",
            "Epoch 37: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 37: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 37: accuracy did not improve from 0.68750\n",
            " 93/121 [======================>.......] - ETA: 0s - loss: 3.2709 - accuracy: 0.5706\n",
            "Epoch 37: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 37: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 37: accuracy did not improve from 0.68750\n",
            "106/121 [=========================>....] - ETA: 0s - loss: 3.2373 - accuracy: 0.5749\n",
            "Epoch 37: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 37: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 37: accuracy did not improve from 0.68750\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 3.2469 - accuracy: 0.5754\n",
            "Epoch 38/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.8647 - accuracy: 0.7188\n",
            "Epoch 38: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 38: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 38: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 38: accuracy did not improve from 0.68750\n",
            " 21/121 [====>.........................] - ETA: 0s - loss: 3.3360 - accuracy: 0.5283\n",
            "Epoch 38: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 38: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 38: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 38: accuracy did not improve from 0.68750\n",
            " 40/121 [========>.....................] - ETA: 0s - loss: 3.3037 - accuracy: 0.5492\n",
            "Epoch 38: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 38: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 38: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 38: accuracy did not improve from 0.68750\n",
            " 58/121 [=============>................] - ETA: 0s - loss: 3.3645 - accuracy: 0.5609\n",
            "Epoch 38: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 38: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 38: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 38: accuracy did not improve from 0.68750\n",
            " 78/121 [==================>...........] - ETA: 0s - loss: 3.3202 - accuracy: 0.5673\n",
            "Epoch 38: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 38: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 38: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 38: accuracy did not improve from 0.68750\n",
            " 98/121 [=======================>......] - ETA: 0s - loss: 3.2538 - accuracy: 0.5721\n",
            "Epoch 38: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 38: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 38: accuracy did not improve from 0.68750\n",
            "116/121 [===========================>..] - ETA: 0s - loss: 3.2404 - accuracy: 0.5749\n",
            "Epoch 38: accuracy did not improve from 0.68750\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 3.2469 - accuracy: 0.5754\n",
            "Epoch 39/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 3.2514 - accuracy: 0.5938\n",
            "Epoch 39: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 39: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 39: accuracy did not improve from 0.68750\n",
            " 15/121 [==>...........................] - ETA: 0s - loss: 3.1071 - accuracy: 0.5771\n",
            "Epoch 39: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 39: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 39: accuracy did not improve from 0.68750\n",
            " 27/121 [=====>........................] - ETA: 0s - loss: 3.2857 - accuracy: 0.5613\n",
            "Epoch 39: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 39: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 39: accuracy did not improve from 0.68750\n",
            " 44/121 [=========>....................] - ETA: 0s - loss: 3.1816 - accuracy: 0.5646\n",
            "Epoch 39: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 39: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 39: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 39: accuracy did not improve from 0.68750\n",
            " 62/121 [==============>...............] - ETA: 0s - loss: 3.2442 - accuracy: 0.5711\n",
            "Epoch 39: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 39: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 39: accuracy did not improve from 0.68750\n",
            " 80/121 [==================>...........] - ETA: 0s - loss: 3.2346 - accuracy: 0.5738\n",
            "Epoch 39: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 39: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 39: accuracy did not improve from 0.68750\n",
            " 93/121 [======================>.......] - ETA: 0s - loss: 3.2516 - accuracy: 0.5759\n",
            "Epoch 39: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 39: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 39: accuracy did not improve from 0.68750\n",
            "111/121 [==========================>...] - ETA: 0s - loss: 3.2408 - accuracy: 0.5791\n",
            "Epoch 39: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 39: accuracy did not improve from 0.68750\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 3.2469 - accuracy: 0.5754\n",
            "Epoch 40/100\n",
            "\n",
            "Epoch 40: accuracy did not improve from 0.68750\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.4846 - accuracy: 0.6562\n",
            "Epoch 40: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 40: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 40: accuracy did not improve from 0.68750\n",
            " 18/121 [===>..........................] - ETA: 0s - loss: 3.1105 - accuracy: 0.5556\n",
            "Epoch 40: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 40: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 40: accuracy did not improve from 0.68750\n",
            " 35/121 [=======>......................] - ETA: 0s - loss: 3.1944 - accuracy: 0.5634\n",
            "Epoch 40: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 40: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 40: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 40: accuracy did not improve from 0.68750\n",
            " 51/121 [===========>..................] - ETA: 0s - loss: 3.2315 - accuracy: 0.5650\n",
            "Epoch 40: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 40: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 40: accuracy did not improve from 0.68750\n",
            " 66/121 [===============>..............] - ETA: 0s - loss: 3.1866 - accuracy: 0.5705\n",
            "Epoch 40: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 40: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 40: accuracy did not improve from 0.68750\n",
            " 81/121 [===================>..........] - ETA: 0s - loss: 3.2336 - accuracy: 0.5718\n",
            "Epoch 40: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 40: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 40: accuracy did not improve from 0.68750\n",
            "100/121 [=======================>......] - ETA: 0s - loss: 3.2461 - accuracy: 0.5728\n",
            "Epoch 40: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 40: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 40: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 40: accuracy did not improve from 0.68750\n",
            "118/121 [============================>.] - ETA: 0s - loss: 3.2454 - accuracy: 0.5749\n",
            "Epoch 40: accuracy did not improve from 0.68750\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 3.2469 - accuracy: 0.5754\n",
            "Epoch 41/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 3.2482 - accuracy: 0.6562\n",
            "Epoch 41: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 41: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 41: accuracy did not improve from 0.68750\n",
            " 17/121 [===>..........................] - ETA: 0s - loss: 3.5913 - accuracy: 0.5460\n",
            "Epoch 41: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 41: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 41: accuracy did not improve from 0.68750\n",
            " 31/121 [======>.......................] - ETA: 0s - loss: 3.3745 - accuracy: 0.5746\n",
            "Epoch 41: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 41: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 41: accuracy did not improve from 0.68750\n",
            " 46/121 [==========>...................] - ETA: 0s - loss: 3.2559 - accuracy: 0.5863\n",
            "Epoch 41: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 41: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 41: accuracy did not improve from 0.68750\n",
            " 62/121 [==============>...............] - ETA: 0s - loss: 3.3199 - accuracy: 0.5741\n",
            "Epoch 41: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 41: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 41: accuracy did not improve from 0.68750\n",
            " 79/121 [==================>...........] - ETA: 0s - loss: 3.2729 - accuracy: 0.5811\n",
            "Epoch 41: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 41: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 41: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 41: accuracy did not improve from 0.68750\n",
            " 95/121 [======================>.......] - ETA: 0s - loss: 3.2604 - accuracy: 0.5770\n",
            "Epoch 41: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 41: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 41: accuracy did not improve from 0.68750\n",
            "113/121 [===========================>..] - ETA: 0s - loss: 3.2510 - accuracy: 0.5752\n",
            "Epoch 41: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 41: accuracy did not improve from 0.68750\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 3.2469 - accuracy: 0.5754\n",
            "Epoch 42/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.9754 - accuracy: 0.6562\n",
            "Epoch 42: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 42: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 42: accuracy did not improve from 0.68750\n",
            " 18/121 [===>..........................] - ETA: 0s - loss: 3.3398 - accuracy: 0.5642\n",
            "Epoch 42: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 42: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 42: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 42: accuracy did not improve from 0.68750\n",
            " 35/121 [=======>......................] - ETA: 0s - loss: 3.2380 - accuracy: 0.5562\n",
            "Epoch 42: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 42: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 42: accuracy did not improve from 0.68750\n",
            " 53/121 [============>.................] - ETA: 0s - loss: 3.2356 - accuracy: 0.5560\n",
            "Epoch 42: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 42: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 42: accuracy did not improve from 0.68750\n",
            " 66/121 [===============>..............] - ETA: 0s - loss: 3.2406 - accuracy: 0.5649\n",
            "Epoch 42: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 42: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 42: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 42: accuracy did not improve from 0.68750\n",
            " 84/121 [===================>..........] - ETA: 0s - loss: 3.2676 - accuracy: 0.5673\n",
            "Epoch 42: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 42: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 42: accuracy did not improve from 0.68750\n",
            "100/121 [=======================>......] - ETA: 0s - loss: 3.2221 - accuracy: 0.5731\n",
            "Epoch 42: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 42: accuracy did not improve from 0.68750\n",
            "113/121 [===========================>..] - ETA: 0s - loss: 3.2369 - accuracy: 0.5766\n",
            "Epoch 42: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 42: accuracy did not improve from 0.68750\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 3.2469 - accuracy: 0.5754\n",
            "Epoch 43/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 3.1561 - accuracy: 0.5938\n",
            "Epoch 43: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 43: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 43: accuracy did not improve from 0.68750\n",
            " 15/121 [==>...........................] - ETA: 0s - loss: 3.2595 - accuracy: 0.5938\n",
            "Epoch 43: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 43: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 43: accuracy did not improve from 0.68750\n",
            " 31/121 [======>.......................] - ETA: 0s - loss: 3.1909 - accuracy: 0.5907\n",
            "Epoch 43: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 43: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 43: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 43: accuracy did not improve from 0.68750\n",
            " 48/121 [==========>...................] - ETA: 0s - loss: 3.2471 - accuracy: 0.5775\n",
            "Epoch 43: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 43: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 43: accuracy did not improve from 0.68750\n",
            " 63/121 [==============>...............] - ETA: 0s - loss: 3.2487 - accuracy: 0.5704\n",
            "Epoch 43: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 43: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 43: accuracy did not improve from 0.68750\n",
            " 82/121 [===================>..........] - ETA: 0s - loss: 3.2630 - accuracy: 0.5755\n",
            "Epoch 43: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 43: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 43: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 43: accuracy did not improve from 0.68750\n",
            " 99/121 [=======================>......] - ETA: 0s - loss: 3.2605 - accuracy: 0.5758\n",
            "Epoch 43: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 43: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 43: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 43: accuracy did not improve from 0.68750\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 3.2469 - accuracy: 0.5754\n",
            "Epoch 44/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.9611 - accuracy: 0.5938\n",
            "Epoch 44: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 44: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 44: accuracy did not improve from 0.68750\n",
            " 14/121 [==>...........................] - ETA: 0s - loss: 3.2180 - accuracy: 0.5826\n",
            "Epoch 44: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 44: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 44: accuracy did not improve from 0.68750\n",
            " 27/121 [=====>........................] - ETA: 0s - loss: 3.1927 - accuracy: 0.5891\n",
            "Epoch 44: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 44: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 44: accuracy did not improve from 0.68750\n",
            " 45/121 [==========>...................] - ETA: 0s - loss: 3.2020 - accuracy: 0.5875\n",
            "Epoch 44: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 44: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 44: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 44: accuracy did not improve from 0.68750\n",
            " 62/121 [==============>...............] - ETA: 0s - loss: 3.2336 - accuracy: 0.5832\n",
            "Epoch 44: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 44: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 44: accuracy did not improve from 0.68750\n",
            " 78/121 [==================>...........] - ETA: 0s - loss: 3.2560 - accuracy: 0.5789\n",
            "Epoch 44: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 44: accuracy did not improve from 0.68750\n",
            " 90/121 [=====================>........] - ETA: 0s - loss: 3.2483 - accuracy: 0.5813\n",
            "Epoch 44: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 44: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 44: accuracy did not improve from 0.68750\n",
            "106/121 [=========================>....] - ETA: 0s - loss: 3.2426 - accuracy: 0.5767\n",
            "Epoch 44: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 44: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 44: accuracy did not improve from 0.68750\n",
            "121/121 [==============================] - 0s 4ms/step - loss: 3.2469 - accuracy: 0.5754\n",
            "Epoch 45/100\n",
            "\n",
            "Epoch 45: accuracy did not improve from 0.68750\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.8669 - accuracy: 0.5000\n",
            "Epoch 45: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 45: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 45: accuracy did not improve from 0.68750\n",
            " 17/121 [===>..........................] - ETA: 0s - loss: 2.9728 - accuracy: 0.5956\n",
            "Epoch 45: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 45: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 45: accuracy did not improve from 0.68750\n",
            " 31/121 [======>.......................] - ETA: 0s - loss: 3.1710 - accuracy: 0.5806\n",
            "Epoch 45: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 45: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 45: accuracy did not improve from 0.68750\n",
            " 47/121 [==========>...................] - ETA: 0s - loss: 3.2618 - accuracy: 0.5705\n",
            "Epoch 45: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 45: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 45: accuracy did not improve from 0.68750\n",
            " 64/121 [==============>...............] - ETA: 0s - loss: 3.2562 - accuracy: 0.5801\n",
            "Epoch 45: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 45: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 45: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 45: accuracy did not improve from 0.68750\n",
            " 83/121 [===================>..........] - ETA: 0s - loss: 3.2359 - accuracy: 0.5791\n",
            "Epoch 45: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 45: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 45: accuracy did not improve from 0.68750\n",
            "100/121 [=======================>......] - ETA: 0s - loss: 3.2678 - accuracy: 0.5713\n",
            "Epoch 45: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 45: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 45: accuracy did not improve from 0.68750\n",
            "112/121 [==========================>...] - ETA: 0s - loss: 3.2681 - accuracy: 0.5709\n",
            "Epoch 45: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 45: accuracy did not improve from 0.68750\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 3.2469 - accuracy: 0.5754\n",
            "Epoch 46/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.2075 - accuracy: 0.6875\n",
            "Epoch 46: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 46: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 46: accuracy did not improve from 0.68750\n",
            " 18/121 [===>..........................] - ETA: 0s - loss: 2.9781 - accuracy: 0.5903\n",
            "Epoch 46: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 46: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 46: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 46: accuracy did not improve from 0.68750\n",
            " 36/121 [=======>......................] - ETA: 0s - loss: 3.0768 - accuracy: 0.5833\n",
            "Epoch 46: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 46: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 46: accuracy did not improve from 0.68750\n",
            " 53/121 [============>.................] - ETA: 0s - loss: 3.1695 - accuracy: 0.5790\n",
            "Epoch 46: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 46: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 46: accuracy did not improve from 0.68750\n",
            " 66/121 [===============>..............] - ETA: 0s - loss: 3.1747 - accuracy: 0.5810\n",
            "Epoch 46: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 46: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 46: accuracy did not improve from 0.68750\n",
            " 80/121 [==================>...........] - ETA: 0s - loss: 3.2099 - accuracy: 0.5758\n",
            "Epoch 46: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 46: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 46: accuracy did not improve from 0.68750\n",
            " 99/121 [=======================>......] - ETA: 0s - loss: 3.2462 - accuracy: 0.5742\n",
            "Epoch 46: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 46: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 46: accuracy did not improve from 0.68750\n",
            "114/121 [===========================>..] - ETA: 0s - loss: 3.2418 - accuracy: 0.5759\n",
            "Epoch 46: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 46: accuracy did not improve from 0.68750\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 3.2469 - accuracy: 0.5754\n",
            "Epoch 47/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.6697 - accuracy: 0.5625\n",
            "Epoch 47: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 47: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 47: accuracy did not improve from 0.68750\n",
            " 14/121 [==>...........................] - ETA: 0s - loss: 3.4868 - accuracy: 0.5357\n",
            "Epoch 47: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 47: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 47: accuracy did not improve from 0.68750\n",
            " 29/121 [======>.......................] - ETA: 0s - loss: 3.4418 - accuracy: 0.5420\n",
            "Epoch 47: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 47: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 47: accuracy did not improve from 0.68750\n",
            " 44/121 [=========>....................] - ETA: 0s - loss: 3.3629 - accuracy: 0.5604\n",
            "Epoch 47: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 47: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 47: accuracy did not improve from 0.68750\n",
            " 59/121 [=============>................] - ETA: 0s - loss: 3.3232 - accuracy: 0.5673\n",
            "Epoch 47: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 47: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 47: accuracy did not improve from 0.68750\n",
            " 75/121 [=================>............] - ETA: 0s - loss: 3.2585 - accuracy: 0.5750\n",
            "Epoch 47: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 47: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 47: accuracy did not improve from 0.68750\n",
            " 90/121 [=====================>........] - ETA: 0s - loss: 3.2569 - accuracy: 0.5788\n",
            "Epoch 47: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 47: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 47: accuracy did not improve from 0.68750\n",
            "106/121 [=========================>....] - ETA: 0s - loss: 3.2563 - accuracy: 0.5749\n",
            "Epoch 47: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 47: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 47: accuracy did not improve from 0.68750\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 3.2469 - accuracy: 0.5754\n",
            "Epoch 48/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.5777 - accuracy: 0.6250\n",
            "Epoch 48: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 48: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 48: accuracy did not improve from 0.68750\n",
            " 16/121 [==>...........................] - ETA: 0s - loss: 3.1870 - accuracy: 0.6113\n",
            "Epoch 48: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 48: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 48: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 48: accuracy did not improve from 0.68750\n",
            " 33/121 [=======>......................] - ETA: 0s - loss: 3.1719 - accuracy: 0.5843\n",
            "Epoch 48: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 48: accuracy did not improve from 0.68750\n",
            " 47/121 [==========>...................] - ETA: 0s - loss: 3.1613 - accuracy: 0.5864\n",
            "Epoch 48: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 48: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 48: accuracy did not improve from 0.68750\n",
            " 61/121 [==============>...............] - ETA: 0s - loss: 3.1478 - accuracy: 0.5835\n",
            "Epoch 48: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 48: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 48: accuracy did not improve from 0.68750\n",
            " 77/121 [==================>...........] - ETA: 0s - loss: 3.1997 - accuracy: 0.5804\n",
            "Epoch 48: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 48: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 48: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 48: accuracy did not improve from 0.68750\n",
            " 93/121 [======================>.......] - ETA: 0s - loss: 3.1895 - accuracy: 0.5830\n",
            "Epoch 48: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 48: accuracy did not improve from 0.68750\n",
            "105/121 [=========================>....] - ETA: 0s - loss: 3.2546 - accuracy: 0.5792\n",
            "Epoch 48: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 48: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 48: accuracy did not improve from 0.68750\n",
            "121/121 [==============================] - 0s 4ms/step - loss: 3.2469 - accuracy: 0.5754\n",
            "Epoch 49/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 3.5396 - accuracy: 0.5312\n",
            "Epoch 49: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 49: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 49: accuracy did not improve from 0.68750\n",
            " 16/121 [==>...........................] - ETA: 0s - loss: 3.2176 - accuracy: 0.5664\n",
            "Epoch 49: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 49: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 49: accuracy did not improve from 0.68750\n",
            " 30/121 [======>.......................] - ETA: 0s - loss: 3.3175 - accuracy: 0.5646\n",
            "Epoch 49: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 49: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 49: accuracy did not improve from 0.68750\n",
            " 46/121 [==========>...................] - ETA: 0s - loss: 3.2492 - accuracy: 0.5740\n",
            "Epoch 49: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 49: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 49: accuracy did not improve from 0.68750\n",
            " 61/121 [==============>...............] - ETA: 0s - loss: 3.2406 - accuracy: 0.5733\n",
            "Epoch 49: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 49: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 49: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 49: accuracy did not improve from 0.68750\n",
            " 77/121 [==================>...........] - ETA: 0s - loss: 3.2782 - accuracy: 0.5743\n",
            "Epoch 49: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 49: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 49: accuracy did not improve from 0.68750\n",
            " 92/121 [=====================>........] - ETA: 0s - loss: 3.2681 - accuracy: 0.5724\n",
            "Epoch 49: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 49: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 49: accuracy did not improve from 0.68750\n",
            "108/121 [=========================>....] - ETA: 0s - loss: 3.2695 - accuracy: 0.5735\n",
            "Epoch 49: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 49: accuracy did not improve from 0.68750\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 3.2469 - accuracy: 0.5754\n",
            "Epoch 50/100\n",
            "\n",
            "Epoch 50: accuracy did not improve from 0.68750\n",
            "  1/121 [..............................] - ETA: 1s - loss: 2.3893 - accuracy: 0.6562\n",
            "Epoch 50: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 50: accuracy did not improve from 0.68750\n",
            " 15/121 [==>...........................] - ETA: 0s - loss: 3.1133 - accuracy: 0.5604\n",
            "Epoch 50: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 50: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 50: accuracy did not improve from 0.68750\n",
            " 30/121 [======>.......................] - ETA: 0s - loss: 3.3085 - accuracy: 0.5677\n",
            "Epoch 50: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 50: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 50: accuracy did not improve from 0.68750\n",
            " 44/121 [=========>....................] - ETA: 0s - loss: 3.3061 - accuracy: 0.5611\n",
            "Epoch 50: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 50: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 50: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 50: accuracy did not improve from 0.68750\n",
            " 62/121 [==============>...............] - ETA: 0s - loss: 3.2632 - accuracy: 0.5691\n",
            "Epoch 50: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 50: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 50: accuracy did not improve from 0.68750\n",
            " 79/121 [==================>...........] - ETA: 0s - loss: 3.2171 - accuracy: 0.5763\n",
            "Epoch 50: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 50: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 50: accuracy did not improve from 0.68750\n",
            " 92/121 [=====================>........] - ETA: 0s - loss: 3.2213 - accuracy: 0.5778\n",
            "Epoch 50: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 50: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 50: accuracy did not improve from 0.68750\n",
            "106/121 [=========================>....] - ETA: 0s - loss: 3.2228 - accuracy: 0.5784\n",
            "Epoch 50: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 50: accuracy did not improve from 0.68750\n",
            "120/121 [============================>.] - ETA: 0s - loss: 3.2449 - accuracy: 0.5753\n",
            "Epoch 50: accuracy did not improve from 0.68750\n",
            "121/121 [==============================] - 0s 4ms/step - loss: 3.2469 - accuracy: 0.5754\n",
            "Epoch 51/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 4.2012 - accuracy: 0.5938\n",
            "Epoch 51: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 51: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 51: accuracy did not improve from 0.68750\n",
            " 17/121 [===>..........................] - ETA: 0s - loss: 3.2689 - accuracy: 0.5717\n",
            "Epoch 51: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 51: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 51: accuracy did not improve from 0.68750\n",
            " 31/121 [======>.......................] - ETA: 0s - loss: 3.3572 - accuracy: 0.5585\n",
            "Epoch 51: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 51: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 51: accuracy did not improve from 0.68750\n",
            " 46/121 [==========>...................] - ETA: 0s - loss: 3.2393 - accuracy: 0.5747\n",
            "Epoch 51: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 51: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 51: accuracy did not improve from 0.68750\n",
            " 63/121 [==============>...............] - ETA: 0s - loss: 3.2741 - accuracy: 0.5739\n",
            "Epoch 51: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 51: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 51: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 51: accuracy did not improve from 0.68750\n",
            " 80/121 [==================>...........] - ETA: 0s - loss: 3.2517 - accuracy: 0.5773\n",
            "Epoch 51: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 51: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 51: accuracy did not improve from 0.68750\n",
            " 96/121 [======================>.......] - ETA: 0s - loss: 3.2405 - accuracy: 0.5771\n",
            "Epoch 51: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 51: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 51: accuracy did not improve from 0.68750\n",
            "112/121 [==========================>...] - ETA: 0s - loss: 3.2528 - accuracy: 0.5745\n",
            "Epoch 51: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 51: accuracy did not improve from 0.68750\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 3.2469 - accuracy: 0.5754\n",
            "Epoch 52/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 3.3489 - accuracy: 0.5938\n",
            "Epoch 52: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 52: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 52: accuracy did not improve from 0.68750\n",
            " 18/121 [===>..........................] - ETA: 0s - loss: 3.2592 - accuracy: 0.5729\n",
            "Epoch 52: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 52: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 52: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 52: accuracy did not improve from 0.68750\n",
            " 36/121 [=======>......................] - ETA: 0s - loss: 3.2349 - accuracy: 0.5720\n",
            "Epoch 52: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 52: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 52: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 52: accuracy did not improve from 0.68750\n",
            " 54/121 [============>.................] - ETA: 0s - loss: 3.2093 - accuracy: 0.5775\n",
            "Epoch 52: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 52: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 52: accuracy did not improve from 0.68750\n",
            " 72/121 [================>.............] - ETA: 0s - loss: 3.2020 - accuracy: 0.5742\n",
            "Epoch 52: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 52: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 52: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 52: accuracy did not improve from 0.68750\n",
            " 89/121 [=====================>........] - ETA: 0s - loss: 3.2183 - accuracy: 0.5716\n",
            "Epoch 52: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 52: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 52: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 52: accuracy did not improve from 0.68750\n",
            "109/121 [==========================>...] - ETA: 0s - loss: 3.2653 - accuracy: 0.5743\n",
            "Epoch 52: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 52: accuracy did not improve from 0.68750\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 3.2469 - accuracy: 0.5754\n",
            "Epoch 53/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 3.4497 - accuracy: 0.5625\n",
            "Epoch 53: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 53: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 53: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 53: accuracy did not improve from 0.68750\n",
            " 19/121 [===>..........................] - ETA: 0s - loss: 3.2094 - accuracy: 0.5872\n",
            "Epoch 53: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 53: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 53: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 53: accuracy did not improve from 0.68750\n",
            " 38/121 [========>.....................] - ETA: 0s - loss: 3.3544 - accuracy: 0.5789\n",
            "Epoch 53: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 53: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 53: accuracy did not improve from 0.68750\n",
            " 55/121 [============>.................] - ETA: 0s - loss: 3.3343 - accuracy: 0.5750\n",
            "Epoch 53: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 53: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 53: accuracy did not improve from 0.68750\n",
            " 68/121 [===============>..............] - ETA: 0s - loss: 3.3268 - accuracy: 0.5694\n",
            "Epoch 53: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 53: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 53: accuracy did not improve from 0.68750\n",
            " 83/121 [===================>..........] - ETA: 0s - loss: 3.2731 - accuracy: 0.5742\n",
            "Epoch 53: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 53: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 53: accuracy did not improve from 0.68750\n",
            " 98/121 [=======================>......] - ETA: 0s - loss: 3.2165 - accuracy: 0.5768\n",
            "Epoch 53: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 53: accuracy did not improve from 0.68750\n",
            "112/121 [==========================>...] - ETA: 0s - loss: 3.2451 - accuracy: 0.5745\n",
            "Epoch 53: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 53: accuracy did not improve from 0.68750\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 3.2469 - accuracy: 0.5754\n",
            "Epoch 54/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 3.6437 - accuracy: 0.5000\n",
            "Epoch 54: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 54: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 54: accuracy did not improve from 0.68750\n",
            " 15/121 [==>...........................] - ETA: 0s - loss: 3.1589 - accuracy: 0.6042\n",
            "Epoch 54: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 54: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 54: accuracy did not improve from 0.68750\n",
            " 27/121 [=====>........................] - ETA: 0s - loss: 3.2895 - accuracy: 0.5822\n",
            "Epoch 54: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 54: accuracy did not improve from 0.68750\n",
            " 39/121 [========>.....................] - ETA: 0s - loss: 3.2497 - accuracy: 0.5881\n",
            "Epoch 54: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 54: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 54: accuracy did not improve from 0.68750\n",
            " 54/121 [============>.................] - ETA: 0s - loss: 3.2613 - accuracy: 0.5816\n",
            "Epoch 54: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 54: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 54: accuracy did not improve from 0.68750\n",
            " 70/121 [================>.............] - ETA: 0s - loss: 3.2882 - accuracy: 0.5790\n",
            "Epoch 54: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 54: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 54: accuracy did not improve from 0.68750\n",
            " 85/121 [====================>.........] - ETA: 0s - loss: 3.2221 - accuracy: 0.5816\n",
            "Epoch 54: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 54: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 54: accuracy did not improve from 0.68750\n",
            "100/121 [=======================>......] - ETA: 0s - loss: 3.2199 - accuracy: 0.5803\n",
            "Epoch 54: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 54: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 54: accuracy did not improve from 0.68750\n",
            "116/121 [===========================>..] - ETA: 0s - loss: 3.2354 - accuracy: 0.5773\n",
            "Epoch 54: accuracy did not improve from 0.68750\n",
            "121/121 [==============================] - 0s 4ms/step - loss: 3.2469 - accuracy: 0.5754\n",
            "Epoch 55/100\n",
            "\n",
            "Epoch 55: accuracy did not improve from 0.68750\n",
            "  1/121 [..............................] - ETA: 1s - loss: 3.7368 - accuracy: 0.6562\n",
            "Epoch 55: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 55: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 55: accuracy did not improve from 0.68750\n",
            " 18/121 [===>..........................] - ETA: 0s - loss: 3.3551 - accuracy: 0.5729\n",
            "Epoch 55: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 55: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 55: accuracy did not improve from 0.68750\n",
            " 33/121 [=======>......................] - ETA: 0s - loss: 3.2765 - accuracy: 0.5748\n",
            "Epoch 55: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 55: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 55: accuracy did not improve from 0.68750\n",
            " 49/121 [===========>..................] - ETA: 0s - loss: 3.2806 - accuracy: 0.5682\n",
            "Epoch 55: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 55: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 55: accuracy did not improve from 0.68750\n",
            " 64/121 [==============>...............] - ETA: 0s - loss: 3.2608 - accuracy: 0.5737\n",
            "Epoch 55: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 55: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 55: accuracy did not improve from 0.68750\n",
            " 78/121 [==================>...........] - ETA: 0s - loss: 3.2325 - accuracy: 0.5805\n",
            "Epoch 55: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 55: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 55: accuracy did not improve from 0.68750\n",
            " 94/121 [======================>.......] - ETA: 0s - loss: 3.2588 - accuracy: 0.5778\n",
            "Epoch 55: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 55: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 55: accuracy did not improve from 0.68750\n",
            "110/121 [==========================>...] - ETA: 0s - loss: 3.2344 - accuracy: 0.5793\n",
            "Epoch 55: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 55: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 55: accuracy did not improve from 0.68750\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 3.2469 - accuracy: 0.5754\n",
            "Epoch 56/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 3.3468 - accuracy: 0.5938\n",
            "Epoch 56: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 56: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 56: accuracy did not improve from 0.68750\n",
            " 15/121 [==>...........................] - ETA: 0s - loss: 3.3657 - accuracy: 0.5958\n",
            "Epoch 56: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 56: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 56: accuracy did not improve from 0.68750\n",
            " 30/121 [======>.......................] - ETA: 0s - loss: 3.2623 - accuracy: 0.5885\n",
            "Epoch 56: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 56: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 56: accuracy did not improve from 0.68750\n",
            " 49/121 [===========>..................] - ETA: 0s - loss: 3.1808 - accuracy: 0.5855\n",
            "Epoch 56: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 56: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 56: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 56: accuracy did not improve from 0.68750\n",
            " 66/121 [===============>..............] - ETA: 0s - loss: 3.1908 - accuracy: 0.5795\n",
            "Epoch 56: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 56: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 56: accuracy did not improve from 0.68750\n",
            " 81/121 [===================>..........] - ETA: 0s - loss: 3.2121 - accuracy: 0.5822\n",
            "Epoch 56: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 56: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 56: accuracy did not improve from 0.68750\n",
            " 95/121 [======================>.......] - ETA: 0s - loss: 3.2393 - accuracy: 0.5813\n",
            "Epoch 56: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 56: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 56: accuracy did not improve from 0.68750\n",
            "111/121 [==========================>...] - ETA: 0s - loss: 3.2199 - accuracy: 0.5788\n",
            "Epoch 56: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 56: accuracy did not improve from 0.68750\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 3.2469 - accuracy: 0.5754\n",
            "Epoch 57/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 4.1048 - accuracy: 0.4688\n",
            "Epoch 57: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 57: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 57: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 57: accuracy did not improve from 0.68750\n",
            " 19/121 [===>..........................] - ETA: 0s - loss: 3.1112 - accuracy: 0.5740\n",
            "Epoch 57: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 57: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 57: accuracy did not improve from 0.68750\n",
            " 36/121 [=======>......................] - ETA: 0s - loss: 3.1934 - accuracy: 0.5799\n",
            "Epoch 57: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 57: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 57: accuracy did not improve from 0.68750\n",
            " 50/121 [===========>..................] - ETA: 0s - loss: 3.1945 - accuracy: 0.5788\n",
            "Epoch 57: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 57: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 57: accuracy did not improve from 0.68750\n",
            " 66/121 [===============>..............] - ETA: 0s - loss: 3.1970 - accuracy: 0.5791\n",
            "Epoch 57: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 57: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 57: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 57: accuracy did not improve from 0.68750\n",
            " 84/121 [===================>..........] - ETA: 0s - loss: 3.2208 - accuracy: 0.5796\n",
            "Epoch 57: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 57: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 57: accuracy did not improve from 0.68750\n",
            "100/121 [=======================>......] - ETA: 0s - loss: 3.2558 - accuracy: 0.5731\n",
            "Epoch 57: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 57: accuracy did not improve from 0.68750\n",
            "110/121 [==========================>...] - ETA: 0s - loss: 3.2478 - accuracy: 0.5741\n",
            "Epoch 57: accuracy did not improve from 0.68750\n",
            "\n",
            "Epoch 57: accuracy did not improve from 0.68750\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 3.2469 - accuracy: 0.5754\n",
            "Epoch 58/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.4912 - accuracy: 0.7812\n",
            "Epoch 58: accuracy improved from 0.68750 to 0.70833, saving model to best_model.hdf5\n",
            "\n",
            "Epoch 58: accuracy did not improve from 0.70833\n",
            " 10/121 [=>............................] - ETA: 0s - loss: 2.6906 - accuracy: 0.6344\n",
            "Epoch 58: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 58: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 58: accuracy did not improve from 0.70833\n",
            " 25/121 [=====>........................] - ETA: 0s - loss: 3.0813 - accuracy: 0.5913\n",
            "Epoch 58: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 58: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 58: accuracy did not improve from 0.70833\n",
            " 40/121 [========>.....................] - ETA: 0s - loss: 3.1530 - accuracy: 0.5914\n",
            "Epoch 58: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 58: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 58: accuracy did not improve from 0.70833\n",
            " 55/121 [============>.................] - ETA: 0s - loss: 3.2015 - accuracy: 0.5790\n",
            "Epoch 58: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 58: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 58: accuracy did not improve from 0.70833\n",
            " 71/121 [================>.............] - ETA: 0s - loss: 3.2230 - accuracy: 0.5841\n",
            "Epoch 58: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 58: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 58: accuracy did not improve from 0.70833\n",
            " 85/121 [====================>.........] - ETA: 0s - loss: 3.2259 - accuracy: 0.5824\n",
            "Epoch 58: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 58: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 58: accuracy did not improve from 0.70833\n",
            "101/121 [========================>.....] - ETA: 0s - loss: 3.2767 - accuracy: 0.5755\n",
            "Epoch 58: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 58: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 58: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 58: accuracy did not improve from 0.70833\n",
            "121/121 [==============================] - 0s 4ms/step - loss: 3.2469 - accuracy: 0.5754\n",
            "Epoch 59/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 3.2635 - accuracy: 0.5625\n",
            "Epoch 59: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 59: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 59: accuracy did not improve from 0.70833\n",
            " 16/121 [==>...........................] - ETA: 0s - loss: 3.2944 - accuracy: 0.5293\n",
            "Epoch 59: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 59: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 59: accuracy did not improve from 0.70833\n",
            " 31/121 [======>.......................] - ETA: 0s - loss: 3.2446 - accuracy: 0.5585\n",
            "Epoch 59: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 59: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 59: accuracy did not improve from 0.70833\n",
            " 46/121 [==========>...................] - ETA: 0s - loss: 3.2332 - accuracy: 0.5781\n",
            "Epoch 59: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 59: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 59: accuracy did not improve from 0.70833\n",
            " 61/121 [==============>...............] - ETA: 0s - loss: 3.2238 - accuracy: 0.5794\n",
            "Epoch 59: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 59: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 59: accuracy did not improve from 0.70833\n",
            " 75/121 [=================>............] - ETA: 0s - loss: 3.2448 - accuracy: 0.5742\n",
            "Epoch 59: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 59: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 59: accuracy did not improve from 0.70833\n",
            " 90/121 [=====================>........] - ETA: 0s - loss: 3.2677 - accuracy: 0.5715\n",
            "Epoch 59: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 59: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 59: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 59: accuracy did not improve from 0.70833\n",
            "107/121 [=========================>....] - ETA: 0s - loss: 3.2572 - accuracy: 0.5718\n",
            "Epoch 59: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 59: accuracy did not improve from 0.70833\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 3.2469 - accuracy: 0.5754\n",
            "Epoch 60/100\n",
            "\n",
            "Epoch 60: accuracy did not improve from 0.70833\n",
            "  1/121 [..............................] - ETA: 1s - loss: 3.2492 - accuracy: 0.5625\n",
            "Epoch 60: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 60: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 60: accuracy did not improve from 0.70833\n",
            " 19/121 [===>..........................] - ETA: 0s - loss: 3.0872 - accuracy: 0.5855\n",
            "Epoch 60: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 60: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 60: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 60: accuracy did not improve from 0.70833\n",
            " 36/121 [=======>......................] - ETA: 0s - loss: 3.1634 - accuracy: 0.5920\n",
            "Epoch 60: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 60: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 60: accuracy did not improve from 0.70833\n",
            " 53/121 [============>.................] - ETA: 0s - loss: 3.1094 - accuracy: 0.5908\n",
            "Epoch 60: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 60: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 60: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 60: accuracy did not improve from 0.70833\n",
            " 71/121 [================>.............] - ETA: 0s - loss: 3.1041 - accuracy: 0.5863\n",
            "Epoch 60: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 60: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 60: accuracy did not improve from 0.70833\n",
            " 89/121 [=====================>........] - ETA: 0s - loss: 3.1718 - accuracy: 0.5825\n",
            "Epoch 60: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 60: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 60: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 60: accuracy did not improve from 0.70833\n",
            "106/121 [=========================>....] - ETA: 0s - loss: 3.2040 - accuracy: 0.5802\n",
            "Epoch 60: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 60: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 60: accuracy did not improve from 0.70833\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 3.2469 - accuracy: 0.5754\n",
            "Epoch 61/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 3.0663 - accuracy: 0.5000\n",
            "Epoch 61: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 61: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 61: accuracy did not improve from 0.70833\n",
            " 19/121 [===>..........................] - ETA: 0s - loss: 3.3340 - accuracy: 0.5411\n",
            "Epoch 61: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 61: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 61: accuracy did not improve from 0.70833\n",
            " 33/121 [=======>......................] - ETA: 0s - loss: 3.4334 - accuracy: 0.5492\n",
            "Epoch 61: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 61: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 61: accuracy did not improve from 0.70833\n",
            " 48/121 [==========>...................] - ETA: 0s - loss: 3.3553 - accuracy: 0.5514\n",
            "Epoch 61: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 61: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 61: accuracy did not improve from 0.70833\n",
            " 64/121 [==============>...............] - ETA: 0s - loss: 3.3542 - accuracy: 0.5527\n",
            "Epoch 61: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 61: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 61: accuracy did not improve from 0.70833\n",
            " 79/121 [==================>...........] - ETA: 0s - loss: 3.3108 - accuracy: 0.5621\n",
            "Epoch 61: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 61: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 61: accuracy did not improve from 0.70833\n",
            " 91/121 [=====================>........] - ETA: 0s - loss: 3.3064 - accuracy: 0.5718\n",
            "Epoch 61: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 61: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 61: accuracy did not improve from 0.70833\n",
            "108/121 [=========================>....] - ETA: 0s - loss: 3.2881 - accuracy: 0.5723\n",
            "Epoch 61: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 61: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 61: accuracy did not improve from 0.70833\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 3.2469 - accuracy: 0.5754\n",
            "Epoch 62/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 3.7401 - accuracy: 0.5938\n",
            "Epoch 62: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 62: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 62: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 62: accuracy did not improve from 0.70833\n",
            " 19/121 [===>..........................] - ETA: 0s - loss: 2.9407 - accuracy: 0.6102\n",
            "Epoch 62: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 62: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 62: accuracy did not improve from 0.70833\n",
            " 36/121 [=======>......................] - ETA: 0s - loss: 3.1557 - accuracy: 0.5842\n",
            "Epoch 62: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 62: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 62: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 62: accuracy did not improve from 0.70833\n",
            " 54/121 [============>.................] - ETA: 0s - loss: 3.1650 - accuracy: 0.5851\n",
            "Epoch 62: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 62: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 62: accuracy did not improve from 0.70833\n",
            " 73/121 [=================>............] - ETA: 0s - loss: 3.2196 - accuracy: 0.5801\n",
            "Epoch 62: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 62: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 62: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 62: accuracy did not improve from 0.70833\n",
            " 90/121 [=====================>........] - ETA: 0s - loss: 3.2558 - accuracy: 0.5781\n",
            "Epoch 62: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 62: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 62: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 62: accuracy did not improve from 0.70833\n",
            "109/121 [==========================>...] - ETA: 0s - loss: 3.2571 - accuracy: 0.5751\n",
            "Epoch 62: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 62: accuracy did not improve from 0.70833\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 3.2469 - accuracy: 0.5754\n",
            "Epoch 63/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.8702 - accuracy: 0.5000\n",
            "Epoch 63: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 63: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 63: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 63: accuracy did not improve from 0.70833\n",
            " 19/121 [===>..........................] - ETA: 0s - loss: 3.4006 - accuracy: 0.5740\n",
            "Epoch 63: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 63: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 63: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 63: accuracy did not improve from 0.70833\n",
            " 38/121 [========>.....................] - ETA: 0s - loss: 3.4123 - accuracy: 0.5641\n",
            "Epoch 63: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 63: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 63: accuracy did not improve from 0.70833\n",
            " 57/121 [=============>................] - ETA: 0s - loss: 3.3998 - accuracy: 0.5707\n",
            "Epoch 63: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 63: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 63: accuracy did not improve from 0.70833\n",
            " 71/121 [================>.............] - ETA: 0s - loss: 3.3533 - accuracy: 0.5735\n",
            "Epoch 63: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 63: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 63: accuracy did not improve from 0.70833\n",
            " 86/121 [====================>.........] - ETA: 0s - loss: 3.3273 - accuracy: 0.5774\n",
            "Epoch 63: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 63: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 63: accuracy did not improve from 0.70833\n",
            "102/121 [========================>.....] - ETA: 0s - loss: 3.2972 - accuracy: 0.5738\n",
            "Epoch 63: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 63: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 63: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 63: accuracy did not improve from 0.70833\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 3.2469 - accuracy: 0.5754\n",
            "Epoch 64/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 3.4421 - accuracy: 0.5000\n",
            "Epoch 64: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 64: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 64: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 64: accuracy did not improve from 0.70833\n",
            " 17/121 [===>..........................] - ETA: 0s - loss: 3.4377 - accuracy: 0.5460\n",
            "Epoch 64: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 64: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 64: accuracy did not improve from 0.70833\n",
            " 32/121 [======>.......................] - ETA: 0s - loss: 3.3034 - accuracy: 0.5566\n",
            "Epoch 64: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 64: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 64: accuracy did not improve from 0.70833\n",
            " 47/121 [==========>...................] - ETA: 0s - loss: 3.2345 - accuracy: 0.5711\n",
            "Epoch 64: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 64: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 64: accuracy did not improve from 0.70833\n",
            " 62/121 [==============>...............] - ETA: 0s - loss: 3.2716 - accuracy: 0.5640\n",
            "Epoch 64: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 64: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 64: accuracy did not improve from 0.70833\n",
            " 78/121 [==================>...........] - ETA: 0s - loss: 3.3196 - accuracy: 0.5665\n",
            "Epoch 64: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 64: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 64: accuracy did not improve from 0.70833\n",
            " 93/121 [======================>.......] - ETA: 0s - loss: 3.3079 - accuracy: 0.5726\n",
            "Epoch 64: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 64: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 64: accuracy did not improve from 0.70833\n",
            "109/121 [==========================>...] - ETA: 0s - loss: 3.2694 - accuracy: 0.5751\n",
            "Epoch 64: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 64: accuracy did not improve from 0.70833\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 3.2469 - accuracy: 0.5754\n",
            "Epoch 65/100\n",
            "\n",
            "Epoch 65: accuracy did not improve from 0.70833\n",
            "  1/121 [..............................] - ETA: 0s - loss: 3.1583 - accuracy: 0.5938\n",
            "Epoch 65: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 65: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 65: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 65: accuracy did not improve from 0.70833\n",
            " 21/121 [====>.........................] - ETA: 0s - loss: 3.0240 - accuracy: 0.5938\n",
            "Epoch 65: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 65: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 65: accuracy did not improve from 0.70833\n",
            " 40/121 [========>.....................] - ETA: 0s - loss: 3.1415 - accuracy: 0.6031\n",
            "Epoch 65: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 65: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 65: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 65: accuracy did not improve from 0.70833\n",
            " 58/121 [=============>................] - ETA: 0s - loss: 3.2470 - accuracy: 0.5889\n",
            "Epoch 65: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 65: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 65: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 65: accuracy did not improve from 0.70833\n",
            " 76/121 [=================>............] - ETA: 0s - loss: 3.2689 - accuracy: 0.5843\n",
            "Epoch 65: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 65: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 65: accuracy did not improve from 0.70833\n",
            " 94/121 [======================>.......] - ETA: 0s - loss: 3.2660 - accuracy: 0.5805\n",
            "Epoch 65: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 65: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 65: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 65: accuracy did not improve from 0.70833\n",
            "111/121 [==========================>...] - ETA: 0s - loss: 3.2407 - accuracy: 0.5774\n",
            "Epoch 65: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 65: accuracy did not improve from 0.70833\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 3.2469 - accuracy: 0.5754\n",
            "Epoch 66/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 3.6426 - accuracy: 0.6562\n",
            "Epoch 66: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 66: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 66: accuracy did not improve from 0.70833\n",
            " 18/121 [===>..........................] - ETA: 0s - loss: 3.4928 - accuracy: 0.5781\n",
            "Epoch 66: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 66: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 66: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 66: accuracy did not improve from 0.70833\n",
            " 35/121 [=======>......................] - ETA: 0s - loss: 3.3240 - accuracy: 0.5741\n",
            "Epoch 66: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 66: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 66: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 66: accuracy did not improve from 0.70833\n",
            " 56/121 [============>.................] - ETA: 0s - loss: 3.2157 - accuracy: 0.5915\n",
            "Epoch 66: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 66: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 66: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 66: accuracy did not improve from 0.70833\n",
            " 76/121 [=================>............] - ETA: 0s - loss: 3.2268 - accuracy: 0.5794\n",
            "Epoch 66: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 66: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 66: accuracy did not improve from 0.70833\n",
            " 92/121 [=====================>........] - ETA: 0s - loss: 3.2756 - accuracy: 0.5781\n",
            "Epoch 66: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 66: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 66: accuracy did not improve from 0.70833\n",
            "105/121 [=========================>....] - ETA: 0s - loss: 3.2885 - accuracy: 0.5744\n",
            "Epoch 66: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 66: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 66: accuracy did not improve from 0.70833\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 3.2469 - accuracy: 0.5754\n",
            "Epoch 67/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 3.4443 - accuracy: 0.5625\n",
            "Epoch 67: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 67: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 67: accuracy did not improve from 0.70833\n",
            " 18/121 [===>..........................] - ETA: 0s - loss: 3.3426 - accuracy: 0.5417\n",
            "Epoch 67: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 67: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 67: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 67: accuracy did not improve from 0.70833\n",
            " 37/121 [========>.....................] - ETA: 0s - loss: 3.2304 - accuracy: 0.5752\n",
            "Epoch 67: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 67: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 67: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 67: accuracy did not improve from 0.70833\n",
            " 54/121 [============>.................] - ETA: 0s - loss: 3.3071 - accuracy: 0.5729\n",
            "Epoch 67: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 67: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 67: accuracy did not improve from 0.70833\n",
            " 72/121 [================>.............] - ETA: 0s - loss: 3.2484 - accuracy: 0.5747\n",
            "Epoch 67: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 67: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 67: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 67: accuracy did not improve from 0.70833\n",
            " 89/121 [=====================>........] - ETA: 0s - loss: 3.2387 - accuracy: 0.5737\n",
            "Epoch 67: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 67: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 67: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 67: accuracy did not improve from 0.70833\n",
            "109/121 [==========================>...] - ETA: 0s - loss: 3.2775 - accuracy: 0.5731\n",
            "Epoch 67: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 67: accuracy did not improve from 0.70833\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 3.2469 - accuracy: 0.5754\n",
            "Epoch 68/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 3.6382 - accuracy: 0.5938\n",
            "Epoch 68: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 68: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 68: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 68: accuracy did not improve from 0.70833\n",
            " 18/121 [===>..........................] - ETA: 0s - loss: 3.0463 - accuracy: 0.6024\n",
            "Epoch 68: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 68: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 68: accuracy did not improve from 0.70833\n",
            " 36/121 [=======>......................] - ETA: 0s - loss: 3.1762 - accuracy: 0.5894\n",
            "Epoch 68: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 68: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 68: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 68: accuracy did not improve from 0.70833\n",
            " 53/121 [============>.................] - ETA: 0s - loss: 3.3204 - accuracy: 0.5713\n",
            "Epoch 68: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 68: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 68: accuracy did not improve from 0.70833\n",
            " 69/121 [================>.............] - ETA: 0s - loss: 3.3023 - accuracy: 0.5824\n",
            "Epoch 68: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 68: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 68: accuracy did not improve from 0.70833\n",
            " 87/121 [====================>.........] - ETA: 0s - loss: 3.2683 - accuracy: 0.5801\n",
            "Epoch 68: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 68: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 68: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 68: accuracy did not improve from 0.70833\n",
            "104/121 [========================>.....] - ETA: 0s - loss: 3.2832 - accuracy: 0.5790\n",
            "Epoch 68: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 68: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 68: accuracy did not improve from 0.70833\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 3.2469 - accuracy: 0.5754\n",
            "Epoch 69/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 3.4541 - accuracy: 0.6250\n",
            "Epoch 69: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 69: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 69: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 69: accuracy did not improve from 0.70833\n",
            " 17/121 [===>..........................] - ETA: 0s - loss: 3.1697 - accuracy: 0.5607\n",
            "Epoch 69: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 69: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 69: accuracy did not improve from 0.70833\n",
            " 35/121 [=======>......................] - ETA: 0s - loss: 3.1871 - accuracy: 0.5625\n",
            "Epoch 69: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 69: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 69: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 69: accuracy did not improve from 0.70833\n",
            " 52/121 [===========>..................] - ETA: 0s - loss: 3.1758 - accuracy: 0.5781\n",
            "Epoch 69: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 69: accuracy did not improve from 0.70833\n",
            " 65/121 [===============>..............] - ETA: 0s - loss: 3.2343 - accuracy: 0.5721\n",
            "Epoch 69: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 69: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 69: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 69: accuracy did not improve from 0.70833\n",
            " 82/121 [===================>..........] - ETA: 0s - loss: 3.2561 - accuracy: 0.5697\n",
            "Epoch 69: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 69: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 69: accuracy did not improve from 0.70833\n",
            " 97/121 [=======================>......] - ETA: 0s - loss: 3.2595 - accuracy: 0.5712\n",
            "Epoch 69: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 69: accuracy did not improve from 0.70833\n",
            "\n",
            "Epoch 69: accuracy did not improve from 0.70833\n",
            "112/121 [==========================>...] - ETA: 0s - loss: 3.2519 - accuracy: 0.5745\n",
            "Epoch 69: accuracy did not improve from 0.70833\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 3.2469 - accuracy: 0.5754\n",
            "Epoch 70/100\n",
            "\n",
            "Epoch 70: accuracy improved from 0.70833 to 0.78125, saving model to best_model.hdf5\n",
            "  1/121 [..............................] - ETA: 2s - loss: 2.9699 - accuracy: 0.7812\n",
            "Epoch 70: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 70: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 70: accuracy did not improve from 0.78125\n",
            " 16/121 [==>...........................] - ETA: 0s - loss: 3.4853 - accuracy: 0.5801\n",
            "Epoch 70: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 70: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 70: accuracy did not improve from 0.78125\n",
            " 31/121 [======>.......................] - ETA: 0s - loss: 3.3295 - accuracy: 0.5786\n",
            "Epoch 70: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 70: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 70: accuracy did not improve from 0.78125\n",
            " 48/121 [==========>...................] - ETA: 0s - loss: 3.2832 - accuracy: 0.5775\n",
            "Epoch 70: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 70: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 70: accuracy did not improve from 0.78125\n",
            " 65/121 [===============>..............] - ETA: 0s - loss: 3.2575 - accuracy: 0.5750\n",
            "Epoch 70: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 70: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 70: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 70: accuracy did not improve from 0.78125\n",
            " 81/121 [===================>..........] - ETA: 0s - loss: 3.2769 - accuracy: 0.5729\n",
            "Epoch 70: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 70: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 70: accuracy did not improve from 0.78125\n",
            " 96/121 [======================>.......] - ETA: 0s - loss: 3.2273 - accuracy: 0.5745\n",
            "Epoch 70: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 70: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 70: accuracy did not improve from 0.78125\n",
            "113/121 [===========================>..] - ETA: 0s - loss: 3.2458 - accuracy: 0.5752\n",
            "Epoch 70: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 70: accuracy did not improve from 0.78125\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 3.2469 - accuracy: 0.5754\n",
            "Epoch 71/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.7771 - accuracy: 0.6250\n",
            "Epoch 71: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 71: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 71: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 71: accuracy did not improve from 0.78125\n",
            " 21/121 [====>.........................] - ETA: 0s - loss: 3.3953 - accuracy: 0.5625\n",
            "Epoch 71: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 71: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 71: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 71: accuracy did not improve from 0.78125\n",
            " 40/121 [========>.....................] - ETA: 0s - loss: 3.3347 - accuracy: 0.5750\n",
            "Epoch 71: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 71: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 71: accuracy did not improve from 0.78125\n",
            " 55/121 [============>.................] - ETA: 0s - loss: 3.3335 - accuracy: 0.5739\n",
            "Epoch 71: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 71: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 71: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 71: accuracy did not improve from 0.78125\n",
            " 75/121 [=================>............] - ETA: 0s - loss: 3.2904 - accuracy: 0.5729\n",
            "Epoch 71: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 71: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 71: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 71: accuracy did not improve from 0.78125\n",
            " 95/121 [======================>.......] - ETA: 0s - loss: 3.2644 - accuracy: 0.5747\n",
            "Epoch 71: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 71: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 71: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 71: accuracy did not improve from 0.78125\n",
            "115/121 [===========================>..] - ETA: 0s - loss: 3.2686 - accuracy: 0.5720\n",
            "Epoch 71: accuracy did not improve from 0.78125\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 3.2469 - accuracy: 0.5754\n",
            "Epoch 72/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.9589 - accuracy: 0.6250\n",
            "Epoch 72: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 72: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 72: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 72: accuracy did not improve from 0.78125\n",
            " 20/121 [===>..........................] - ETA: 0s - loss: 3.1683 - accuracy: 0.5813\n",
            "Epoch 72: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 72: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 72: accuracy did not improve from 0.78125\n",
            " 37/121 [========>.....................] - ETA: 0s - loss: 3.1791 - accuracy: 0.5760\n",
            "Epoch 72: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 72: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 72: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 72: accuracy did not improve from 0.78125\n",
            " 57/121 [=============>................] - ETA: 0s - loss: 3.2823 - accuracy: 0.5685\n",
            "Epoch 72: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 72: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 72: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 72: accuracy did not improve from 0.78125\n",
            " 76/121 [=================>............] - ETA: 0s - loss: 3.2981 - accuracy: 0.5765\n",
            "Epoch 72: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 72: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 72: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 72: accuracy did not improve from 0.78125\n",
            " 97/121 [=======================>......] - ETA: 0s - loss: 3.2774 - accuracy: 0.5718\n",
            "Epoch 72: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 72: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 72: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 72: accuracy did not improve from 0.78125\n",
            "117/121 [============================>.] - ETA: 0s - loss: 3.2438 - accuracy: 0.5756\n",
            "Epoch 72: accuracy did not improve from 0.78125\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 3.2469 - accuracy: 0.5754\n",
            "Epoch 73/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 4.8739 - accuracy: 0.4688\n",
            "Epoch 73: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 73: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 73: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 73: accuracy did not improve from 0.78125\n",
            " 21/121 [====>.........................] - ETA: 0s - loss: 3.2721 - accuracy: 0.5863\n",
            "Epoch 73: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 73: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 73: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 73: accuracy did not improve from 0.78125\n",
            " 41/121 [=========>....................] - ETA: 0s - loss: 3.2399 - accuracy: 0.5846\n",
            "Epoch 73: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 73: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 73: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 73: accuracy did not improve from 0.78125\n",
            " 61/121 [==============>...............] - ETA: 0s - loss: 3.2600 - accuracy: 0.5830\n",
            "Epoch 73: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 73: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 73: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 73: accuracy did not improve from 0.78125\n",
            " 80/121 [==================>...........] - ETA: 0s - loss: 3.2775 - accuracy: 0.5828\n",
            "Epoch 73: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 73: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 73: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 73: accuracy did not improve from 0.78125\n",
            " 99/121 [=======================>......] - ETA: 0s - loss: 3.2806 - accuracy: 0.5764\n",
            "Epoch 73: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 73: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 73: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 73: accuracy did not improve from 0.78125\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 3.2469 - accuracy: 0.5754\n",
            "Epoch 74/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 3.4465 - accuracy: 0.4688\n",
            "Epoch 74: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 74: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 74: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 74: accuracy did not improve from 0.78125\n",
            " 19/121 [===>..........................] - ETA: 0s - loss: 3.2734 - accuracy: 0.5789\n",
            "Epoch 74: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 74: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 74: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 74: accuracy did not improve from 0.78125\n",
            " 39/121 [========>.....................] - ETA: 0s - loss: 3.2045 - accuracy: 0.5817\n",
            "Epoch 74: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 74: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 74: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 74: accuracy did not improve from 0.78125\n",
            " 58/121 [=============>................] - ETA: 0s - loss: 3.1854 - accuracy: 0.5770\n",
            "Epoch 74: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 74: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 74: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 74: accuracy did not improve from 0.78125\n",
            " 79/121 [==================>...........] - ETA: 0s - loss: 3.2341 - accuracy: 0.5748\n",
            "Epoch 74: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 74: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 74: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 74: accuracy did not improve from 0.78125\n",
            " 99/121 [=======================>......] - ETA: 0s - loss: 3.2225 - accuracy: 0.5792\n",
            "Epoch 74: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 74: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 74: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 74: accuracy did not improve from 0.78125\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 3.2469 - accuracy: 0.5754\n",
            "Epoch 75/100\n",
            "\n",
            "Epoch 75: accuracy did not improve from 0.78125\n",
            "  1/121 [..............................] - ETA: 0s - loss: 4.5025 - accuracy: 0.4688\n",
            "Epoch 75: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 75: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 75: accuracy did not improve from 0.78125\n",
            " 20/121 [===>..........................] - ETA: 0s - loss: 3.1186 - accuracy: 0.6047\n",
            "Epoch 75: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 75: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 75: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 75: accuracy did not improve from 0.78125\n",
            " 39/121 [========>.....................] - ETA: 0s - loss: 3.2097 - accuracy: 0.5769\n",
            "Epoch 75: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 75: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 75: accuracy did not improve from 0.78125\n",
            " 55/121 [============>.................] - ETA: 0s - loss: 3.2448 - accuracy: 0.5739\n",
            "Epoch 75: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 75: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 75: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 75: accuracy did not improve from 0.78125\n",
            " 72/121 [================>.............] - ETA: 0s - loss: 3.2772 - accuracy: 0.5725\n",
            "Epoch 75: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 75: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 75: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 75: accuracy did not improve from 0.78125\n",
            " 92/121 [=====================>........] - ETA: 0s - loss: 3.2558 - accuracy: 0.5720\n",
            "Epoch 75: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 75: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 75: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 75: accuracy did not improve from 0.78125\n",
            "112/121 [==========================>...] - ETA: 0s - loss: 3.2656 - accuracy: 0.5723\n",
            "Epoch 75: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 75: accuracy did not improve from 0.78125\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 3.2469 - accuracy: 0.5754\n",
            "Epoch 76/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 3.6437 - accuracy: 0.5312\n",
            "Epoch 76: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 76: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 76: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 76: accuracy did not improve from 0.78125\n",
            " 22/121 [====>.........................] - ETA: 0s - loss: 3.4094 - accuracy: 0.5469\n",
            "Epoch 76: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 76: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 76: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 76: accuracy did not improve from 0.78125\n",
            " 42/121 [=========>....................] - ETA: 0s - loss: 3.3035 - accuracy: 0.5722\n",
            "Epoch 76: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 76: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 76: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 76: accuracy did not improve from 0.78125\n",
            " 63/121 [==============>...............] - ETA: 0s - loss: 3.2775 - accuracy: 0.5784\n",
            "Epoch 76: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 76: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 76: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 76: accuracy did not improve from 0.78125\n",
            " 84/121 [===================>..........] - ETA: 0s - loss: 3.2592 - accuracy: 0.5804\n",
            "Epoch 76: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 76: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 76: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 76: accuracy did not improve from 0.78125\n",
            "102/121 [========================>.....] - ETA: 0s - loss: 3.2271 - accuracy: 0.5815\n",
            "Epoch 76: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 76: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 76: accuracy did not improve from 0.78125\n",
            "118/121 [============================>.] - ETA: 0s - loss: 3.2341 - accuracy: 0.5771\n",
            "Epoch 76: accuracy did not improve from 0.78125\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 3.2469 - accuracy: 0.5754\n",
            "Epoch 77/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 4.8816 - accuracy: 0.5938\n",
            "Epoch 77: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 77: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 77: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 77: accuracy did not improve from 0.78125\n",
            " 19/121 [===>..........................] - ETA: 0s - loss: 3.4646 - accuracy: 0.5691\n",
            "Epoch 77: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 77: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 77: accuracy did not improve from 0.78125\n",
            " 37/121 [========>.....................] - ETA: 0s - loss: 3.3232 - accuracy: 0.5811\n",
            "Epoch 77: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 77: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 77: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 77: accuracy did not improve from 0.78125\n",
            " 54/121 [============>.................] - ETA: 0s - loss: 3.2979 - accuracy: 0.5804\n",
            "Epoch 77: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 77: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 77: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 77: accuracy did not improve from 0.78125\n",
            " 74/121 [=================>............] - ETA: 0s - loss: 3.2475 - accuracy: 0.5845\n",
            "Epoch 77: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 77: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 77: accuracy did not improve from 0.78125\n",
            " 91/121 [=====================>........] - ETA: 0s - loss: 3.2569 - accuracy: 0.5797\n",
            "Epoch 77: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 77: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 77: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 77: accuracy did not improve from 0.78125\n",
            "109/121 [==========================>...] - ETA: 0s - loss: 3.2511 - accuracy: 0.5765\n",
            "Epoch 77: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 77: accuracy did not improve from 0.78125\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 3.2469 - accuracy: 0.5754\n",
            "Epoch 78/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 3.4410 - accuracy: 0.5312\n",
            "Epoch 78: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 78: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 78: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 78: accuracy did not improve from 0.78125\n",
            " 19/121 [===>..........................] - ETA: 0s - loss: 3.3231 - accuracy: 0.5822\n",
            "Epoch 78: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 78: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 78: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 78: accuracy did not improve from 0.78125\n",
            " 38/121 [========>.....................] - ETA: 0s - loss: 3.3613 - accuracy: 0.5650\n",
            "Epoch 78: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 78: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 78: accuracy did not improve from 0.78125\n",
            " 54/121 [============>.................] - ETA: 0s - loss: 3.3331 - accuracy: 0.5671\n",
            "Epoch 78: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 78: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 78: accuracy did not improve from 0.78125\n",
            " 70/121 [================>.............] - ETA: 0s - loss: 3.3234 - accuracy: 0.5661\n",
            "Epoch 78: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 78: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 78: accuracy did not improve from 0.78125\n",
            " 87/121 [====================>.........] - ETA: 0s - loss: 3.2889 - accuracy: 0.5769\n",
            "Epoch 78: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 78: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 78: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 78: accuracy did not improve from 0.78125\n",
            "103/121 [========================>.....] - ETA: 0s - loss: 3.2640 - accuracy: 0.5768\n",
            "Epoch 78: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 78: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 78: accuracy did not improve from 0.78125\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 3.2469 - accuracy: 0.5754\n",
            "Epoch 79/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 3.3489 - accuracy: 0.5000\n",
            "Epoch 79: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 79: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 79: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 79: accuracy did not improve from 0.78125\n",
            " 19/121 [===>..........................] - ETA: 0s - loss: 3.2645 - accuracy: 0.5921\n",
            "Epoch 79: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 79: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 79: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 79: accuracy did not improve from 0.78125\n",
            " 38/121 [========>.....................] - ETA: 0s - loss: 3.2974 - accuracy: 0.5921\n",
            "Epoch 79: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 79: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 79: accuracy did not improve from 0.78125\n",
            " 56/121 [============>.................] - ETA: 0s - loss: 3.2331 - accuracy: 0.5926\n",
            "Epoch 79: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 79: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 79: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 79: accuracy did not improve from 0.78125\n",
            " 73/121 [=================>............] - ETA: 0s - loss: 3.2664 - accuracy: 0.5826\n",
            "Epoch 79: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 79: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 79: accuracy did not improve from 0.78125\n",
            " 90/121 [=====================>........] - ETA: 0s - loss: 3.2644 - accuracy: 0.5774\n",
            "Epoch 79: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 79: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 79: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 79: accuracy did not improve from 0.78125\n",
            "107/121 [=========================>....] - ETA: 0s - loss: 3.2544 - accuracy: 0.5777\n",
            "Epoch 79: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 79: accuracy did not improve from 0.78125\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 3.2469 - accuracy: 0.5754\n",
            "Epoch 80/100\n",
            "\n",
            "Epoch 80: accuracy did not improve from 0.78125\n",
            "  1/121 [..............................] - ETA: 0s - loss: 4.6975 - accuracy: 0.4062\n",
            "Epoch 80: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 80: accuracy did not improve from 0.78125\n",
            " 15/121 [==>...........................] - ETA: 0s - loss: 3.2680 - accuracy: 0.5667\n",
            "Epoch 80: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 80: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 80: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 80: accuracy did not improve from 0.78125\n",
            " 31/121 [======>.......................] - ETA: 0s - loss: 3.1834 - accuracy: 0.5867\n",
            "Epoch 80: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 80: accuracy did not improve from 0.78125\n",
            " 45/121 [==========>...................] - ETA: 0s - loss: 3.1520 - accuracy: 0.5861\n",
            "Epoch 80: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 80: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 80: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 80: accuracy did not improve from 0.78125\n",
            " 61/121 [==============>...............] - ETA: 0s - loss: 3.1988 - accuracy: 0.5774\n",
            "Epoch 80: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 80: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 80: accuracy did not improve from 0.78125\n",
            " 77/121 [==================>...........] - ETA: 0s - loss: 3.1830 - accuracy: 0.5844\n",
            "Epoch 80: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 80: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 80: accuracy did not improve from 0.78125\n",
            " 94/121 [======================>.......] - ETA: 0s - loss: 3.1785 - accuracy: 0.5831\n",
            "Epoch 80: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 80: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 80: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 80: accuracy did not improve from 0.78125\n",
            "112/121 [==========================>...] - ETA: 0s - loss: 3.2505 - accuracy: 0.5745\n",
            "Epoch 80: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 80: accuracy did not improve from 0.78125\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 3.2469 - accuracy: 0.5754\n",
            "Epoch 81/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 3.2613 - accuracy: 0.6562\n",
            "Epoch 81: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 81: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 81: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 81: accuracy did not improve from 0.78125\n",
            " 20/121 [===>..........................] - ETA: 0s - loss: 3.3603 - accuracy: 0.5719\n",
            "Epoch 81: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 81: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 81: accuracy did not improve from 0.78125\n",
            " 37/121 [========>.....................] - ETA: 0s - loss: 3.3608 - accuracy: 0.5676\n",
            "Epoch 81: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 81: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 81: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 81: accuracy did not improve from 0.78125\n",
            " 58/121 [=============>................] - ETA: 0s - loss: 3.3039 - accuracy: 0.5738\n",
            "Epoch 81: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 81: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 81: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 81: accuracy did not improve from 0.78125\n",
            " 76/121 [=================>............] - ETA: 0s - loss: 3.2956 - accuracy: 0.5678\n",
            "Epoch 81: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 81: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 81: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 81: accuracy did not improve from 0.78125\n",
            " 96/121 [======================>.......] - ETA: 0s - loss: 3.3026 - accuracy: 0.5706\n",
            "Epoch 81: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 81: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 81: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 81: accuracy did not improve from 0.78125\n",
            "116/121 [===========================>..] - ETA: 0s - loss: 3.2652 - accuracy: 0.5757\n",
            "Epoch 81: accuracy did not improve from 0.78125\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 3.2469 - accuracy: 0.5754\n",
            "Epoch 82/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.2984 - accuracy: 0.5938\n",
            "Epoch 82: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 82: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 82: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 82: accuracy did not improve from 0.78125\n",
            " 19/121 [===>..........................] - ETA: 0s - loss: 3.0027 - accuracy: 0.6069\n",
            "Epoch 82: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 82: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 82: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 82: accuracy did not improve from 0.78125\n",
            " 39/121 [========>.....................] - ETA: 0s - loss: 3.0503 - accuracy: 0.5978\n",
            "Epoch 82: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 82: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 82: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 82: accuracy did not improve from 0.78125\n",
            " 59/121 [=============>................] - ETA: 0s - loss: 3.1648 - accuracy: 0.5810\n",
            "Epoch 82: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 82: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 82: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 82: accuracy did not improve from 0.78125\n",
            " 79/121 [==================>...........] - ETA: 0s - loss: 3.1923 - accuracy: 0.5843\n",
            "Epoch 82: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 82: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 82: accuracy did not improve from 0.78125\n",
            " 97/121 [=======================>......] - ETA: 0s - loss: 3.2587 - accuracy: 0.5770\n",
            "Epoch 82: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 82: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 82: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 82: accuracy did not improve from 0.78125\n",
            "116/121 [===========================>..] - ETA: 0s - loss: 3.2659 - accuracy: 0.5735\n",
            "Epoch 82: accuracy did not improve from 0.78125\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 3.2469 - accuracy: 0.5754\n",
            "Epoch 83/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 3.9186 - accuracy: 0.5938\n",
            "Epoch 83: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 83: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 83: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 83: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 83: accuracy did not improve from 0.78125\n",
            " 23/121 [====>.........................] - ETA: 0s - loss: 3.1298 - accuracy: 0.5761\n",
            "Epoch 83: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 83: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 83: accuracy did not improve from 0.78125\n",
            " 42/121 [=========>....................] - ETA: 0s - loss: 3.1328 - accuracy: 0.5885\n",
            "Epoch 83: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 83: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 83: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 83: accuracy did not improve from 0.78125\n",
            " 59/121 [=============>................] - ETA: 0s - loss: 3.1598 - accuracy: 0.5773\n",
            "Epoch 83: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 83: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 83: accuracy did not improve from 0.78125\n",
            " 76/121 [=================>............] - ETA: 0s - loss: 3.2108 - accuracy: 0.5761\n",
            "Epoch 83: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 83: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 83: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 83: accuracy did not improve from 0.78125\n",
            " 93/121 [======================>.......] - ETA: 0s - loss: 3.2371 - accuracy: 0.5776\n",
            "Epoch 83: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 83: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 83: accuracy did not improve from 0.78125\n",
            "111/121 [==========================>...] - ETA: 0s - loss: 3.2372 - accuracy: 0.5715\n",
            "Epoch 83: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 83: accuracy did not improve from 0.78125\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 3.2469 - accuracy: 0.5754\n",
            "Epoch 84/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 4.4992 - accuracy: 0.5000\n",
            "Epoch 84: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 84: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 84: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 84: accuracy did not improve from 0.78125\n",
            " 17/121 [===>..........................] - ETA: 0s - loss: 3.1515 - accuracy: 0.5772\n",
            "Epoch 84: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 84: accuracy did not improve from 0.78125\n",
            " 30/121 [======>.......................] - ETA: 0s - loss: 3.2017 - accuracy: 0.5938\n",
            "Epoch 84: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 84: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 84: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 84: accuracy did not improve from 0.78125\n",
            " 47/121 [==========>...................] - ETA: 0s - loss: 3.2430 - accuracy: 0.5738\n",
            "Epoch 84: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 84: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 84: accuracy did not improve from 0.78125\n",
            " 64/121 [==============>...............] - ETA: 0s - loss: 3.1831 - accuracy: 0.5806\n",
            "Epoch 84: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 84: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 84: accuracy did not improve from 0.78125\n",
            " 80/121 [==================>...........] - ETA: 0s - loss: 3.1663 - accuracy: 0.5820\n",
            "Epoch 84: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 84: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 84: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 84: accuracy did not improve from 0.78125\n",
            " 98/121 [=======================>......] - ETA: 0s - loss: 3.2360 - accuracy: 0.5756\n",
            "Epoch 84: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 84: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 84: accuracy did not improve from 0.78125\n",
            "115/121 [===========================>..] - ETA: 0s - loss: 3.2552 - accuracy: 0.5739\n",
            "Epoch 84: accuracy did not improve from 0.78125\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 3.2469 - accuracy: 0.5754\n",
            "Epoch 85/100\n",
            "\n",
            "Epoch 85: accuracy did not improve from 0.78125\n",
            "  1/121 [..............................] - ETA: 0s - loss: 3.8332 - accuracy: 0.5312\n",
            "Epoch 85: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 85: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 85: accuracy did not improve from 0.78125\n",
            " 17/121 [===>..........................] - ETA: 0s - loss: 3.3780 - accuracy: 0.5846\n",
            "Epoch 85: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 85: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 85: accuracy did not improve from 0.78125\n",
            " 34/121 [=======>......................] - ETA: 0s - loss: 3.2851 - accuracy: 0.5671\n",
            "Epoch 85: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 85: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 85: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 85: accuracy did not improve from 0.78125\n",
            " 52/121 [===========>..................] - ETA: 0s - loss: 3.2542 - accuracy: 0.5763\n",
            "Epoch 85: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 85: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 85: accuracy did not improve from 0.78125\n",
            " 70/121 [================>.............] - ETA: 0s - loss: 3.2378 - accuracy: 0.5768\n",
            "Epoch 85: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 85: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 85: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 85: accuracy did not improve from 0.78125\n",
            " 88/121 [====================>.........] - ETA: 0s - loss: 3.2396 - accuracy: 0.5710\n",
            "Epoch 85: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 85: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 85: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 85: accuracy did not improve from 0.78125\n",
            "110/121 [==========================>...] - ETA: 0s - loss: 3.2198 - accuracy: 0.5770\n",
            "Epoch 85: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 85: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 85: accuracy did not improve from 0.78125\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 3.2469 - accuracy: 0.5754\n",
            "Epoch 86/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.9732 - accuracy: 0.5938\n",
            "Epoch 86: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 86: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 86: accuracy did not improve from 0.78125\n",
            " 15/121 [==>...........................] - ETA: 0s - loss: 3.2482 - accuracy: 0.5750\n",
            "Epoch 86: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 86: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 86: accuracy did not improve from 0.78125\n",
            " 31/121 [======>.......................] - ETA: 0s - loss: 3.2566 - accuracy: 0.5665\n",
            "Epoch 86: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 86: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 86: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 86: accuracy did not improve from 0.78125\n",
            " 50/121 [===========>..................] - ETA: 0s - loss: 3.2301 - accuracy: 0.5700\n",
            "Epoch 86: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 86: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 86: accuracy did not improve from 0.78125\n",
            " 65/121 [===============>..............] - ETA: 0s - loss: 3.1825 - accuracy: 0.5740\n",
            "Epoch 86: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 86: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 86: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 86: accuracy did not improve from 0.78125\n",
            " 85/121 [====================>.........] - ETA: 0s - loss: 3.1832 - accuracy: 0.5783\n",
            "Epoch 86: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 86: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 86: accuracy did not improve from 0.78125\n",
            "104/121 [========================>.....] - ETA: 0s - loss: 3.2175 - accuracy: 0.5763\n",
            "Epoch 86: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 86: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 86: accuracy did not improve from 0.78125\n",
            "119/121 [============================>.] - ETA: 0s - loss: 3.2536 - accuracy: 0.5754\n",
            "Epoch 86: accuracy did not improve from 0.78125\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 3.2469 - accuracy: 0.5754\n",
            "Epoch 87/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 3.6316 - accuracy: 0.4688\n",
            "Epoch 87: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 87: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 87: accuracy did not improve from 0.78125\n",
            " 17/121 [===>..........................] - ETA: 0s - loss: 3.1914 - accuracy: 0.5919\n",
            "Epoch 87: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 87: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 87: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 87: accuracy did not improve from 0.78125\n",
            " 36/121 [=======>......................] - ETA: 0s - loss: 3.2891 - accuracy: 0.5833\n",
            "Epoch 87: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 87: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 87: accuracy did not improve from 0.78125\n",
            " 53/121 [============>.................] - ETA: 0s - loss: 3.2806 - accuracy: 0.5784\n",
            "Epoch 87: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 87: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 87: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 87: accuracy did not improve from 0.78125\n",
            " 71/121 [================>.............] - ETA: 0s - loss: 3.2686 - accuracy: 0.5753\n",
            "Epoch 87: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 87: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 87: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 87: accuracy did not improve from 0.78125\n",
            " 91/121 [=====================>........] - ETA: 0s - loss: 3.2612 - accuracy: 0.5745\n",
            "Epoch 87: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 87: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 87: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 87: accuracy did not improve from 0.78125\n",
            "110/121 [==========================>...] - ETA: 0s - loss: 3.2554 - accuracy: 0.5741\n",
            "Epoch 87: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 87: accuracy did not improve from 0.78125\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 3.2469 - accuracy: 0.5754\n",
            "Epoch 88/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.8724 - accuracy: 0.6250\n",
            "Epoch 88: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 88: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 88: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 88: accuracy did not improve from 0.78125\n",
            " 22/121 [====>.........................] - ETA: 0s - loss: 3.2500 - accuracy: 0.5938\n",
            "Epoch 88: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 88: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 88: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 88: accuracy did not improve from 0.78125\n",
            " 42/121 [=========>....................] - ETA: 0s - loss: 3.3448 - accuracy: 0.5662\n",
            "Epoch 88: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 88: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 88: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 88: accuracy did not improve from 0.78125\n",
            " 59/121 [=============>................] - ETA: 0s - loss: 3.3497 - accuracy: 0.5651\n",
            "Epoch 88: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 88: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 88: accuracy did not improve from 0.78125\n",
            " 74/121 [=================>............] - ETA: 0s - loss: 3.3496 - accuracy: 0.5659\n",
            "Epoch 88: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 88: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 88: accuracy did not improve from 0.78125\n",
            " 88/121 [====================>.........] - ETA: 0s - loss: 3.2983 - accuracy: 0.5689\n",
            "Epoch 88: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 88: accuracy did not improve from 0.78125\n",
            "100/121 [=======================>......] - ETA: 0s - loss: 3.2575 - accuracy: 0.5744\n",
            "Epoch 88: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 88: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 88: accuracy did not improve from 0.78125\n",
            "113/121 [===========================>..] - ETA: 0s - loss: 3.2665 - accuracy: 0.5755\n",
            "Epoch 88: accuracy did not improve from 0.78125\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 3.2469 - accuracy: 0.5754\n",
            "Epoch 89/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.8735 - accuracy: 0.6250\n",
            "Epoch 89: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 89: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 89: accuracy did not improve from 0.78125\n",
            " 16/121 [==>...........................] - ETA: 0s - loss: 3.2769 - accuracy: 0.5430\n",
            "Epoch 89: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 89: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 89: accuracy did not improve from 0.78125\n",
            " 31/121 [======>.......................] - ETA: 0s - loss: 3.4028 - accuracy: 0.5363\n",
            "Epoch 89: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 89: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 89: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 89: accuracy did not improve from 0.78125\n",
            " 48/121 [==========>...................] - ETA: 0s - loss: 3.3287 - accuracy: 0.5514\n",
            "Epoch 89: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 89: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 89: accuracy did not improve from 0.78125\n",
            " 62/121 [==============>...............] - ETA: 0s - loss: 3.2681 - accuracy: 0.5630\n",
            "Epoch 89: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 89: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 89: accuracy did not improve from 0.78125\n",
            " 77/121 [==================>...........] - ETA: 0s - loss: 3.3216 - accuracy: 0.5625\n",
            "Epoch 89: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 89: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 89: accuracy did not improve from 0.78125\n",
            " 92/121 [=====================>........] - ETA: 0s - loss: 3.3124 - accuracy: 0.5686\n",
            "Epoch 89: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 89: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 89: accuracy did not improve from 0.78125\n",
            "107/121 [=========================>....] - ETA: 0s - loss: 3.2879 - accuracy: 0.5710\n",
            "Epoch 89: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 89: accuracy did not improve from 0.78125\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 3.2469 - accuracy: 0.5754\n",
            "Epoch 90/100\n",
            "\n",
            "Epoch 90: accuracy did not improve from 0.78125\n",
            "  1/121 [..............................] - ETA: 0s - loss: 4.5967 - accuracy: 0.3750\n",
            "Epoch 90: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 90: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 90: accuracy did not improve from 0.78125\n",
            " 17/121 [===>..........................] - ETA: 0s - loss: 3.8107 - accuracy: 0.5533\n",
            "Epoch 90: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 90: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 90: accuracy did not improve from 0.78125\n",
            " 33/121 [=======>......................] - ETA: 0s - loss: 3.5030 - accuracy: 0.5672\n",
            "Epoch 90: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 90: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 90: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 90: accuracy did not improve from 0.78125\n",
            " 51/121 [===========>..................] - ETA: 0s - loss: 3.3778 - accuracy: 0.5692\n",
            "Epoch 90: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 90: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 90: accuracy did not improve from 0.78125\n",
            " 66/121 [===============>..............] - ETA: 0s - loss: 3.2870 - accuracy: 0.5705\n",
            "Epoch 90: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 90: accuracy did not improve from 0.78125\n",
            " 80/121 [==================>...........] - ETA: 0s - loss: 3.2764 - accuracy: 0.5715\n",
            "Epoch 90: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 90: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 90: accuracy did not improve from 0.78125\n",
            " 92/121 [=====================>........] - ETA: 0s - loss: 3.2421 - accuracy: 0.5740\n",
            "Epoch 90: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 90: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 90: accuracy did not improve from 0.78125\n",
            "106/121 [=========================>....] - ETA: 0s - loss: 3.2219 - accuracy: 0.5764\n",
            "Epoch 90: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 90: accuracy did not improve from 0.78125\n",
            "120/121 [============================>.] - ETA: 0s - loss: 3.2472 - accuracy: 0.5747\n",
            "Epoch 90: accuracy did not improve from 0.78125\n",
            "121/121 [==============================] - 0s 4ms/step - loss: 3.2469 - accuracy: 0.5754\n",
            "Epoch 91/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 3.1594 - accuracy: 0.5938\n",
            "Epoch 91: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 91: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 91: accuracy did not improve from 0.78125\n",
            " 17/121 [===>..........................] - ETA: 0s - loss: 3.3669 - accuracy: 0.5662\n",
            "Epoch 91: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 91: accuracy did not improve from 0.78125\n",
            " 27/121 [=====>........................] - ETA: 0s - loss: 3.4663 - accuracy: 0.5498\n",
            "Epoch 91: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 91: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 91: accuracy did not improve from 0.78125\n",
            " 44/121 [=========>....................] - ETA: 0s - loss: 3.3273 - accuracy: 0.5661\n",
            "Epoch 91: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 91: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 91: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 91: accuracy did not improve from 0.78125\n",
            " 60/121 [=============>................] - ETA: 0s - loss: 3.3157 - accuracy: 0.5682\n",
            "Epoch 91: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 91: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 91: accuracy did not improve from 0.78125\n",
            " 78/121 [==================>...........] - ETA: 0s - loss: 3.3312 - accuracy: 0.5681\n",
            "Epoch 91: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 91: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 91: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 91: accuracy did not improve from 0.78125\n",
            " 96/121 [======================>.......] - ETA: 0s - loss: 3.3166 - accuracy: 0.5742\n",
            "Epoch 91: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 91: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 91: accuracy did not improve from 0.78125\n",
            "114/121 [===========================>..] - ETA: 0s - loss: 3.2579 - accuracy: 0.5770\n",
            "Epoch 91: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 91: accuracy did not improve from 0.78125\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 3.2469 - accuracy: 0.5754\n",
            "Epoch 92/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 3.1528 - accuracy: 0.6875\n",
            "Epoch 92: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 92: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 92: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 92: accuracy did not improve from 0.78125\n",
            " 19/121 [===>..........................] - ETA: 0s - loss: 3.2438 - accuracy: 0.5724\n",
            "Epoch 92: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 92: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 92: accuracy did not improve from 0.78125\n",
            " 34/121 [=======>......................] - ETA: 0s - loss: 3.2033 - accuracy: 0.5699\n",
            "Epoch 92: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 92: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 92: accuracy did not improve from 0.78125\n",
            " 52/121 [===========>..................] - ETA: 0s - loss: 3.1992 - accuracy: 0.5829\n",
            "Epoch 92: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 92: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 92: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 92: accuracy did not improve from 0.78125\n",
            " 69/121 [================>.............] - ETA: 0s - loss: 3.2460 - accuracy: 0.5802\n",
            "Epoch 92: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 92: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 92: accuracy did not improve from 0.78125\n",
            " 87/121 [====================>.........] - ETA: 0s - loss: 3.2297 - accuracy: 0.5790\n",
            "Epoch 92: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 92: accuracy did not improve from 0.78125\n",
            " 97/121 [=======================>......] - ETA: 0s - loss: 3.2467 - accuracy: 0.5760\n",
            "Epoch 92: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 92: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 92: accuracy did not improve from 0.78125\n",
            "110/121 [==========================>...] - ETA: 0s - loss: 3.2326 - accuracy: 0.5781\n",
            "Epoch 92: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 92: accuracy did not improve from 0.78125\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 3.2469 - accuracy: 0.5754\n",
            "Epoch 93/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 4.2166 - accuracy: 0.4375\n",
            "Epoch 93: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 93: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 93: accuracy did not improve from 0.78125\n",
            " 15/121 [==>...........................] - ETA: 0s - loss: 3.0819 - accuracy: 0.5896\n",
            "Epoch 93: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 93: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 93: accuracy did not improve from 0.78125\n",
            " 30/121 [======>.......................] - ETA: 0s - loss: 3.1163 - accuracy: 0.5823\n",
            "Epoch 93: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 93: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 93: accuracy did not improve from 0.78125\n",
            " 45/121 [==========>...................] - ETA: 0s - loss: 3.1604 - accuracy: 0.5840\n",
            "Epoch 93: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 93: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 93: accuracy did not improve from 0.78125\n",
            " 61/121 [==============>...............] - ETA: 0s - loss: 3.1641 - accuracy: 0.5774\n",
            "Epoch 93: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 93: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 93: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 93: accuracy did not improve from 0.78125\n",
            " 78/121 [==================>...........] - ETA: 0s - loss: 3.1540 - accuracy: 0.5793\n",
            "Epoch 93: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 93: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 93: accuracy did not improve from 0.78125\n",
            " 93/121 [======================>.......] - ETA: 0s - loss: 3.2103 - accuracy: 0.5796\n",
            "Epoch 93: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 93: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 93: accuracy did not improve from 0.78125\n",
            "111/121 [==========================>...] - ETA: 0s - loss: 3.2435 - accuracy: 0.5774\n",
            "Epoch 93: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 93: accuracy did not improve from 0.78125\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 3.2469 - accuracy: 0.5754\n",
            "Epoch 94/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.6752 - accuracy: 0.6250\n",
            "Epoch 94: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 94: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 94: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 94: accuracy did not improve from 0.78125\n",
            " 21/121 [====>.........................] - ETA: 0s - loss: 3.1213 - accuracy: 0.6057\n",
            "Epoch 94: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 94: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 94: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 94: accuracy did not improve from 0.78125\n",
            " 41/121 [=========>....................] - ETA: 0s - loss: 3.1772 - accuracy: 0.5823\n",
            "Epoch 94: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 94: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 94: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 94: accuracy did not improve from 0.78125\n",
            " 60/121 [=============>................] - ETA: 0s - loss: 3.2300 - accuracy: 0.5786\n",
            "Epoch 94: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 94: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 94: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 94: accuracy did not improve from 0.78125\n",
            " 79/121 [==================>...........] - ETA: 0s - loss: 3.2680 - accuracy: 0.5716\n",
            "Epoch 94: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 94: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 94: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 94: accuracy did not improve from 0.78125\n",
            " 97/121 [=======================>......] - ETA: 0s - loss: 3.2457 - accuracy: 0.5744\n",
            "Epoch 94: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 94: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 94: accuracy did not improve from 0.78125\n",
            "115/121 [===========================>..] - ETA: 0s - loss: 3.2662 - accuracy: 0.5734\n",
            "Epoch 94: accuracy did not improve from 0.78125\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 3.2469 - accuracy: 0.5754\n",
            "Epoch 95/100\n",
            "\n",
            "Epoch 95: accuracy did not improve from 0.78125\n",
            "  1/121 [..............................] - ETA: 0s - loss: 3.9307 - accuracy: 0.5000\n",
            "Epoch 95: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 95: accuracy did not improve from 0.78125\n",
            " 12/121 [=>............................] - ETA: 0s - loss: 3.1351 - accuracy: 0.5677\n",
            "Epoch 95: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 95: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 95: accuracy did not improve from 0.78125\n",
            " 27/121 [=====>........................] - ETA: 0s - loss: 3.1436 - accuracy: 0.5810\n",
            "Epoch 95: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 95: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 95: accuracy did not improve from 0.78125\n",
            " 42/121 [=========>....................] - ETA: 0s - loss: 3.2772 - accuracy: 0.5848\n",
            "Epoch 95: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 95: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 95: accuracy did not improve from 0.78125\n",
            " 58/121 [=============>................] - ETA: 0s - loss: 3.3267 - accuracy: 0.5781\n",
            "Epoch 95: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 95: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 95: accuracy did not improve from 0.78125\n",
            " 72/121 [================>.............] - ETA: 0s - loss: 3.2751 - accuracy: 0.5881\n",
            "Epoch 95: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 95: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 95: accuracy did not improve from 0.78125\n",
            " 87/121 [====================>.........] - ETA: 0s - loss: 3.2538 - accuracy: 0.5823\n",
            "Epoch 95: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 95: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 95: accuracy did not improve from 0.78125\n",
            "101/121 [========================>.....] - ETA: 0s - loss: 3.2292 - accuracy: 0.5823\n",
            "Epoch 95: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 95: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 95: accuracy did not improve from 0.78125\n",
            "117/121 [============================>.] - ETA: 0s - loss: 3.2471 - accuracy: 0.5759\n",
            "Epoch 95: accuracy did not improve from 0.78125\n",
            "121/121 [==============================] - 0s 4ms/step - loss: 3.2469 - accuracy: 0.5754\n",
            "Epoch 96/100\n",
            "  1/121 [..............................] - ETA: 1s - loss: 2.1965 - accuracy: 0.5938\n",
            "Epoch 96: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 96: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 96: accuracy did not improve from 0.78125\n",
            " 16/121 [==>...........................] - ETA: 0s - loss: 3.1424 - accuracy: 0.5703\n",
            "Epoch 96: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 96: accuracy did not improve from 0.78125\n",
            " 29/121 [======>.......................] - ETA: 0s - loss: 3.2360 - accuracy: 0.5787\n",
            "Epoch 96: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 96: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 96: accuracy did not improve from 0.78125\n",
            " 44/121 [=========>....................] - ETA: 0s - loss: 3.1812 - accuracy: 0.5881\n",
            "Epoch 96: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 96: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 96: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 96: accuracy did not improve from 0.78125\n",
            " 61/121 [==============>...............] - ETA: 0s - loss: 3.2501 - accuracy: 0.5825\n",
            "Epoch 96: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 96: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 96: accuracy did not improve from 0.78125\n",
            " 77/121 [==================>...........] - ETA: 0s - loss: 3.2938 - accuracy: 0.5714\n",
            "Epoch 96: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 96: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 96: accuracy did not improve from 0.78125\n",
            " 93/121 [======================>.......] - ETA: 0s - loss: 3.2745 - accuracy: 0.5722\n",
            "Epoch 96: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 96: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 96: accuracy did not improve from 0.78125\n",
            "109/121 [==========================>...] - ETA: 0s - loss: 3.2520 - accuracy: 0.5740\n",
            "Epoch 96: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 96: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 96: accuracy did not improve from 0.78125\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 3.2469 - accuracy: 0.5754\n",
            "Epoch 97/100\n",
            "  1/121 [..............................] - ETA: 1s - loss: 3.0597 - accuracy: 0.6562\n",
            "Epoch 97: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 97: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 97: accuracy did not improve from 0.78125\n",
            " 17/121 [===>..........................] - ETA: 0s - loss: 3.0773 - accuracy: 0.6121\n",
            "Epoch 97: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 97: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 97: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 97: accuracy did not improve from 0.78125\n",
            " 36/121 [=======>......................] - ETA: 0s - loss: 3.2722 - accuracy: 0.5833\n",
            "Epoch 97: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 97: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 97: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 97: accuracy did not improve from 0.78125\n",
            " 55/121 [============>.................] - ETA: 0s - loss: 3.2330 - accuracy: 0.5875\n",
            "Epoch 97: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 97: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 97: accuracy did not improve from 0.78125\n",
            " 72/121 [================>.............] - ETA: 0s - loss: 3.2417 - accuracy: 0.5751\n",
            "Epoch 97: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 97: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 97: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 97: accuracy did not improve from 0.78125\n",
            " 89/121 [=====================>........] - ETA: 0s - loss: 3.2485 - accuracy: 0.5776\n",
            "Epoch 97: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 97: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 97: accuracy did not improve from 0.78125\n",
            "108/121 [=========================>....] - ETA: 0s - loss: 3.2643 - accuracy: 0.5729\n",
            "Epoch 97: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 97: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 97: accuracy did not improve from 0.78125\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 3.2469 - accuracy: 0.5754\n",
            "Epoch 98/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 4.5923 - accuracy: 0.4688\n",
            "Epoch 98: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 98: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 98: accuracy did not improve from 0.78125\n",
            " 15/121 [==>...........................] - ETA: 0s - loss: 3.4764 - accuracy: 0.5542\n",
            "Epoch 98: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 98: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 98: accuracy did not improve from 0.78125\n",
            " 28/121 [=====>........................] - ETA: 0s - loss: 3.2428 - accuracy: 0.5692\n",
            "Epoch 98: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 98: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 98: accuracy did not improve from 0.78125\n",
            " 44/121 [=========>....................] - ETA: 0s - loss: 3.2385 - accuracy: 0.5810\n",
            "Epoch 98: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 98: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 98: accuracy did not improve from 0.78125\n",
            " 60/121 [=============>................] - ETA: 0s - loss: 3.1878 - accuracy: 0.5828\n",
            "Epoch 98: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 98: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 98: accuracy did not improve from 0.78125\n",
            " 76/121 [=================>............] - ETA: 0s - loss: 3.2301 - accuracy: 0.5794\n",
            "Epoch 98: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 98: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 98: accuracy did not improve from 0.78125\n",
            " 88/121 [====================>.........] - ETA: 0s - loss: 3.2588 - accuracy: 0.5749\n",
            "Epoch 98: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 98: accuracy did not improve from 0.78125\n",
            "100/121 [=======================>......] - ETA: 0s - loss: 3.2497 - accuracy: 0.5728\n",
            "Epoch 98: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 98: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 98: accuracy did not improve from 0.78125\n",
            "115/121 [===========================>..] - ETA: 0s - loss: 3.2561 - accuracy: 0.5758\n",
            "Epoch 98: accuracy did not improve from 0.78125\n",
            "121/121 [==============================] - 0s 4ms/step - loss: 3.2469 - accuracy: 0.5754\n",
            "Epoch 99/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.9600 - accuracy: 0.6250\n",
            "Epoch 99: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 99: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 99: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 99: accuracy did not improve from 0.78125\n",
            " 17/121 [===>..........................] - ETA: 0s - loss: 3.3050 - accuracy: 0.5790\n",
            "Epoch 99: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 99: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 99: accuracy did not improve from 0.78125\n",
            " 32/121 [======>.......................] - ETA: 0s - loss: 3.2517 - accuracy: 0.5957\n",
            "Epoch 99: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 99: accuracy did not improve from 0.78125\n",
            " 42/121 [=========>....................] - ETA: 0s - loss: 3.1860 - accuracy: 0.5960\n",
            "Epoch 99: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 99: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 99: accuracy did not improve from 0.78125\n",
            " 57/121 [=============>................] - ETA: 0s - loss: 3.2725 - accuracy: 0.5844\n",
            "Epoch 99: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 99: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 99: accuracy did not improve from 0.78125\n",
            " 74/121 [=================>............] - ETA: 0s - loss: 3.2692 - accuracy: 0.5781\n",
            "Epoch 99: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 99: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 99: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 99: accuracy did not improve from 0.78125\n",
            " 92/121 [=====================>........] - ETA: 0s - loss: 3.2735 - accuracy: 0.5727\n",
            "Epoch 99: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 99: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 99: accuracy did not improve from 0.78125\n",
            "109/121 [==========================>...] - ETA: 0s - loss: 3.2291 - accuracy: 0.5743\n",
            "Epoch 99: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 99: accuracy did not improve from 0.78125\n",
            "121/121 [==============================] - 0s 4ms/step - loss: 3.2469 - accuracy: 0.5754\n",
            "Epoch 100/100\n",
            "\n",
            "Epoch 100: accuracy did not improve from 0.78125\n",
            "  1/121 [..............................] - ETA: 1s - loss: 2.9655 - accuracy: 0.4688\n",
            "Epoch 100: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 100: accuracy did not improve from 0.78125\n",
            " 14/121 [==>...........................] - ETA: 0s - loss: 3.3101 - accuracy: 0.5312\n",
            "Epoch 100: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 100: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 100: accuracy did not improve from 0.78125\n",
            " 26/121 [=====>........................] - ETA: 0s - loss: 3.2329 - accuracy: 0.5673\n",
            "Epoch 100: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 100: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 100: accuracy did not improve from 0.78125\n",
            " 41/121 [=========>....................] - ETA: 0s - loss: 3.2030 - accuracy: 0.5800\n",
            "Epoch 100: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 100: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 100: accuracy did not improve from 0.78125\n",
            " 57/121 [=============>................] - ETA: 0s - loss: 3.1858 - accuracy: 0.5817\n",
            "Epoch 100: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 100: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 100: accuracy did not improve from 0.78125\n",
            " 74/121 [=================>............] - ETA: 0s - loss: 3.1817 - accuracy: 0.5878\n",
            "Epoch 100: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 100: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 100: accuracy did not improve from 0.78125\n",
            " 90/121 [=====================>........] - ETA: 0s - loss: 3.1867 - accuracy: 0.5833\n",
            "Epoch 100: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 100: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 100: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 100: accuracy did not improve from 0.78125\n",
            "106/121 [=========================>....] - ETA: 0s - loss: 3.2217 - accuracy: 0.5775\n",
            "Epoch 100: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 100: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 100: accuracy did not improve from 0.78125\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 3.2469 - accuracy: 0.5754\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model using the test data\n",
        "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=1)\n",
        "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ScXOhixnu_nu",
        "outputId": "eab032b4-29a0-4ba5-8f2d-b1e60d0c1d02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "41/41 [==============================] - 0s 2ms/step - loss: 3.2609 - accuracy: 0.5776\n",
            "Loss: 3.260925531387329, Accuracy: 0.5775526165962219\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JkscMHgdu_tq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#NN Dropping Only Computer Science\n",
        "\n",
        "summary of model\n",
        "41/41 [==============================] - \n",
        "\n",
        "Loss: 2.330411672592163, \n",
        "\n",
        "Accuracy: 0.6297739744186401"
      ],
      "metadata": {
        "id": "EKp1dEYTwjgF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "comp_data = cat_data.copy()\n",
        "comp_data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352
        },
        "id": "eIZ1au1YwoH6",
        "outputId": "16a3407f-ed92-4b80-dfd8-820b075991e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Grade  Section_Grade  Course_AP Research (Capstone Year 2)  \\\n",
              "0      9          96.67                                     0   \n",
              "1      9          87.92                                     0   \n",
              "2      9          86.02                                     0   \n",
              "3      9          88.89                                     0   \n",
              "4      9          88.49                                     0   \n",
              "\n",
              "   Course_AP Seminar (Capstone Year 1)  Course_Algebra II  \\\n",
              "0                                    0                  0   \n",
              "1                                    0                  0   \n",
              "2                                    0                  0   \n",
              "3                                    0                  0   \n",
              "4                                    0                  0   \n",
              "\n",
              "   Course_Algebra II Honors  Course_Anatomy and Physiology Honors  \\\n",
              "0                         0                                     0   \n",
              "1                         0                                     0   \n",
              "2                         0                                     0   \n",
              "3                         0                                     0   \n",
              "4                         0                                     0   \n",
              "\n",
              "   Course_Art History AP  Course_Artificial Intelligence Post-AP  \\\n",
              "0                      0                                       0   \n",
              "1                      0                                       0   \n",
              "2                      0                                       0   \n",
              "3                      0                                       0   \n",
              "4                      0                                       0   \n",
              "\n",
              "   Course_Astronomy Honors  ...  Course_Type_Computer Science  \\\n",
              "0                        0  ...                             0   \n",
              "1                        0  ...                             0   \n",
              "2                        0  ...                             0   \n",
              "3                        0  ...                             0   \n",
              "4                        0  ...                             0   \n",
              "\n",
              "   Course_Type_English  Course_Type_Entrepreneurship  \\\n",
              "0                    1                             0   \n",
              "1                    0                             0   \n",
              "2                    0                             0   \n",
              "3                    0                             0   \n",
              "4                    0                             0   \n",
              "\n",
              "   Course_Type_Foreign Language  Course_Type_Humanities  \\\n",
              "0                             0                       0   \n",
              "1                             1                       0   \n",
              "2                             0                       0   \n",
              "3                             0                       0   \n",
              "4                             0                       1   \n",
              "\n",
              "   Course_Type_Law and Politics  Course_Type_Math  Course_Type_Psychology  \\\n",
              "0                             0                 0                       0   \n",
              "1                             0                 0                       0   \n",
              "2                             0                 0                       0   \n",
              "3                             0                 0                       0   \n",
              "4                             0                 0                       0   \n",
              "\n",
              "   Course_Type_Research  Course_Type_Science  \n",
              "0                     0                    0  \n",
              "1                     0                    0  \n",
              "2                     0                    1  \n",
              "3                     0                    1  \n",
              "4                     0                    0  \n",
              "\n",
              "[5 rows x 118 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c30662fe-6865-450f-be4b-f7db5ae13dd0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Grade</th>\n",
              "      <th>Section_Grade</th>\n",
              "      <th>Course_AP Research (Capstone Year 2)</th>\n",
              "      <th>Course_AP Seminar (Capstone Year 1)</th>\n",
              "      <th>Course_Algebra II</th>\n",
              "      <th>Course_Algebra II Honors</th>\n",
              "      <th>Course_Anatomy and Physiology Honors</th>\n",
              "      <th>Course_Art History AP</th>\n",
              "      <th>Course_Artificial Intelligence Post-AP</th>\n",
              "      <th>Course_Astronomy Honors</th>\n",
              "      <th>...</th>\n",
              "      <th>Course_Type_Computer Science</th>\n",
              "      <th>Course_Type_English</th>\n",
              "      <th>Course_Type_Entrepreneurship</th>\n",
              "      <th>Course_Type_Foreign Language</th>\n",
              "      <th>Course_Type_Humanities</th>\n",
              "      <th>Course_Type_Law and Politics</th>\n",
              "      <th>Course_Type_Math</th>\n",
              "      <th>Course_Type_Psychology</th>\n",
              "      <th>Course_Type_Research</th>\n",
              "      <th>Course_Type_Science</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>9</td>\n",
              "      <td>96.67</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>9</td>\n",
              "      <td>87.92</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>9</td>\n",
              "      <td>86.02</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9</td>\n",
              "      <td>88.89</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9</td>\n",
              "      <td>88.49</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 118 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c30662fe-6865-450f-be4b-f7db5ae13dd0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c30662fe-6865-450f-be4b-f7db5ae13dd0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c30662fe-6865-450f-be4b-f7db5ae13dd0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split our preprocessed data into our features and target arrays\n",
        "X = comp_data.drop('Course_Type_Computer Science', axis=1).values\n",
        "y = comp_data['Course_Type_Computer Science'].values\n",
        "\n",
        "# Split the preprocessed data into a training and testing dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=13)"
      ],
      "metadata": {
        "id": "2QHnLYwFxCQW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a StandardScaler instances\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit the StandardScaler\n",
        "X_scaler = scaler.fit(X_train)\n",
        "\n",
        "# Scale the data\n",
        "X_train_scaled = X_scaler.transform(X_train)\n",
        "X_test_scaled = X_scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "arK13hL8xCpU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
        "input = X_train_scaled.shape[1]\n",
        "nn = tf.keras.models.Sequential()\n",
        "\n",
        "# First hidden layer\n",
        "nn.add(tf.keras.layers.Dense(units=5, activation=\"relu\", input_dim=input))\n",
        "\n",
        "# Check the structure of the model\n",
        "nn.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DCU_Iq_rxCx9",
        "outputId": "bf2cd39d-19d7-4071-805a-491ebfbc627d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_1 (Dense)             (None, 5)                 590       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 590\n",
            "Trainable params: 590\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Compile the model\n",
        "nn.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "fHcziaIpxVCd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "checkpoint = ModelCheckpoint(\"best_model.hdf5\", monitor='accuracy', verbose=1,\n",
        "    save_best_only=True, mode='auto', save_freq=5)\n",
        "\n",
        "fit_model = nn.fit(X_train_scaled, y_train, epochs=100, verbose=1, callbacks=[checkpoint])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JHTvDs2OxYs9",
        "outputId": "b1c5e814-d4a4-4132-f551-d5b3fb87066a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Epoch 1: accuracy did not improve from 0.20625\n",
            "100/121 [=======================>......] - ETA: 0s - loss: 2.9481 - accuracy: 0.2022\n",
            "Epoch 1: accuracy improved from 0.20625 to 0.20744, saving model to best_model.hdf5\n",
            "\n",
            "Epoch 1: accuracy improved from 0.20744 to 0.20966, saving model to best_model.hdf5\n",
            "110/121 [==========================>...] - ETA: 0s - loss: 2.9116 - accuracy: 0.2097\n",
            "Epoch 1: accuracy improved from 0.20966 to 0.21033, saving model to best_model.hdf5\n",
            "\n",
            "Epoch 1: accuracy did not improve from 0.21033\n",
            "121/121 [==============================] - 1s 4ms/step - loss: 2.8754 - accuracy: 0.2095\n",
            "Epoch 2/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.1937 - accuracy: 0.2500\n",
            "Epoch 2: accuracy did not improve from 0.21033\n",
            "\n",
            "Epoch 2: accuracy did not improve from 0.21033\n",
            "\n",
            "Epoch 2: accuracy improved from 0.21033 to 0.23438, saving model to best_model.hdf5\n",
            " 14/121 [==>...........................] - ETA: 0s - loss: 2.6971 - accuracy: 0.2344\n",
            "Epoch 2: accuracy improved from 0.23438 to 0.23684, saving model to best_model.hdf5\n",
            "\n",
            "Epoch 2: accuracy improved from 0.23684 to 0.24219, saving model to best_model.hdf5\n",
            " 24/121 [====>.........................] - ETA: 0s - loss: 2.6740 - accuracy: 0.2422\n",
            "Epoch 2: accuracy improved from 0.24219 to 0.24461, saving model to best_model.hdf5\n",
            "\n",
            "Epoch 2: accuracy did not improve from 0.24461\n",
            " 36/121 [=======>......................] - ETA: 0s - loss: 2.6951 - accuracy: 0.2413\n",
            "Epoch 2: accuracy did not improve from 0.24461\n",
            "\n",
            "Epoch 2: accuracy did not improve from 0.24461\n",
            "\n",
            "Epoch 2: accuracy did not improve from 0.24461\n",
            "\n",
            "Epoch 2: accuracy did not improve from 0.24461\n",
            " 54/121 [============>.................] - ETA: 0s - loss: 2.6416 - accuracy: 0.2413\n",
            "Epoch 2: accuracy did not improve from 0.24461\n",
            "\n",
            "Epoch 2: accuracy improved from 0.24461 to 0.24658, saving model to best_model.hdf5\n",
            " 66/121 [===============>..............] - ETA: 0s - loss: 2.6260 - accuracy: 0.2462\n",
            "Epoch 2: accuracy did not improve from 0.24658\n",
            "\n",
            "Epoch 2: accuracy did not improve from 0.24658\n",
            "\n",
            "Epoch 2: accuracy did not improve from 0.24658\n",
            " 80/121 [==================>...........] - ETA: 0s - loss: 2.5860 - accuracy: 0.2453\n",
            "Epoch 2: accuracy did not improve from 0.24658\n",
            "\n",
            "Epoch 2: accuracy did not improve from 0.24658\n",
            "\n",
            "Epoch 2: accuracy did not improve from 0.24658\n",
            " 95/121 [======================>.......] - ETA: 0s - loss: 2.5549 - accuracy: 0.2431\n",
            "Epoch 2: accuracy did not improve from 0.24658\n",
            "\n",
            "Epoch 2: accuracy improved from 0.24658 to 0.24760, saving model to best_model.hdf5\n",
            "107/121 [=========================>....] - ETA: 0s - loss: 2.5415 - accuracy: 0.2488\n",
            "Epoch 2: accuracy improved from 0.24760 to 0.24799, saving model to best_model.hdf5\n",
            "\n",
            "Epoch 2: accuracy did not improve from 0.24799\n",
            "\n",
            "Epoch 2: accuracy improved from 0.24799 to 0.24842, saving model to best_model.hdf5\n",
            "121/121 [==============================] - 1s 4ms/step - loss: 2.5410 - accuracy: 0.2495\n",
            "Epoch 3/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.0591 - accuracy: 0.1875\n",
            "Epoch 3: accuracy improved from 0.24842 to 0.25000, saving model to best_model.hdf5\n",
            "\n",
            "Epoch 3: accuracy did not improve from 0.25000\n",
            "\n",
            "Epoch 3: accuracy improved from 0.25000 to 0.26202, saving model to best_model.hdf5\n",
            " 13/121 [==>...........................] - ETA: 0s - loss: 2.4360 - accuracy: 0.2620\n",
            "Epoch 3: accuracy improved from 0.26202 to 0.26562, saving model to best_model.hdf5\n",
            "\n",
            "Epoch 3: accuracy improved from 0.26562 to 0.27038, saving model to best_model.hdf5\n",
            " 23/121 [====>.........................] - ETA: 0s - loss: 2.4122 - accuracy: 0.2704\n",
            "Epoch 3: accuracy did not improve from 0.27038\n",
            "\n",
            "Epoch 3: accuracy did not improve from 0.27038\n",
            "\n",
            "Epoch 3: accuracy did not improve from 0.27038\n",
            " 42/121 [=========>....................] - ETA: 0s - loss: 2.4627 - accuracy: 0.2775\n",
            "Epoch 3: accuracy improved from 0.27038 to 0.27616, saving model to best_model.hdf5\n",
            "\n",
            "Epoch 3: accuracy improved from 0.27616 to 0.27734, saving model to best_model.hdf5\n",
            " 50/121 [===========>..................] - ETA: 0s - loss: 2.4716 - accuracy: 0.2763\n",
            "Epoch 3: accuracy improved from 0.27734 to 0.28007, saving model to best_model.hdf5\n",
            "\n",
            "Epoch 3: accuracy improved from 0.28007 to 0.28179, saving model to best_model.hdf5\n",
            " 58/121 [=============>................] - ETA: 0s - loss: 2.4610 - accuracy: 0.2818\n",
            "Epoch 3: accuracy improved from 0.28179 to 0.28423, saving model to best_model.hdf5\n",
            "\n",
            "Epoch 3: accuracy improved from 0.28423 to 0.28952, saving model to best_model.hdf5\n",
            " 68/121 [===============>..............] - ETA: 0s - loss: 2.4575 - accuracy: 0.2895\n",
            "Epoch 3: accuracy improved from 0.28952 to 0.29666, saving model to best_model.hdf5\n",
            "\n",
            "Epoch 3: accuracy improved from 0.29666 to 0.29848, saving model to best_model.hdf5\n",
            " 78/121 [==================>...........] - ETA: 0s - loss: 2.4498 - accuracy: 0.2985\n",
            "Epoch 3: accuracy improved from 0.29848 to 0.29970, saving model to best_model.hdf5\n",
            "\n",
            "Epoch 3: accuracy improved from 0.29970 to 0.30114, saving model to best_model.hdf5\n",
            " 88/121 [====================>.........] - ETA: 0s - loss: 2.4508 - accuracy: 0.3011\n",
            "Epoch 3: accuracy improved from 0.30114 to 0.30578, saving model to best_model.hdf5\n",
            "\n",
            "Epoch 3: accuracy did not improve from 0.30578\n",
            "102/121 [========================>.....] - ETA: 0s - loss: 2.4856 - accuracy: 0.3018\n",
            "Epoch 3: accuracy did not improve from 0.30578\n",
            "\n",
            "Epoch 3: accuracy did not improve from 0.30578\n",
            "\n",
            "Epoch 3: accuracy did not improve from 0.30578\n",
            "\n",
            "Epoch 3: accuracy did not improve from 0.30578\n",
            "121/121 [==============================] - 1s 5ms/step - loss: 2.4649 - accuracy: 0.3046\n",
            "Epoch 4/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 1.8741 - accuracy: 0.3125\n",
            "Epoch 4: accuracy did not improve from 0.30578\n",
            "\n",
            "Epoch 4: accuracy improved from 0.30578 to 0.34375, saving model to best_model.hdf5\n",
            "\n",
            "Epoch 4: accuracy did not improve from 0.34375\n",
            " 13/121 [==>...........................] - ETA: 0s - loss: 2.3548 - accuracy: 0.3462\n",
            "Epoch 4: accuracy did not improve from 0.34375\n",
            "\n",
            "Epoch 4: accuracy did not improve from 0.34375\n",
            "\n",
            "Epoch 4: accuracy did not improve from 0.34375\n",
            " 31/121 [======>.......................] - ETA: 0s - loss: 2.4369 - accuracy: 0.3347\n",
            "Epoch 4: accuracy did not improve from 0.34375\n",
            "\n",
            "Epoch 4: accuracy did not improve from 0.34375\n",
            "\n",
            "Epoch 4: accuracy did not improve from 0.34375\n",
            "\n",
            "Epoch 4: accuracy did not improve from 0.34375\n",
            " 48/121 [==========>...................] - ETA: 0s - loss: 2.4284 - accuracy: 0.3411\n",
            "Epoch 4: accuracy did not improve from 0.34375\n",
            "\n",
            "Epoch 4: accuracy improved from 0.34375 to 0.34539, saving model to best_model.hdf5\n",
            " 61/121 [==============>...............] - ETA: 0s - loss: 2.4444 - accuracy: 0.3453\n",
            "Epoch 4: accuracy did not improve from 0.34539\n",
            "\n",
            "Epoch 4: accuracy improved from 0.34539 to 0.35075, saving model to best_model.hdf5\n",
            "\n",
            "Epoch 4: accuracy did not improve from 0.35075\n",
            " 72/121 [================>.............] - ETA: 0s - loss: 2.4245 - accuracy: 0.3494\n",
            "Epoch 4: accuracy improved from 0.35075 to 0.35146, saving model to best_model.hdf5\n",
            "\n",
            "Epoch 4: accuracy improved from 0.35146 to 0.35442, saving model to best_model.hdf5\n",
            " 82/121 [===================>..........] - ETA: 0s - loss: 2.4081 - accuracy: 0.3544\n",
            "Epoch 4: accuracy improved from 0.35442 to 0.35632, saving model to best_model.hdf5\n",
            "\n",
            "Epoch 4: accuracy improved from 0.35632 to 0.35802, saving model to best_model.hdf5\n",
            " 92/121 [=====================>........] - ETA: 0s - loss: 2.4206 - accuracy: 0.3580\n",
            "Epoch 4: accuracy did not improve from 0.35802\n",
            "\n",
            "Epoch 4: accuracy did not improve from 0.35802\n",
            "\n",
            "Epoch 4: accuracy improved from 0.35802 to 0.35806, saving model to best_model.hdf5\n",
            "107/121 [=========================>....] - ETA: 0s - loss: 2.4053 - accuracy: 0.3581\n",
            "Epoch 4: accuracy improved from 0.35806 to 0.36077, saving model to best_model.hdf5\n",
            "\n",
            "Epoch 4: accuracy improved from 0.36077 to 0.36538, saving model to best_model.hdf5\n",
            "121/121 [==============================] - 1s 4ms/step - loss: 2.3914 - accuracy: 0.3675\n",
            "Epoch 5/100\n",
            "\n",
            "Epoch 5: accuracy improved from 0.36538 to 0.43750, saving model to best_model.hdf5\n",
            "  1/121 [..............................] - ETA: 2s - loss: 1.6824 - accuracy: 0.4375\n",
            "Epoch 5: accuracy did not improve from 0.43750\n",
            "\n",
            "Epoch 5: accuracy did not improve from 0.43750\n",
            "\n",
            "Epoch 5: accuracy did not improve from 0.43750\n",
            " 17/121 [===>..........................] - ETA: 0s - loss: 2.2961 - accuracy: 0.4301\n",
            "Epoch 5: accuracy did not improve from 0.43750\n",
            "\n",
            "Epoch 5: accuracy did not improve from 0.43750\n",
            "\n",
            "Epoch 5: accuracy did not improve from 0.43750\n",
            " 33/121 [=======>......................] - ETA: 0s - loss: 2.3041 - accuracy: 0.4233\n",
            "Epoch 5: accuracy did not improve from 0.43750\n",
            "\n",
            "Epoch 5: accuracy did not improve from 0.43750\n",
            "\n",
            "Epoch 5: accuracy did not improve from 0.43750\n",
            " 50/121 [===========>..................] - ETA: 0s - loss: 2.3786 - accuracy: 0.4300\n",
            "Epoch 5: accuracy did not improve from 0.43750\n",
            "\n",
            "Epoch 5: accuracy did not improve from 0.43750\n",
            "\n",
            "Epoch 5: accuracy did not improve from 0.43750\n",
            "\n",
            "Epoch 5: accuracy did not improve from 0.43750\n",
            " 66/121 [===============>..............] - ETA: 0s - loss: 2.3820 - accuracy: 0.4375\n",
            "Epoch 5: accuracy did not improve from 0.43750\n",
            "\n",
            "Epoch 5: accuracy did not improve from 0.43750\n",
            "\n",
            "Epoch 5: accuracy improved from 0.43750 to 0.43943, saving model to best_model.hdf5\n",
            " 81/121 [===================>..........] - ETA: 0s - loss: 2.3473 - accuracy: 0.4394\n",
            "Epoch 5: accuracy improved from 0.43943 to 0.44440, saving model to best_model.hdf5\n",
            "\n",
            "Epoch 5: accuracy did not improve from 0.44440\n",
            " 91/121 [=====================>........] - ETA: 0s - loss: 2.3378 - accuracy: 0.4437\n",
            "Epoch 5: accuracy improved from 0.44440 to 0.44499, saving model to best_model.hdf5\n",
            "\n",
            "Epoch 5: accuracy did not improve from 0.44499\n",
            "101/121 [========================>.....] - ETA: 0s - loss: 2.3199 - accuracy: 0.4431\n",
            "Epoch 5: accuracy did not improve from 0.44499\n",
            "\n",
            "Epoch 5: accuracy improved from 0.44499 to 0.44566, saving model to best_model.hdf5\n",
            "114/121 [===========================>..] - ETA: 0s - loss: 2.2991 - accuracy: 0.4460\n",
            "Epoch 5: accuracy improved from 0.44566 to 0.44693, saving model to best_model.hdf5\n",
            "\n",
            "Epoch 5: accuracy did not improve from 0.44693\n",
            "121/121 [==============================] - 0s 4ms/step - loss: 2.3051 - accuracy: 0.4457\n",
            "Epoch 6/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.1579 - accuracy: 0.3125\n",
            "Epoch 6: accuracy did not improve from 0.44693\n",
            "\n",
            "Epoch 6: accuracy improved from 0.44693 to 0.45625, saving model to best_model.hdf5\n",
            "\n",
            "Epoch 6: accuracy improved from 0.45625 to 0.47917, saving model to best_model.hdf5\n",
            " 15/121 [==>...........................] - ETA: 0s - loss: 2.2053 - accuracy: 0.4792\n",
            "Epoch 6: accuracy did not improve from 0.47917\n",
            "\n",
            "Epoch 6: accuracy did not improve from 0.47917\n",
            "\n",
            "Epoch 6: accuracy did not improve from 0.47917\n",
            " 32/121 [======>.......................] - ETA: 0s - loss: 2.2189 - accuracy: 0.4678\n",
            "Epoch 6: accuracy did not improve from 0.47917\n",
            "\n",
            "Epoch 6: accuracy did not improve from 0.47917\n",
            "\n",
            "Epoch 6: accuracy did not improve from 0.47917\n",
            " 48/121 [==========>...................] - ETA: 0s - loss: 2.2481 - accuracy: 0.4746\n",
            "Epoch 6: accuracy did not improve from 0.47917\n",
            "\n",
            "Epoch 6: accuracy did not improve from 0.47917\n",
            "\n",
            "Epoch 6: accuracy improved from 0.47917 to 0.48073, saving model to best_model.hdf5\n",
            " 61/121 [==============>...............] - ETA: 0s - loss: 2.2468 - accuracy: 0.4816\n",
            "Epoch 6: accuracy improved from 0.48073 to 0.48702, saving model to best_model.hdf5\n",
            "\n",
            "Epoch 6: accuracy improved from 0.48702 to 0.48839, saving model to best_model.hdf5\n",
            " 70/121 [================>.............] - ETA: 0s - loss: 2.2227 - accuracy: 0.4884\n",
            "Epoch 6: accuracy did not improve from 0.48839\n",
            "\n",
            "Epoch 6: accuracy did not improve from 0.48839\n",
            "\n",
            "Epoch 6: accuracy did not improve from 0.48839\n",
            " 85/121 [====================>.........] - ETA: 0s - loss: 2.2117 - accuracy: 0.4860\n",
            "Epoch 6: accuracy did not improve from 0.48839\n",
            "\n",
            "Epoch 6: accuracy did not improve from 0.48839\n",
            "\n",
            "Epoch 6: accuracy did not improve from 0.48839\n",
            "100/121 [=======================>......] - ETA: 0s - loss: 2.2361 - accuracy: 0.4850\n",
            "Epoch 6: accuracy did not improve from 0.48839\n",
            "\n",
            "Epoch 6: accuracy did not improve from 0.48839\n",
            "\n",
            "Epoch 6: accuracy did not improve from 0.48839\n",
            "117/121 [============================>.] - ETA: 0s - loss: 2.2518 - accuracy: 0.4813\n",
            "Epoch 6: accuracy did not improve from 0.48839\n",
            "121/121 [==============================] - 0s 4ms/step - loss: 2.2402 - accuracy: 0.4834\n",
            "Epoch 7/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 3.0874 - accuracy: 0.3750\n",
            "Epoch 7: accuracy improved from 0.48839 to 0.49219, saving model to best_model.hdf5\n",
            "\n",
            "Epoch 7: accuracy improved from 0.49219 to 0.50694, saving model to best_model.hdf5\n",
            "  9/121 [=>............................] - ETA: 0s - loss: 2.0668 - accuracy: 0.5069\n",
            "Epoch 7: accuracy did not improve from 0.50694\n",
            "\n",
            "Epoch 7: accuracy improved from 0.50694 to 0.51480, saving model to best_model.hdf5\n",
            " 20/121 [===>..........................] - ETA: 0s - loss: 2.1013 - accuracy: 0.5172\n",
            "Epoch 7: accuracy did not improve from 0.51480\n",
            "\n",
            "Epoch 7: accuracy did not improve from 0.51480\n",
            "\n",
            "Epoch 7: accuracy did not improve from 0.51480\n",
            " 35/121 [=======>......................] - ETA: 0s - loss: 2.1475 - accuracy: 0.4857\n",
            "Epoch 7: accuracy did not improve from 0.51480\n",
            "\n",
            "Epoch 7: accuracy did not improve from 0.51480\n",
            "\n",
            "Epoch 7: accuracy did not improve from 0.51480\n",
            " 49/121 [===========>..................] - ETA: 0s - loss: 2.2122 - accuracy: 0.4802\n",
            "Epoch 7: accuracy did not improve from 0.51480\n",
            "\n",
            "Epoch 7: accuracy did not improve from 0.51480\n",
            " 63/121 [==============>...............] - ETA: 0s - loss: 2.2184 - accuracy: 0.4861\n",
            "Epoch 7: accuracy did not improve from 0.51480\n",
            "\n",
            "Epoch 7: accuracy did not improve from 0.51480\n",
            "\n",
            "Epoch 7: accuracy did not improve from 0.51480\n",
            "\n",
            "Epoch 7: accuracy did not improve from 0.51480\n",
            " 80/121 [==================>...........] - ETA: 0s - loss: 2.2058 - accuracy: 0.4898\n",
            "Epoch 7: accuracy did not improve from 0.51480\n",
            "\n",
            "Epoch 7: accuracy did not improve from 0.51480\n",
            "\n",
            "Epoch 7: accuracy did not improve from 0.51480\n",
            " 97/121 [=======================>......] - ETA: 0s - loss: 2.1978 - accuracy: 0.4903\n",
            "Epoch 7: accuracy did not improve from 0.51480\n",
            "\n",
            "Epoch 7: accuracy did not improve from 0.51480\n",
            "\n",
            "Epoch 7: accuracy did not improve from 0.51480\n",
            "\n",
            "Epoch 7: accuracy did not improve from 0.51480\n",
            "115/121 [===========================>..] - ETA: 0s - loss: 2.2123 - accuracy: 0.4927\n",
            "Epoch 7: accuracy did not improve from 0.51480\n",
            "121/121 [==============================] - 0s 4ms/step - loss: 2.2174 - accuracy: 0.4922\n",
            "Epoch 8/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.2950 - accuracy: 0.5312\n",
            "Epoch 8: accuracy improved from 0.51480 to 0.52083, saving model to best_model.hdf5\n",
            "\n",
            "Epoch 8: accuracy did not improve from 0.52083\n",
            " 11/121 [=>............................] - ETA: 0s - loss: 2.1132 - accuracy: 0.4972\n",
            "Epoch 8: accuracy did not improve from 0.52083\n",
            "\n",
            "Epoch 8: accuracy did not improve from 0.52083\n",
            "\n",
            "Epoch 8: accuracy improved from 0.52083 to 0.52310, saving model to best_model.hdf5\n",
            " 23/121 [====>.........................] - ETA: 0s - loss: 2.1154 - accuracy: 0.5231\n",
            "Epoch 8: accuracy did not improve from 0.52310\n",
            "\n",
            "Epoch 8: accuracy did not improve from 0.52310\n",
            "\n",
            "Epoch 8: accuracy did not improve from 0.52310\n",
            " 38/121 [========>.....................] - ETA: 0s - loss: 2.1598 - accuracy: 0.5000\n",
            "Epoch 8: accuracy did not improve from 0.52310\n",
            "\n",
            "Epoch 8: accuracy did not improve from 0.52310\n",
            "\n",
            "Epoch 8: accuracy did not improve from 0.52310\n",
            " 57/121 [=============>................] - ETA: 0s - loss: 2.2245 - accuracy: 0.4951\n",
            "Epoch 8: accuracy did not improve from 0.52310\n",
            "\n",
            "Epoch 8: accuracy did not improve from 0.52310\n",
            "\n",
            "Epoch 8: accuracy did not improve from 0.52310\n",
            "\n",
            "Epoch 8: accuracy did not improve from 0.52310\n",
            " 75/121 [=================>............] - ETA: 0s - loss: 2.2062 - accuracy: 0.5000\n",
            "Epoch 8: accuracy did not improve from 0.52310\n",
            "\n",
            "Epoch 8: accuracy did not improve from 0.52310\n",
            "\n",
            "Epoch 8: accuracy did not improve from 0.52310\n",
            "\n",
            "Epoch 8: accuracy did not improve from 0.52310\n",
            " 94/121 [======================>.......] - ETA: 0s - loss: 2.2276 - accuracy: 0.5007\n",
            "Epoch 8: accuracy did not improve from 0.52310\n",
            "\n",
            "Epoch 8: accuracy did not improve from 0.52310\n",
            "\n",
            "Epoch 8: accuracy did not improve from 0.52310\n",
            "\n",
            "Epoch 8: accuracy did not improve from 0.52310\n",
            "113/121 [===========================>..] - ETA: 0s - loss: 2.2303 - accuracy: 0.4994\n",
            "Epoch 8: accuracy did not improve from 0.52310\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.2113 - accuracy: 0.5003\n",
            "Epoch 9/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.2265 - accuracy: 0.5625\n",
            "Epoch 9: accuracy improved from 0.52310 to 0.56250, saving model to best_model.hdf5\n",
            "\n",
            "Epoch 9: accuracy did not improve from 0.56250\n",
            "\n",
            "Epoch 9: accuracy did not improve from 0.56250\n",
            " 12/121 [=>............................] - ETA: 0s - loss: 2.4179 - accuracy: 0.5000\n",
            "Epoch 9: accuracy did not improve from 0.56250\n",
            "\n",
            "Epoch 9: accuracy did not improve from 0.56250\n",
            " 26/121 [=====>........................] - ETA: 0s - loss: 2.3065 - accuracy: 0.4976\n",
            "Epoch 9: accuracy did not improve from 0.56250\n",
            "\n",
            "Epoch 9: accuracy did not improve from 0.56250\n",
            "\n",
            "Epoch 9: accuracy did not improve from 0.56250\n",
            "\n",
            "Epoch 9: accuracy did not improve from 0.56250\n",
            " 43/121 [=========>....................] - ETA: 0s - loss: 2.2069 - accuracy: 0.5116\n",
            "Epoch 9: accuracy did not improve from 0.56250\n",
            "\n",
            "Epoch 9: accuracy did not improve from 0.56250\n",
            "\n",
            "Epoch 9: accuracy did not improve from 0.56250\n",
            "\n",
            "Epoch 9: accuracy did not improve from 0.56250\n",
            " 62/121 [==============>...............] - ETA: 0s - loss: 2.2484 - accuracy: 0.5111\n",
            "Epoch 9: accuracy did not improve from 0.56250\n",
            "\n",
            "Epoch 9: accuracy did not improve from 0.56250\n",
            "\n",
            "Epoch 9: accuracy did not improve from 0.56250\n",
            "\n",
            "Epoch 9: accuracy did not improve from 0.56250\n",
            " 83/121 [===================>..........] - ETA: 0s - loss: 2.2119 - accuracy: 0.5120\n",
            "Epoch 9: accuracy did not improve from 0.56250\n",
            "\n",
            "Epoch 9: accuracy did not improve from 0.56250\n",
            "\n",
            "Epoch 9: accuracy did not improve from 0.56250\n",
            "\n",
            "Epoch 9: accuracy did not improve from 0.56250\n",
            "103/121 [========================>.....] - ETA: 0s - loss: 2.2047 - accuracy: 0.5115\n",
            "Epoch 9: accuracy did not improve from 0.56250\n",
            "\n",
            "Epoch 9: accuracy did not improve from 0.56250\n",
            "\n",
            "Epoch 9: accuracy did not improve from 0.56250\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.2069 - accuracy: 0.5070\n",
            "Epoch 10/100\n",
            "\n",
            "Epoch 10: accuracy did not improve from 0.56250\n",
            "  1/121 [..............................] - ETA: 0s - loss: 1.8243 - accuracy: 0.5000\n",
            "Epoch 10: accuracy did not improve from 0.56250\n",
            "\n",
            "Epoch 10: accuracy did not improve from 0.56250\n",
            "\n",
            "Epoch 10: accuracy did not improve from 0.56250\n",
            " 20/121 [===>..........................] - ETA: 0s - loss: 2.1652 - accuracy: 0.5203\n",
            "Epoch 10: accuracy did not improve from 0.56250\n",
            "\n",
            "Epoch 10: accuracy did not improve from 0.56250\n",
            "\n",
            "Epoch 10: accuracy did not improve from 0.56250\n",
            "\n",
            "Epoch 10: accuracy did not improve from 0.56250\n",
            " 38/121 [========>.....................] - ETA: 0s - loss: 2.2106 - accuracy: 0.5115\n",
            "Epoch 10: accuracy did not improve from 0.56250\n",
            "\n",
            "Epoch 10: accuracy did not improve from 0.56250\n",
            "\n",
            "Epoch 10: accuracy did not improve from 0.56250\n",
            "\n",
            "Epoch 10: accuracy did not improve from 0.56250\n",
            " 57/121 [=============>................] - ETA: 0s - loss: 2.2080 - accuracy: 0.5077\n",
            "Epoch 10: accuracy did not improve from 0.56250\n",
            "\n",
            "Epoch 10: accuracy did not improve from 0.56250\n",
            "\n",
            "Epoch 10: accuracy did not improve from 0.56250\n",
            "\n",
            "Epoch 10: accuracy did not improve from 0.56250\n",
            " 77/121 [==================>...........] - ETA: 0s - loss: 2.2097 - accuracy: 0.5085\n",
            "Epoch 10: accuracy did not improve from 0.56250\n",
            "\n",
            "Epoch 10: accuracy did not improve from 0.56250\n",
            "\n",
            "Epoch 10: accuracy did not improve from 0.56250\n",
            " 92/121 [=====================>........] - ETA: 0s - loss: 2.1844 - accuracy: 0.5102\n",
            "Epoch 10: accuracy did not improve from 0.56250\n",
            "\n",
            "Epoch 10: accuracy did not improve from 0.56250\n",
            "\n",
            "Epoch 10: accuracy did not improve from 0.56250\n",
            "107/121 [=========================>....] - ETA: 0s - loss: 2.1798 - accuracy: 0.5093\n",
            "Epoch 10: accuracy did not improve from 0.56250\n",
            "\n",
            "Epoch 10: accuracy did not improve from 0.56250\n",
            "\n",
            "Epoch 10: accuracy did not improve from 0.56250\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.2033 - accuracy: 0.5099\n",
            "Epoch 11/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.9576 - accuracy: 0.5000\n",
            "Epoch 11: accuracy did not improve from 0.56250\n",
            "\n",
            "Epoch 11: accuracy did not improve from 0.56250\n",
            "\n",
            "Epoch 11: accuracy did not improve from 0.56250\n",
            "\n",
            "Epoch 11: accuracy did not improve from 0.56250\n",
            " 21/121 [====>.........................] - ETA: 0s - loss: 2.2520 - accuracy: 0.5268\n",
            "Epoch 11: accuracy did not improve from 0.56250\n",
            "\n",
            "Epoch 11: accuracy did not improve from 0.56250\n",
            "\n",
            "Epoch 11: accuracy did not improve from 0.56250\n",
            " 37/121 [========>.....................] - ETA: 0s - loss: 2.2648 - accuracy: 0.5152\n",
            "Epoch 11: accuracy did not improve from 0.56250\n",
            "\n",
            "Epoch 11: accuracy did not improve from 0.56250\n",
            "\n",
            "Epoch 11: accuracy did not improve from 0.56250\n",
            "\n",
            "Epoch 11: accuracy did not improve from 0.56250\n",
            " 55/121 [============>.................] - ETA: 0s - loss: 2.2473 - accuracy: 0.5142\n",
            "Epoch 11: accuracy did not improve from 0.56250\n",
            "\n",
            "Epoch 11: accuracy did not improve from 0.56250\n",
            " 69/121 [================>.............] - ETA: 0s - loss: 2.2088 - accuracy: 0.5163\n",
            "Epoch 11: accuracy did not improve from 0.56250\n",
            "\n",
            "Epoch 11: accuracy did not improve from 0.56250\n",
            "\n",
            "Epoch 11: accuracy did not improve from 0.56250\n",
            "\n",
            "Epoch 11: accuracy did not improve from 0.56250\n",
            " 89/121 [=====================>........] - ETA: 0s - loss: 2.1994 - accuracy: 0.5105\n",
            "Epoch 11: accuracy did not improve from 0.56250\n",
            "\n",
            "Epoch 11: accuracy did not improve from 0.56250\n",
            "\n",
            "Epoch 11: accuracy did not improve from 0.56250\n",
            "\n",
            "Epoch 11: accuracy did not improve from 0.56250\n",
            "\n",
            "Epoch 11: accuracy did not improve from 0.56250\n",
            "110/121 [==========================>...] - ETA: 0s - loss: 2.2084 - accuracy: 0.5168\n",
            "Epoch 11: accuracy did not improve from 0.56250\n",
            "\n",
            "Epoch 11: accuracy did not improve from 0.56250\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.2004 - accuracy: 0.5166\n",
            "Epoch 12/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 1.8205 - accuracy: 0.5938\n",
            "Epoch 12: accuracy did not improve from 0.56250\n",
            "\n",
            "Epoch 12: accuracy did not improve from 0.56250\n",
            "\n",
            "Epoch 12: accuracy did not improve from 0.56250\n",
            " 16/121 [==>...........................] - ETA: 0s - loss: 2.0931 - accuracy: 0.5273\n",
            "Epoch 12: accuracy did not improve from 0.56250\n",
            "\n",
            "Epoch 12: accuracy did not improve from 0.56250\n",
            "\n",
            "Epoch 12: accuracy did not improve from 0.56250\n",
            " 33/121 [=======>......................] - ETA: 0s - loss: 2.0511 - accuracy: 0.5407\n",
            "Epoch 12: accuracy did not improve from 0.56250\n",
            "\n",
            "Epoch 12: accuracy did not improve from 0.56250\n",
            "\n",
            "Epoch 12: accuracy did not improve from 0.56250\n",
            "\n",
            "Epoch 12: accuracy did not improve from 0.56250\n",
            " 50/121 [===========>..................] - ETA: 0s - loss: 2.1537 - accuracy: 0.5300\n",
            "Epoch 12: accuracy did not improve from 0.56250\n",
            "\n",
            "Epoch 12: accuracy did not improve from 0.56250\n",
            "\n",
            "Epoch 12: accuracy did not improve from 0.56250\n",
            "\n",
            "Epoch 12: accuracy did not improve from 0.56250\n",
            " 69/121 [================>.............] - ETA: 0s - loss: 2.1584 - accuracy: 0.5294\n",
            "Epoch 12: accuracy did not improve from 0.56250\n",
            "\n",
            "Epoch 12: accuracy did not improve from 0.56250\n",
            "\n",
            "Epoch 12: accuracy did not improve from 0.56250\n",
            " 86/121 [====================>.........] - ETA: 0s - loss: 2.1867 - accuracy: 0.5254\n",
            "Epoch 12: accuracy did not improve from 0.56250\n",
            "\n",
            "Epoch 12: accuracy did not improve from 0.56250\n",
            "\n",
            "Epoch 12: accuracy did not improve from 0.56250\n",
            "\n",
            "Epoch 12: accuracy did not improve from 0.56250\n",
            "104/121 [========================>.....] - ETA: 0s - loss: 2.2084 - accuracy: 0.5225\n",
            "Epoch 12: accuracy did not improve from 0.56250\n",
            "\n",
            "Epoch 12: accuracy did not improve from 0.56250\n",
            "\n",
            "Epoch 12: accuracy did not improve from 0.56250\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.1978 - accuracy: 0.5242\n",
            "Epoch 13/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.1050 - accuracy: 0.5312\n",
            "Epoch 13: accuracy did not improve from 0.56250\n",
            "\n",
            "Epoch 13: accuracy did not improve from 0.56250\n",
            "\n",
            "Epoch 13: accuracy did not improve from 0.56250\n",
            "\n",
            "Epoch 13: accuracy did not improve from 0.56250\n",
            " 19/121 [===>..........................] - ETA: 0s - loss: 2.2688 - accuracy: 0.5197\n",
            "Epoch 13: accuracy did not improve from 0.56250\n",
            "\n",
            "Epoch 13: accuracy did not improve from 0.56250\n",
            "\n",
            "Epoch 13: accuracy did not improve from 0.56250\n",
            "\n",
            "Epoch 13: accuracy did not improve from 0.56250\n",
            " 38/121 [========>.....................] - ETA: 0s - loss: 2.2765 - accuracy: 0.5370\n",
            "Epoch 13: accuracy did not improve from 0.56250\n",
            "\n",
            "Epoch 13: accuracy did not improve from 0.56250\n",
            "\n",
            "Epoch 13: accuracy did not improve from 0.56250\n",
            " 56/121 [============>.................] - ETA: 0s - loss: 2.2095 - accuracy: 0.5391\n",
            "Epoch 13: accuracy did not improve from 0.56250\n",
            "\n",
            "Epoch 13: accuracy did not improve from 0.56250\n",
            "\n",
            "Epoch 13: accuracy did not improve from 0.56250\n",
            "\n",
            "Epoch 13: accuracy did not improve from 0.56250\n",
            " 74/121 [=================>............] - ETA: 0s - loss: 2.1246 - accuracy: 0.5452\n",
            "Epoch 13: accuracy did not improve from 0.56250\n",
            "\n",
            "Epoch 13: accuracy did not improve from 0.56250\n",
            "\n",
            "Epoch 13: accuracy did not improve from 0.56250\n",
            "\n",
            "Epoch 13: accuracy did not improve from 0.56250\n",
            " 93/121 [======================>.......] - ETA: 0s - loss: 2.1881 - accuracy: 0.5309\n",
            "Epoch 13: accuracy did not improve from 0.56250\n",
            "\n",
            "Epoch 13: accuracy did not improve from 0.56250\n",
            "\n",
            "Epoch 13: accuracy did not improve from 0.56250\n",
            "\n",
            "Epoch 13: accuracy did not improve from 0.56250\n",
            "113/121 [===========================>..] - ETA: 0s - loss: 2.1892 - accuracy: 0.5337\n",
            "Epoch 13: accuracy did not improve from 0.56250\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.1956 - accuracy: 0.5356\n",
            "Epoch 14/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 1.3464 - accuracy: 0.6562\n",
            "Epoch 14: accuracy improved from 0.56250 to 0.57812, saving model to best_model.hdf5\n",
            "\n",
            "Epoch 14: accuracy improved from 0.57812 to 0.58482, saving model to best_model.hdf5\n",
            "  9/121 [=>............................] - ETA: 0s - loss: 2.0621 - accuracy: 0.5833\n",
            "Epoch 14: accuracy did not improve from 0.58482\n",
            "\n",
            "Epoch 14: accuracy did not improve from 0.58482\n",
            "\n",
            "Epoch 14: accuracy did not improve from 0.58482\n",
            "\n",
            "Epoch 14: accuracy did not improve from 0.58482\n",
            " 27/121 [=====>........................] - ETA: 0s - loss: 2.0570 - accuracy: 0.5706\n",
            "Epoch 14: accuracy did not improve from 0.58482\n",
            "\n",
            "Epoch 14: accuracy did not improve from 0.58482\n",
            "\n",
            "Epoch 14: accuracy did not improve from 0.58482\n",
            " 46/121 [==========>...................] - ETA: 0s - loss: 2.1339 - accuracy: 0.5713\n",
            "Epoch 14: accuracy did not improve from 0.58482\n",
            "\n",
            "Epoch 14: accuracy did not improve from 0.58482\n",
            "\n",
            "Epoch 14: accuracy did not improve from 0.58482\n",
            "\n",
            "Epoch 14: accuracy did not improve from 0.58482\n",
            " 64/121 [==============>...............] - ETA: 0s - loss: 2.1684 - accuracy: 0.5669\n",
            "Epoch 14: accuracy did not improve from 0.58482\n",
            "\n",
            "Epoch 14: accuracy did not improve from 0.58482\n",
            "\n",
            "Epoch 14: accuracy did not improve from 0.58482\n",
            "\n",
            "Epoch 14: accuracy did not improve from 0.58482\n",
            " 83/121 [===================>..........] - ETA: 0s - loss: 2.1684 - accuracy: 0.5595\n",
            "Epoch 14: accuracy did not improve from 0.58482\n",
            "\n",
            "Epoch 14: accuracy did not improve from 0.58482\n",
            "\n",
            "Epoch 14: accuracy did not improve from 0.58482\n",
            "100/121 [=======================>......] - ETA: 0s - loss: 2.1894 - accuracy: 0.5609\n",
            "Epoch 14: accuracy did not improve from 0.58482\n",
            "\n",
            "Epoch 14: accuracy did not improve from 0.58482\n",
            "\n",
            "Epoch 14: accuracy did not improve from 0.58482\n",
            "115/121 [===========================>..] - ETA: 0s - loss: 2.1912 - accuracy: 0.5663\n",
            "Epoch 14: accuracy did not improve from 0.58482\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.1940 - accuracy: 0.5663\n",
            "Epoch 15/100\n",
            "\n",
            "Epoch 15: accuracy did not improve from 0.58482\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.7677 - accuracy: 0.5000\n",
            "Epoch 15: accuracy did not improve from 0.58482\n",
            "\n",
            "Epoch 15: accuracy did not improve from 0.58482\n",
            "\n",
            "Epoch 15: accuracy did not improve from 0.58482\n",
            " 20/121 [===>..........................] - ETA: 0s - loss: 2.2596 - accuracy: 0.5266\n",
            "Epoch 15: accuracy did not improve from 0.58482\n",
            "\n",
            "Epoch 15: accuracy did not improve from 0.58482\n",
            "\n",
            "Epoch 15: accuracy did not improve from 0.58482\n",
            "\n",
            "Epoch 15: accuracy did not improve from 0.58482\n",
            "\n",
            "Epoch 15: accuracy did not improve from 0.58482\n",
            " 42/121 [=========>....................] - ETA: 0s - loss: 2.1609 - accuracy: 0.5580\n",
            "Epoch 15: accuracy did not improve from 0.58482\n",
            "\n",
            "Epoch 15: accuracy did not improve from 0.58482\n",
            "\n",
            "Epoch 15: accuracy did not improve from 0.58482\n",
            "\n",
            "Epoch 15: accuracy did not improve from 0.58482\n",
            " 65/121 [===============>..............] - ETA: 0s - loss: 2.1734 - accuracy: 0.5683\n",
            "Epoch 15: accuracy did not improve from 0.58482\n",
            "\n",
            "Epoch 15: accuracy did not improve from 0.58482\n",
            "\n",
            "Epoch 15: accuracy did not improve from 0.58482\n",
            "\n",
            "Epoch 15: accuracy did not improve from 0.58482\n",
            " 84/121 [===================>..........] - ETA: 0s - loss: 2.1617 - accuracy: 0.5673\n",
            "Epoch 15: accuracy did not improve from 0.58482\n",
            "\n",
            "Epoch 15: accuracy did not improve from 0.58482\n",
            "\n",
            "Epoch 15: accuracy did not improve from 0.58482\n",
            "\n",
            "Epoch 15: accuracy did not improve from 0.58482\n",
            "103/121 [========================>.....] - ETA: 0s - loss: 2.1848 - accuracy: 0.5725\n",
            "Epoch 15: accuracy did not improve from 0.58482\n",
            "\n",
            "Epoch 15: accuracy did not improve from 0.58482\n",
            "\n",
            "Epoch 15: accuracy did not improve from 0.58482\n",
            "\n",
            "Epoch 15: accuracy did not improve from 0.58482\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.1928 - accuracy: 0.5738\n",
            "Epoch 16/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.0024 - accuracy: 0.6250\n",
            "Epoch 16: accuracy did not improve from 0.58482\n",
            "\n",
            "Epoch 16: accuracy did not improve from 0.58482\n",
            "\n",
            "Epoch 16: accuracy improved from 0.58482 to 0.59375, saving model to best_model.hdf5\n",
            " 15/121 [==>...........................] - ETA: 0s - loss: 2.1255 - accuracy: 0.5938\n",
            "Epoch 16: accuracy improved from 0.59375 to 0.60156, saving model to best_model.hdf5\n",
            "\n",
            "Epoch 16: accuracy did not improve from 0.60156\n",
            "\n",
            "Epoch 16: accuracy did not improve from 0.60156\n",
            " 30/121 [======>.......................] - ETA: 0s - loss: 2.1989 - accuracy: 0.5896\n",
            "Epoch 16: accuracy did not improve from 0.60156\n",
            "\n",
            "Epoch 16: accuracy did not improve from 0.60156\n",
            "\n",
            "Epoch 16: accuracy did not improve from 0.60156\n",
            "\n",
            "Epoch 16: accuracy did not improve from 0.60156\n",
            " 50/121 [===========>..................] - ETA: 0s - loss: 2.2514 - accuracy: 0.5838\n",
            "Epoch 16: accuracy did not improve from 0.60156\n",
            "\n",
            "Epoch 16: accuracy did not improve from 0.60156\n",
            "\n",
            "Epoch 16: accuracy did not improve from 0.60156\n",
            " 68/121 [===============>..............] - ETA: 0s - loss: 2.2016 - accuracy: 0.5790\n",
            "Epoch 16: accuracy did not improve from 0.60156\n",
            "\n",
            "Epoch 16: accuracy did not improve from 0.60156\n",
            "\n",
            "Epoch 16: accuracy did not improve from 0.60156\n",
            "\n",
            "Epoch 16: accuracy did not improve from 0.60156\n",
            " 85/121 [====================>.........] - ETA: 0s - loss: 2.1936 - accuracy: 0.5798\n",
            "Epoch 16: accuracy did not improve from 0.60156\n",
            "\n",
            "Epoch 16: accuracy did not improve from 0.60156\n",
            "\n",
            "Epoch 16: accuracy did not improve from 0.60156\n",
            "104/121 [========================>.....] - ETA: 0s - loss: 2.1791 - accuracy: 0.5820\n",
            "Epoch 16: accuracy did not improve from 0.60156\n",
            "\n",
            "Epoch 16: accuracy did not improve from 0.60156\n",
            "\n",
            "Epoch 16: accuracy did not improve from 0.60156\n",
            "\n",
            "Epoch 16: accuracy did not improve from 0.60156\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.1919 - accuracy: 0.5829\n",
            "Epoch 17/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.9602 - accuracy: 0.5000\n",
            "Epoch 17: accuracy did not improve from 0.60156\n",
            "\n",
            "Epoch 17: accuracy did not improve from 0.60156\n",
            "\n",
            "Epoch 17: accuracy did not improve from 0.60156\n",
            "\n",
            "Epoch 17: accuracy did not improve from 0.60156\n",
            "\n",
            "Epoch 17: accuracy did not improve from 0.60156\n",
            " 24/121 [====>.........................] - ETA: 0s - loss: 2.2152 - accuracy: 0.5990\n",
            "Epoch 17: accuracy did not improve from 0.60156\n",
            "\n",
            "Epoch 17: accuracy did not improve from 0.60156\n",
            "\n",
            "Epoch 17: accuracy did not improve from 0.60156\n",
            "\n",
            "Epoch 17: accuracy did not improve from 0.60156\n",
            " 45/121 [==========>...................] - ETA: 0s - loss: 2.1762 - accuracy: 0.5951\n",
            "Epoch 17: accuracy did not improve from 0.60156\n",
            "\n",
            "Epoch 17: accuracy did not improve from 0.60156\n",
            "\n",
            "Epoch 17: accuracy did not improve from 0.60156\n",
            "\n",
            "Epoch 17: accuracy did not improve from 0.60156\n",
            " 66/121 [===============>..............] - ETA: 0s - loss: 2.1444 - accuracy: 0.5923\n",
            "Epoch 17: accuracy did not improve from 0.60156\n",
            "\n",
            "Epoch 17: accuracy did not improve from 0.60156\n",
            "\n",
            "Epoch 17: accuracy did not improve from 0.60156\n",
            "\n",
            "Epoch 17: accuracy did not improve from 0.60156\n",
            " 85/121 [====================>.........] - ETA: 0s - loss: 2.1793 - accuracy: 0.5908\n",
            "Epoch 17: accuracy did not improve from 0.60156\n",
            "\n",
            "Epoch 17: accuracy did not improve from 0.60156\n",
            "\n",
            "Epoch 17: accuracy did not improve from 0.60156\n",
            "\n",
            "Epoch 17: accuracy did not improve from 0.60156\n",
            "104/121 [========================>.....] - ETA: 0s - loss: 2.2032 - accuracy: 0.5865\n",
            "Epoch 17: accuracy did not improve from 0.60156\n",
            "\n",
            "Epoch 17: accuracy did not improve from 0.60156\n",
            "\n",
            "Epoch 17: accuracy did not improve from 0.60156\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.1911 - accuracy: 0.5928\n",
            "Epoch 18/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.1960 - accuracy: 0.5000\n",
            "Epoch 18: accuracy improved from 0.60156 to 0.66667, saving model to best_model.hdf5\n",
            "\n",
            "Epoch 18: accuracy did not improve from 0.66667\n",
            " 10/121 [=>............................] - ETA: 0s - loss: 2.1937 - accuracy: 0.6281\n",
            "Epoch 18: accuracy did not improve from 0.66667\n",
            "\n",
            "Epoch 18: accuracy did not improve from 0.66667\n",
            "\n",
            "Epoch 18: accuracy did not improve from 0.66667\n",
            "\n",
            "Epoch 18: accuracy did not improve from 0.66667\n",
            " 28/121 [=====>........................] - ETA: 0s - loss: 2.2215 - accuracy: 0.6250\n",
            "Epoch 18: accuracy did not improve from 0.66667\n",
            "\n",
            "Epoch 18: accuracy did not improve from 0.66667\n",
            "\n",
            "Epoch 18: accuracy did not improve from 0.66667\n",
            " 43/121 [=========>....................] - ETA: 0s - loss: 2.2097 - accuracy: 0.6323\n",
            "Epoch 18: accuracy did not improve from 0.66667\n",
            "\n",
            "Epoch 18: accuracy did not improve from 0.66667\n",
            "\n",
            "Epoch 18: accuracy did not improve from 0.66667\n",
            " 58/121 [=============>................] - ETA: 0s - loss: 2.1745 - accuracy: 0.6304\n",
            "Epoch 18: accuracy did not improve from 0.66667\n",
            "\n",
            "Epoch 18: accuracy did not improve from 0.66667\n",
            "\n",
            "Epoch 18: accuracy did not improve from 0.66667\n",
            " 74/121 [=================>............] - ETA: 0s - loss: 2.1956 - accuracy: 0.6225\n",
            "Epoch 18: accuracy did not improve from 0.66667\n",
            "\n",
            "Epoch 18: accuracy did not improve from 0.66667\n",
            "\n",
            "Epoch 18: accuracy did not improve from 0.66667\n",
            " 91/121 [=====================>........] - ETA: 0s - loss: 2.2027 - accuracy: 0.6240\n",
            "Epoch 18: accuracy did not improve from 0.66667\n",
            "\n",
            "Epoch 18: accuracy did not improve from 0.66667\n",
            "\n",
            "Epoch 18: accuracy did not improve from 0.66667\n",
            "\n",
            "Epoch 18: accuracy did not improve from 0.66667\n",
            "112/121 [==========================>...] - ETA: 0s - loss: 2.1951 - accuracy: 0.6211\n",
            "Epoch 18: accuracy did not improve from 0.66667\n",
            "\n",
            "Epoch 18: accuracy did not improve from 0.66667\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.1906 - accuracy: 0.6242\n",
            "Epoch 19/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.0025 - accuracy: 0.6250\n",
            "Epoch 19: accuracy improved from 0.66667 to 0.70312, saving model to best_model.hdf5\n",
            "\n",
            "Epoch 19: accuracy did not improve from 0.70312\n",
            "  9/121 [=>............................] - ETA: 0s - loss: 2.3313 - accuracy: 0.6493\n",
            "Epoch 19: accuracy did not improve from 0.70312\n",
            "\n",
            "Epoch 19: accuracy did not improve from 0.70312\n",
            "\n",
            "Epoch 19: accuracy did not improve from 0.70312\n",
            " 24/121 [====>.........................] - ETA: 0s - loss: 2.0947 - accuracy: 0.6471\n",
            "Epoch 19: accuracy did not improve from 0.70312\n",
            "\n",
            "Epoch 19: accuracy did not improve from 0.70312\n",
            "\n",
            "Epoch 19: accuracy did not improve from 0.70312\n",
            "\n",
            "Epoch 19: accuracy did not improve from 0.70312\n",
            " 43/121 [=========>....................] - ETA: 0s - loss: 2.1630 - accuracy: 0.6337\n",
            "Epoch 19: accuracy did not improve from 0.70312\n",
            "\n",
            "Epoch 19: accuracy did not improve from 0.70312\n",
            "\n",
            "Epoch 19: accuracy did not improve from 0.70312\n",
            "\n",
            "Epoch 19: accuracy did not improve from 0.70312\n",
            " 62/121 [==============>...............] - ETA: 0s - loss: 2.1725 - accuracy: 0.6416\n",
            "Epoch 19: accuracy did not improve from 0.70312\n",
            "\n",
            "Epoch 19: accuracy did not improve from 0.70312\n",
            "\n",
            "Epoch 19: accuracy did not improve from 0.70312\n",
            "\n",
            "Epoch 19: accuracy did not improve from 0.70312\n",
            " 82/121 [===================>..........] - ETA: 0s - loss: 2.2148 - accuracy: 0.6376\n",
            "Epoch 19: accuracy did not improve from 0.70312\n",
            "\n",
            "Epoch 19: accuracy did not improve from 0.70312\n",
            "\n",
            "Epoch 19: accuracy did not improve from 0.70312\n",
            "\n",
            "Epoch 19: accuracy did not improve from 0.70312\n",
            "103/121 [========================>.....] - ETA: 0s - loss: 2.1773 - accuracy: 0.6377\n",
            "Epoch 19: accuracy did not improve from 0.70312\n",
            "\n",
            "Epoch 19: accuracy did not improve from 0.70312\n",
            "\n",
            "Epoch 19: accuracy did not improve from 0.70312\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.1902 - accuracy: 0.6349\n",
            "Epoch 20/100\n",
            "\n",
            "Epoch 20: accuracy did not improve from 0.70312\n",
            "  1/121 [..............................] - ETA: 0s - loss: 1.9062 - accuracy: 0.6875\n",
            "Epoch 20: accuracy did not improve from 0.70312\n",
            "\n",
            "Epoch 20: accuracy did not improve from 0.70312\n",
            "\n",
            "Epoch 20: accuracy did not improve from 0.70312\n",
            " 18/121 [===>..........................] - ETA: 0s - loss: 2.1569 - accuracy: 0.6580\n",
            "Epoch 20: accuracy did not improve from 0.70312\n",
            "\n",
            "Epoch 20: accuracy did not improve from 0.70312\n",
            "\n",
            "Epoch 20: accuracy did not improve from 0.70312\n",
            " 34/121 [=======>......................] - ETA: 0s - loss: 2.2221 - accuracy: 0.6369\n",
            "Epoch 20: accuracy did not improve from 0.70312\n",
            "\n",
            "Epoch 20: accuracy did not improve from 0.70312\n",
            "\n",
            "Epoch 20: accuracy did not improve from 0.70312\n",
            "\n",
            "Epoch 20: accuracy did not improve from 0.70312\n",
            " 51/121 [===========>..................] - ETA: 0s - loss: 2.1476 - accuracy: 0.6422\n",
            "Epoch 20: accuracy did not improve from 0.70312\n",
            "\n",
            "Epoch 20: accuracy did not improve from 0.70312\n",
            "\n",
            "Epoch 20: accuracy did not improve from 0.70312\n",
            " 66/121 [===============>..............] - ETA: 0s - loss: 2.1594 - accuracy: 0.6420\n",
            "Epoch 20: accuracy did not improve from 0.70312\n",
            "\n",
            "Epoch 20: accuracy did not improve from 0.70312\n",
            "\n",
            "Epoch 20: accuracy did not improve from 0.70312\n",
            " 85/121 [====================>.........] - ETA: 0s - loss: 2.1896 - accuracy: 0.6338\n",
            "Epoch 20: accuracy did not improve from 0.70312\n",
            "\n",
            "Epoch 20: accuracy did not improve from 0.70312\n",
            "\n",
            "Epoch 20: accuracy did not improve from 0.70312\n",
            "\n",
            "Epoch 20: accuracy did not improve from 0.70312\n",
            "101/121 [========================>.....] - ETA: 0s - loss: 2.2128 - accuracy: 0.6349\n",
            "Epoch 20: accuracy did not improve from 0.70312\n",
            "\n",
            "Epoch 20: accuracy did not improve from 0.70312\n",
            "\n",
            "Epoch 20: accuracy did not improve from 0.70312\n",
            "119/121 [============================>.] - ETA: 0s - loss: 2.1914 - accuracy: 0.6402\n",
            "Epoch 20: accuracy did not improve from 0.70312\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.1900 - accuracy: 0.6403\n",
            "Epoch 21/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.0979 - accuracy: 0.7188\n",
            "Epoch 21: accuracy did not improve from 0.70312\n",
            "\n",
            "Epoch 21: accuracy did not improve from 0.70312\n",
            "\n",
            "Epoch 21: accuracy did not improve from 0.70312\n",
            "\n",
            "Epoch 21: accuracy did not improve from 0.70312\n",
            " 20/121 [===>..........................] - ETA: 0s - loss: 2.0312 - accuracy: 0.6625\n",
            "Epoch 21: accuracy did not improve from 0.70312\n",
            "\n",
            "Epoch 21: accuracy did not improve from 0.70312\n",
            "\n",
            "Epoch 21: accuracy did not improve from 0.70312\n",
            "\n",
            "Epoch 21: accuracy did not improve from 0.70312\n",
            " 40/121 [========>.....................] - ETA: 0s - loss: 2.0742 - accuracy: 0.6594\n",
            "Epoch 21: accuracy did not improve from 0.70312\n",
            "\n",
            "Epoch 21: accuracy did not improve from 0.70312\n",
            "\n",
            "Epoch 21: accuracy did not improve from 0.70312\n",
            "\n",
            "Epoch 21: accuracy did not improve from 0.70312\n",
            " 60/121 [=============>................] - ETA: 0s - loss: 2.1285 - accuracy: 0.6536\n",
            "Epoch 21: accuracy did not improve from 0.70312\n",
            "\n",
            "Epoch 21: accuracy did not improve from 0.70312\n",
            "\n",
            "Epoch 21: accuracy did not improve from 0.70312\n",
            "\n",
            "Epoch 21: accuracy did not improve from 0.70312\n",
            " 80/121 [==================>...........] - ETA: 0s - loss: 2.1482 - accuracy: 0.6500\n",
            "Epoch 21: accuracy did not improve from 0.70312\n",
            "\n",
            "Epoch 21: accuracy did not improve from 0.70312\n",
            "\n",
            "Epoch 21: accuracy did not improve from 0.70312\n",
            "\n",
            "Epoch 21: accuracy did not improve from 0.70312\n",
            "100/121 [=======================>......] - ETA: 0s - loss: 2.1886 - accuracy: 0.6450\n",
            "Epoch 21: accuracy did not improve from 0.70312\n",
            "\n",
            "Epoch 21: accuracy did not improve from 0.70312\n",
            "\n",
            "Epoch 21: accuracy did not improve from 0.70312\n",
            "\n",
            "Epoch 21: accuracy did not improve from 0.70312\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.1898 - accuracy: 0.6473\n",
            "Epoch 22/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.0976 - accuracy: 0.5625\n",
            "Epoch 22: accuracy did not improve from 0.70312\n",
            "\n",
            "Epoch 22: accuracy did not improve from 0.70312\n",
            "\n",
            "Epoch 22: accuracy did not improve from 0.70312\n",
            "\n",
            "Epoch 22: accuracy did not improve from 0.70312\n",
            " 21/121 [====>.........................] - ETA: 0s - loss: 2.3342 - accuracy: 0.6190\n",
            "Epoch 22: accuracy did not improve from 0.70312\n",
            "\n",
            "Epoch 22: accuracy did not improve from 0.70312\n",
            "\n",
            "Epoch 22: accuracy did not improve from 0.70312\n",
            "\n",
            "Epoch 22: accuracy did not improve from 0.70312\n",
            " 41/121 [=========>....................] - ETA: 0s - loss: 2.1676 - accuracy: 0.6616\n",
            "Epoch 22: accuracy did not improve from 0.70312\n",
            "\n",
            "Epoch 22: accuracy did not improve from 0.70312\n",
            "\n",
            "Epoch 22: accuracy did not improve from 0.70312\n",
            "\n",
            "Epoch 22: accuracy did not improve from 0.70312\n",
            " 61/121 [==============>...............] - ETA: 0s - loss: 2.2027 - accuracy: 0.6542\n",
            "Epoch 22: accuracy did not improve from 0.70312\n",
            "\n",
            "Epoch 22: accuracy did not improve from 0.70312\n",
            "\n",
            "Epoch 22: accuracy did not improve from 0.70312\n",
            "\n",
            "Epoch 22: accuracy did not improve from 0.70312\n",
            " 80/121 [==================>...........] - ETA: 0s - loss: 2.2079 - accuracy: 0.6535\n",
            "Epoch 22: accuracy did not improve from 0.70312\n",
            "\n",
            "Epoch 22: accuracy did not improve from 0.70312\n",
            "\n",
            "Epoch 22: accuracy did not improve from 0.70312\n",
            "\n",
            "Epoch 22: accuracy did not improve from 0.70312\n",
            "100/121 [=======================>......] - ETA: 0s - loss: 2.2030 - accuracy: 0.6488\n",
            "Epoch 22: accuracy did not improve from 0.70312\n",
            "\n",
            "Epoch 22: accuracy did not improve from 0.70312\n",
            "\n",
            "Epoch 22: accuracy did not improve from 0.70312\n",
            "\n",
            "Epoch 22: accuracy did not improve from 0.70312\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.1897 - accuracy: 0.6518\n",
            "Epoch 23/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.8627 - accuracy: 0.5938\n",
            "Epoch 23: accuracy did not improve from 0.70312\n",
            "\n",
            "Epoch 23: accuracy did not improve from 0.70312\n",
            "\n",
            "Epoch 23: accuracy did not improve from 0.70312\n",
            "\n",
            "Epoch 23: accuracy did not improve from 0.70312\n",
            " 20/121 [===>..........................] - ETA: 0s - loss: 2.1546 - accuracy: 0.6641\n",
            "Epoch 23: accuracy did not improve from 0.70312\n",
            "\n",
            "Epoch 23: accuracy did not improve from 0.70312\n",
            "\n",
            "Epoch 23: accuracy did not improve from 0.70312\n",
            "\n",
            "Epoch 23: accuracy did not improve from 0.70312\n",
            " 40/121 [========>.....................] - ETA: 0s - loss: 2.1811 - accuracy: 0.6539\n",
            "Epoch 23: accuracy did not improve from 0.70312\n",
            "\n",
            "Epoch 23: accuracy did not improve from 0.70312\n",
            "\n",
            "Epoch 23: accuracy did not improve from 0.70312\n",
            "\n",
            "Epoch 23: accuracy did not improve from 0.70312\n",
            " 61/121 [==============>...............] - ETA: 0s - loss: 2.1963 - accuracy: 0.6557\n",
            "Epoch 23: accuracy did not improve from 0.70312\n",
            "\n",
            "Epoch 23: accuracy did not improve from 0.70312\n",
            "\n",
            "Epoch 23: accuracy did not improve from 0.70312\n",
            "\n",
            "Epoch 23: accuracy did not improve from 0.70312\n",
            " 80/121 [==================>...........] - ETA: 0s - loss: 2.1862 - accuracy: 0.6547\n",
            "Epoch 23: accuracy did not improve from 0.70312\n",
            "\n",
            "Epoch 23: accuracy did not improve from 0.70312\n",
            "\n",
            "Epoch 23: accuracy did not improve from 0.70312\n",
            "\n",
            "Epoch 23: accuracy did not improve from 0.70312\n",
            "100/121 [=======================>......] - ETA: 0s - loss: 2.1952 - accuracy: 0.6525\n",
            "Epoch 23: accuracy did not improve from 0.70312\n",
            "\n",
            "Epoch 23: accuracy did not improve from 0.70312\n",
            "\n",
            "Epoch 23: accuracy did not improve from 0.70312\n",
            "\n",
            "Epoch 23: accuracy did not improve from 0.70312\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.1896 - accuracy: 0.6546\n",
            "Epoch 24/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 1.9070 - accuracy: 0.6875\n",
            "Epoch 24: accuracy did not improve from 0.70312\n",
            "\n",
            "Epoch 24: accuracy did not improve from 0.70312\n",
            "\n",
            "Epoch 24: accuracy did not improve from 0.70312\n",
            "\n",
            "Epoch 24: accuracy did not improve from 0.70312\n",
            " 18/121 [===>..........................] - ETA: 0s - loss: 2.2192 - accuracy: 0.6545\n",
            "Epoch 24: accuracy did not improve from 0.70312\n",
            "\n",
            "Epoch 24: accuracy did not improve from 0.70312\n",
            "\n",
            "Epoch 24: accuracy did not improve from 0.70312\n",
            " 32/121 [======>.......................] - ETA: 0s - loss: 2.2113 - accuracy: 0.6631\n",
            "Epoch 24: accuracy did not improve from 0.70312\n",
            "\n",
            "Epoch 24: accuracy did not improve from 0.70312\n",
            "\n",
            "Epoch 24: accuracy did not improve from 0.70312\n",
            " 50/121 [===========>..................] - ETA: 0s - loss: 2.1933 - accuracy: 0.6637\n",
            "Epoch 24: accuracy did not improve from 0.70312\n",
            "\n",
            "Epoch 24: accuracy did not improve from 0.70312\n",
            "\n",
            "Epoch 24: accuracy did not improve from 0.70312\n",
            "\n",
            "Epoch 24: accuracy did not improve from 0.70312\n",
            " 67/121 [===============>..............] - ETA: 0s - loss: 2.1818 - accuracy: 0.6590\n",
            "Epoch 24: accuracy did not improve from 0.70312\n",
            "\n",
            "Epoch 24: accuracy did not improve from 0.70312\n",
            "\n",
            "Epoch 24: accuracy did not improve from 0.70312\n",
            "\n",
            "Epoch 24: accuracy did not improve from 0.70312\n",
            " 88/121 [====================>.........] - ETA: 0s - loss: 2.2159 - accuracy: 0.6559\n",
            "Epoch 24: accuracy did not improve from 0.70312\n",
            "\n",
            "Epoch 24: accuracy did not improve from 0.70312\n",
            "\n",
            "Epoch 24: accuracy did not improve from 0.70312\n",
            "\n",
            "Epoch 24: accuracy did not improve from 0.70312\n",
            "108/121 [=========================>....] - ETA: 0s - loss: 2.2082 - accuracy: 0.6568\n",
            "Epoch 24: accuracy did not improve from 0.70312\n",
            "112/121 [==========================>...] - ETA: 0s - loss: 2.2094 - accuracy: 0.6582\n",
            "Epoch 24: accuracy did not improve from 0.70312\n",
            "121/121 [==============================] - 1s 4ms/step - loss: 2.1895 - accuracy: 0.6590\n",
            "Epoch 25/100\n",
            "\n",
            "Epoch 25: accuracy improved from 0.70312 to 0.78125, saving model to best_model.hdf5\n",
            "  1/121 [..............................] - ETA: 15s - loss: 2.1954 - accuracy: 0.7812\n",
            "Epoch 25: accuracy did not improve from 0.78125\n",
            "  6/121 [>.............................] - ETA: 1s - loss: 2.1147 - accuracy: 0.7240 \n",
            "Epoch 25: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 25: accuracy did not improve from 0.78125\n",
            " 19/121 [===>..........................] - ETA: 0s - loss: 2.1685 - accuracy: 0.6924\n",
            "Epoch 25: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 25: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 25: accuracy did not improve from 0.78125\n",
            " 33/121 [=======>......................] - ETA: 0s - loss: 2.2107 - accuracy: 0.6695\n",
            "Epoch 25: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 25: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 25: accuracy did not improve from 0.78125\n",
            " 48/121 [==========>...................] - ETA: 0s - loss: 2.2132 - accuracy: 0.6582\n",
            "Epoch 25: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 25: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 25: accuracy did not improve from 0.78125\n",
            " 64/121 [==============>...............] - ETA: 0s - loss: 2.2259 - accuracy: 0.6567\n",
            "Epoch 25: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 25: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 25: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 25: accuracy did not improve from 0.78125\n",
            " 81/121 [===================>..........] - ETA: 0s - loss: 2.2167 - accuracy: 0.6597\n",
            "Epoch 25: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 25: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 25: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 25: accuracy did not improve from 0.78125\n",
            "101/121 [========================>.....] - ETA: 0s - loss: 2.1977 - accuracy: 0.6624\n",
            "Epoch 25: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 25: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 25: accuracy did not improve from 0.78125\n",
            "116/121 [===========================>..] - ETA: 0s - loss: 2.1799 - accuracy: 0.6646\n",
            "Epoch 25: accuracy did not improve from 0.78125\n",
            "121/121 [==============================] - 1s 4ms/step - loss: 2.1894 - accuracy: 0.6619\n",
            "Epoch 26/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 1.6202 - accuracy: 0.9062\n",
            "Epoch 26: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 26: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 26: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 26: accuracy did not improve from 0.78125\n",
            " 20/121 [===>..........................] - ETA: 0s - loss: 2.0977 - accuracy: 0.6797\n",
            "Epoch 26: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 26: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 26: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 26: accuracy did not improve from 0.78125\n",
            " 40/121 [========>.....................] - ETA: 0s - loss: 2.1428 - accuracy: 0.6797\n",
            "Epoch 26: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 26: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 26: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 26: accuracy did not improve from 0.78125\n",
            " 60/121 [=============>................] - ETA: 0s - loss: 2.1677 - accuracy: 0.6667\n",
            "Epoch 26: accuracy did not improve from 0.78125\n",
            " 66/121 [===============>..............] - ETA: 0s - loss: 2.1471 - accuracy: 0.6742\n",
            "Epoch 26: accuracy did not improve from 0.78125\n",
            " 74/121 [=================>............] - ETA: 0s - loss: 2.1765 - accuracy: 0.6706\n",
            "Epoch 26: accuracy did not improve from 0.78125\n",
            " 78/121 [==================>...........] - ETA: 0s - loss: 2.1896 - accuracy: 0.6691\n",
            "Epoch 26: accuracy did not improve from 0.78125\n",
            " 82/121 [===================>..........] - ETA: 0s - loss: 2.1653 - accuracy: 0.6723\n",
            "Epoch 26: accuracy did not improve from 0.78125\n",
            " 87/121 [====================>.........] - ETA: 0s - loss: 2.1659 - accuracy: 0.6692\n",
            "Epoch 26: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 26: accuracy did not improve from 0.78125\n",
            " 95/121 [======================>.......] - ETA: 0s - loss: 2.1831 - accuracy: 0.6645\n",
            "Epoch 26: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 26: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 26: accuracy did not improve from 0.78125\n",
            "110/121 [==========================>...] - ETA: 0s - loss: 2.1880 - accuracy: 0.6656\n",
            "Epoch 26: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 26: accuracy did not improve from 0.78125\n",
            "121/121 [==============================] - 1s 5ms/step - loss: 2.1894 - accuracy: 0.6642\n",
            "Epoch 27/100\n",
            "  1/121 [..............................] - ETA: 1s - loss: 2.0976 - accuracy: 0.6562\n",
            "Epoch 27: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 27: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 27: accuracy did not improve from 0.78125\n",
            " 17/121 [===>..........................] - ETA: 0s - loss: 2.1821 - accuracy: 0.6765\n",
            "Epoch 27: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 27: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 27: accuracy did not improve from 0.78125\n",
            " 31/121 [======>.......................] - ETA: 0s - loss: 2.1838 - accuracy: 0.6653\n",
            "Epoch 27: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 27: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 27: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 27: accuracy did not improve from 0.78125\n",
            " 49/121 [===========>..................] - ETA: 0s - loss: 2.1657 - accuracy: 0.6690\n",
            "Epoch 27: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 27: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 27: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 27: accuracy did not improve from 0.78125\n",
            " 69/121 [================>.............] - ETA: 0s - loss: 2.1447 - accuracy: 0.6793\n",
            "Epoch 27: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 27: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 27: accuracy did not improve from 0.78125\n",
            " 85/121 [====================>.........] - ETA: 0s - loss: 2.1627 - accuracy: 0.6761\n",
            "Epoch 27: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 27: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 27: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 27: accuracy did not improve from 0.78125\n",
            "104/121 [========================>.....] - ETA: 0s - loss: 2.1737 - accuracy: 0.6695\n",
            "Epoch 27: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 27: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 27: accuracy did not improve from 0.78125\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.1893 - accuracy: 0.6658\n",
            "Epoch 28/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.3827 - accuracy: 0.7500\n",
            "Epoch 28: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 28: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 28: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 28: accuracy did not improve from 0.78125\n",
            " 18/121 [===>..........................] - ETA: 0s - loss: 2.1824 - accuracy: 0.6354\n",
            "Epoch 28: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 28: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 28: accuracy did not improve from 0.78125\n",
            " 36/121 [=======>......................] - ETA: 0s - loss: 2.2408 - accuracy: 0.6510\n",
            "Epoch 28: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 28: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 28: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 28: accuracy did not improve from 0.78125\n",
            " 54/121 [============>.................] - ETA: 0s - loss: 2.1826 - accuracy: 0.6568\n",
            "Epoch 28: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 28: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 28: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 28: accuracy did not improve from 0.78125\n",
            " 74/121 [=================>............] - ETA: 0s - loss: 2.1416 - accuracy: 0.6689\n",
            "Epoch 28: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 28: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 28: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 28: accuracy did not improve from 0.78125\n",
            " 94/121 [======================>.......] - ETA: 0s - loss: 2.1464 - accuracy: 0.6719\n",
            "Epoch 28: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 28: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 28: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 28: accuracy did not improve from 0.78125\n",
            "115/121 [===========================>..] - ETA: 0s - loss: 2.1723 - accuracy: 0.6693\n",
            "Epoch 28: accuracy did not improve from 0.78125\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.1893 - accuracy: 0.6681\n",
            "Epoch 29/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 1.8122 - accuracy: 0.7188\n",
            "Epoch 29: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 29: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 29: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 29: accuracy did not improve from 0.78125\n",
            " 17/121 [===>..........................] - ETA: 0s - loss: 2.1989 - accuracy: 0.6710\n",
            "Epoch 29: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 29: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 29: accuracy did not improve from 0.78125\n",
            " 34/121 [=======>......................] - ETA: 0s - loss: 2.0949 - accuracy: 0.6746\n",
            "Epoch 29: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 29: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 29: accuracy did not improve from 0.78125\n",
            " 50/121 [===========>..................] - ETA: 0s - loss: 2.1339 - accuracy: 0.6694\n",
            "Epoch 29: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 29: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 29: accuracy did not improve from 0.78125\n",
            " 64/121 [==============>...............] - ETA: 0s - loss: 2.1363 - accuracy: 0.6689\n",
            "Epoch 29: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 29: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 29: accuracy did not improve from 0.78125\n",
            " 77/121 [==================>...........] - ETA: 0s - loss: 2.1547 - accuracy: 0.6713\n",
            "Epoch 29: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 29: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 29: accuracy did not improve from 0.78125\n",
            " 92/121 [=====================>........] - ETA: 0s - loss: 2.1890 - accuracy: 0.6685\n",
            "Epoch 29: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 29: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 29: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 29: accuracy did not improve from 0.78125\n",
            "112/121 [==========================>...] - ETA: 0s - loss: 2.1811 - accuracy: 0.6694\n",
            "Epoch 29: accuracy did not improve from 0.78125\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.1893 - accuracy: 0.6692\n",
            "Epoch 30/100\n",
            "\n",
            "Epoch 30: accuracy did not improve from 0.78125\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.3831 - accuracy: 0.5625\n",
            "Epoch 30: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 30: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 30: accuracy did not improve from 0.78125\n",
            " 19/121 [===>..........................] - ETA: 0s - loss: 2.2029 - accuracy: 0.6661\n",
            "Epoch 30: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 30: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 30: accuracy did not improve from 0.78125\n",
            " 35/121 [=======>......................] - ETA: 0s - loss: 2.2204 - accuracy: 0.6670\n",
            "Epoch 30: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 30: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 30: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 30: accuracy did not improve from 0.78125\n",
            " 51/121 [===========>..................] - ETA: 0s - loss: 2.2194 - accuracy: 0.6697\n",
            "Epoch 30: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 30: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 30: accuracy did not improve from 0.78125\n",
            " 66/121 [===============>..............] - ETA: 0s - loss: 2.1918 - accuracy: 0.6733\n",
            "Epoch 30: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 30: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 30: accuracy did not improve from 0.78125\n",
            " 81/121 [===================>..........] - ETA: 0s - loss: 2.1932 - accuracy: 0.6732\n",
            "Epoch 30: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 30: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 30: accuracy did not improve from 0.78125\n",
            " 99/121 [=======================>......] - ETA: 0s - loss: 2.1912 - accuracy: 0.6708\n",
            "Epoch 30: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 30: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 30: accuracy did not improve from 0.78125\n",
            "111/121 [==========================>...] - ETA: 0s - loss: 2.1905 - accuracy: 0.6703\n",
            "Epoch 30: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 30: accuracy did not improve from 0.78125\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.1893 - accuracy: 0.6715\n",
            "Epoch 31/100\n",
            "  1/121 [..............................] - ETA: 1s - loss: 2.0968 - accuracy: 0.6562\n",
            "Epoch 31: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 31: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 31: accuracy did not improve from 0.78125\n",
            " 15/121 [==>...........................] - ETA: 0s - loss: 2.1927 - accuracy: 0.6750\n",
            "Epoch 31: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 31: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 31: accuracy did not improve from 0.78125\n",
            " 30/121 [======>.......................] - ETA: 0s - loss: 2.1645 - accuracy: 0.6687\n",
            "Epoch 31: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 31: accuracy did not improve from 0.78125\n",
            " 44/121 [=========>....................] - ETA: 0s - loss: 2.1301 - accuracy: 0.6705\n",
            "Epoch 31: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 31: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 31: accuracy did not improve from 0.78125\n",
            " 58/121 [=============>................] - ETA: 0s - loss: 2.1766 - accuracy: 0.6703\n",
            "Epoch 31: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 31: accuracy did not improve from 0.78125\n",
            " 69/121 [================>.............] - ETA: 0s - loss: 2.1363 - accuracy: 0.6775\n",
            "Epoch 31: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 31: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 31: accuracy did not improve from 0.78125\n",
            " 83/121 [===================>..........] - ETA: 0s - loss: 2.1552 - accuracy: 0.6766\n",
            "Epoch 31: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 31: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 31: accuracy did not improve from 0.78125\n",
            " 97/121 [=======================>......] - ETA: 0s - loss: 2.1675 - accuracy: 0.6749\n",
            "Epoch 31: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 31: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 31: accuracy did not improve from 0.78125\n",
            "110/121 [==========================>...] - ETA: 0s - loss: 2.1748 - accuracy: 0.6727\n",
            "Epoch 31: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 31: accuracy did not improve from 0.78125\n",
            "121/121 [==============================] - 0s 4ms/step - loss: 2.1892 - accuracy: 0.6728\n",
            "Epoch 32/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.1921 - accuracy: 0.6562\n",
            "Epoch 32: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 32: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 32: accuracy did not improve from 0.78125\n",
            " 18/121 [===>..........................] - ETA: 0s - loss: 2.3471 - accuracy: 0.6684\n",
            "Epoch 32: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 32: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 32: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 32: accuracy did not improve from 0.78125\n",
            " 36/121 [=======>......................] - ETA: 0s - loss: 2.2352 - accuracy: 0.6641\n",
            "Epoch 32: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 32: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 32: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 32: accuracy did not improve from 0.78125\n",
            " 54/121 [============>.................] - ETA: 0s - loss: 2.1540 - accuracy: 0.6771\n",
            "Epoch 32: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 32: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 32: accuracy did not improve from 0.78125\n",
            " 70/121 [================>.............] - ETA: 0s - loss: 2.1860 - accuracy: 0.6728\n",
            "Epoch 32: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 32: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 32: accuracy did not improve from 0.78125\n",
            " 88/121 [====================>.........] - ETA: 0s - loss: 2.1994 - accuracy: 0.6754\n",
            "Epoch 32: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 32: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 32: accuracy did not improve from 0.78125\n",
            "103/121 [========================>.....] - ETA: 0s - loss: 2.2041 - accuracy: 0.6729\n",
            "Epoch 32: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 32: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 32: accuracy did not improve from 0.78125\n",
            "118/121 [============================>.] - ETA: 0s - loss: 2.1881 - accuracy: 0.6740\n",
            "Epoch 32: accuracy did not improve from 0.78125\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.1892 - accuracy: 0.6741\n",
            "Epoch 33/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.2907 - accuracy: 0.7500\n",
            "Epoch 33: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 33: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 33: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 33: accuracy did not improve from 0.78125\n",
            " 18/121 [===>..........................] - ETA: 0s - loss: 2.2144 - accuracy: 0.6632\n",
            "Epoch 33: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 33: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 33: accuracy did not improve from 0.78125\n",
            " 33/121 [=======>......................] - ETA: 0s - loss: 2.1904 - accuracy: 0.6723\n",
            "Epoch 33: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 33: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 33: accuracy did not improve from 0.78125\n",
            " 48/121 [==========>...................] - ETA: 0s - loss: 2.1713 - accuracy: 0.6790\n",
            "Epoch 33: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 33: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 33: accuracy did not improve from 0.78125\n",
            " 64/121 [==============>...............] - ETA: 0s - loss: 2.2126 - accuracy: 0.6772\n",
            "Epoch 33: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 33: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 33: accuracy did not improve from 0.78125\n",
            " 82/121 [===================>..........] - ETA: 0s - loss: 2.1978 - accuracy: 0.6757\n",
            "Epoch 33: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 33: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 33: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 33: accuracy did not improve from 0.78125\n",
            " 98/121 [=======================>......] - ETA: 0s - loss: 2.2136 - accuracy: 0.6776\n",
            "Epoch 33: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 33: accuracy did not improve from 0.78125\n",
            "\n",
            "Epoch 33: accuracy did not improve from 0.78125\n",
            "117/121 [============================>.] - ETA: 0s - loss: 2.1914 - accuracy: 0.6755\n",
            "Epoch 33: accuracy did not improve from 0.78125\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.1892 - accuracy: 0.6752\n",
            "Epoch 34/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 1.8108 - accuracy: 0.7812\n",
            "Epoch 34: accuracy improved from 0.78125 to 0.82812, saving model to best_model.hdf5\n",
            "\n",
            "Epoch 34: accuracy did not improve from 0.82812\n",
            " 10/121 [=>............................] - ETA: 0s - loss: 2.1927 - accuracy: 0.7000\n",
            "Epoch 34: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 34: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 34: accuracy did not improve from 0.82812\n",
            " 23/121 [====>.........................] - ETA: 0s - loss: 2.2051 - accuracy: 0.6984\n",
            "Epoch 34: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 34: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 34: accuracy did not improve from 0.82812\n",
            " 38/121 [========>.....................] - ETA: 0s - loss: 2.1877 - accuracy: 0.6875\n",
            "Epoch 34: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 34: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 34: accuracy did not improve from 0.82812\n",
            " 52/121 [===========>..................] - ETA: 0s - loss: 2.2259 - accuracy: 0.6827\n",
            "Epoch 34: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 34: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 34: accuracy did not improve from 0.82812\n",
            " 68/121 [===============>..............] - ETA: 0s - loss: 2.2239 - accuracy: 0.6719\n",
            "Epoch 34: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 34: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 34: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 34: accuracy did not improve from 0.82812\n",
            " 87/121 [====================>.........] - ETA: 0s - loss: 2.2039 - accuracy: 0.6746\n",
            "Epoch 34: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 34: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 34: accuracy did not improve from 0.82812\n",
            "103/121 [========================>.....] - ETA: 0s - loss: 2.1772 - accuracy: 0.6760\n",
            "Epoch 34: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 34: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 34: accuracy did not improve from 0.82812\n",
            "121/121 [==============================] - 0s 4ms/step - loss: 2.1892 - accuracy: 0.6754\n",
            "Epoch 35/100\n",
            "\n",
            "Epoch 35: accuracy did not improve from 0.82812\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.8625 - accuracy: 0.6562\n",
            "Epoch 35: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 35: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 35: accuracy did not improve from 0.82812\n",
            " 20/121 [===>..........................] - ETA: 0s - loss: 2.1023 - accuracy: 0.6938\n",
            "Epoch 35: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 35: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 35: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 35: accuracy did not improve from 0.82812\n",
            " 37/121 [========>.....................] - ETA: 0s - loss: 2.0667 - accuracy: 0.6943\n",
            "Epoch 35: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 35: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 35: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 35: accuracy did not improve from 0.82812\n",
            " 56/121 [============>.................] - ETA: 0s - loss: 2.1503 - accuracy: 0.6836\n",
            "Epoch 35: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 35: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 35: accuracy did not improve from 0.82812\n",
            " 74/121 [=================>............] - ETA: 0s - loss: 2.1620 - accuracy: 0.6837\n",
            "Epoch 35: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 35: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 35: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 35: accuracy did not improve from 0.82812\n",
            " 92/121 [=====================>........] - ETA: 0s - loss: 2.1950 - accuracy: 0.6814\n",
            "Epoch 35: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 35: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 35: accuracy did not improve from 0.82812\n",
            "107/121 [=========================>....] - ETA: 0s - loss: 2.1894 - accuracy: 0.6802\n",
            "Epoch 35: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 35: accuracy did not improve from 0.82812\n",
            "119/121 [============================>.] - ETA: 0s - loss: 2.1858 - accuracy: 0.6757\n",
            "Epoch 35: accuracy did not improve from 0.82812\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.1892 - accuracy: 0.6754\n",
            "Epoch 36/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.0968 - accuracy: 0.7188\n",
            "Epoch 36: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 36: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 36: accuracy did not improve from 0.82812\n",
            " 15/121 [==>...........................] - ETA: 0s - loss: 2.2688 - accuracy: 0.6542\n",
            "Epoch 36: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 36: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 36: accuracy did not improve from 0.82812\n",
            " 33/121 [=======>......................] - ETA: 0s - loss: 2.1636 - accuracy: 0.6705\n",
            "Epoch 36: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 36: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 36: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 36: accuracy did not improve from 0.82812\n",
            " 51/121 [===========>..................] - ETA: 0s - loss: 2.1871 - accuracy: 0.6746\n",
            "Epoch 36: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 36: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 36: accuracy did not improve from 0.82812\n",
            " 68/121 [===============>..............] - ETA: 0s - loss: 2.2054 - accuracy: 0.6682\n",
            "Epoch 36: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 36: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 36: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 36: accuracy did not improve from 0.82812\n",
            " 85/121 [====================>.........] - ETA: 0s - loss: 2.2175 - accuracy: 0.6687\n",
            "Epoch 36: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 36: accuracy did not improve from 0.82812\n",
            " 99/121 [=======================>......] - ETA: 0s - loss: 2.1892 - accuracy: 0.6774\n",
            "Epoch 36: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 36: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 36: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 36: accuracy did not improve from 0.82812\n",
            "116/121 [===========================>..] - ETA: 0s - loss: 2.1749 - accuracy: 0.6778\n",
            "Epoch 36: accuracy did not improve from 0.82812\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.1892 - accuracy: 0.6762\n",
            "Epoch 37/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 3.0509 - accuracy: 0.5000\n",
            "Epoch 37: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 37: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 37: accuracy did not improve from 0.82812\n",
            " 15/121 [==>...........................] - ETA: 0s - loss: 2.2504 - accuracy: 0.6750\n",
            "Epoch 37: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 37: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 37: accuracy did not improve from 0.82812\n",
            " 30/121 [======>.......................] - ETA: 0s - loss: 2.2569 - accuracy: 0.6615\n",
            "Epoch 37: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 37: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 37: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 37: accuracy did not improve from 0.82812\n",
            " 49/121 [===========>..................] - ETA: 0s - loss: 2.1738 - accuracy: 0.6779\n",
            "Epoch 37: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 37: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 37: accuracy did not improve from 0.82812\n",
            " 67/121 [===============>..............] - ETA: 0s - loss: 2.1702 - accuracy: 0.6819\n",
            "Epoch 37: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 37: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 37: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 37: accuracy did not improve from 0.82812\n",
            " 84/121 [===================>..........] - ETA: 0s - loss: 2.1737 - accuracy: 0.6763\n",
            "Epoch 37: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 37: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 37: accuracy did not improve from 0.82812\n",
            "102/121 [========================>.....] - ETA: 0s - loss: 2.2005 - accuracy: 0.6756\n",
            "Epoch 37: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 37: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 37: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 37: accuracy did not improve from 0.82812\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.1892 - accuracy: 0.6767\n",
            "Epoch 38/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 1.8108 - accuracy: 0.6875\n",
            "Epoch 38: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 38: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 38: accuracy did not improve from 0.82812\n",
            " 17/121 [===>..........................] - ETA: 0s - loss: 2.1426 - accuracy: 0.6893\n",
            "Epoch 38: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 38: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 38: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 38: accuracy did not improve from 0.82812\n",
            " 34/121 [=======>......................] - ETA: 0s - loss: 2.1339 - accuracy: 0.6765\n",
            "Epoch 38: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 38: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 38: accuracy did not improve from 0.82812\n",
            " 51/121 [===========>..................] - ETA: 0s - loss: 2.1085 - accuracy: 0.6850\n",
            "Epoch 38: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 38: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 38: accuracy did not improve from 0.82812\n",
            " 63/121 [==============>...............] - ETA: 0s - loss: 2.1595 - accuracy: 0.6791\n",
            "Epoch 38: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 38: accuracy did not improve from 0.82812\n",
            " 76/121 [=================>............] - ETA: 0s - loss: 2.1578 - accuracy: 0.6830\n",
            "Epoch 38: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 38: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 38: accuracy did not improve from 0.82812\n",
            " 89/121 [=====================>........] - ETA: 0s - loss: 2.1651 - accuracy: 0.6787\n",
            "Epoch 38: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 38: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 38: accuracy did not improve from 0.82812\n",
            "103/121 [========================>.....] - ETA: 0s - loss: 2.1615 - accuracy: 0.6799\n",
            "Epoch 38: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 38: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 38: accuracy did not improve from 0.82812\n",
            "121/121 [==============================] - 0s 4ms/step - loss: 2.1892 - accuracy: 0.6767\n",
            "Epoch 39/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.4780 - accuracy: 0.6875\n",
            "Epoch 39: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 39: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 39: accuracy did not improve from 0.82812\n",
            " 14/121 [==>...........................] - ETA: 0s - loss: 2.3966 - accuracy: 0.6384\n",
            "Epoch 39: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 39: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 39: accuracy did not improve from 0.82812\n",
            " 28/121 [=====>........................] - ETA: 0s - loss: 2.3118 - accuracy: 0.6518\n",
            "Epoch 39: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 39: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 39: accuracy did not improve from 0.82812\n",
            " 43/121 [=========>....................] - ETA: 0s - loss: 2.1996 - accuracy: 0.6708\n",
            "Epoch 39: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 39: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 39: accuracy did not improve from 0.82812\n",
            " 59/121 [=============>................] - ETA: 0s - loss: 2.1751 - accuracy: 0.6716\n",
            "Epoch 39: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 39: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 39: accuracy did not improve from 0.82812\n",
            " 73/121 [=================>............] - ETA: 0s - loss: 2.1473 - accuracy: 0.6807\n",
            "Epoch 39: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 39: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 39: accuracy did not improve from 0.82812\n",
            " 91/121 [=====================>........] - ETA: 0s - loss: 2.1762 - accuracy: 0.6793\n",
            "Epoch 39: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 39: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 39: accuracy did not improve from 0.82812\n",
            "106/121 [=========================>....] - ETA: 0s - loss: 2.1688 - accuracy: 0.6798\n",
            "Epoch 39: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 39: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 39: accuracy did not improve from 0.82812\n",
            "121/121 [==============================] - 0s 4ms/step - loss: 2.1892 - accuracy: 0.6772\n",
            "Epoch 40/100\n",
            "\n",
            "Epoch 40: accuracy did not improve from 0.82812\n",
            "  1/121 [..............................] - ETA: 1s - loss: 3.1452 - accuracy: 0.5938\n",
            "Epoch 40: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 40: accuracy did not improve from 0.82812\n",
            " 12/121 [=>............................] - ETA: 0s - loss: 2.3195 - accuracy: 0.6953\n",
            "Epoch 40: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 40: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 40: accuracy did not improve from 0.82812\n",
            " 26/121 [=====>........................] - ETA: 0s - loss: 2.2369 - accuracy: 0.6911\n",
            "Epoch 40: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 40: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 40: accuracy did not improve from 0.82812\n",
            " 41/121 [=========>....................] - ETA: 0s - loss: 2.2231 - accuracy: 0.6875\n",
            "Epoch 40: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 40: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 40: accuracy did not improve from 0.82812\n",
            " 56/121 [============>.................] - ETA: 0s - loss: 2.1724 - accuracy: 0.6920\n",
            "Epoch 40: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 40: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 40: accuracy did not improve from 0.82812\n",
            " 72/121 [================>.............] - ETA: 0s - loss: 2.2380 - accuracy: 0.6727\n",
            "Epoch 40: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 40: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 40: accuracy did not improve from 0.82812\n",
            " 87/121 [====================>.........] - ETA: 0s - loss: 2.1831 - accuracy: 0.6789\n",
            "Epoch 40: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 40: accuracy did not improve from 0.82812\n",
            " 99/121 [=======================>......] - ETA: 0s - loss: 2.1641 - accuracy: 0.6812\n",
            "Epoch 40: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 40: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 40: accuracy did not improve from 0.82812\n",
            "112/121 [==========================>...] - ETA: 0s - loss: 2.1734 - accuracy: 0.6811\n",
            "Epoch 40: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 40: accuracy did not improve from 0.82812\n",
            "121/121 [==============================] - 0s 4ms/step - loss: 2.1892 - accuracy: 0.6775\n",
            "Epoch 41/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.4780 - accuracy: 0.6875\n",
            "Epoch 41: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 41: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 41: accuracy did not improve from 0.82812\n",
            " 15/121 [==>...........................] - ETA: 0s - loss: 2.1424 - accuracy: 0.6812\n",
            "Epoch 41: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 41: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 41: accuracy did not improve from 0.82812\n",
            " 30/121 [======>.......................] - ETA: 0s - loss: 2.2118 - accuracy: 0.6677\n",
            "Epoch 41: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 41: accuracy did not improve from 0.82812\n",
            " 43/121 [=========>....................] - ETA: 0s - loss: 2.2130 - accuracy: 0.6737\n",
            "Epoch 41: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 41: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 41: accuracy did not improve from 0.82812\n",
            " 58/121 [=============>................] - ETA: 0s - loss: 2.2917 - accuracy: 0.6665\n",
            "Epoch 41: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 41: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 41: accuracy did not improve from 0.82812\n",
            " 71/121 [================>.............] - ETA: 0s - loss: 2.2575 - accuracy: 0.6677\n",
            "Epoch 41: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 41: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 41: accuracy did not improve from 0.82812\n",
            " 86/121 [====================>.........] - ETA: 0s - loss: 2.2140 - accuracy: 0.6733\n",
            "Epoch 41: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 41: accuracy did not improve from 0.82812\n",
            " 99/121 [=======================>......] - ETA: 0s - loss: 2.1958 - accuracy: 0.6783\n",
            "Epoch 41: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 41: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 41: accuracy did not improve from 0.82812\n",
            "112/121 [==========================>...] - ETA: 0s - loss: 2.1990 - accuracy: 0.6780\n",
            "Epoch 41: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 41: accuracy did not improve from 0.82812\n",
            "121/121 [==============================] - 0s 4ms/step - loss: 2.1892 - accuracy: 0.6783\n",
            "Epoch 42/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 1.6235 - accuracy: 0.7188\n",
            "Epoch 42: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 42: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 42: accuracy did not improve from 0.82812\n",
            " 14/121 [==>...........................] - ETA: 0s - loss: 2.0161 - accuracy: 0.6830\n",
            "Epoch 42: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 42: accuracy did not improve from 0.82812\n",
            " 26/121 [=====>........................] - ETA: 0s - loss: 2.0721 - accuracy: 0.6935\n",
            "Epoch 42: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 42: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 42: accuracy did not improve from 0.82812\n",
            " 40/121 [========>.....................] - ETA: 0s - loss: 2.0884 - accuracy: 0.6930\n",
            "Epoch 42: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 42: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 42: accuracy did not improve from 0.82812\n",
            " 55/121 [============>.................] - ETA: 0s - loss: 2.1100 - accuracy: 0.6886\n",
            "Epoch 42: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 42: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 42: accuracy did not improve from 0.82812\n",
            " 73/121 [=================>............] - ETA: 0s - loss: 2.1318 - accuracy: 0.6862\n",
            "Epoch 42: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 42: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 42: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 42: accuracy did not improve from 0.82812\n",
            " 90/121 [=====================>........] - ETA: 0s - loss: 2.1666 - accuracy: 0.6802\n",
            "Epoch 42: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 42: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 42: accuracy did not improve from 0.82812\n",
            "107/121 [=========================>....] - ETA: 0s - loss: 2.1449 - accuracy: 0.6831\n",
            "Epoch 42: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 42: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 42: accuracy did not improve from 0.82812\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.1892 - accuracy: 0.6783\n",
            "Epoch 43/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 1.5282 - accuracy: 0.8125\n",
            "Epoch 43: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 43: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 43: accuracy did not improve from 0.82812\n",
            " 17/121 [===>..........................] - ETA: 0s - loss: 2.2606 - accuracy: 0.6526\n",
            "Epoch 43: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 43: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 43: accuracy did not improve from 0.82812\n",
            " 32/121 [======>.......................] - ETA: 0s - loss: 2.1931 - accuracy: 0.6670\n",
            "Epoch 43: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 43: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 43: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 43: accuracy did not improve from 0.82812\n",
            " 49/121 [===========>..................] - ETA: 0s - loss: 2.2222 - accuracy: 0.6658\n",
            "Epoch 43: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 43: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 43: accuracy did not improve from 0.82812\n",
            " 67/121 [===============>..............] - ETA: 0s - loss: 2.2015 - accuracy: 0.6749\n",
            "Epoch 43: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 43: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 43: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 43: accuracy did not improve from 0.82812\n",
            " 84/121 [===================>..........] - ETA: 0s - loss: 2.2168 - accuracy: 0.6749\n",
            "Epoch 43: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 43: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 43: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 43: accuracy did not improve from 0.82812\n",
            "103/121 [========================>.....] - ETA: 0s - loss: 2.2105 - accuracy: 0.6732\n",
            "Epoch 43: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 43: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 43: accuracy did not improve from 0.82812\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.1892 - accuracy: 0.6783\n",
            "Epoch 44/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.6697 - accuracy: 0.6562\n",
            "Epoch 44: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 44: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 44: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 44: accuracy did not improve from 0.82812\n",
            " 17/121 [===>..........................] - ETA: 0s - loss: 2.2715 - accuracy: 0.6452\n",
            "Epoch 44: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 44: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 44: accuracy did not improve from 0.82812\n",
            " 34/121 [=======>......................] - ETA: 0s - loss: 2.1928 - accuracy: 0.6581\n",
            "Epoch 44: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 44: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 44: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 44: accuracy did not improve from 0.82812\n",
            " 52/121 [===========>..................] - ETA: 0s - loss: 2.1817 - accuracy: 0.6671\n",
            "Epoch 44: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 44: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 44: accuracy did not improve from 0.82812\n",
            " 68/121 [===============>..............] - ETA: 0s - loss: 2.2167 - accuracy: 0.6691\n",
            "Epoch 44: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 44: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 44: accuracy did not improve from 0.82812\n",
            " 86/121 [====================>.........] - ETA: 0s - loss: 2.1995 - accuracy: 0.6748\n",
            "Epoch 44: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 44: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 44: accuracy did not improve from 0.82812\n",
            "101/121 [========================>.....] - ETA: 0s - loss: 2.2110 - accuracy: 0.6761\n",
            "Epoch 44: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 44: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 44: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 44: accuracy did not improve from 0.82812\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.1892 - accuracy: 0.6783\n",
            "Epoch 45/100\n",
            "\n",
            "Epoch 45: accuracy did not improve from 0.82812\n",
            "  1/121 [..............................] - ETA: 1s - loss: 2.1001 - accuracy: 0.6875\n",
            "Epoch 45: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 45: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 45: accuracy did not improve from 0.82812\n",
            " 18/121 [===>..........................] - ETA: 0s - loss: 2.2087 - accuracy: 0.6858\n",
            "Epoch 45: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 45: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 45: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 45: accuracy did not improve from 0.82812\n",
            " 37/121 [========>.....................] - ETA: 0s - loss: 2.1517 - accuracy: 0.6917\n",
            "Epoch 45: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 45: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 45: accuracy did not improve from 0.82812\n",
            " 55/121 [============>.................] - ETA: 0s - loss: 2.1602 - accuracy: 0.6864\n",
            "Epoch 45: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 45: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 45: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 45: accuracy did not improve from 0.82812\n",
            " 73/121 [=================>............] - ETA: 0s - loss: 2.2074 - accuracy: 0.6781\n",
            "Epoch 45: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 45: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 45: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 45: accuracy did not improve from 0.82812\n",
            " 91/121 [=====================>........] - ETA: 0s - loss: 2.1920 - accuracy: 0.6813\n",
            "Epoch 45: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 45: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 45: accuracy did not improve from 0.82812\n",
            "110/121 [==========================>...] - ETA: 0s - loss: 2.2069 - accuracy: 0.6787\n",
            "Epoch 45: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 45: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 45: accuracy did not improve from 0.82812\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.1892 - accuracy: 0.6785\n",
            "Epoch 46/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.5733 - accuracy: 0.6562\n",
            "Epoch 46: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 46: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 46: accuracy did not improve from 0.82812\n",
            " 19/121 [===>..........................] - ETA: 0s - loss: 2.2029 - accuracy: 0.6974\n",
            "Epoch 46: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 46: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 46: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 46: accuracy did not improve from 0.82812\n",
            " 37/121 [========>.....................] - ETA: 0s - loss: 2.2034 - accuracy: 0.6892\n",
            "Epoch 46: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 46: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 46: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 46: accuracy did not improve from 0.82812\n",
            " 55/121 [============>.................] - ETA: 0s - loss: 2.1758 - accuracy: 0.6835\n",
            "Epoch 46: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 46: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 46: accuracy did not improve from 0.82812\n",
            " 70/121 [================>.............] - ETA: 0s - loss: 2.1985 - accuracy: 0.6817\n",
            "Epoch 46: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 46: accuracy did not improve from 0.82812\n",
            " 80/121 [==================>...........] - ETA: 0s - loss: 2.1966 - accuracy: 0.6828\n",
            "Epoch 46: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 46: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 46: accuracy did not improve from 0.82812\n",
            " 95/121 [======================>.......] - ETA: 0s - loss: 2.1870 - accuracy: 0.6812\n",
            "Epoch 46: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 46: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 46: accuracy did not improve from 0.82812\n",
            "113/121 [===========================>..] - ETA: 0s - loss: 2.1972 - accuracy: 0.6795\n",
            "Epoch 46: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 46: accuracy did not improve from 0.82812\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.1892 - accuracy: 0.6788\n",
            "Epoch 47/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.4813 - accuracy: 0.6250\n",
            "Epoch 47: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 47: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 47: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 47: accuracy did not improve from 0.82812\n",
            " 19/121 [===>..........................] - ETA: 0s - loss: 2.4949 - accuracy: 0.6562\n",
            "Epoch 47: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 47: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 47: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 47: accuracy did not improve from 0.82812\n",
            " 39/121 [========>.....................] - ETA: 0s - loss: 2.2789 - accuracy: 0.6843\n",
            "Epoch 47: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 47: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 47: accuracy did not improve from 0.82812\n",
            " 55/121 [============>.................] - ETA: 0s - loss: 2.1897 - accuracy: 0.6898\n",
            "Epoch 47: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 47: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 47: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 47: accuracy did not improve from 0.82812\n",
            " 74/121 [=================>............] - ETA: 0s - loss: 2.1570 - accuracy: 0.6896\n",
            "Epoch 47: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 47: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 47: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 47: accuracy did not improve from 0.82812\n",
            " 94/121 [======================>.......] - ETA: 0s - loss: 2.2010 - accuracy: 0.6799\n",
            "Epoch 47: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 47: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 47: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 47: accuracy did not improve from 0.82812\n",
            "114/121 [===========================>..] - ETA: 0s - loss: 2.1921 - accuracy: 0.6806\n",
            "Epoch 47: accuracy did not improve from 0.82812\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.1892 - accuracy: 0.6788\n",
            "Epoch 48/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.3827 - accuracy: 0.6250\n",
            "Epoch 48: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 48: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 48: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 48: accuracy did not improve from 0.82812\n",
            " 20/121 [===>..........................] - ETA: 0s - loss: 2.1457 - accuracy: 0.6875\n",
            "Epoch 48: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 48: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 48: accuracy did not improve from 0.82812\n",
            " 37/121 [========>.....................] - ETA: 0s - loss: 2.1443 - accuracy: 0.6875\n",
            "Epoch 48: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 48: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 48: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 48: accuracy did not improve from 0.82812\n",
            " 54/121 [============>.................] - ETA: 0s - loss: 2.1242 - accuracy: 0.6898\n",
            "Epoch 48: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 48: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 48: accuracy did not improve from 0.82812\n",
            " 71/121 [================>.............] - ETA: 0s - loss: 2.1312 - accuracy: 0.6897\n",
            "Epoch 48: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 48: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 48: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 48: accuracy did not improve from 0.82812\n",
            " 88/121 [====================>.........] - ETA: 0s - loss: 2.1843 - accuracy: 0.6776\n",
            "Epoch 48: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 48: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 48: accuracy did not improve from 0.82812\n",
            "104/121 [========================>.....] - ETA: 0s - loss: 2.1783 - accuracy: 0.6803\n",
            "Epoch 48: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 48: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 48: accuracy did not improve from 0.82812\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.1892 - accuracy: 0.6788\n",
            "Epoch 49/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.4780 - accuracy: 0.6250\n",
            "Epoch 49: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 49: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 49: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 49: accuracy did not improve from 0.82812\n",
            " 18/121 [===>..........................] - ETA: 0s - loss: 2.1982 - accuracy: 0.6771\n",
            "Epoch 49: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 49: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 49: accuracy did not improve from 0.82812\n",
            " 36/121 [=======>......................] - ETA: 0s - loss: 2.2698 - accuracy: 0.6727\n",
            "Epoch 49: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 49: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 49: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 49: accuracy did not improve from 0.82812\n",
            " 52/121 [===========>..................] - ETA: 0s - loss: 2.2425 - accuracy: 0.6707\n",
            "Epoch 49: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 49: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 49: accuracy did not improve from 0.82812\n",
            " 70/121 [================>.............] - ETA: 0s - loss: 2.1875 - accuracy: 0.6790\n",
            "Epoch 49: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 49: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 49: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 49: accuracy did not improve from 0.82812\n",
            " 87/121 [====================>.........] - ETA: 0s - loss: 2.1886 - accuracy: 0.6846\n",
            "Epoch 49: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 49: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 49: accuracy did not improve from 0.82812\n",
            "104/121 [========================>.....] - ETA: 0s - loss: 2.2030 - accuracy: 0.6779\n",
            "Epoch 49: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 49: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 49: accuracy did not improve from 0.82812\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.1892 - accuracy: 0.6788\n",
            "Epoch 50/100\n",
            "\n",
            "Epoch 50: accuracy did not improve from 0.82812\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.0048 - accuracy: 0.6562\n",
            "Epoch 50: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 50: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 50: accuracy did not improve from 0.82812\n",
            " 18/121 [===>..........................] - ETA: 0s - loss: 2.2728 - accuracy: 0.6823\n",
            "Epoch 50: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 50: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 50: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 50: accuracy did not improve from 0.82812\n",
            " 36/121 [=======>......................] - ETA: 0s - loss: 2.2195 - accuracy: 0.6762\n",
            "Epoch 50: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 50: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 50: accuracy did not improve from 0.82812\n",
            " 55/121 [============>.................] - ETA: 0s - loss: 2.1843 - accuracy: 0.6790\n",
            "Epoch 50: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 50: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 50: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 50: accuracy did not improve from 0.82812\n",
            " 71/121 [================>.............] - ETA: 0s - loss: 2.1580 - accuracy: 0.6879\n",
            "Epoch 50: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 50: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 50: accuracy did not improve from 0.82812\n",
            " 87/121 [====================>.........] - ETA: 0s - loss: 2.1896 - accuracy: 0.6846\n",
            "Epoch 50: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 50: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 50: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 50: accuracy did not improve from 0.82812\n",
            "106/121 [=========================>....] - ETA: 0s - loss: 2.1750 - accuracy: 0.6831\n",
            "Epoch 50: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 50: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 50: accuracy did not improve from 0.82812\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.1892 - accuracy: 0.6788\n",
            "Epoch 51/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.6686 - accuracy: 0.5938\n",
            "Epoch 51: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 51: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 51: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 51: accuracy did not improve from 0.82812\n",
            " 20/121 [===>..........................] - ETA: 0s - loss: 2.1450 - accuracy: 0.6719\n",
            "Epoch 51: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 51: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 51: accuracy did not improve from 0.82812\n",
            " 35/121 [=======>......................] - ETA: 0s - loss: 2.0920 - accuracy: 0.6929\n",
            "Epoch 51: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 51: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 51: accuracy did not improve from 0.82812\n",
            " 52/121 [===========>..................] - ETA: 0s - loss: 2.1212 - accuracy: 0.6893\n",
            "Epoch 51: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 51: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 51: accuracy did not improve from 0.82812\n",
            " 65/121 [===============>..............] - ETA: 0s - loss: 2.1575 - accuracy: 0.6851\n",
            "Epoch 51: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 51: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 51: accuracy did not improve from 0.82812\n",
            " 80/121 [==================>...........] - ETA: 0s - loss: 2.1713 - accuracy: 0.6848\n",
            "Epoch 51: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 51: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 51: accuracy did not improve from 0.82812\n",
            " 98/121 [=======================>......] - ETA: 0s - loss: 2.1647 - accuracy: 0.6856\n",
            "Epoch 51: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 51: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 51: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 51: accuracy did not improve from 0.82812\n",
            "115/121 [===========================>..] - ETA: 0s - loss: 2.1963 - accuracy: 0.6783\n",
            "Epoch 51: accuracy did not improve from 0.82812\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.1892 - accuracy: 0.6788\n",
            "Epoch 52/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 1.8108 - accuracy: 0.6875\n",
            "Epoch 52: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 52: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 52: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 52: accuracy did not improve from 0.82812\n",
            " 19/121 [===>..........................] - ETA: 0s - loss: 2.2131 - accuracy: 0.6859\n",
            "Epoch 52: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 52: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 52: accuracy did not improve from 0.82812\n",
            " 37/121 [========>.....................] - ETA: 0s - loss: 2.2527 - accuracy: 0.6740\n",
            "Epoch 52: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 52: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 52: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 52: accuracy did not improve from 0.82812\n",
            " 56/121 [============>.................] - ETA: 0s - loss: 2.2086 - accuracy: 0.6752\n",
            "Epoch 52: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 52: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 52: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 52: accuracy did not improve from 0.82812\n",
            " 74/121 [=================>............] - ETA: 0s - loss: 2.1737 - accuracy: 0.6845\n",
            "Epoch 52: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 52: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 52: accuracy did not improve from 0.82812\n",
            " 92/121 [=====================>........] - ETA: 0s - loss: 2.1733 - accuracy: 0.6831\n",
            "Epoch 52: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 52: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 52: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 52: accuracy did not improve from 0.82812\n",
            "110/121 [==========================>...] - ETA: 0s - loss: 2.1808 - accuracy: 0.6810\n",
            "Epoch 52: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 52: accuracy did not improve from 0.82812\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.1892 - accuracy: 0.6788\n",
            "Epoch 53/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 1.9062 - accuracy: 0.7188\n",
            "Epoch 53: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 53: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 53: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 53: accuracy did not improve from 0.82812\n",
            " 18/121 [===>..........................] - ETA: 0s - loss: 2.0716 - accuracy: 0.6962\n",
            "Epoch 53: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 53: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 53: accuracy did not improve from 0.82812\n",
            " 37/121 [========>.....................] - ETA: 0s - loss: 2.2263 - accuracy: 0.6799\n",
            "Epoch 53: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 53: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 53: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 53: accuracy did not improve from 0.82812\n",
            " 56/121 [============>.................] - ETA: 0s - loss: 2.2252 - accuracy: 0.6853\n",
            "Epoch 53: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 53: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 53: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 53: accuracy did not improve from 0.82812\n",
            " 74/121 [=================>............] - ETA: 0s - loss: 2.2033 - accuracy: 0.6816\n",
            "Epoch 53: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 53: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 53: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 53: accuracy did not improve from 0.82812\n",
            " 93/121 [======================>.......] - ETA: 0s - loss: 2.1816 - accuracy: 0.6838\n",
            "Epoch 53: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 53: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 53: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 53: accuracy did not improve from 0.82812\n",
            "113/121 [===========================>..] - ETA: 0s - loss: 2.1879 - accuracy: 0.6800\n",
            "Epoch 53: accuracy did not improve from 0.82812\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.1892 - accuracy: 0.6788\n",
            "Epoch 54/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 3.8123 - accuracy: 0.4062\n",
            "Epoch 54: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 54: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 54: accuracy did not improve from 0.82812\n",
            " 15/121 [==>...........................] - ETA: 0s - loss: 2.3262 - accuracy: 0.6417\n",
            "Epoch 54: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 54: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 54: accuracy did not improve from 0.82812\n",
            " 31/121 [======>.......................] - ETA: 0s - loss: 2.2574 - accuracy: 0.6633\n",
            "Epoch 54: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 54: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 54: accuracy did not improve from 0.82812\n",
            " 45/121 [==========>...................] - ETA: 0s - loss: 2.2480 - accuracy: 0.6743\n",
            "Epoch 54: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 54: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 54: accuracy did not improve from 0.82812\n",
            " 57/121 [=============>................] - ETA: 0s - loss: 2.2698 - accuracy: 0.6689\n",
            "Epoch 54: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 54: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 54: accuracy did not improve from 0.82812\n",
            " 76/121 [=================>............] - ETA: 0s - loss: 2.2168 - accuracy: 0.6743\n",
            "Epoch 54: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 54: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 54: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 54: accuracy did not improve from 0.82812\n",
            " 93/121 [======================>.......] - ETA: 0s - loss: 2.2032 - accuracy: 0.6754\n",
            "Epoch 54: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 54: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 54: accuracy did not improve from 0.82812\n",
            "111/121 [==========================>...] - ETA: 0s - loss: 2.1955 - accuracy: 0.6799\n",
            "Epoch 54: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 54: accuracy did not improve from 0.82812\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.1892 - accuracy: 0.6788\n",
            "Epoch 55/100\n",
            "\n",
            "Epoch 55: accuracy did not improve from 0.82812\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.1954 - accuracy: 0.8125\n",
            "Epoch 55: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 55: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 55: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 55: accuracy did not improve from 0.82812\n",
            " 21/121 [====>.........................] - ETA: 0s - loss: 2.0838 - accuracy: 0.7083\n",
            "Epoch 55: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 55: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 55: accuracy did not improve from 0.82812\n",
            " 40/121 [========>.....................] - ETA: 0s - loss: 2.1520 - accuracy: 0.6938\n",
            "Epoch 55: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 55: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 55: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 55: accuracy did not improve from 0.82812\n",
            " 56/121 [============>.................] - ETA: 0s - loss: 2.1177 - accuracy: 0.6936\n",
            "Epoch 55: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 55: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 55: accuracy did not improve from 0.82812\n",
            " 75/121 [=================>............] - ETA: 0s - loss: 2.1395 - accuracy: 0.6904\n",
            "Epoch 55: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 55: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 55: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 55: accuracy did not improve from 0.82812\n",
            " 94/121 [======================>.......] - ETA: 0s - loss: 2.1576 - accuracy: 0.6852\n",
            "Epoch 55: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 55: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 55: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 55: accuracy did not improve from 0.82812\n",
            "114/121 [===========================>..] - ETA: 0s - loss: 2.1788 - accuracy: 0.6806\n",
            "Epoch 55: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 55: accuracy did not improve from 0.82812\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.1892 - accuracy: 0.6788\n",
            "Epoch 56/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 3.1452 - accuracy: 0.5312\n",
            "Epoch 56: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 56: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 56: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 56: accuracy did not improve from 0.82812\n",
            " 20/121 [===>..........................] - ETA: 0s - loss: 2.2408 - accuracy: 0.6953\n",
            "Epoch 56: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 56: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 56: accuracy did not improve from 0.82812\n",
            " 39/121 [========>.....................] - ETA: 0s - loss: 2.2003 - accuracy: 0.6955\n",
            "Epoch 56: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 56: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 56: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 56: accuracy did not improve from 0.82812\n",
            " 58/121 [=============>................] - ETA: 0s - loss: 2.1601 - accuracy: 0.6907\n",
            "Epoch 56: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 56: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 56: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 56: accuracy did not improve from 0.82812\n",
            " 75/121 [=================>............] - ETA: 0s - loss: 2.1764 - accuracy: 0.6867\n",
            "Epoch 56: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 56: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 56: accuracy did not improve from 0.82812\n",
            " 93/121 [======================>.......] - ETA: 0s - loss: 2.2164 - accuracy: 0.6808\n",
            "Epoch 56: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 56: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 56: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 56: accuracy did not improve from 0.82812\n",
            "110/121 [==========================>...] - ETA: 0s - loss: 2.2241 - accuracy: 0.6761\n",
            "Epoch 56: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 56: accuracy did not improve from 0.82812\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.1892 - accuracy: 0.6788\n",
            "Epoch 57/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.9545 - accuracy: 0.5312\n",
            "Epoch 57: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 57: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 57: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 57: accuracy did not improve from 0.82812\n",
            " 20/121 [===>..........................] - ETA: 0s - loss: 2.2449 - accuracy: 0.6656\n",
            "Epoch 57: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 57: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 57: accuracy did not improve from 0.82812\n",
            " 37/121 [========>.....................] - ETA: 0s - loss: 2.1643 - accuracy: 0.6706\n",
            "Epoch 57: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 57: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 57: accuracy did not improve from 0.82812\n",
            " 50/121 [===========>..................] - ETA: 0s - loss: 2.2080 - accuracy: 0.6694\n",
            "Epoch 57: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 57: accuracy did not improve from 0.82812\n",
            " 62/121 [==============>...............] - ETA: 0s - loss: 2.2114 - accuracy: 0.6704\n",
            "Epoch 57: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 57: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 57: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 57: accuracy did not improve from 0.82812\n",
            " 80/121 [==================>...........] - ETA: 0s - loss: 2.1583 - accuracy: 0.6797\n",
            "Epoch 57: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 57: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 57: accuracy did not improve from 0.82812\n",
            " 94/121 [======================>.......] - ETA: 0s - loss: 2.1767 - accuracy: 0.6789\n",
            "Epoch 57: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 57: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 57: accuracy did not improve from 0.82812\n",
            "111/121 [==========================>...] - ETA: 0s - loss: 2.1792 - accuracy: 0.6802\n",
            "Epoch 57: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 57: accuracy did not improve from 0.82812\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.1892 - accuracy: 0.6788\n",
            "Epoch 58/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.1001 - accuracy: 0.6875\n",
            "Epoch 58: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 58: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 58: accuracy did not improve from 0.82812\n",
            " 17/121 [===>..........................] - ETA: 0s - loss: 2.1258 - accuracy: 0.6783\n",
            "Epoch 58: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 58: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 58: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 58: accuracy did not improve from 0.82812\n",
            " 33/121 [=======>......................] - ETA: 0s - loss: 2.1292 - accuracy: 0.6903\n",
            "Epoch 58: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 58: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 58: accuracy did not improve from 0.82812\n",
            " 50/121 [===========>..................] - ETA: 0s - loss: 2.1356 - accuracy: 0.6888\n",
            "Epoch 58: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 58: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 58: accuracy did not improve from 0.82812\n",
            " 63/121 [==============>...............] - ETA: 0s - loss: 2.1581 - accuracy: 0.6840\n",
            "Epoch 58: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 58: accuracy did not improve from 0.82812\n",
            " 77/121 [==================>...........] - ETA: 0s - loss: 2.1631 - accuracy: 0.6786\n",
            "Epoch 58: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 58: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 58: accuracy did not improve from 0.82812\n",
            " 89/121 [=====================>........] - ETA: 0s - loss: 2.1618 - accuracy: 0.6826\n",
            "Epoch 58: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 58: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 58: accuracy did not improve from 0.82812\n",
            "104/121 [========================>.....] - ETA: 0s - loss: 2.1764 - accuracy: 0.6806\n",
            "Epoch 58: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 58: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 58: accuracy did not improve from 0.82812\n",
            "121/121 [==============================] - 0s 4ms/step - loss: 2.1892 - accuracy: 0.6788\n",
            "Epoch 59/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 1.8119 - accuracy: 0.6562\n",
            "Epoch 59: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 59: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 59: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 59: accuracy did not improve from 0.82812\n",
            " 17/121 [===>..........................] - ETA: 0s - loss: 2.0696 - accuracy: 0.7096\n",
            "Epoch 59: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 59: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 59: accuracy did not improve from 0.82812\n",
            " 35/121 [=======>......................] - ETA: 0s - loss: 2.2420 - accuracy: 0.6741\n",
            "Epoch 59: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 59: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 59: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 59: accuracy did not improve from 0.82812\n",
            " 52/121 [===========>..................] - ETA: 0s - loss: 2.2059 - accuracy: 0.6779\n",
            "Epoch 59: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 59: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 59: accuracy did not improve from 0.82812\n",
            " 67/121 [===============>..............] - ETA: 0s - loss: 2.1944 - accuracy: 0.6805\n",
            "Epoch 59: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 59: accuracy did not improve from 0.82812\n",
            " 81/121 [===================>..........] - ETA: 0s - loss: 2.1955 - accuracy: 0.6763\n",
            "Epoch 59: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 59: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 59: accuracy did not improve from 0.82812\n",
            " 94/121 [======================>.......] - ETA: 0s - loss: 2.2153 - accuracy: 0.6719\n",
            "Epoch 59: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 59: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 59: accuracy did not improve from 0.82812\n",
            "109/121 [==========================>...] - ETA: 0s - loss: 2.1886 - accuracy: 0.6769\n",
            "Epoch 59: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 59: accuracy did not improve from 0.82812\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.1892 - accuracy: 0.6788\n",
            "Epoch 60/100\n",
            "\n",
            "Epoch 60: accuracy did not improve from 0.82812\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.1954 - accuracy: 0.6562\n",
            "Epoch 60: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 60: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 60: accuracy did not improve from 0.82812\n",
            " 16/121 [==>...........................] - ETA: 0s - loss: 2.5092 - accuracy: 0.6230\n",
            "Epoch 60: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 60: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 60: accuracy did not improve from 0.82812\n",
            " 31/121 [======>.......................] - ETA: 0s - loss: 2.2704 - accuracy: 0.6583\n",
            "Epoch 60: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 60: accuracy did not improve from 0.82812\n",
            " 45/121 [==========>...................] - ETA: 0s - loss: 2.2420 - accuracy: 0.6674\n",
            "Epoch 60: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 60: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 60: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 60: accuracy did not improve from 0.82812\n",
            " 61/121 [==============>...............] - ETA: 0s - loss: 2.2790 - accuracy: 0.6685\n",
            "Epoch 60: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 60: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 60: accuracy did not improve from 0.82812\n",
            " 76/121 [=================>............] - ETA: 0s - loss: 2.2081 - accuracy: 0.6752\n",
            "Epoch 60: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 60: accuracy did not improve from 0.82812\n",
            " 90/121 [=====================>........] - ETA: 0s - loss: 2.1707 - accuracy: 0.6792\n",
            "Epoch 60: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 60: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 60: accuracy did not improve from 0.82812\n",
            "105/121 [=========================>....] - ETA: 0s - loss: 2.2093 - accuracy: 0.6786\n",
            "Epoch 60: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 60: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 60: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 60: accuracy did not improve from 0.82812\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.1892 - accuracy: 0.6788\n",
            "Epoch 61/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.9578 - accuracy: 0.5625\n",
            "Epoch 61: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 61: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 61: accuracy did not improve from 0.82812\n",
            " 15/121 [==>...........................] - ETA: 0s - loss: 2.2057 - accuracy: 0.6646\n",
            "Epoch 61: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 61: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 61: accuracy did not improve from 0.82812\n",
            " 30/121 [======>.......................] - ETA: 0s - loss: 2.1928 - accuracy: 0.6792\n",
            "Epoch 61: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 61: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 61: accuracy did not improve from 0.82812\n",
            " 47/121 [==========>...................] - ETA: 0s - loss: 2.2355 - accuracy: 0.6815\n",
            "Epoch 61: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 61: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 61: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 61: accuracy did not improve from 0.82812\n",
            " 68/121 [===============>..............] - ETA: 0s - loss: 2.2266 - accuracy: 0.6838\n",
            "Epoch 61: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 61: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 61: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 61: accuracy did not improve from 0.82812\n",
            " 85/121 [====================>.........] - ETA: 0s - loss: 2.2210 - accuracy: 0.6801\n",
            "Epoch 61: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 61: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 61: accuracy did not improve from 0.82812\n",
            "102/121 [========================>.....] - ETA: 0s - loss: 2.2145 - accuracy: 0.6777\n",
            "Epoch 61: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 61: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 61: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 61: accuracy did not improve from 0.82812\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.1892 - accuracy: 0.6788\n",
            "Epoch 62/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.0015 - accuracy: 0.8125\n",
            "Epoch 62: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 62: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 62: accuracy did not improve from 0.82812\n",
            " 18/121 [===>..........................] - ETA: 0s - loss: 2.2776 - accuracy: 0.6719\n",
            "Epoch 62: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 62: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 62: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 62: accuracy did not improve from 0.82812\n",
            " 36/121 [=======>......................] - ETA: 0s - loss: 2.1291 - accuracy: 0.6849\n",
            "Epoch 62: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 62: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 62: accuracy did not improve from 0.82812\n",
            " 52/121 [===========>..................] - ETA: 0s - loss: 2.1506 - accuracy: 0.6845\n",
            "Epoch 62: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 62: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 62: accuracy did not improve from 0.82812\n",
            " 66/121 [===============>..............] - ETA: 0s - loss: 2.1481 - accuracy: 0.6861\n",
            "Epoch 62: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 62: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 62: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 62: accuracy did not improve from 0.82812\n",
            " 84/121 [===================>..........] - ETA: 0s - loss: 2.1475 - accuracy: 0.6830\n",
            "Epoch 62: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 62: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 62: accuracy did not improve from 0.82812\n",
            "100/121 [=======================>......] - ETA: 0s - loss: 2.1558 - accuracy: 0.6831\n",
            "Epoch 62: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 62: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 62: accuracy did not improve from 0.82812\n",
            "115/121 [===========================>..] - ETA: 0s - loss: 2.1748 - accuracy: 0.6799\n",
            "Epoch 62: accuracy did not improve from 0.82812\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.1892 - accuracy: 0.6788\n",
            "Epoch 63/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 1.7155 - accuracy: 0.7188\n",
            "Epoch 63: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 63: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 63: accuracy did not improve from 0.82812\n",
            " 16/121 [==>...........................] - ETA: 0s - loss: 2.1391 - accuracy: 0.7109\n",
            "Epoch 63: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 63: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 63: accuracy did not improve from 0.82812\n",
            " 30/121 [======>.......................] - ETA: 0s - loss: 2.1547 - accuracy: 0.6906\n",
            "Epoch 63: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 63: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 63: accuracy did not improve from 0.82812\n",
            " 45/121 [==========>...................] - ETA: 0s - loss: 2.1378 - accuracy: 0.6910\n",
            "Epoch 63: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 63: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 63: accuracy did not improve from 0.82812\n",
            " 61/121 [==============>...............] - ETA: 0s - loss: 2.2086 - accuracy: 0.6870\n",
            "Epoch 63: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 63: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 63: accuracy did not improve from 0.82812\n",
            " 76/121 [=================>............] - ETA: 0s - loss: 2.2081 - accuracy: 0.6822\n",
            "Epoch 63: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 63: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 63: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 63: accuracy did not improve from 0.82812\n",
            " 93/121 [======================>.......] - ETA: 0s - loss: 2.1663 - accuracy: 0.6811\n",
            "Epoch 63: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 63: accuracy did not improve from 0.82812\n",
            "107/121 [=========================>....] - ETA: 0s - loss: 2.1876 - accuracy: 0.6787\n",
            "Epoch 63: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 63: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 63: accuracy did not improve from 0.82812\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.1892 - accuracy: 0.6788\n",
            "Epoch 64/100\n",
            "  1/121 [..............................] - ETA: 1s - loss: 1.9094 - accuracy: 0.7500\n",
            "Epoch 64: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 64: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 64: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 64: accuracy did not improve from 0.82812\n",
            " 17/121 [===>..........................] - ETA: 0s - loss: 2.3226 - accuracy: 0.6765\n",
            "Epoch 64: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 64: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 64: accuracy did not improve from 0.82812\n",
            " 33/121 [=======>......................] - ETA: 0s - loss: 2.2192 - accuracy: 0.6780\n",
            "Epoch 64: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 64: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 64: accuracy did not improve from 0.82812\n",
            " 49/121 [===========>..................] - ETA: 0s - loss: 2.1987 - accuracy: 0.6760\n",
            "Epoch 64: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 64: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 64: accuracy did not improve from 0.82812\n",
            " 65/121 [===============>..............] - ETA: 0s - loss: 2.2443 - accuracy: 0.6731\n",
            "Epoch 64: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 64: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 64: accuracy did not improve from 0.82812\n",
            " 80/121 [==================>...........] - ETA: 0s - loss: 2.2263 - accuracy: 0.6723\n",
            "Epoch 64: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 64: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 64: accuracy did not improve from 0.82812\n",
            " 94/121 [======================>.......] - ETA: 0s - loss: 2.2204 - accuracy: 0.6789\n",
            "Epoch 64: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 64: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 64: accuracy did not improve from 0.82812\n",
            "108/121 [=========================>....] - ETA: 0s - loss: 2.1912 - accuracy: 0.6785\n",
            "Epoch 64: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 64: accuracy did not improve from 0.82812\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.1892 - accuracy: 0.6788\n",
            "Epoch 65/100\n",
            "\n",
            "Epoch 65: accuracy did not improve from 0.82812\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.5733 - accuracy: 0.6875\n",
            "Epoch 65: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 65: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 65: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 65: accuracy did not improve from 0.82812\n",
            " 21/121 [====>.........................] - ETA: 0s - loss: 2.1427 - accuracy: 0.6890\n",
            "Epoch 65: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 65: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 65: accuracy did not improve from 0.82812\n",
            " 37/121 [========>.....................] - ETA: 0s - loss: 2.1955 - accuracy: 0.6757\n",
            "Epoch 65: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 65: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 65: accuracy did not improve from 0.82812\n",
            " 54/121 [============>.................] - ETA: 0s - loss: 2.1876 - accuracy: 0.6829\n",
            "Epoch 65: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 65: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 65: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 65: accuracy did not improve from 0.82812\n",
            " 71/121 [================>.............] - ETA: 0s - loss: 2.1794 - accuracy: 0.6831\n",
            "Epoch 65: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 65: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 65: accuracy did not improve from 0.82812\n",
            " 89/121 [=====================>........] - ETA: 0s - loss: 2.1886 - accuracy: 0.6815\n",
            "Epoch 65: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 65: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 65: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 65: accuracy did not improve from 0.82812\n",
            "106/121 [=========================>....] - ETA: 0s - loss: 2.1831 - accuracy: 0.6807\n",
            "Epoch 65: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 65: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 65: accuracy did not improve from 0.82812\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.1892 - accuracy: 0.6788\n",
            "Epoch 66/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.5733 - accuracy: 0.7500\n",
            "Epoch 66: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 66: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 66: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 66: accuracy did not improve from 0.82812\n",
            " 21/121 [====>.........................] - ETA: 0s - loss: 2.2929 - accuracy: 0.6771\n",
            "Epoch 66: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 66: accuracy did not improve from 0.82812\n",
            " 33/121 [=======>......................] - ETA: 0s - loss: 2.1903 - accuracy: 0.6837\n",
            "Epoch 66: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 66: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 66: accuracy did not improve from 0.82812\n",
            " 48/121 [==========>...................] - ETA: 0s - loss: 2.1753 - accuracy: 0.6849\n",
            "Epoch 66: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 66: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 66: accuracy did not improve from 0.82812\n",
            " 64/121 [==============>...............] - ETA: 0s - loss: 2.1842 - accuracy: 0.6831\n",
            "Epoch 66: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 66: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 66: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 66: accuracy did not improve from 0.82812\n",
            " 81/121 [===================>..........] - ETA: 0s - loss: 2.1789 - accuracy: 0.6782\n",
            "Epoch 66: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 66: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 66: accuracy did not improve from 0.82812\n",
            " 98/121 [=======================>......] - ETA: 0s - loss: 2.1881 - accuracy: 0.6770\n",
            "Epoch 66: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 66: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 66: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 66: accuracy did not improve from 0.82812\n",
            "116/121 [===========================>..] - ETA: 0s - loss: 2.1864 - accuracy: 0.6789\n",
            "Epoch 66: accuracy did not improve from 0.82812\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.1892 - accuracy: 0.6788\n",
            "Epoch 67/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.4780 - accuracy: 0.7188\n",
            "Epoch 67: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 67: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 67: accuracy did not improve from 0.82812\n",
            " 16/121 [==>...........................] - ETA: 0s - loss: 2.2228 - accuracy: 0.6719\n",
            "Epoch 67: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 67: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 67: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 67: accuracy did not improve from 0.82812\n",
            " 34/121 [=======>......................] - ETA: 0s - loss: 2.2465 - accuracy: 0.6728\n",
            "Epoch 67: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 67: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 67: accuracy did not improve from 0.82812\n",
            " 52/121 [===========>..................] - ETA: 0s - loss: 2.2390 - accuracy: 0.6779\n",
            "Epoch 67: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 67: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 67: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 67: accuracy did not improve from 0.82812\n",
            " 70/121 [================>.............] - ETA: 0s - loss: 2.2529 - accuracy: 0.6701\n",
            "Epoch 67: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 67: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 67: accuracy did not improve from 0.82812\n",
            " 85/121 [====================>.........] - ETA: 0s - loss: 2.2188 - accuracy: 0.6765\n",
            "Epoch 67: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 67: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 67: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 67: accuracy did not improve from 0.82812\n",
            "104/121 [========================>.....] - ETA: 0s - loss: 2.2077 - accuracy: 0.6770\n",
            "Epoch 67: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 67: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 67: accuracy did not improve from 0.82812\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.1892 - accuracy: 0.6788\n",
            "Epoch 68/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.4780 - accuracy: 0.6562\n",
            "Epoch 68: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 68: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 68: accuracy did not improve from 0.82812\n",
            " 16/121 [==>...........................] - ETA: 0s - loss: 2.0619 - accuracy: 0.6543\n",
            "Epoch 68: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 68: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 68: accuracy did not improve from 0.82812\n",
            " 32/121 [======>.......................] - ETA: 0s - loss: 2.2145 - accuracy: 0.6660\n",
            "Epoch 68: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 68: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 68: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 68: accuracy did not improve from 0.82812\n",
            " 52/121 [===========>..................] - ETA: 0s - loss: 2.1217 - accuracy: 0.6815\n",
            "Epoch 68: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 68: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 68: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 68: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 68: accuracy did not improve from 0.82812\n",
            " 73/121 [=================>............] - ETA: 0s - loss: 2.1761 - accuracy: 0.6789\n",
            "Epoch 68: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 68: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 68: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 68: accuracy did not improve from 0.82812\n",
            " 93/121 [======================>.......] - ETA: 0s - loss: 2.1602 - accuracy: 0.6865\n",
            "Epoch 68: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 68: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 68: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 68: accuracy did not improve from 0.82812\n",
            "113/121 [===========================>..] - ETA: 0s - loss: 2.1710 - accuracy: 0.6825\n",
            "Epoch 68: accuracy did not improve from 0.82812\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.1892 - accuracy: 0.6788\n",
            "Epoch 69/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.4780 - accuracy: 0.6875\n",
            "Epoch 69: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 69: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 69: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 69: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 69: accuracy did not improve from 0.82812\n",
            " 22/121 [====>.........................] - ETA: 0s - loss: 2.3274 - accuracy: 0.6619\n",
            "Epoch 69: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 69: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 69: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 69: accuracy did not improve from 0.82812\n",
            " 42/121 [=========>....................] - ETA: 0s - loss: 2.2179 - accuracy: 0.6756\n",
            "Epoch 69: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 69: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 69: accuracy did not improve from 0.82812\n",
            " 59/121 [=============>................] - ETA: 0s - loss: 2.2301 - accuracy: 0.6642\n",
            "Epoch 69: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 69: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 69: accuracy did not improve from 0.82812\n",
            " 72/121 [================>.............] - ETA: 0s - loss: 2.2299 - accuracy: 0.6680\n",
            "Epoch 69: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 69: accuracy did not improve from 0.82812\n",
            " 86/121 [====================>.........] - ETA: 0s - loss: 2.2296 - accuracy: 0.6693\n",
            "Epoch 69: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 69: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 69: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 69: accuracy did not improve from 0.82812\n",
            "102/121 [========================>.....] - ETA: 0s - loss: 2.2023 - accuracy: 0.6731\n",
            "Epoch 69: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 69: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 69: accuracy did not improve from 0.82812\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.1892 - accuracy: 0.6788\n",
            "Epoch 70/100\n",
            "\n",
            "Epoch 70: accuracy did not improve from 0.82812\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.0015 - accuracy: 0.6562\n",
            "Epoch 70: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 70: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 70: accuracy did not improve from 0.82812\n",
            " 17/121 [===>..........................] - ETA: 0s - loss: 2.2209 - accuracy: 0.6691\n",
            "Epoch 70: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 70: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 70: accuracy did not improve from 0.82812\n",
            " 34/121 [=======>......................] - ETA: 0s - loss: 2.1957 - accuracy: 0.6682\n",
            "Epoch 70: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 70: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 70: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 70: accuracy did not improve from 0.82812\n",
            " 52/121 [===========>..................] - ETA: 0s - loss: 2.1802 - accuracy: 0.6791\n",
            "Epoch 70: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 70: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 70: accuracy did not improve from 0.82812\n",
            " 68/121 [===============>..............] - ETA: 0s - loss: 2.1369 - accuracy: 0.6843\n",
            "Epoch 70: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 70: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 70: accuracy did not improve from 0.82812\n",
            " 85/121 [====================>.........] - ETA: 0s - loss: 2.1740 - accuracy: 0.6750\n",
            "Epoch 70: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 70: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 70: accuracy did not improve from 0.82812\n",
            " 98/121 [=======================>......] - ETA: 0s - loss: 2.1862 - accuracy: 0.6779\n",
            "Epoch 70: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 70: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 70: accuracy did not improve from 0.82812\n",
            "114/121 [===========================>..] - ETA: 0s - loss: 2.1813 - accuracy: 0.6796\n",
            "Epoch 70: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 70: accuracy did not improve from 0.82812\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.1892 - accuracy: 0.6788\n",
            "Epoch 71/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 3.4344 - accuracy: 0.5625\n",
            "Epoch 71: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 71: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 71: accuracy did not improve from 0.82812\n",
            " 18/121 [===>..........................] - ETA: 0s - loss: 2.1724 - accuracy: 0.6823\n",
            "Epoch 71: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 71: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 71: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 71: accuracy did not improve from 0.82812\n",
            " 35/121 [=======>......................] - ETA: 0s - loss: 2.1332 - accuracy: 0.6821\n",
            "Epoch 71: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 71: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 71: accuracy did not improve from 0.82812\n",
            " 53/121 [============>.................] - ETA: 0s - loss: 2.0778 - accuracy: 0.6822\n",
            "Epoch 71: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 71: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 71: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 71: accuracy did not improve from 0.82812\n",
            " 70/121 [================>.............] - ETA: 0s - loss: 2.1098 - accuracy: 0.6839\n",
            "Epoch 71: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 71: accuracy did not improve from 0.82812\n",
            " 82/121 [===================>..........] - ETA: 0s - loss: 2.1568 - accuracy: 0.6803\n",
            "Epoch 71: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 71: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 71: accuracy did not improve from 0.82812\n",
            " 97/121 [=======================>......] - ETA: 0s - loss: 2.1910 - accuracy: 0.6753\n",
            "Epoch 71: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 71: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 71: accuracy did not improve from 0.82812\n",
            "111/121 [==========================>...] - ETA: 0s - loss: 2.2041 - accuracy: 0.6751\n",
            "Epoch 71: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 71: accuracy did not improve from 0.82812\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.1892 - accuracy: 0.6788\n",
            "Epoch 72/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.3827 - accuracy: 0.7500\n",
            "Epoch 72: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 72: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 72: accuracy did not improve from 0.82812\n",
            " 18/121 [===>..........................] - ETA: 0s - loss: 2.2354 - accuracy: 0.6632\n",
            "Epoch 72: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 72: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 72: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 72: accuracy did not improve from 0.82812\n",
            " 34/121 [=======>......................] - ETA: 0s - loss: 2.2350 - accuracy: 0.6645\n",
            "Epoch 72: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 72: accuracy did not improve from 0.82812\n",
            " 48/121 [==========>...................] - ETA: 0s - loss: 2.2206 - accuracy: 0.6706\n",
            "Epoch 72: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 72: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 72: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 72: accuracy did not improve from 0.82812\n",
            " 65/121 [===============>..............] - ETA: 0s - loss: 2.2193 - accuracy: 0.6716\n",
            "Epoch 72: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 72: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 72: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 72: accuracy did not improve from 0.82812\n",
            " 84/121 [===================>..........] - ETA: 0s - loss: 2.1804 - accuracy: 0.6760\n",
            "Epoch 72: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 72: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 72: accuracy did not improve from 0.82812\n",
            "103/121 [========================>.....] - ETA: 0s - loss: 2.1837 - accuracy: 0.6778\n",
            "Epoch 72: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 72: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 72: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 72: accuracy did not improve from 0.82812\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.1892 - accuracy: 0.6788\n",
            "Epoch 73/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.1921 - accuracy: 0.7188\n",
            "Epoch 73: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 73: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 73: accuracy did not improve from 0.82812\n",
            " 17/121 [===>..........................] - ETA: 0s - loss: 2.2780 - accuracy: 0.6838\n",
            "Epoch 73: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 73: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 73: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 73: accuracy did not improve from 0.82812\n",
            " 33/121 [=======>......................] - ETA: 0s - loss: 2.1238 - accuracy: 0.6960\n",
            "Epoch 73: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 73: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 73: accuracy did not improve from 0.82812\n",
            " 52/121 [===========>..................] - ETA: 0s - loss: 2.1840 - accuracy: 0.6863\n",
            "Epoch 73: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 73: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 73: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 73: accuracy did not improve from 0.82812\n",
            " 69/121 [================>.............] - ETA: 0s - loss: 2.1599 - accuracy: 0.6898\n",
            "Epoch 73: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 73: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 73: accuracy did not improve from 0.82812\n",
            " 87/121 [====================>.........] - ETA: 0s - loss: 2.1448 - accuracy: 0.6893\n",
            "Epoch 73: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 73: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 73: accuracy did not improve from 0.82812\n",
            "101/121 [========================>.....] - ETA: 0s - loss: 2.1477 - accuracy: 0.6866\n",
            "Epoch 73: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 73: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 73: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 73: accuracy did not improve from 0.82812\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.1892 - accuracy: 0.6788\n",
            "Epoch 74/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 1.9094 - accuracy: 0.6562\n",
            "Epoch 74: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 74: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 74: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 74: accuracy did not improve from 0.82812\n",
            " 17/121 [===>..........................] - ETA: 0s - loss: 2.1874 - accuracy: 0.6691\n",
            "Epoch 74: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 74: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 74: accuracy did not improve from 0.82812\n",
            " 33/121 [=======>......................] - ETA: 0s - loss: 2.1640 - accuracy: 0.6657\n",
            "Epoch 74: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 74: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 74: accuracy did not improve from 0.82812\n",
            " 50/121 [===========>..................] - ETA: 0s - loss: 2.2079 - accuracy: 0.6656\n",
            "Epoch 74: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 74: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 74: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 74: accuracy did not improve from 0.82812\n",
            " 67/121 [===============>..............] - ETA: 0s - loss: 2.2241 - accuracy: 0.6716\n",
            "Epoch 74: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 74: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 74: accuracy did not improve from 0.82812\n",
            " 86/121 [====================>.........] - ETA: 0s - loss: 2.2149 - accuracy: 0.6719\n",
            "Epoch 74: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 74: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 74: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 74: accuracy did not improve from 0.82812\n",
            "105/121 [=========================>....] - ETA: 0s - loss: 2.1774 - accuracy: 0.6762\n",
            "Epoch 74: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 74: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 74: accuracy did not improve from 0.82812\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.1892 - accuracy: 0.6788\n",
            "Epoch 75/100\n",
            "\n",
            "Epoch 75: accuracy did not improve from 0.82812\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.5766 - accuracy: 0.7188\n",
            "Epoch 75: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 75: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 75: accuracy did not improve from 0.82812\n",
            " 18/121 [===>..........................] - ETA: 0s - loss: 2.2251 - accuracy: 0.6892\n",
            "Epoch 75: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 75: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 75: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 75: accuracy did not improve from 0.82812\n",
            " 36/121 [=======>......................] - ETA: 0s - loss: 2.2275 - accuracy: 0.6710\n",
            "Epoch 75: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 75: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 75: accuracy did not improve from 0.82812\n",
            " 51/121 [===========>..................] - ETA: 0s - loss: 2.1686 - accuracy: 0.6820\n",
            "Epoch 75: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 75: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 75: accuracy did not improve from 0.82812\n",
            " 69/121 [================>.............] - ETA: 0s - loss: 2.1611 - accuracy: 0.6816\n",
            "Epoch 75: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 75: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 75: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 75: accuracy did not improve from 0.82812\n",
            " 87/121 [====================>.........] - ETA: 0s - loss: 2.1578 - accuracy: 0.6825\n",
            "Epoch 75: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 75: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 75: accuracy did not improve from 0.82812\n",
            "105/121 [=========================>....] - ETA: 0s - loss: 2.1903 - accuracy: 0.6801\n",
            "Epoch 75: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 75: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 75: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 75: accuracy did not improve from 0.82812\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.1892 - accuracy: 0.6788\n",
            "Epoch 76/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.1921 - accuracy: 0.6562\n",
            "Epoch 76: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 76: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 76: accuracy did not improve from 0.82812\n",
            " 19/121 [===>..........................] - ETA: 0s - loss: 2.0374 - accuracy: 0.6990\n",
            "Epoch 76: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 76: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 76: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 76: accuracy did not improve from 0.82812\n",
            " 36/121 [=======>......................] - ETA: 0s - loss: 2.1560 - accuracy: 0.6849\n",
            "Epoch 76: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 76: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 76: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 76: accuracy did not improve from 0.82812\n",
            " 55/121 [============>.................] - ETA: 0s - loss: 2.2242 - accuracy: 0.6790\n",
            "Epoch 76: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 76: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 76: accuracy did not improve from 0.82812\n",
            " 73/121 [=================>............] - ETA: 0s - loss: 2.1879 - accuracy: 0.6871\n",
            "Epoch 76: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 76: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 76: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 76: accuracy did not improve from 0.82812\n",
            " 91/121 [=====================>........] - ETA: 0s - loss: 2.2245 - accuracy: 0.6758\n",
            "Epoch 76: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 76: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 76: accuracy did not improve from 0.82812\n",
            "109/121 [==========================>...] - ETA: 0s - loss: 2.2035 - accuracy: 0.6778\n",
            "Epoch 76: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 76: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 76: accuracy did not improve from 0.82812\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.1892 - accuracy: 0.6788\n",
            "Epoch 77/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.0968 - accuracy: 0.6562\n",
            "Epoch 77: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 77: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 77: accuracy did not improve from 0.82812\n",
            " 18/121 [===>..........................] - ETA: 0s - loss: 2.1195 - accuracy: 0.6788\n",
            "Epoch 77: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 77: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 77: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 77: accuracy did not improve from 0.82812\n",
            " 36/121 [=======>......................] - ETA: 0s - loss: 2.1801 - accuracy: 0.6788\n",
            "Epoch 77: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 77: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 77: accuracy did not improve from 0.82812\n",
            " 52/121 [===========>..................] - ETA: 0s - loss: 2.2115 - accuracy: 0.6719\n",
            "Epoch 77: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 77: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 77: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 77: accuracy did not improve from 0.82812\n",
            " 69/121 [================>.............] - ETA: 0s - loss: 2.2193 - accuracy: 0.6766\n",
            "Epoch 77: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 77: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 77: accuracy did not improve from 0.82812\n",
            " 87/121 [====================>.........] - ETA: 0s - loss: 2.2271 - accuracy: 0.6771\n",
            "Epoch 77: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 77: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 77: accuracy did not improve from 0.82812\n",
            "103/121 [========================>.....] - ETA: 0s - loss: 2.2060 - accuracy: 0.6754\n",
            "Epoch 77: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 77: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 77: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 77: accuracy did not improve from 0.82812\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.1892 - accuracy: 0.6788\n",
            "Epoch 78/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 1.9062 - accuracy: 0.6875\n",
            "Epoch 78: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 78: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 78: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 78: accuracy did not improve from 0.82812\n",
            " 19/121 [===>..........................] - ETA: 0s - loss: 1.9371 - accuracy: 0.7089\n",
            "Epoch 78: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 78: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 78: accuracy did not improve from 0.82812\n",
            " 37/121 [========>.....................] - ETA: 0s - loss: 2.1491 - accuracy: 0.6799\n",
            "Epoch 78: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 78: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 78: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 78: accuracy did not improve from 0.82812\n",
            " 53/121 [============>.................] - ETA: 0s - loss: 2.2219 - accuracy: 0.6781\n",
            "Epoch 78: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 78: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 78: accuracy did not improve from 0.82812\n",
            " 69/121 [================>.............] - ETA: 0s - loss: 2.2261 - accuracy: 0.6730\n",
            "Epoch 78: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 78: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 78: accuracy did not improve from 0.82812\n",
            " 86/121 [====================>.........] - ETA: 0s - loss: 2.1919 - accuracy: 0.6762\n",
            "Epoch 78: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 78: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 78: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 78: accuracy did not improve from 0.82812\n",
            "103/121 [========================>.....] - ETA: 0s - loss: 2.1883 - accuracy: 0.6763\n",
            "Epoch 78: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 78: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 78: accuracy did not improve from 0.82812\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.1892 - accuracy: 0.6788\n",
            "Epoch 79/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.4780 - accuracy: 0.6250\n",
            "Epoch 79: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 79: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 79: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 79: accuracy did not improve from 0.82812\n",
            " 18/121 [===>..........................] - ETA: 0s - loss: 2.2513 - accuracy: 0.6649\n",
            "Epoch 79: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 79: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 79: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 79: accuracy did not improve from 0.82812\n",
            " 37/121 [========>.....................] - ETA: 0s - loss: 2.2467 - accuracy: 0.6588\n",
            "Epoch 79: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 79: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 79: accuracy did not improve from 0.82812\n",
            " 55/121 [============>.................] - ETA: 0s - loss: 2.1911 - accuracy: 0.6722\n",
            "Epoch 79: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 79: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 79: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 79: accuracy did not improve from 0.82812\n",
            " 72/121 [================>.............] - ETA: 0s - loss: 2.2180 - accuracy: 0.6701\n",
            "Epoch 79: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 79: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 79: accuracy did not improve from 0.82812\n",
            " 91/121 [=====================>........] - ETA: 0s - loss: 2.1908 - accuracy: 0.6734\n",
            "Epoch 79: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 79: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 79: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 79: accuracy did not improve from 0.82812\n",
            "107/121 [=========================>....] - ETA: 0s - loss: 2.1947 - accuracy: 0.6741\n",
            "Epoch 79: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 79: accuracy did not improve from 0.82812\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.1892 - accuracy: 0.6788\n",
            "Epoch 80/100\n",
            "\n",
            "Epoch 80: accuracy did not improve from 0.82812\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.8592 - accuracy: 0.5625\n",
            "Epoch 80: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 80: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 80: accuracy did not improve from 0.82812\n",
            " 19/121 [===>..........................] - ETA: 0s - loss: 2.2881 - accuracy: 0.6760\n",
            "Epoch 80: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 80: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 80: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 80: accuracy did not improve from 0.82812\n",
            " 37/121 [========>.....................] - ETA: 0s - loss: 2.2318 - accuracy: 0.6715\n",
            "Epoch 80: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 80: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 80: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 80: accuracy did not improve from 0.82812\n",
            " 56/121 [============>.................] - ETA: 0s - loss: 2.2150 - accuracy: 0.6708\n",
            "Epoch 80: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 80: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 80: accuracy did not improve from 0.82812\n",
            " 72/121 [================>.............] - ETA: 0s - loss: 2.2103 - accuracy: 0.6732\n",
            "Epoch 80: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 80: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 80: accuracy did not improve from 0.82812\n",
            " 90/121 [=====================>........] - ETA: 0s - loss: 2.1888 - accuracy: 0.6819\n",
            "Epoch 80: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 80: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 80: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 80: accuracy did not improve from 0.82812\n",
            "106/121 [=========================>....] - ETA: 0s - loss: 2.1769 - accuracy: 0.6828\n",
            "Epoch 80: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 80: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 80: accuracy did not improve from 0.82812\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.1892 - accuracy: 0.6788\n",
            "Epoch 81/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.8625 - accuracy: 0.6562\n",
            "Epoch 81: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 81: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 81: accuracy did not improve from 0.82812\n",
            " 19/121 [===>..........................] - ETA: 0s - loss: 2.2335 - accuracy: 0.6776\n",
            "Epoch 81: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 81: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 81: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 81: accuracy did not improve from 0.82812\n",
            " 36/121 [=======>......................] - ETA: 0s - loss: 2.2195 - accuracy: 0.6875\n",
            "Epoch 81: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 81: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 81: accuracy did not improve from 0.82812\n",
            " 54/121 [============>.................] - ETA: 0s - loss: 2.2071 - accuracy: 0.6834\n",
            "Epoch 81: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 81: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 81: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 81: accuracy did not improve from 0.82812\n",
            " 70/121 [================>.............] - ETA: 0s - loss: 2.1902 - accuracy: 0.6786\n",
            "Epoch 81: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 81: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 81: accuracy did not improve from 0.82812\n",
            " 88/121 [====================>.........] - ETA: 0s - loss: 2.1854 - accuracy: 0.6772\n",
            "Epoch 81: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 81: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 81: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 81: accuracy did not improve from 0.82812\n",
            "105/121 [=========================>....] - ETA: 0s - loss: 2.1784 - accuracy: 0.6780\n",
            "Epoch 81: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 81: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 81: accuracy did not improve from 0.82812\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.1892 - accuracy: 0.6788\n",
            "Epoch 82/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 1.7166 - accuracy: 0.7500\n",
            "Epoch 82: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 82: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 82: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 82: accuracy did not improve from 0.82812\n",
            " 19/121 [===>..........................] - ETA: 0s - loss: 2.1977 - accuracy: 0.6924\n",
            "Epoch 82: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 82: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 82: accuracy did not improve from 0.82812\n",
            " 38/121 [========>.....................] - ETA: 0s - loss: 2.0851 - accuracy: 0.7056\n",
            "Epoch 82: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 82: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 82: accuracy did not improve from 0.82812\n",
            " 51/121 [===========>..................] - ETA: 0s - loss: 2.1219 - accuracy: 0.6998\n",
            "Epoch 82: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 82: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 82: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 82: accuracy did not improve from 0.82812\n",
            " 69/121 [================>.............] - ETA: 0s - loss: 2.1930 - accuracy: 0.6839\n",
            "Epoch 82: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 82: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 82: accuracy did not improve from 0.82812\n",
            " 88/121 [====================>.........] - ETA: 0s - loss: 2.2049 - accuracy: 0.6783\n",
            "Epoch 82: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 82: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 82: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 82: accuracy did not improve from 0.82812\n",
            "106/121 [=========================>....] - ETA: 0s - loss: 2.1938 - accuracy: 0.6742\n",
            "Epoch 82: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 82: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 82: accuracy did not improve from 0.82812\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.1892 - accuracy: 0.6788\n",
            "Epoch 83/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 1.7155 - accuracy: 0.7188\n",
            "Epoch 83: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 83: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 83: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 83: accuracy did not improve from 0.82812\n",
            " 20/121 [===>..........................] - ETA: 0s - loss: 2.1645 - accuracy: 0.6781\n",
            "Epoch 83: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 83: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 83: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 83: accuracy did not improve from 0.82812\n",
            " 38/121 [========>.....................] - ETA: 0s - loss: 2.1778 - accuracy: 0.6768\n",
            "Epoch 83: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 83: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 83: accuracy did not improve from 0.82812\n",
            " 56/121 [============>.................] - ETA: 0s - loss: 2.2098 - accuracy: 0.6775\n",
            "Epoch 83: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 83: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 83: accuracy did not improve from 0.82812\n",
            " 70/121 [================>.............] - ETA: 0s - loss: 2.1343 - accuracy: 0.6835\n",
            "Epoch 83: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 83: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 83: accuracy did not improve from 0.82812\n",
            " 85/121 [====================>.........] - ETA: 0s - loss: 2.1693 - accuracy: 0.6772\n",
            "Epoch 83: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 83: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 83: accuracy did not improve from 0.82812\n",
            " 99/121 [=======================>......] - ETA: 0s - loss: 2.1688 - accuracy: 0.6793\n",
            "Epoch 83: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 83: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 83: accuracy did not improve from 0.82812\n",
            "113/121 [===========================>..] - ETA: 0s - loss: 2.1761 - accuracy: 0.6809\n",
            "Epoch 83: accuracy did not improve from 0.82812\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.1892 - accuracy: 0.6788\n",
            "Epoch 84/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 1.8152 - accuracy: 0.7812\n",
            "Epoch 84: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 84: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 84: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 84: accuracy did not improve from 0.82812\n",
            " 19/121 [===>..........................] - ETA: 0s - loss: 2.1425 - accuracy: 0.6842\n",
            "Epoch 84: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 84: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 84: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 84: accuracy did not improve from 0.82812\n",
            " 38/121 [========>.....................] - ETA: 0s - loss: 2.2355 - accuracy: 0.6826\n",
            "Epoch 84: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 84: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 84: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 84: accuracy did not improve from 0.82812\n",
            " 59/121 [=============>................] - ETA: 0s - loss: 2.1943 - accuracy: 0.6923\n",
            "Epoch 84: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 84: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 84: accuracy did not improve from 0.82812\n",
            " 74/121 [=================>............] - ETA: 0s - loss: 2.1891 - accuracy: 0.6867\n",
            "Epoch 84: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 84: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 84: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 84: accuracy did not improve from 0.82812\n",
            " 94/121 [======================>.......] - ETA: 0s - loss: 2.1665 - accuracy: 0.6868\n",
            "Epoch 84: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 84: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 84: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 84: accuracy did not improve from 0.82812\n",
            "114/121 [===========================>..] - ETA: 0s - loss: 2.1838 - accuracy: 0.6820\n",
            "Epoch 84: accuracy did not improve from 0.82812\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.1892 - accuracy: 0.6788\n",
            "Epoch 85/100\n",
            "\n",
            "Epoch 85: accuracy did not improve from 0.82812\n",
            "  1/121 [..............................] - ETA: 0s - loss: 1.9062 - accuracy: 0.6562\n",
            "Epoch 85: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 85: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 85: accuracy did not improve from 0.82812\n",
            " 18/121 [===>..........................] - ETA: 0s - loss: 2.1718 - accuracy: 0.6979\n",
            "Epoch 85: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 85: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 85: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 85: accuracy did not improve from 0.82812\n",
            " 36/121 [=======>......................] - ETA: 0s - loss: 2.1718 - accuracy: 0.6910\n",
            "Epoch 85: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 85: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 85: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 85: accuracy did not improve from 0.82812\n",
            " 56/121 [============>.................] - ETA: 0s - loss: 2.2613 - accuracy: 0.6808\n",
            "Epoch 85: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 85: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 85: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 85: accuracy did not improve from 0.82812\n",
            " 76/121 [=================>............] - ETA: 0s - loss: 2.2283 - accuracy: 0.6793\n",
            "Epoch 85: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 85: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 85: accuracy did not improve from 0.82812\n",
            " 92/121 [=====================>........] - ETA: 0s - loss: 2.1600 - accuracy: 0.6872\n",
            "Epoch 85: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 85: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 85: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 85: accuracy did not improve from 0.82812\n",
            "111/121 [==========================>...] - ETA: 0s - loss: 2.1578 - accuracy: 0.6830\n",
            "Epoch 85: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 85: accuracy did not improve from 0.82812\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.1892 - accuracy: 0.6788\n",
            "Epoch 86/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 1.9062 - accuracy: 0.6875\n",
            "Epoch 86: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 86: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 86: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 86: accuracy did not improve from 0.82812\n",
            " 21/121 [====>.........................] - ETA: 0s - loss: 2.0973 - accuracy: 0.6964\n",
            "Epoch 86: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 86: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 86: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 86: accuracy did not improve from 0.82812\n",
            " 40/121 [========>.....................] - ETA: 0s - loss: 2.1930 - accuracy: 0.6914\n",
            "Epoch 86: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 86: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 86: accuracy did not improve from 0.82812\n",
            " 56/121 [============>.................] - ETA: 0s - loss: 2.1811 - accuracy: 0.6853\n",
            "Epoch 86: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 86: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 86: accuracy did not improve from 0.82812\n",
            " 70/121 [================>.............] - ETA: 0s - loss: 2.1985 - accuracy: 0.6875\n",
            "Epoch 86: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 86: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 86: accuracy did not improve from 0.82812\n",
            " 85/121 [====================>.........] - ETA: 0s - loss: 2.2143 - accuracy: 0.6831\n",
            "Epoch 86: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 86: accuracy did not improve from 0.82812\n",
            " 99/121 [=======================>......] - ETA: 0s - loss: 2.2045 - accuracy: 0.6774\n",
            "Epoch 86: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 86: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 86: accuracy did not improve from 0.82812\n",
            "113/121 [===========================>..] - ETA: 0s - loss: 2.2116 - accuracy: 0.6751\n",
            "Epoch 86: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 86: accuracy did not improve from 0.82812\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.1892 - accuracy: 0.6788\n",
            "Epoch 87/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.1921 - accuracy: 0.7500\n",
            "Epoch 87: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 87: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 87: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 87: accuracy did not improve from 0.82812\n",
            " 19/121 [===>..........................] - ETA: 0s - loss: 2.1935 - accuracy: 0.6908\n",
            "Epoch 87: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 87: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 87: accuracy did not improve from 0.82812\n",
            " 37/121 [========>.....................] - ETA: 0s - loss: 2.2652 - accuracy: 0.6639\n",
            "Epoch 87: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 87: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 87: accuracy did not improve from 0.82812\n",
            " 52/121 [===========>..................] - ETA: 0s - loss: 2.2296 - accuracy: 0.6677\n",
            "Epoch 87: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 87: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 87: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 87: accuracy did not improve from 0.82812\n",
            " 69/121 [================>.............] - ETA: 0s - loss: 2.2137 - accuracy: 0.6762\n",
            "Epoch 87: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 87: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 87: accuracy did not improve from 0.82812\n",
            " 87/121 [====================>.........] - ETA: 0s - loss: 2.1930 - accuracy: 0.6796\n",
            "Epoch 87: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 87: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 87: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 87: accuracy did not improve from 0.82812\n",
            "106/121 [=========================>....] - ETA: 0s - loss: 2.1831 - accuracy: 0.6810\n",
            "Epoch 87: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 87: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 87: accuracy did not improve from 0.82812\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.1892 - accuracy: 0.6788\n",
            "Epoch 88/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.6686 - accuracy: 0.5000\n",
            "Epoch 88: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 88: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 88: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 88: accuracy did not improve from 0.82812\n",
            " 19/121 [===>..........................] - ETA: 0s - loss: 2.2933 - accuracy: 0.6645\n",
            "Epoch 88: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 88: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 88: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 88: accuracy did not improve from 0.82812\n",
            " 38/121 [========>.....................] - ETA: 0s - loss: 2.2003 - accuracy: 0.6785\n",
            "Epoch 88: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 88: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 88: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 88: accuracy did not improve from 0.82812\n",
            " 58/121 [=============>................] - ETA: 0s - loss: 2.1847 - accuracy: 0.6783\n",
            "Epoch 88: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 88: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 88: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 88: accuracy did not improve from 0.82812\n",
            " 78/121 [==================>...........] - ETA: 0s - loss: 2.1843 - accuracy: 0.6727\n",
            "Epoch 88: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 88: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 88: accuracy did not improve from 0.82812\n",
            " 96/121 [======================>.......] - ETA: 0s - loss: 2.1433 - accuracy: 0.6823\n",
            "Epoch 88: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 88: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 88: accuracy did not improve from 0.82812\n",
            "112/121 [==========================>...] - ETA: 0s - loss: 2.1964 - accuracy: 0.6769\n",
            "Epoch 88: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 88: accuracy did not improve from 0.82812\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.1892 - accuracy: 0.6788\n",
            "Epoch 89/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 1.7155 - accuracy: 0.6875\n",
            "Epoch 89: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 89: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 89: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 89: accuracy did not improve from 0.82812\n",
            " 17/121 [===>..........................] - ETA: 0s - loss: 1.9963 - accuracy: 0.6875\n",
            "Epoch 89: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 89: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 89: accuracy did not improve from 0.82812\n",
            " 34/121 [=======>......................] - ETA: 0s - loss: 2.1087 - accuracy: 0.6921\n",
            "Epoch 89: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 89: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 89: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 89: accuracy did not improve from 0.82812\n",
            " 52/121 [===========>..................] - ETA: 0s - loss: 2.1636 - accuracy: 0.6905\n",
            "Epoch 89: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 89: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 89: accuracy did not improve from 0.82812\n",
            " 69/121 [================>.............] - ETA: 0s - loss: 2.1709 - accuracy: 0.6861\n",
            "Epoch 89: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 89: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 89: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 89: accuracy did not improve from 0.82812\n",
            " 87/121 [====================>.........] - ETA: 0s - loss: 2.1568 - accuracy: 0.6825\n",
            "Epoch 89: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 89: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 89: accuracy did not improve from 0.82812\n",
            "106/121 [=========================>....] - ETA: 0s - loss: 2.1786 - accuracy: 0.6822\n",
            "Epoch 89: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 89: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 89: accuracy did not improve from 0.82812\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.1892 - accuracy: 0.6788\n",
            "Epoch 90/100\n",
            "\n",
            "Epoch 90: accuracy did not improve from 0.82812\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.1932 - accuracy: 0.7500\n",
            "Epoch 90: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 90: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 90: accuracy did not improve from 0.82812\n",
            " 17/121 [===>..........................] - ETA: 0s - loss: 2.2101 - accuracy: 0.6912\n",
            "Epoch 90: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 90: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 90: accuracy did not improve from 0.82812\n",
            " 32/121 [======>.......................] - ETA: 0s - loss: 2.2644 - accuracy: 0.6680\n",
            "Epoch 90: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 90: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 90: accuracy did not improve from 0.82812\n",
            " 48/121 [==========>...................] - ETA: 0s - loss: 2.2307 - accuracy: 0.6738\n",
            "Epoch 90: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 90: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 90: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 90: accuracy did not improve from 0.82812\n",
            " 66/121 [===============>..............] - ETA: 0s - loss: 2.2016 - accuracy: 0.6813\n",
            "Epoch 90: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 90: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 90: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 90: accuracy did not improve from 0.82812\n",
            " 86/121 [====================>.........] - ETA: 0s - loss: 2.1798 - accuracy: 0.6835\n",
            "Epoch 90: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 90: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 90: accuracy did not improve from 0.82812\n",
            "101/121 [========================>.....] - ETA: 0s - loss: 2.1978 - accuracy: 0.6801\n",
            "Epoch 90: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 90: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 90: accuracy did not improve from 0.82812\n",
            "116/121 [===========================>..] - ETA: 0s - loss: 2.1996 - accuracy: 0.6773\n",
            "Epoch 90: accuracy did not improve from 0.82812\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.1892 - accuracy: 0.6788\n",
            "Epoch 91/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 1.5249 - accuracy: 0.7188\n",
            "Epoch 91: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 91: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 91: accuracy did not improve from 0.82812\n",
            " 18/121 [===>..........................] - ETA: 0s - loss: 2.3356 - accuracy: 0.6493\n",
            "Epoch 91: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 91: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 91: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 91: accuracy did not improve from 0.82812\n",
            " 36/121 [=======>......................] - ETA: 0s - loss: 2.2775 - accuracy: 0.6476\n",
            "Epoch 91: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 91: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 91: accuracy did not improve from 0.82812\n",
            " 51/121 [===========>..................] - ETA: 0s - loss: 2.2358 - accuracy: 0.6630\n",
            "Epoch 91: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 91: accuracy did not improve from 0.82812\n",
            " 63/121 [==============>...............] - ETA: 0s - loss: 2.2050 - accuracy: 0.6741\n",
            "Epoch 91: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 91: accuracy did not improve from 0.82812\n",
            " 74/121 [=================>............] - ETA: 0s - loss: 2.1837 - accuracy: 0.6765\n",
            "Epoch 91: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 91: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 91: accuracy did not improve from 0.82812\n",
            " 87/121 [====================>.........] - ETA: 0s - loss: 2.1995 - accuracy: 0.6771\n",
            "Epoch 91: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 91: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 91: accuracy did not improve from 0.82812\n",
            "104/121 [========================>.....] - ETA: 0s - loss: 2.1994 - accuracy: 0.6794\n",
            "Epoch 91: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 91: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 91: accuracy did not improve from 0.82812\n",
            "115/121 [===========================>..] - ETA: 0s - loss: 2.1988 - accuracy: 0.6783\n",
            "Epoch 91: accuracy did not improve from 0.82812\n",
            "121/121 [==============================] - 0s 4ms/step - loss: 2.1892 - accuracy: 0.6788\n",
            "Epoch 92/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 1.9062 - accuracy: 0.5938\n",
            "Epoch 92: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 92: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 92: accuracy did not improve from 0.82812\n",
            " 17/121 [===>..........................] - ETA: 0s - loss: 2.1253 - accuracy: 0.6746\n",
            "Epoch 92: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 92: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 92: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 92: accuracy did not improve from 0.82812\n",
            " 34/121 [=======>......................] - ETA: 0s - loss: 2.1001 - accuracy: 0.6903\n",
            "Epoch 92: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 92: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 92: accuracy did not improve from 0.82812\n",
            " 51/121 [===========>..................] - ETA: 0s - loss: 2.0917 - accuracy: 0.6906\n",
            "Epoch 92: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 92: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 92: accuracy did not improve from 0.82812\n",
            " 67/121 [===============>..............] - ETA: 0s - loss: 2.0775 - accuracy: 0.6931\n",
            "Epoch 92: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 92: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 92: accuracy did not improve from 0.82812\n",
            " 83/121 [===================>..........] - ETA: 0s - loss: 2.1195 - accuracy: 0.6890\n",
            "Epoch 92: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 92: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 92: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 92: accuracy did not improve from 0.82812\n",
            " 99/121 [=======================>......] - ETA: 0s - loss: 2.1901 - accuracy: 0.6793\n",
            "Epoch 92: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 92: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 92: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 92: accuracy did not improve from 0.82812\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.1892 - accuracy: 0.6788\n",
            "Epoch 93/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.1921 - accuracy: 0.6250\n",
            "Epoch 93: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 93: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 93: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 93: accuracy did not improve from 0.82812\n",
            " 18/121 [===>..........................] - ETA: 0s - loss: 2.2197 - accuracy: 0.6753\n",
            "Epoch 93: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 93: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 93: accuracy did not improve from 0.82812\n",
            " 35/121 [=======>......................] - ETA: 0s - loss: 2.1931 - accuracy: 0.6723\n",
            "Epoch 93: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 93: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 93: accuracy did not improve from 0.82812\n",
            " 48/121 [==========>...................] - ETA: 0s - loss: 2.1631 - accuracy: 0.6764\n",
            "Epoch 93: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 93: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 93: accuracy did not improve from 0.82812\n",
            " 67/121 [===============>..............] - ETA: 0s - loss: 2.2028 - accuracy: 0.6754\n",
            "Epoch 93: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 93: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 93: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 93: accuracy did not improve from 0.82812\n",
            " 84/121 [===================>..........] - ETA: 0s - loss: 2.2224 - accuracy: 0.6734\n",
            "Epoch 93: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 93: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 93: accuracy did not improve from 0.82812\n",
            "101/121 [========================>.....] - ETA: 0s - loss: 2.2090 - accuracy: 0.6761\n",
            "Epoch 93: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 93: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 93: accuracy did not improve from 0.82812\n",
            "115/121 [===========================>..] - ETA: 0s - loss: 2.2053 - accuracy: 0.6750\n",
            "Epoch 93: accuracy did not improve from 0.82812\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.1892 - accuracy: 0.6788\n",
            "Epoch 94/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 1.9062 - accuracy: 0.5938\n",
            "Epoch 94: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 94: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 94: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 94: accuracy did not improve from 0.82812\n",
            " 17/121 [===>..........................] - ETA: 0s - loss: 2.1706 - accuracy: 0.6581\n",
            "Epoch 94: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 94: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 94: accuracy did not improve from 0.82812\n",
            " 32/121 [======>.......................] - ETA: 0s - loss: 2.1842 - accuracy: 0.6719\n",
            "Epoch 94: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 94: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 94: accuracy did not improve from 0.82812\n",
            " 47/121 [==========>...................] - ETA: 0s - loss: 2.1424 - accuracy: 0.6875\n",
            "Epoch 94: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 94: accuracy did not improve from 0.82812\n",
            " 61/121 [==============>...............] - ETA: 0s - loss: 2.1946 - accuracy: 0.6808\n",
            "Epoch 94: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 94: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 94: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 94: accuracy did not improve from 0.82812\n",
            " 80/121 [==================>...........] - ETA: 0s - loss: 2.2169 - accuracy: 0.6789\n",
            "Epoch 94: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 94: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 94: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 94: accuracy did not improve from 0.82812\n",
            " 97/121 [=======================>......] - ETA: 0s - loss: 2.2195 - accuracy: 0.6717\n",
            "Epoch 94: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 94: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 94: accuracy did not improve from 0.82812\n",
            "114/121 [===========================>..] - ETA: 0s - loss: 2.1855 - accuracy: 0.6787\n",
            "Epoch 94: accuracy did not improve from 0.82812\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.1892 - accuracy: 0.6788\n",
            "Epoch 95/100\n",
            "\n",
            "Epoch 95: accuracy did not improve from 0.82812\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.8592 - accuracy: 0.5625\n",
            "Epoch 95: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 95: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 95: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 95: accuracy did not improve from 0.82812\n",
            " 21/121 [====>.........................] - ETA: 0s - loss: 2.3334 - accuracy: 0.6562\n",
            "Epoch 95: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 95: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 95: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 95: accuracy did not improve from 0.82812\n",
            " 41/121 [=========>....................] - ETA: 0s - loss: 2.2880 - accuracy: 0.6768\n",
            "Epoch 95: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 95: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 95: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 95: accuracy did not improve from 0.82812\n",
            " 61/121 [==============>...............] - ETA: 0s - loss: 2.2272 - accuracy: 0.6808\n",
            "Epoch 95: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 95: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 95: accuracy did not improve from 0.82812\n",
            " 80/121 [==================>...........] - ETA: 0s - loss: 2.2155 - accuracy: 0.6754\n",
            "Epoch 95: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 95: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 95: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 95: accuracy did not improve from 0.82812\n",
            " 98/121 [=======================>......] - ETA: 0s - loss: 2.2065 - accuracy: 0.6776\n",
            "Epoch 95: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 95: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 95: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 95: accuracy did not improve from 0.82812\n",
            "116/121 [===========================>..] - ETA: 0s - loss: 2.1996 - accuracy: 0.6791\n",
            "Epoch 95: accuracy did not improve from 0.82812\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.1892 - accuracy: 0.6788\n",
            "Epoch 96/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.4813 - accuracy: 0.5938\n",
            "Epoch 96: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 96: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 96: accuracy did not improve from 0.82812\n",
            " 18/121 [===>..........................] - ETA: 0s - loss: 2.3159 - accuracy: 0.6545\n",
            "Epoch 96: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 96: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 96: accuracy did not improve from 0.82812\n",
            " 33/121 [=======>......................] - ETA: 0s - loss: 2.2949 - accuracy: 0.6600\n",
            "Epoch 96: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 96: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 96: accuracy did not improve from 0.82812\n",
            " 49/121 [===========>..................] - ETA: 0s - loss: 2.1758 - accuracy: 0.6716\n",
            "Epoch 96: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 96: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 96: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 96: accuracy did not improve from 0.82812\n",
            " 65/121 [===============>..............] - ETA: 0s - loss: 2.1346 - accuracy: 0.6822\n",
            "Epoch 96: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 96: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 96: accuracy did not improve from 0.82812\n",
            " 80/121 [==================>...........] - ETA: 0s - loss: 2.1812 - accuracy: 0.6793\n",
            "Epoch 96: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 96: accuracy did not improve from 0.82812\n",
            " 94/121 [======================>.......] - ETA: 0s - loss: 2.1687 - accuracy: 0.6802\n",
            "Epoch 96: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 96: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 96: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 96: accuracy did not improve from 0.82812\n",
            "114/121 [===========================>..] - ETA: 0s - loss: 2.1905 - accuracy: 0.6785\n",
            "Epoch 96: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 96: accuracy did not improve from 0.82812\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.1892 - accuracy: 0.6788\n",
            "Epoch 97/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 1.4296 - accuracy: 0.7188\n",
            "Epoch 97: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 97: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 97: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 97: accuracy did not improve from 0.82812\n",
            " 19/121 [===>..........................] - ETA: 0s - loss: 2.0072 - accuracy: 0.7105\n",
            "Epoch 97: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 97: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 97: accuracy did not improve from 0.82812\n",
            " 37/121 [========>.....................] - ETA: 0s - loss: 2.1901 - accuracy: 0.6858\n",
            "Epoch 97: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 97: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 97: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 97: accuracy did not improve from 0.82812\n",
            " 56/121 [============>.................] - ETA: 0s - loss: 2.2215 - accuracy: 0.6735\n",
            "Epoch 97: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 97: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 97: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 97: accuracy did not improve from 0.82812\n",
            " 74/121 [=================>............] - ETA: 0s - loss: 2.1735 - accuracy: 0.6807\n",
            "Epoch 97: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 97: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 97: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 97: accuracy did not improve from 0.82812\n",
            " 94/121 [======================>.......] - ETA: 0s - loss: 2.1980 - accuracy: 0.6775\n",
            "Epoch 97: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 97: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 97: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 97: accuracy did not improve from 0.82812\n",
            "114/121 [===========================>..] - ETA: 0s - loss: 2.1855 - accuracy: 0.6782\n",
            "Epoch 97: accuracy did not improve from 0.82812\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.1892 - accuracy: 0.6788\n",
            "Epoch 98/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.6686 - accuracy: 0.5938\n",
            "Epoch 98: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 98: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 98: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 98: accuracy did not improve from 0.82812\n",
            " 18/121 [===>..........................] - ETA: 0s - loss: 2.0772 - accuracy: 0.6910\n",
            "Epoch 98: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 98: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 98: accuracy did not improve from 0.82812\n",
            " 33/121 [=======>......................] - ETA: 0s - loss: 2.1728 - accuracy: 0.6818\n",
            "Epoch 98: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 98: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 98: accuracy did not improve from 0.82812\n",
            " 51/121 [===========>..................] - ETA: 0s - loss: 2.1834 - accuracy: 0.6783\n",
            "Epoch 98: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 98: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 98: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 98: accuracy did not improve from 0.82812\n",
            " 68/121 [===============>..............] - ETA: 0s - loss: 2.1632 - accuracy: 0.6834\n",
            "Epoch 98: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 98: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 98: accuracy did not improve from 0.82812\n",
            " 87/121 [====================>.........] - ETA: 0s - loss: 2.1545 - accuracy: 0.6818\n",
            "Epoch 98: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 98: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 98: accuracy did not improve from 0.82812\n",
            "102/121 [========================>.....] - ETA: 0s - loss: 2.1574 - accuracy: 0.6826\n",
            "Epoch 98: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 98: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 98: accuracy did not improve from 0.82812\n",
            "117/121 [============================>.] - ETA: 0s - loss: 2.1881 - accuracy: 0.6803\n",
            "Epoch 98: accuracy did not improve from 0.82812\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.1892 - accuracy: 0.6788\n",
            "Epoch 99/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.3827 - accuracy: 0.5625\n",
            "Epoch 99: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 99: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 99: accuracy did not improve from 0.82812\n",
            " 12/121 [=>............................] - ETA: 0s - loss: 2.2004 - accuracy: 0.6406\n",
            "Epoch 99: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 99: accuracy did not improve from 0.82812\n",
            " 22/121 [====>.........................] - ETA: 0s - loss: 2.2748 - accuracy: 0.6619\n",
            "Epoch 99: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 99: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 99: accuracy did not improve from 0.82812\n",
            " 38/121 [========>.....................] - ETA: 0s - loss: 2.2303 - accuracy: 0.6776\n",
            "Epoch 99: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 99: accuracy did not improve from 0.82812\n",
            " 51/121 [===========>..................] - ETA: 0s - loss: 2.1722 - accuracy: 0.6789\n",
            "Epoch 99: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 99: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 99: accuracy did not improve from 0.82812\n",
            " 63/121 [==============>...............] - ETA: 0s - loss: 2.1943 - accuracy: 0.6721\n",
            "Epoch 99: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 99: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 99: accuracy did not improve from 0.82812\n",
            " 80/121 [==================>...........] - ETA: 0s - loss: 2.2275 - accuracy: 0.6734\n",
            "Epoch 99: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 99: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 99: accuracy did not improve from 0.82812\n",
            " 95/121 [======================>.......] - ETA: 0s - loss: 2.1940 - accuracy: 0.6799\n",
            "Epoch 99: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 99: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 99: accuracy did not improve from 0.82812\n",
            "111/121 [==========================>...] - ETA: 0s - loss: 2.1783 - accuracy: 0.6819\n",
            "Epoch 99: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 99: accuracy did not improve from 0.82812\n",
            "121/121 [==============================] - 0s 4ms/step - loss: 2.1892 - accuracy: 0.6788\n",
            "Epoch 100/100\n",
            "\n",
            "Epoch 100: accuracy did not improve from 0.82812\n",
            "  1/121 [..............................] - ETA: 1s - loss: 2.1921 - accuracy: 0.7500\n",
            "Epoch 100: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 100: accuracy did not improve from 0.82812\n",
            " 13/121 [==>...........................] - ETA: 0s - loss: 2.1413 - accuracy: 0.6755\n",
            "Epoch 100: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 100: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 100: accuracy did not improve from 0.82812\n",
            " 28/121 [=====>........................] - ETA: 0s - loss: 2.2099 - accuracy: 0.6763\n",
            "Epoch 100: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 100: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 100: accuracy did not improve from 0.82812\n",
            " 45/121 [==========>...................] - ETA: 0s - loss: 2.1718 - accuracy: 0.6764\n",
            "Epoch 100: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 100: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 100: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 100: accuracy did not improve from 0.82812\n",
            " 61/121 [==============>...............] - ETA: 0s - loss: 2.1429 - accuracy: 0.6783\n",
            "Epoch 100: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 100: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 100: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 100: accuracy did not improve from 0.82812\n",
            " 81/121 [===================>..........] - ETA: 0s - loss: 2.1623 - accuracy: 0.6775\n",
            "Epoch 100: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 100: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 100: accuracy did not improve from 0.82812\n",
            " 97/121 [=======================>......] - ETA: 0s - loss: 2.1811 - accuracy: 0.6759\n",
            "Epoch 100: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 100: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 100: accuracy did not improve from 0.82812\n",
            "\n",
            "Epoch 100: accuracy did not improve from 0.82812\n",
            "116/121 [===========================>..] - ETA: 0s - loss: 2.1864 - accuracy: 0.6789\n",
            "Epoch 100: accuracy did not improve from 0.82812\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.1892 - accuracy: 0.6788\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model using the test data\n",
        "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=1)\n",
        "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Prv_UdaxhSC",
        "outputId": "6e4cc9fd-fa93-4f2b-f701-29758909ec17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "41/41 [==============================] - 0s 2ms/step - loss: 2.0381 - accuracy: 0.6968\n",
            "Loss: 2.0380661487579346, Accuracy: 0.6968043446540833\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Other Models"
      ],
      "metadata": {
        "id": "gw-wQNEBwZHm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "which students are capable/ with predictions--passsing.\n",
        "\n",
        "predicting grade/ability\n",
        "\n",
        "turn grade levels into\n",
        "\n",
        "look what has the greates amount of points."
      ],
      "metadata": {
        "id": "Cvu9k0LQYh4E"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "K5e0Eb3mu_zU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# One-hot encode the categorical variables\n",
        "encoder = OneHotEncoder()\n",
        "X = encoder.fit_transform(new_df[['Grade', 'Course_Type']])\n",
        "\n",
        "# Extract the target variable\n",
        "y = new_df['Section_Grade']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "mxX4_Kr-dubx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Train the model\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "duZDrAZmdxp6",
        "outputId": "d8314800-c2c7-44be-e26d-9a5d282c38c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearRegression()"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate the mean absolute error\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "print('Mean Absolute Error:', mae)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0BG4aySveH4o",
        "outputId": "291d8b05-35b1-4b93-a554-194b9350a093"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Absolute Error: 3.96020623868929\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " a MAE of 3.96020623868929 means that, on average, the model's predictions are off by approximately 3.96 units (in the same units as the target variable). This indicates that the model's performance may not be very accurate, and there may be room for improvement. However, the interpretation of the MAE also depends on the scale of the target variable and the context of the problem."
      ],
      "metadata": {
        "id": "YxEoUDfRUscX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create a scatter plot of the actual vs predicted grades\n",
        "plt.scatter(y_test, y_pred)\n",
        "plt.xlabel('Actual Grade')\n",
        "plt.ylabel('Predicted Grade')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "EObfSXjqePoJ",
        "outputId": "227d88ca-0cc0-49de-b0a6-289bcb87a611"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "tXbTw0PCezUz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "\n",
        "\n",
        "# Select the features that you want to use for clustering\n",
        "X = new_df[['Grade', 'Section_Grade']]\n",
        "\n",
        "# Define the number of clusters you want to create\n",
        "num_clusters = 3\n",
        "\n",
        "# Create a k-means clustering model with the specified number of clusters\n",
        "kmeans = KMeans(n_clusters=3, n_init=10)\n",
        "\n",
        "# Fit the model to the data\n",
        "kmeans.fit(X)\n",
        "\n",
        "# Add a new column to the original DataFrame with the cluster labels for each data point\n",
        "new_df['Cluster'] = kmeans.labels_\n",
        "\n",
        "# Print the cluster centers\n",
        "print(kmeans.cluster_centers_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2V0qDdgQezdP",
        "outputId": "a1902b43-dfac-4c91-a534-0053b0f0d068"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[10.47836203 90.54000465]\n",
            " [10.55361252 96.17394846]\n",
            " [10.65883807 82.79583436]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        },
        "id": "lVZWQ2cyQNFD",
        "outputId": "9f98fe54-96e7-4d22-c48d-d403c56a2a15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                           Course  Grade  Section_Grade       Course_Type  \\\n",
              "0                English I Honors      9          96.67           English   \n",
              "1                French II Honors      9          87.92  Foreign Language   \n",
              "2  Computer Science Principles AP      9          86.02           Science   \n",
              "3                       Chemistry      9          88.89           Science   \n",
              "4              Human Geography AP      9          88.49        Humanities   \n",
              "\n",
              "   Cluster  \n",
              "0        1  \n",
              "1        0  \n",
              "2        2  \n",
              "3        0  \n",
              "4        0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b80ca4be-cd0c-4af7-a2fb-53a5413e9fab\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Course</th>\n",
              "      <th>Grade</th>\n",
              "      <th>Section_Grade</th>\n",
              "      <th>Course_Type</th>\n",
              "      <th>Cluster</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>English I Honors</td>\n",
              "      <td>9</td>\n",
              "      <td>96.67</td>\n",
              "      <td>English</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>French II Honors</td>\n",
              "      <td>9</td>\n",
              "      <td>87.92</td>\n",
              "      <td>Foreign Language</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Computer Science Principles AP</td>\n",
              "      <td>9</td>\n",
              "      <td>86.02</td>\n",
              "      <td>Science</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Chemistry</td>\n",
              "      <td>9</td>\n",
              "      <td>88.89</td>\n",
              "      <td>Science</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Human Geography AP</td>\n",
              "      <td>9</td>\n",
              "      <td>88.49</td>\n",
              "      <td>Humanities</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b80ca4be-cd0c-4af7-a2fb-53a5413e9fab')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b80ca4be-cd0c-4af7-a2fb-53a5413e9fab button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b80ca4be-cd0c-4af7-a2fb-53a5413e9fab');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_df.to_csv('new_PC_data.csv')\n"
      ],
      "metadata": {
        "id": "u_ygEAA3McdC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Plot the data points colored by their assigned clusters\n",
        "colors = ['r', 'g', 'b']\n",
        "for i in range(num_clusters):\n",
        "    plt.scatter(X[new_df['Cluster'] == i]['Grade'], X[new_df['Cluster'] == i]['Section_Grade'], c=colors[i])\n",
        "plt.xlabel('Grade')\n",
        "plt.ylabel('Section_Grade')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "wO-tF4bnU6DU",
        "outputId": "fcf7b743-9115-4515-f909-36acc3ad3fc1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "# encode the categorical variable \"Course\" using label encoding\n",
        "le = LabelEncoder()\n",
        "new_df['Course_enc'] = le.fit_transform(new_df['Course'])\n",
        "\n",
        "# split the data into training and testing sets with a 80:20 ratio\n",
        "X_train, X_test, y_train, y_test = train_test_split(new_df.drop(['Grade'], axis=1), df['Grade'], test_size=0.2, random_state=42)\n",
        "\n",
        "# print the shapes of the training and testing sets\n",
        "print(\"Training set shape:\", X_train.shape, y_train.shape)\n",
        "print(\"Testing set shape:\", X_test.shape, y_test.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HT8aXjGJRi0I",
        "outputId": "79a8c109-48a0-4a75-cf8f-483d50c65698"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set shape: (4104, 5) (4104,)\n",
            "Testing set shape: (1027, 5) (1027,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "df = new_df.copy()\n",
        "\n",
        "# Encode the categorical variables\n",
        "le = LabelEncoder()\n",
        "df['Course_enc'] = le.fit_transform(df['Course'])\n",
        "df['Course_Type_enc'] = le.fit_transform(df['Course_Type'])\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(df[['Course_enc', 'Section_Grade', 'Course_Type_enc']], df['Grade'], test_size=0.2, random_state=42)\n",
        "\n",
        "# Train a random forest regressor on the training set\n",
        "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the testing set\n",
        "y_pred = rf.predict(X_test)\n",
        "\n",
        "# Evaluate the model's performance using mean squared error\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(\"Mean squared error:\", mse)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wf0SFjUaS7bj",
        "outputId": "fc6b23a0-e8db-45a4-800a-addb9873223f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean squared error: 0.2298913848612861\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The mean squared error (MSE) is a measure of how well a regression model fits the data. It measures the average squared difference between the predicted values and the actual values. The value of MSE ranges from 0 to infinity, with a lower value indicating a better fit of the model.\n",
        "\n",
        "In your case, the value of MSE is 0.2298, which means that on average, the predicted values are off by the square root of 0.2298. A lower value of MSE indicates a better fit of the model to the data."
      ],
      "metadata": {
        "id": "wCXN7aGL5TgC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "computer_df = new_df.copy()\n",
        "computer_df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_voLZ8af59_-",
        "outputId": "ba2cdc95-4315-4253-cd41-f9b926dec911"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Course', 'Grade', 'Section_Grade', 'Course_Type', 'Cluster',\n",
              "       'Course_enc'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "computer_df = pd.get_dummies(computer_df, columns=['Course_Type_Arts', 'Course_Type_Computer Science',\n",
        "       'Course_Type_English', 'Course_Type_Entrepreneurship',\n",
        "       'Course_Type_Foreign Language', 'Course_Type_Humanities',\n",
        "       'Course_Type_Law and Politics', 'Course_Type_Math',\n",
        "       'Course_Type_Psychology', 'Course_Type_Research',\n",
        "       'Course_Type_Science'])"
      ],
      "metadata": {
        "id": "5xYp1-Fb7iil",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 586
        },
        "outputId": "ac269086-8b7e-471e-920f-32b6e1724ecc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-fe63d80c8036>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m computer_df = pd.get_dummies(computer_df, columns=['Course_Type_Arts', 'Course_Type_Computer Science',\n\u001b[0m\u001b[1;32m      2\u001b[0m        \u001b[0;34m'Course_Type_English'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Course_Type_Entrepreneurship'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m        \u001b[0;34m'Course_Type_Foreign Language'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Course_Type_Humanities'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m        \u001b[0;34m'Course_Type_Law and Politics'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Course_Type_Math'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m        \u001b[0;34m'Course_Type_Psychology'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Course_Type_Research'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/reshape/encoding.py\u001b[0m in \u001b[0;36mget_dummies\u001b[0;34m(data, prefix, prefix_sep, dummy_na, columns, sparse, drop_first, dtype)\u001b[0m\n\u001b[1;32m    144\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Input must be a list-like for parameter `columns`\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m             \u001b[0mdata_to_encode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0;31m# validate prefixes and separator to avoid silently dropping cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3811\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3812\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3813\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_indexer_strict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"columns\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3814\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3815\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6068\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6069\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6070\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_if_missing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6071\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6072\u001b[0m         \u001b[0mkeyarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6128\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0muse_interval_msg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6129\u001b[0m                     \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6130\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"None of [{key}] are in the [{axis_name}]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6132\u001b[0m             \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmissing_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"None of [Index(['Course_Type_Arts', 'Course_Type_Computer Science',\\n       'Course_Type_English', 'Course_Type_Entrepreneurship',\\n       'Course_Type_Foreign Language', 'Course_Type_Humanities',\\n       'Course_Type_Law and Politics', 'Course_Type_Math',\\n       'Course_Type_Psychology', 'Course_Type_Research',\\n       'Course_Type_Science'],\\n      dtype='object')] are in the [columns]\""
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "computer_df.describe()"
      ],
      "metadata": {
        "id": "F1eR5hRq7qpu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3LYMzqgJ8GNa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "\n",
        "# Define features and target variable\n",
        "X = new_df.drop(['StudentID', 'Course', 'Grade', 'Section_Grade', 'Cluster'], axis=1)\n",
        "y = new_df['Course_Type_Computer Science'].values # Binary target variable: 1 if the course is a computer course, 0 otherwise\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train logistic regression model\n",
        "clf = LogisticRegression()\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Predict target variable on testing set\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Compute accuracy score\n",
        "acc_score = accuracy_score(y_test, y_pred)\n",
        "print('Accuracy score:', acc_score)\n"
      ],
      "metadata": {
        "id": "_leii-PV5uSG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "BRNQme4xX9wk"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TBVHQxPvX9R6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}