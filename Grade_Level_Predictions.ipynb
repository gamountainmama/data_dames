{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNJFuZ1+cRklOYdp1BN/Cin",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gamountainmama/data_dames/blob/kelly_branch/Grade_Level_Predictions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Private School Fort Lauderdale"
      ],
      "metadata": {
        "id": "WFMLIvHEyzzr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NN Model - Dropping Math Courses\n",
        "\n",
        "1/41 [==============================] - 0s \n",
        "\n",
        "Loss: 2.519768238067627, \n",
        "\n",
        "Accuracy: 0.48012471199035645"
      ],
      "metadata": {
        "id": "XZA69vaewPoa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "7e9tgr_9dt7n"
      },
      "outputs": [],
      "source": [
        "# Import our dependencies\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import pandas as pd \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load the data\n",
        "df = pd.read_csv('Data_Set_9-12.csv')\n",
        "\n",
        "# Check the shape of the DataFrame\n",
        "print(df.shape)\n",
        "\n",
        "# Check the first few rows of the DataFrame\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C736F297d0qK",
        "outputId": "a1f063cd-eebb-485e-e3ba-e026f7ced63c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5131, 4)\n",
            "  StudentID                          Course  Grade  Section_Grade\n",
            "0    STU711                English I Honors      9          96.67\n",
            "1    STU711                French II Honors      9          87.92\n",
            "2    STU711  Computer Science Principles AP      9          86.02\n",
            "3    STU711                       Chemistry      9          88.89\n",
            "4    STU711              Human Geography AP      9          88.49\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop the non-beneficial columns.\n",
        "df = df.drop(columns='StudentID', axis=1)"
      ],
      "metadata": {
        "id": "NrPINnjFphc0"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "new_df = df.copy()\n",
        "\n",
        "keywords_to_course_type = {\n",
        "    'french spanish german latin chinese': 'Foreign Language',\n",
        "    'math algebra statistics geometry calculus': 'Math',\n",
        "    'english writers literature shakespeare': 'English',\n",
        "    'human government world history microeconomics': 'Humanities',\n",
        "    'science astronomy biology physics anatomy chemistry': 'Science',\n",
        "    'data computer artificial': \"Computer Science\",\n",
        "    'capstone': \"Research\",\n",
        "    'visual arts art music': 'Arts',\n",
        "    'psychology great decisions': 'Psychology',\n",
        "    'entrepreneurship': 'Entrepreneurship',\n",
        "    'constitutional international politics':'Law and Politics'\n",
        "}\n",
        "\n",
        "def get_course_type(course):\n",
        "    '''find words in keywords and assign'''\n",
        "    for keyword, course_type in keywords_to_course_type.items():\n",
        "        if any(word in course.lower() for word in keyword.split()):\n",
        "            return course_type\n",
        "    return 'unknown'\n",
        "\n",
        "# apply the function to the 'Course' column to create a new 'Course_Type' column\n",
        "new_df['Course_Type'] = new_df['Course'].apply(get_course_type)\n",
        "\n",
        "# display the updated dataframe\n",
        "new_df.head(100)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "3_BxSn7HNllW",
        "outputId": "c5351b78-e0ff-4d96-b02a-d8284ff04ba8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                            Course  Grade  Section_Grade       Course_Type\n",
              "0                 English I Honors      9          96.67           English\n",
              "1                 French II Honors      9          87.92  Foreign Language\n",
              "2   Computer Science Principles AP      9          86.02           Science\n",
              "3                        Chemistry      9          88.89           Science\n",
              "4               Human Geography AP      9          88.49        Humanities\n",
              "..                             ...    ...            ...               ...\n",
              "95  Computer Science Principles AP      9          98.83           Science\n",
              "96                Chemistry Honors      9          93.57           Science\n",
              "97                World History AP      9          98.98        Humanities\n",
              "98                English I Honors      9          94.60           English\n",
              "99               Chinese II Honors      9          97.60  Foreign Language\n",
              "\n",
              "[100 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c58c8de2-59a1-4161-b2d3-2ab15a8789cd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Course</th>\n",
              "      <th>Grade</th>\n",
              "      <th>Section_Grade</th>\n",
              "      <th>Course_Type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>English I Honors</td>\n",
              "      <td>9</td>\n",
              "      <td>96.67</td>\n",
              "      <td>English</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>French II Honors</td>\n",
              "      <td>9</td>\n",
              "      <td>87.92</td>\n",
              "      <td>Foreign Language</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Computer Science Principles AP</td>\n",
              "      <td>9</td>\n",
              "      <td>86.02</td>\n",
              "      <td>Science</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Chemistry</td>\n",
              "      <td>9</td>\n",
              "      <td>88.89</td>\n",
              "      <td>Science</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Human Geography AP</td>\n",
              "      <td>9</td>\n",
              "      <td>88.49</td>\n",
              "      <td>Humanities</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>Computer Science Principles AP</td>\n",
              "      <td>9</td>\n",
              "      <td>98.83</td>\n",
              "      <td>Science</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>Chemistry Honors</td>\n",
              "      <td>9</td>\n",
              "      <td>93.57</td>\n",
              "      <td>Science</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>World History AP</td>\n",
              "      <td>9</td>\n",
              "      <td>98.98</td>\n",
              "      <td>Humanities</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>English I Honors</td>\n",
              "      <td>9</td>\n",
              "      <td>94.60</td>\n",
              "      <td>English</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>Chinese II Honors</td>\n",
              "      <td>9</td>\n",
              "      <td>97.60</td>\n",
              "      <td>Foreign Language</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c58c8de2-59a1-4161-b2d3-2ab15a8789cd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c58c8de2-59a1-4161-b2d3-2ab15a8789cd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c58c8de2-59a1-4161-b2d3-2ab15a8789cd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# find unknown data strings in the 'col1' column\n",
        "# unknowns = new_df[new_df['Course_Type'] == 'unknown']\n",
        "# print(unknowns)"
      ],
      "metadata": {
        "id": "fnHLPCUMZPDD"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_df.dtypes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5E4OYBkrrMRS",
        "outputId": "fcf50baa-0841-45bc-c484-a2011659b598"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Course            object\n",
              "Grade              int64\n",
              "Section_Grade    float64\n",
              "Course_Type       object\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_df[\"Course_Type\"].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o77kLyDVVloy",
        "outputId": "29fdf309-ecd5-4398-df93-45c7b83148df"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['English', 'Foreign Language', 'Science', 'Humanities', 'Math',\n",
              "       'Psychology', 'Arts', 'Law and Politics', 'Entrepreneurship',\n",
              "       'Computer Science', 'Research'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate the average grade per course\n",
        "avg_grades = new_df.groupby('Course')['Section_Grade'].mean()\n",
        "\n",
        "# print the result\n",
        "print(avg_grades)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q9Tl0_pcfKXO",
        "outputId": "2c40e2ac-b8ab-4d42-dd61-4925df37f778"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Course\n",
            "AP Research (Capstone Year 2)          97.055000\n",
            "AP Seminar (Capstone Year 1)           90.933333\n",
            "Algebra II                             86.140000\n",
            "Algebra II Honors                      90.570000\n",
            "Anatomy and Physiology Honors          91.059403\n",
            "                                         ...    \n",
            "Talented Writers Program III Honors    90.171429\n",
            "United States History AP               90.253567\n",
            "United States History Honors           89.568125\n",
            "Women Writers Post-AP                  95.564667\n",
            "World History AP                       95.681765\n",
            "Name: Section_Grade, Length: 105, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert categorical data to numeric with `pd.get_dummies`\n",
        "cat_data = pd.get_dummies(new_df)\n",
        "cat_data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352
        },
        "id": "hIWBR4-kt_gA",
        "outputId": "37e84bca-980c-485d-c728-14de8398802e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Grade  Section_Grade  Course_AP Research (Capstone Year 2)  \\\n",
              "0      9          96.67                                     0   \n",
              "1      9          87.92                                     0   \n",
              "2      9          86.02                                     0   \n",
              "3      9          88.89                                     0   \n",
              "4      9          88.49                                     0   \n",
              "\n",
              "   Course_AP Seminar (Capstone Year 1)  Course_Algebra II  \\\n",
              "0                                    0                  0   \n",
              "1                                    0                  0   \n",
              "2                                    0                  0   \n",
              "3                                    0                  0   \n",
              "4                                    0                  0   \n",
              "\n",
              "   Course_Algebra II Honors  Course_Anatomy and Physiology Honors  \\\n",
              "0                         0                                     0   \n",
              "1                         0                                     0   \n",
              "2                         0                                     0   \n",
              "3                         0                                     0   \n",
              "4                         0                                     0   \n",
              "\n",
              "   Course_Art History AP  Course_Artificial Intelligence Post-AP  \\\n",
              "0                      0                                       0   \n",
              "1                      0                                       0   \n",
              "2                      0                                       0   \n",
              "3                      0                                       0   \n",
              "4                      0                                       0   \n",
              "\n",
              "   Course_Astronomy Honors  ...  Course_Type_Computer Science  \\\n",
              "0                        0  ...                             0   \n",
              "1                        0  ...                             0   \n",
              "2                        0  ...                             0   \n",
              "3                        0  ...                             0   \n",
              "4                        0  ...                             0   \n",
              "\n",
              "   Course_Type_English  Course_Type_Entrepreneurship  \\\n",
              "0                    1                             0   \n",
              "1                    0                             0   \n",
              "2                    0                             0   \n",
              "3                    0                             0   \n",
              "4                    0                             0   \n",
              "\n",
              "   Course_Type_Foreign Language  Course_Type_Humanities  \\\n",
              "0                             0                       0   \n",
              "1                             1                       0   \n",
              "2                             0                       0   \n",
              "3                             0                       0   \n",
              "4                             0                       1   \n",
              "\n",
              "   Course_Type_Law and Politics  Course_Type_Math  Course_Type_Psychology  \\\n",
              "0                             0                 0                       0   \n",
              "1                             0                 0                       0   \n",
              "2                             0                 0                       0   \n",
              "3                             0                 0                       0   \n",
              "4                             0                 0                       0   \n",
              "\n",
              "   Course_Type_Research  Course_Type_Science  \n",
              "0                     0                    0  \n",
              "1                     0                    0  \n",
              "2                     0                    1  \n",
              "3                     0                    1  \n",
              "4                     0                    0  \n",
              "\n",
              "[5 rows x 118 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-df38b931-0a5c-4b65-a975-53b3aa21a225\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Grade</th>\n",
              "      <th>Section_Grade</th>\n",
              "      <th>Course_AP Research (Capstone Year 2)</th>\n",
              "      <th>Course_AP Seminar (Capstone Year 1)</th>\n",
              "      <th>Course_Algebra II</th>\n",
              "      <th>Course_Algebra II Honors</th>\n",
              "      <th>Course_Anatomy and Physiology Honors</th>\n",
              "      <th>Course_Art History AP</th>\n",
              "      <th>Course_Artificial Intelligence Post-AP</th>\n",
              "      <th>Course_Astronomy Honors</th>\n",
              "      <th>...</th>\n",
              "      <th>Course_Type_Computer Science</th>\n",
              "      <th>Course_Type_English</th>\n",
              "      <th>Course_Type_Entrepreneurship</th>\n",
              "      <th>Course_Type_Foreign Language</th>\n",
              "      <th>Course_Type_Humanities</th>\n",
              "      <th>Course_Type_Law and Politics</th>\n",
              "      <th>Course_Type_Math</th>\n",
              "      <th>Course_Type_Psychology</th>\n",
              "      <th>Course_Type_Research</th>\n",
              "      <th>Course_Type_Science</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>9</td>\n",
              "      <td>96.67</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>9</td>\n",
              "      <td>87.92</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>9</td>\n",
              "      <td>86.02</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9</td>\n",
              "      <td>88.89</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9</td>\n",
              "      <td>88.49</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 118 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-df38b931-0a5c-4b65-a975-53b3aa21a225')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-df38b931-0a5c-4b65-a975-53b3aa21a225 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-df38b931-0a5c-4b65-a975-53b3aa21a225');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cat_data.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WzmM8J50ulzJ",
        "outputId": "d32dc409-25e8-47d3-b1ee-e3b14274abe5"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Grade', 'Section_Grade', 'Course_AP Research (Capstone Year 2)',\n",
              "       'Course_AP Seminar (Capstone Year 1)', 'Course_Algebra II',\n",
              "       'Course_Algebra II Honors', 'Course_Anatomy and Physiology Honors',\n",
              "       'Course_Art History AP', 'Course_Artificial Intelligence Post-AP',\n",
              "       'Course_Astronomy Honors',\n",
              "       ...\n",
              "       'Course_Type_Computer Science', 'Course_Type_English',\n",
              "       'Course_Type_Entrepreneurship', 'Course_Type_Foreign Language',\n",
              "       'Course_Type_Humanities', 'Course_Type_Law and Politics',\n",
              "       'Course_Type_Math', 'Course_Type_Psychology', 'Course_Type_Research',\n",
              "       'Course_Type_Science'],\n",
              "      dtype='object', length=118)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split our preprocessed data into our features and target arrays\n",
        "X = cat_data.drop('Course_Type_Math', axis=1).values\n",
        "y = cat_data['Course_Type_Math'].values\n",
        "\n",
        "# Split the preprocessed data into a training and testing dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=13)"
      ],
      "metadata": {
        "id": "QA-gnjHCuM9V"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a StandardScaler instances\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit the StandardScaler\n",
        "X_scaler = scaler.fit(X_train)\n",
        "\n",
        "# Scale the data\n",
        "X_train_scaled = X_scaler.transform(X_train)\n",
        "X_test_scaled = X_scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "OuSh79R_uxDp"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Compile, Train and Evaluate the Model\n",
        "\n",
        "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
        "input = X_train_scaled.shape[1]\n",
        "nn = tf.keras.models.Sequential()\n",
        "\n",
        "# First hidden layer\n",
        "nn.add(tf.keras.layers.Dense(units=5, activation=\"relu\", input_dim=input))\n",
        "\n",
        "# Check the structure of the model\n",
        "nn.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vmV-xclduzJi",
        "outputId": "16a01f44-113b-498a-e2fd-c88ed525265c"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_1 (Dense)             (None, 5)                 590       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 590\n",
            "Trainable params: 590\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "nn.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "Tmo4LobQu962"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "checkpoint = ModelCheckpoint(\"best_model.hdf5\", monitor='accuracy', verbose=1,\n",
        "    save_best_only=True, mode='auto', save_freq=5)\n",
        "\n",
        "fit_model = nn.fit(X_train_scaled, y_train, epochs=100, verbose=1, callbacks=[checkpoint])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fjQbnq_Iu_W8",
        "outputId": "2481c369-1ee2-4580-b3fc-bcffb0626dc1"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Epoch 1: accuracy did not improve from 0.24375\n",
            "101/121 [========================>.....] - ETA: 0s - loss: 3.3305 - accuracy: 0.2123\n",
            "Epoch 1: accuracy did not improve from 0.24375\n",
            "\n",
            "Epoch 1: accuracy did not improve from 0.24375\n",
            "\n",
            "Epoch 1: accuracy did not improve from 0.24375\n",
            "\n",
            "Epoch 1: accuracy did not improve from 0.24375\n",
            "121/121 [==============================] - 2s 3ms/step - loss: 3.3121 - accuracy: 0.2123\n",
            "Epoch 2/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.4514 - accuracy: 0.2188\n",
            "Epoch 2: accuracy did not improve from 0.24375\n",
            "\n",
            "Epoch 2: accuracy did not improve from 0.24375\n",
            "\n",
            "Epoch 2: accuracy did not improve from 0.24375\n",
            " 17/121 [===>..........................] - ETA: 0s - loss: 3.1396 - accuracy: 0.2224\n",
            "Epoch 2: accuracy did not improve from 0.24375\n",
            "\n",
            "Epoch 2: accuracy did not improve from 0.24375\n",
            "\n",
            "Epoch 2: accuracy did not improve from 0.24375\n",
            "\n",
            "Epoch 2: accuracy did not improve from 0.24375\n",
            " 34/121 [=======>......................] - ETA: 0s - loss: 3.1488 - accuracy: 0.2307\n",
            "Epoch 2: accuracy did not improve from 0.24375\n",
            "\n",
            "Epoch 2: accuracy did not improve from 0.24375\n",
            "\n",
            "Epoch 2: accuracy did not improve from 0.24375\n",
            "\n",
            "Epoch 2: accuracy did not improve from 0.24375\n",
            " 54/121 [============>.................] - ETA: 0s - loss: 3.0307 - accuracy: 0.2431\n",
            "Epoch 2: accuracy did not improve from 0.24375\n",
            "\n",
            "Epoch 2: accuracy improved from 0.24375 to 0.24756, saving model to best_model.hdf5\n",
            " 64/121 [==============>...............] - ETA: 0s - loss: 3.0304 - accuracy: 0.2476\n",
            "Epoch 2: accuracy did not improve from 0.24756\n",
            "\n",
            "Epoch 2: accuracy did not improve from 0.24756\n",
            "\n",
            "Epoch 2: accuracy improved from 0.24756 to 0.24960, saving model to best_model.hdf5\n",
            " 79/121 [==================>...........] - ETA: 0s - loss: 3.0605 - accuracy: 0.2496\n",
            "Epoch 2: accuracy improved from 0.24960 to 0.25186, saving model to best_model.hdf5\n",
            "\n",
            "Epoch 2: accuracy improved from 0.25186 to 0.25421, saving model to best_model.hdf5\n",
            " 89/121 [=====================>........] - ETA: 0s - loss: 3.0473 - accuracy: 0.2542\n",
            "Epoch 2: accuracy improved from 0.25421 to 0.25465, saving model to best_model.hdf5\n",
            "\n",
            "Epoch 2: accuracy did not improve from 0.25465\n",
            "100/121 [=======================>......] - ETA: 0s - loss: 3.0552 - accuracy: 0.2537\n",
            "Epoch 2: accuracy did not improve from 0.25465\n",
            "\n",
            "Epoch 2: accuracy did not improve from 0.25465\n",
            "\n",
            "Epoch 2: accuracy did not improve from 0.25465\n",
            "\n",
            "Epoch 2: accuracy did not improve from 0.25465\n",
            "121/121 [==============================] - 0s 4ms/step - loss: 3.0911 - accuracy: 0.2492\n",
            "Epoch 3/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.8994 - accuracy: 0.2812\n",
            "Epoch 3: accuracy improved from 0.25465 to 0.27083, saving model to best_model.hdf5\n",
            "\n",
            "Epoch 3: accuracy did not improve from 0.27083\n",
            "\n",
            "Epoch 3: accuracy did not improve from 0.27083\n",
            " 13/121 [==>...........................] - ETA: 0s - loss: 2.9326 - accuracy: 0.2524\n",
            "Epoch 3: accuracy did not improve from 0.27083\n",
            "\n",
            "Epoch 3: accuracy did not improve from 0.27083\n",
            "\n",
            "Epoch 3: accuracy did not improve from 0.27083\n",
            " 32/121 [======>.......................] - ETA: 0s - loss: 2.9903 - accuracy: 0.2480\n",
            "Epoch 3: accuracy did not improve from 0.27083\n",
            "\n",
            "Epoch 3: accuracy did not improve from 0.27083\n",
            "\n",
            "Epoch 3: accuracy did not improve from 0.27083\n",
            " 47/121 [==========>...................] - ETA: 0s - loss: 3.0015 - accuracy: 0.2573\n",
            "Epoch 3: accuracy did not improve from 0.27083\n",
            "\n",
            "Epoch 3: accuracy did not improve from 0.27083\n",
            "\n",
            "Epoch 3: accuracy did not improve from 0.27083\n",
            "\n",
            "Epoch 3: accuracy did not improve from 0.27083\n",
            " 64/121 [==============>...............] - ETA: 0s - loss: 3.0564 - accuracy: 0.2559\n",
            "Epoch 3: accuracy did not improve from 0.27083\n",
            "\n",
            "Epoch 3: accuracy did not improve from 0.27083\n",
            "\n",
            "Epoch 3: accuracy did not improve from 0.27083\n",
            " 81/121 [===================>..........] - ETA: 0s - loss: 3.0542 - accuracy: 0.2569\n",
            "Epoch 3: accuracy did not improve from 0.27083\n",
            "\n",
            "Epoch 3: accuracy did not improve from 0.27083\n",
            "\n",
            "Epoch 3: accuracy did not improve from 0.27083\n",
            "\n",
            "Epoch 3: accuracy did not improve from 0.27083\n",
            " 99/121 [=======================>......] - ETA: 0s - loss: 3.0537 - accuracy: 0.2573\n",
            "Epoch 3: accuracy did not improve from 0.27083\n",
            "\n",
            "Epoch 3: accuracy did not improve from 0.27083\n",
            "\n",
            "Epoch 3: accuracy did not improve from 0.27083\n",
            "116/121 [===========================>..] - ETA: 0s - loss: 3.0334 - accuracy: 0.2619\n",
            "Epoch 3: accuracy did not improve from 0.27083\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 3.0226 - accuracy: 0.2638\n",
            "Epoch 4/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 3.9992 - accuracy: 0.1875\n",
            "Epoch 4: accuracy did not improve from 0.27083\n",
            "\n",
            "Epoch 4: accuracy did not improve from 0.27083\n",
            "\n",
            "Epoch 4: accuracy did not improve from 0.27083\n",
            "\n",
            "Epoch 4: accuracy did not improve from 0.27083\n",
            " 19/121 [===>..........................] - ETA: 0s - loss: 3.0419 - accuracy: 0.2615\n",
            "Epoch 4: accuracy did not improve from 0.27083\n",
            "\n",
            "Epoch 4: accuracy did not improve from 0.27083\n",
            "\n",
            "Epoch 4: accuracy did not improve from 0.27083\n",
            "\n",
            "Epoch 4: accuracy did not improve from 0.27083\n",
            " 38/121 [========>.....................] - ETA: 0s - loss: 2.9787 - accuracy: 0.2673\n",
            "Epoch 4: accuracy did not improve from 0.27083\n",
            "\n",
            "Epoch 4: accuracy did not improve from 0.27083\n",
            "\n",
            "Epoch 4: accuracy did not improve from 0.27083\n",
            " 52/121 [===========>..................] - ETA: 0s - loss: 2.9357 - accuracy: 0.2662\n",
            "Epoch 4: accuracy did not improve from 0.27083\n",
            "\n",
            "Epoch 4: accuracy did not improve from 0.27083\n",
            "\n",
            "Epoch 4: accuracy did not improve from 0.27083\n",
            "\n",
            "Epoch 4: accuracy did not improve from 0.27083\n",
            " 72/121 [================>.............] - ETA: 0s - loss: 2.9750 - accuracy: 0.2661\n",
            "Epoch 4: accuracy did not improve from 0.27083\n",
            "\n",
            "Epoch 4: accuracy did not improve from 0.27083\n",
            "\n",
            "Epoch 4: accuracy improved from 0.27083 to 0.27155, saving model to best_model.hdf5\n",
            " 87/121 [====================>.........] - ETA: 0s - loss: 2.9667 - accuracy: 0.2716\n",
            "Epoch 4: accuracy did not improve from 0.27155\n",
            "\n",
            "Epoch 4: accuracy did not improve from 0.27155\n",
            "\n",
            "Epoch 4: accuracy did not improve from 0.27155\n",
            "103/121 [========================>.....] - ETA: 0s - loss: 2.9785 - accuracy: 0.2676\n",
            "Epoch 4: accuracy did not improve from 0.27155\n",
            "\n",
            "Epoch 4: accuracy did not improve from 0.27155\n",
            "\n",
            "Epoch 4: accuracy did not improve from 0.27155\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.9888 - accuracy: 0.2710\n",
            "Epoch 5/100\n",
            "\n",
            "Epoch 5: accuracy improved from 0.27155 to 0.31250, saving model to best_model.hdf5\n",
            "  1/121 [..............................] - ETA: 1s - loss: 2.6591 - accuracy: 0.3125\n",
            "Epoch 5: accuracy did not improve from 0.31250\n",
            "\n",
            "Epoch 5: accuracy did not improve from 0.31250\n",
            "\n",
            "Epoch 5: accuracy did not improve from 0.31250\n",
            " 18/121 [===>..........................] - ETA: 0s - loss: 2.9716 - accuracy: 0.2934\n",
            "Epoch 5: accuracy did not improve from 0.31250\n",
            "\n",
            "Epoch 5: accuracy did not improve from 0.31250\n",
            "\n",
            "Epoch 5: accuracy did not improve from 0.31250\n",
            " 34/121 [=======>......................] - ETA: 0s - loss: 2.9963 - accuracy: 0.2858\n",
            "Epoch 5: accuracy did not improve from 0.31250\n",
            "\n",
            "Epoch 5: accuracy did not improve from 0.31250\n",
            "\n",
            "Epoch 5: accuracy did not improve from 0.31250\n",
            "\n",
            "Epoch 5: accuracy did not improve from 0.31250\n",
            " 55/121 [============>.................] - ETA: 0s - loss: 2.9446 - accuracy: 0.3011\n",
            "Epoch 5: accuracy did not improve from 0.31250\n",
            "\n",
            "Epoch 5: accuracy did not improve from 0.31250\n",
            "\n",
            "Epoch 5: accuracy did not improve from 0.31250\n",
            "\n",
            "Epoch 5: accuracy did not improve from 0.31250\n",
            " 71/121 [================>.............] - ETA: 0s - loss: 2.9581 - accuracy: 0.2940\n",
            "Epoch 5: accuracy did not improve from 0.31250\n",
            "\n",
            "Epoch 5: accuracy did not improve from 0.31250\n",
            "\n",
            "Epoch 5: accuracy did not improve from 0.31250\n",
            "\n",
            "Epoch 5: accuracy did not improve from 0.31250\n",
            " 91/121 [=====================>........] - ETA: 0s - loss: 2.9789 - accuracy: 0.3012\n",
            "Epoch 5: accuracy did not improve from 0.31250\n",
            "\n",
            "Epoch 5: accuracy did not improve from 0.31250\n",
            "\n",
            "Epoch 5: accuracy did not improve from 0.31250\n",
            "\n",
            "Epoch 5: accuracy did not improve from 0.31250\n",
            "112/121 [==========================>...] - ETA: 0s - loss: 2.9694 - accuracy: 0.3011\n",
            "Epoch 5: accuracy did not improve from 0.31250\n",
            "\n",
            "Epoch 5: accuracy did not improve from 0.31250\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.9579 - accuracy: 0.3043\n",
            "Epoch 6/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.6415 - accuracy: 0.3750\n",
            "Epoch 6: accuracy did not improve from 0.31250\n",
            "\n",
            "Epoch 6: accuracy did not improve from 0.31250\n",
            "\n",
            "Epoch 6: accuracy did not improve from 0.31250\n",
            "\n",
            "Epoch 6: accuracy improved from 0.31250 to 0.31875, saving model to best_model.hdf5\n",
            " 20/121 [===>..........................] - ETA: 0s - loss: 2.9395 - accuracy: 0.3187\n",
            "Epoch 6: accuracy improved from 0.31875 to 0.32500, saving model to best_model.hdf5\n",
            "\n",
            "Epoch 6: accuracy improved from 0.32500 to 0.33646, saving model to best_model.hdf5\n",
            " 33/121 [=======>......................] - ETA: 0s - loss: 2.8433 - accuracy: 0.3485\n",
            "Epoch 6: accuracy improved from 0.33646 to 0.34375, saving model to best_model.hdf5\n",
            "\n",
            "Epoch 6: accuracy did not improve from 0.34375\n",
            "\n",
            "Epoch 6: accuracy did not improve from 0.34375\n",
            " 49/121 [===========>..................] - ETA: 0s - loss: 2.8889 - accuracy: 0.3316\n",
            "Epoch 6: accuracy did not improve from 0.34375\n",
            "\n",
            "Epoch 6: accuracy did not improve from 0.34375\n",
            "\n",
            "Epoch 6: accuracy did not improve from 0.34375\n",
            "\n",
            "Epoch 6: accuracy did not improve from 0.34375\n",
            "\n",
            "Epoch 6: accuracy did not improve from 0.34375\n",
            " 70/121 [================>.............] - ETA: 0s - loss: 2.8754 - accuracy: 0.3299\n",
            "Epoch 6: accuracy did not improve from 0.34375\n",
            "\n",
            "Epoch 6: accuracy did not improve from 0.34375\n",
            "\n",
            "Epoch 6: accuracy did not improve from 0.34375\n",
            " 86/121 [====================>.........] - ETA: 0s - loss: 2.8720 - accuracy: 0.3358\n",
            "Epoch 6: accuracy did not improve from 0.34375\n",
            "\n",
            "Epoch 6: accuracy did not improve from 0.34375\n",
            "\n",
            "Epoch 6: accuracy did not improve from 0.34375\n",
            "104/121 [========================>.....] - ETA: 0s - loss: 2.8772 - accuracy: 0.3341\n",
            "Epoch 6: accuracy did not improve from 0.34375\n",
            "\n",
            "Epoch 6: accuracy did not improve from 0.34375\n",
            "\n",
            "Epoch 6: accuracy did not improve from 0.34375\n",
            "\n",
            "Epoch 6: accuracy did not improve from 0.34375\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.8552 - accuracy: 0.3423\n",
            "Epoch 7/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.0727 - accuracy: 0.4375\n",
            "Epoch 7: accuracy improved from 0.34375 to 0.38281, saving model to best_model.hdf5\n",
            "\n",
            "Epoch 7: accuracy did not improve from 0.38281\n",
            "\n",
            "Epoch 7: accuracy did not improve from 0.38281\n",
            " 15/121 [==>...........................] - ETA: 0s - loss: 2.7732 - accuracy: 0.3500\n",
            "Epoch 7: accuracy did not improve from 0.38281\n",
            "\n",
            "Epoch 7: accuracy did not improve from 0.38281\n",
            "\n",
            "Epoch 7: accuracy did not improve from 0.38281\n",
            "\n",
            "Epoch 7: accuracy did not improve from 0.38281\n",
            " 36/121 [=======>......................] - ETA: 0s - loss: 2.8090 - accuracy: 0.3342\n",
            "Epoch 7: accuracy did not improve from 0.38281\n",
            "\n",
            "Epoch 7: accuracy did not improve from 0.38281\n",
            "\n",
            "Epoch 7: accuracy did not improve from 0.38281\n",
            "\n",
            "Epoch 7: accuracy did not improve from 0.38281\n",
            "\n",
            "Epoch 7: accuracy did not improve from 0.38281\n",
            " 59/121 [=============>................] - ETA: 0s - loss: 2.8552 - accuracy: 0.3459\n",
            "Epoch 7: accuracy did not improve from 0.38281\n",
            "\n",
            "Epoch 7: accuracy did not improve from 0.38281\n",
            "\n",
            "Epoch 7: accuracy did not improve from 0.38281\n",
            " 78/121 [==================>...........] - ETA: 0s - loss: 2.8243 - accuracy: 0.3498\n",
            "Epoch 7: accuracy did not improve from 0.38281\n",
            "\n",
            "Epoch 7: accuracy did not improve from 0.38281\n",
            "\n",
            "Epoch 7: accuracy did not improve from 0.38281\n",
            "\n",
            "Epoch 7: accuracy did not improve from 0.38281\n",
            " 96/121 [======================>.......] - ETA: 0s - loss: 2.8130 - accuracy: 0.3538\n",
            "Epoch 7: accuracy did not improve from 0.38281\n",
            "\n",
            "Epoch 7: accuracy did not improve from 0.38281\n",
            "\n",
            "Epoch 7: accuracy did not improve from 0.38281\n",
            "\n",
            "Epoch 7: accuracy did not improve from 0.38281\n",
            "117/121 [============================>.] - ETA: 0s - loss: 2.7955 - accuracy: 0.3563\n",
            "Epoch 7: accuracy did not improve from 0.38281\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.7927 - accuracy: 0.3571\n",
            "Epoch 8/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 3.7215 - accuracy: 0.1875\n",
            "Epoch 8: accuracy did not improve from 0.38281\n",
            "\n",
            "Epoch 8: accuracy did not improve from 0.38281\n",
            "\n",
            "Epoch 8: accuracy did not improve from 0.38281\n",
            "\n",
            "Epoch 8: accuracy did not improve from 0.38281\n",
            " 20/121 [===>..........................] - ETA: 0s - loss: 2.8313 - accuracy: 0.3578\n",
            "Epoch 8: accuracy did not improve from 0.38281\n",
            "\n",
            "Epoch 8: accuracy did not improve from 0.38281\n",
            "\n",
            "Epoch 8: accuracy did not improve from 0.38281\n",
            "\n",
            "Epoch 8: accuracy did not improve from 0.38281\n",
            " 39/121 [========>.....................] - ETA: 0s - loss: 2.7580 - accuracy: 0.3726\n",
            "Epoch 8: accuracy did not improve from 0.38281\n",
            "\n",
            "Epoch 8: accuracy did not improve from 0.38281\n",
            "\n",
            "Epoch 8: accuracy did not improve from 0.38281\n",
            "\n",
            "Epoch 8: accuracy did not improve from 0.38281\n",
            " 58/121 [=============>................] - ETA: 0s - loss: 2.7641 - accuracy: 0.3615\n",
            "Epoch 8: accuracy did not improve from 0.38281\n",
            "\n",
            "Epoch 8: accuracy did not improve from 0.38281\n",
            "\n",
            "Epoch 8: accuracy did not improve from 0.38281\n",
            " 73/121 [=================>............] - ETA: 0s - loss: 2.7225 - accuracy: 0.3690\n",
            "Epoch 8: accuracy did not improve from 0.38281\n",
            "\n",
            "Epoch 8: accuracy did not improve from 0.38281\n",
            "\n",
            "Epoch 8: accuracy did not improve from 0.38281\n",
            "\n",
            "Epoch 8: accuracy did not improve from 0.38281\n",
            " 93/121 [======================>.......] - ETA: 0s - loss: 2.7588 - accuracy: 0.3666\n",
            "Epoch 8: accuracy did not improve from 0.38281\n",
            "\n",
            "Epoch 8: accuracy did not improve from 0.38281\n",
            "\n",
            "Epoch 8: accuracy did not improve from 0.38281\n",
            "112/121 [==========================>...] - ETA: 0s - loss: 2.7584 - accuracy: 0.3641\n",
            "Epoch 8: accuracy did not improve from 0.38281\n",
            "\n",
            "Epoch 8: accuracy did not improve from 0.38281\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.7670 - accuracy: 0.3649\n",
            "Epoch 9/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 1.7471 - accuracy: 0.4688\n",
            "Epoch 9: accuracy improved from 0.38281 to 0.39062, saving model to best_model.hdf5\n",
            "\n",
            "Epoch 9: accuracy improved from 0.39062 to 0.41518, saving model to best_model.hdf5\n",
            "\n",
            "Epoch 9: accuracy did not improve from 0.41518\n",
            " 12/121 [=>............................] - ETA: 0s - loss: 2.8992 - accuracy: 0.3620\n",
            "Epoch 9: accuracy did not improve from 0.41518\n",
            "\n",
            "Epoch 9: accuracy did not improve from 0.41518\n",
            "\n",
            "Epoch 9: accuracy did not improve from 0.41518\n",
            " 28/121 [=====>........................] - ETA: 0s - loss: 2.9483 - accuracy: 0.3705\n",
            "Epoch 9: accuracy did not improve from 0.41518\n",
            "\n",
            "Epoch 9: accuracy did not improve from 0.41518\n",
            "\n",
            "Epoch 9: accuracy did not improve from 0.41518\n",
            " 43/121 [=========>....................] - ETA: 0s - loss: 2.8813 - accuracy: 0.3779\n",
            "Epoch 9: accuracy did not improve from 0.41518\n",
            "\n",
            "Epoch 9: accuracy did not improve from 0.41518\n",
            "\n",
            "Epoch 9: accuracy did not improve from 0.41518\n",
            "\n",
            "Epoch 9: accuracy did not improve from 0.41518\n",
            " 62/121 [==============>...............] - ETA: 0s - loss: 2.8096 - accuracy: 0.3760\n",
            "Epoch 9: accuracy did not improve from 0.41518\n",
            "\n",
            "Epoch 9: accuracy did not improve from 0.41518\n",
            "\n",
            "Epoch 9: accuracy did not improve from 0.41518\n",
            " 78/121 [==================>...........] - ETA: 0s - loss: 2.7775 - accuracy: 0.3786\n",
            "Epoch 9: accuracy did not improve from 0.41518\n",
            "\n",
            "Epoch 9: accuracy did not improve from 0.41518\n",
            "\n",
            "Epoch 9: accuracy did not improve from 0.41518\n",
            "\n",
            "Epoch 9: accuracy did not improve from 0.41518\n",
            " 97/121 [=======================>......] - ETA: 0s - loss: 2.7872 - accuracy: 0.3753\n",
            "Epoch 9: accuracy did not improve from 0.41518\n",
            "\n",
            "Epoch 9: accuracy did not improve from 0.41518\n",
            "\n",
            "Epoch 9: accuracy did not improve from 0.41518\n",
            "116/121 [===========================>..] - ETA: 0s - loss: 2.7540 - accuracy: 0.3772\n",
            "Epoch 9: accuracy did not improve from 0.41518\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.7573 - accuracy: 0.3745\n",
            "Epoch 10/100\n",
            "\n",
            "Epoch 10: accuracy did not improve from 0.41518\n",
            "  1/121 [..............................] - ETA: 1s - loss: 3.4690 - accuracy: 0.2500\n",
            "Epoch 10: accuracy did not improve from 0.41518\n",
            "\n",
            "Epoch 10: accuracy did not improve from 0.41518\n",
            "\n",
            "Epoch 10: accuracy did not improve from 0.41518\n",
            "\n",
            "Epoch 10: accuracy did not improve from 0.41518\n",
            " 21/121 [====>.........................] - ETA: 0s - loss: 2.7432 - accuracy: 0.3884\n",
            "Epoch 10: accuracy did not improve from 0.41518\n",
            "\n",
            "Epoch 10: accuracy did not improve from 0.41518\n",
            "\n",
            "Epoch 10: accuracy did not improve from 0.41518\n",
            " 37/121 [========>.....................] - ETA: 0s - loss: 2.7215 - accuracy: 0.3986\n",
            "Epoch 10: accuracy did not improve from 0.41518\n",
            "\n",
            "Epoch 10: accuracy did not improve from 0.41518\n",
            "\n",
            "Epoch 10: accuracy did not improve from 0.41518\n",
            " 55/121 [============>.................] - ETA: 0s - loss: 2.7070 - accuracy: 0.3966\n",
            "Epoch 10: accuracy did not improve from 0.41518\n",
            "\n",
            "Epoch 10: accuracy did not improve from 0.41518\n",
            "\n",
            "Epoch 10: accuracy did not improve from 0.41518\n",
            "\n",
            "Epoch 10: accuracy did not improve from 0.41518\n",
            " 73/121 [=================>............] - ETA: 0s - loss: 2.7434 - accuracy: 0.3964\n",
            "Epoch 10: accuracy did not improve from 0.41518\n",
            "\n",
            "Epoch 10: accuracy did not improve from 0.41518\n",
            "\n",
            "Epoch 10: accuracy did not improve from 0.41518\n",
            " 88/121 [====================>.........] - ETA: 0s - loss: 2.7545 - accuracy: 0.3984\n",
            "Epoch 10: accuracy did not improve from 0.41518\n",
            "\n",
            "Epoch 10: accuracy did not improve from 0.41518\n",
            "\n",
            "Epoch 10: accuracy did not improve from 0.41518\n",
            "\n",
            "Epoch 10: accuracy did not improve from 0.41518\n",
            "108/121 [=========================>....] - ETA: 0s - loss: 2.7492 - accuracy: 0.3984\n",
            "Epoch 10: accuracy did not improve from 0.41518\n",
            "\n",
            "Epoch 10: accuracy did not improve from 0.41518\n",
            "\n",
            "Epoch 10: accuracy did not improve from 0.41518\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.7512 - accuracy: 0.3999\n",
            "Epoch 11/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.1106 - accuracy: 0.4688\n",
            "Epoch 11: accuracy did not improve from 0.41518\n",
            "\n",
            "Epoch 11: accuracy did not improve from 0.41518\n",
            "\n",
            "Epoch 11: accuracy did not improve from 0.41518\n",
            " 18/121 [===>..........................] - ETA: 0s - loss: 2.5669 - accuracy: 0.4167\n",
            "Epoch 11: accuracy improved from 0.41518 to 0.42031, saving model to best_model.hdf5\n",
            "\n",
            "Epoch 11: accuracy did not improve from 0.42031\n",
            "\n",
            "Epoch 11: accuracy did not improve from 0.42031\n",
            " 32/121 [======>.......................] - ETA: 0s - loss: 2.6126 - accuracy: 0.4170\n",
            "Epoch 11: accuracy did not improve from 0.42031\n",
            "\n",
            "Epoch 11: accuracy did not improve from 0.42031\n",
            "\n",
            "Epoch 11: accuracy did not improve from 0.42031\n",
            "\n",
            "Epoch 11: accuracy did not improve from 0.42031\n",
            " 52/121 [===========>..................] - ETA: 0s - loss: 2.7412 - accuracy: 0.4165\n",
            "Epoch 11: accuracy did not improve from 0.42031\n",
            "\n",
            "Epoch 11: accuracy did not improve from 0.42031\n",
            "\n",
            "Epoch 11: accuracy did not improve from 0.42031\n",
            " 69/121 [================>.............] - ETA: 0s - loss: 2.7918 - accuracy: 0.4072\n",
            "Epoch 11: accuracy did not improve from 0.42031\n",
            "\n",
            "Epoch 11: accuracy did not improve from 0.42031\n",
            "\n",
            "Epoch 11: accuracy did not improve from 0.42031\n",
            "\n",
            "Epoch 11: accuracy did not improve from 0.42031\n",
            " 87/121 [====================>.........] - ETA: 0s - loss: 2.7704 - accuracy: 0.4091\n",
            "Epoch 11: accuracy did not improve from 0.42031\n",
            "\n",
            "Epoch 11: accuracy did not improve from 0.42031\n",
            "\n",
            "Epoch 11: accuracy did not improve from 0.42031\n",
            "\n",
            "Epoch 11: accuracy did not improve from 0.42031\n",
            "107/121 [=========================>....] - ETA: 0s - loss: 2.7654 - accuracy: 0.4136\n",
            "Epoch 11: accuracy did not improve from 0.42031\n",
            "\n",
            "Epoch 11: accuracy did not improve from 0.42031\n",
            "\n",
            "Epoch 11: accuracy did not improve from 0.42031\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.7472 - accuracy: 0.4114\n",
            "Epoch 12/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.7007 - accuracy: 0.3750\n",
            "Epoch 12: accuracy did not improve from 0.42031\n",
            "\n",
            "Epoch 12: accuracy did not improve from 0.42031\n",
            "\n",
            "Epoch 12: accuracy did not improve from 0.42031\n",
            "\n",
            "Epoch 12: accuracy improved from 0.42031 to 0.42928, saving model to best_model.hdf5\n",
            " 19/121 [===>..........................] - ETA: 0s - loss: 2.6783 - accuracy: 0.4293\n",
            "Epoch 12: accuracy did not improve from 0.42928\n",
            "\n",
            "Epoch 12: accuracy did not improve from 0.42928\n",
            "\n",
            "Epoch 12: accuracy did not improve from 0.42928\n",
            " 35/121 [=======>......................] - ETA: 0s - loss: 2.7481 - accuracy: 0.4223\n",
            "Epoch 12: accuracy did not improve from 0.42928\n",
            "\n",
            "Epoch 12: accuracy improved from 0.42928 to 0.43395, saving model to best_model.hdf5\n",
            "\n",
            "Epoch 12: accuracy did not improve from 0.43395\n",
            " 50/121 [===========>..................] - ETA: 0s - loss: 2.6869 - accuracy: 0.4250\n",
            "Epoch 12: accuracy did not improve from 0.43395\n",
            "\n",
            "Epoch 12: accuracy did not improve from 0.43395\n",
            "\n",
            "Epoch 12: accuracy did not improve from 0.43395\n",
            " 66/121 [===============>..............] - ETA: 0s - loss: 2.7104 - accuracy: 0.4176\n",
            "Epoch 12: accuracy did not improve from 0.43395\n",
            "\n",
            "Epoch 12: accuracy did not improve from 0.43395\n",
            "\n",
            "Epoch 12: accuracy did not improve from 0.43395\n",
            "\n",
            "Epoch 12: accuracy did not improve from 0.43395\n",
            " 85/121 [====================>.........] - ETA: 0s - loss: 2.7116 - accuracy: 0.4199\n",
            "Epoch 12: accuracy did not improve from 0.43395\n",
            "\n",
            "Epoch 12: accuracy did not improve from 0.43395\n",
            "\n",
            "Epoch 12: accuracy did not improve from 0.43395\n",
            "\n",
            "Epoch 12: accuracy did not improve from 0.43395\n",
            "108/121 [=========================>....] - ETA: 0s - loss: 2.7372 - accuracy: 0.4138\n",
            "Epoch 12: accuracy did not improve from 0.43395\n",
            "\n",
            "Epoch 12: accuracy did not improve from 0.43395\n",
            "\n",
            "Epoch 12: accuracy did not improve from 0.43395\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.7436 - accuracy: 0.4142\n",
            "Epoch 13/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.6060 - accuracy: 0.4688\n",
            "Epoch 13: accuracy did not improve from 0.43395\n",
            "\n",
            "Epoch 13: accuracy did not improve from 0.43395\n",
            "\n",
            "Epoch 13: accuracy did not improve from 0.43395\n",
            "\n",
            "Epoch 13: accuracy did not improve from 0.43395\n",
            " 19/121 [===>..........................] - ETA: 0s - loss: 2.8067 - accuracy: 0.4112\n",
            "Epoch 13: accuracy did not improve from 0.43395\n",
            "\n",
            "Epoch 13: accuracy did not improve from 0.43395\n",
            "\n",
            "Epoch 13: accuracy did not improve from 0.43395\n",
            "\n",
            "Epoch 13: accuracy did not improve from 0.43395\n",
            " 38/121 [========>.....................] - ETA: 0s - loss: 2.8008 - accuracy: 0.4169\n",
            "Epoch 13: accuracy did not improve from 0.43395\n",
            "\n",
            "Epoch 13: accuracy did not improve from 0.43395\n",
            "\n",
            "Epoch 13: accuracy did not improve from 0.43395\n",
            " 56/121 [============>.................] - ETA: 0s - loss: 2.7923 - accuracy: 0.4090\n",
            "Epoch 13: accuracy did not improve from 0.43395\n",
            "\n",
            "Epoch 13: accuracy did not improve from 0.43395\n",
            "\n",
            "Epoch 13: accuracy did not improve from 0.43395\n",
            " 70/121 [================>.............] - ETA: 0s - loss: 2.7666 - accuracy: 0.4116\n",
            "Epoch 13: accuracy did not improve from 0.43395\n",
            "\n",
            "Epoch 13: accuracy did not improve from 0.43395\n",
            "\n",
            "Epoch 13: accuracy did not improve from 0.43395\n",
            "\n",
            "Epoch 13: accuracy did not improve from 0.43395\n",
            " 90/121 [=====================>........] - ETA: 0s - loss: 2.7256 - accuracy: 0.4174\n",
            "Epoch 13: accuracy did not improve from 0.43395\n",
            "\n",
            "Epoch 13: accuracy did not improve from 0.43395\n",
            "\n",
            "Epoch 13: accuracy did not improve from 0.43395\n",
            "\n",
            "Epoch 13: accuracy did not improve from 0.43395\n",
            "\n",
            "Epoch 13: accuracy did not improve from 0.43395\n",
            "113/121 [===========================>..] - ETA: 0s - loss: 2.7350 - accuracy: 0.4184\n",
            "Epoch 13: accuracy did not improve from 0.43395\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.7411 - accuracy: 0.4148\n",
            "Epoch 14/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.4175 - accuracy: 0.5000\n",
            "Epoch 14: accuracy improved from 0.43395 to 0.43750, saving model to best_model.hdf5\n",
            "\n",
            "Epoch 14: accuracy did not improve from 0.43750\n",
            "\n",
            "Epoch 14: accuracy did not improve from 0.43750\n",
            "\n",
            "Epoch 14: accuracy did not improve from 0.43750\n",
            " 18/121 [===>..........................] - ETA: 0s - loss: 2.6576 - accuracy: 0.4097\n",
            "Epoch 14: accuracy did not improve from 0.43750\n",
            "\n",
            "Epoch 14: accuracy did not improve from 0.43750\n",
            "\n",
            "Epoch 14: accuracy did not improve from 0.43750\n",
            "\n",
            "Epoch 14: accuracy did not improve from 0.43750\n",
            " 39/121 [========>.....................] - ETA: 0s - loss: 2.6970 - accuracy: 0.4183\n",
            "Epoch 14: accuracy did not improve from 0.43750\n",
            "\n",
            "Epoch 14: accuracy did not improve from 0.43750\n",
            "\n",
            "Epoch 14: accuracy did not improve from 0.43750\n",
            " 54/121 [============>.................] - ETA: 0s - loss: 2.6812 - accuracy: 0.4253\n",
            "Epoch 14: accuracy did not improve from 0.43750\n",
            "\n",
            "Epoch 14: accuracy did not improve from 0.43750\n",
            "\n",
            "Epoch 14: accuracy did not improve from 0.43750\n",
            "\n",
            "Epoch 14: accuracy did not improve from 0.43750\n",
            " 73/121 [=================>............] - ETA: 0s - loss: 2.7177 - accuracy: 0.4204\n",
            "Epoch 14: accuracy did not improve from 0.43750\n",
            "\n",
            "Epoch 14: accuracy did not improve from 0.43750\n",
            "\n",
            "Epoch 14: accuracy did not improve from 0.43750\n",
            "\n",
            "Epoch 14: accuracy did not improve from 0.43750\n",
            " 92/121 [=====================>........] - ETA: 0s - loss: 2.7065 - accuracy: 0.4185\n",
            "Epoch 14: accuracy did not improve from 0.43750\n",
            "\n",
            "Epoch 14: accuracy did not improve from 0.43750\n",
            "\n",
            "Epoch 14: accuracy did not improve from 0.43750\n",
            "111/121 [==========================>...] - ETA: 0s - loss: 2.7353 - accuracy: 0.4147\n",
            "Epoch 14: accuracy did not improve from 0.43750\n",
            "\n",
            "Epoch 14: accuracy did not improve from 0.43750\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.7392 - accuracy: 0.4145\n",
            "Epoch 15/100\n",
            "\n",
            "Epoch 15: accuracy improved from 0.43750 to 0.53125, saving model to best_model.hdf5\n",
            "  1/121 [..............................] - ETA: 2s - loss: 2.0315 - accuracy: 0.5312\n",
            "Epoch 15: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 15: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 15: accuracy did not improve from 0.53125\n",
            " 16/121 [==>...........................] - ETA: 0s - loss: 2.7871 - accuracy: 0.4102\n",
            "Epoch 15: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 15: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 15: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 15: accuracy did not improve from 0.53125\n",
            " 37/121 [========>.....................] - ETA: 0s - loss: 2.7475 - accuracy: 0.4231\n",
            "Epoch 15: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 15: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 15: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 15: accuracy did not improve from 0.53125\n",
            " 57/121 [=============>................] - ETA: 0s - loss: 2.7457 - accuracy: 0.4123\n",
            "Epoch 15: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 15: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 15: accuracy did not improve from 0.53125\n",
            " 75/121 [=================>............] - ETA: 0s - loss: 2.7342 - accuracy: 0.4096\n",
            "Epoch 15: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 15: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 15: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 15: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 15: accuracy did not improve from 0.53125\n",
            " 96/121 [======================>.......] - ETA: 0s - loss: 2.7335 - accuracy: 0.4105\n",
            "Epoch 15: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 15: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 15: accuracy did not improve from 0.53125\n",
            "114/121 [===========================>..] - ETA: 0s - loss: 2.7440 - accuracy: 0.4158\n",
            "Epoch 15: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 15: accuracy did not improve from 0.53125\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.7377 - accuracy: 0.4148\n",
            "Epoch 16/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 3.5386 - accuracy: 0.2188\n",
            "Epoch 16: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 16: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 16: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 16: accuracy did not improve from 0.53125\n",
            " 21/121 [====>.........................] - ETA: 0s - loss: 2.8454 - accuracy: 0.4167\n",
            "Epoch 16: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 16: accuracy did not improve from 0.53125\n",
            " 32/121 [======>.......................] - ETA: 0s - loss: 2.8483 - accuracy: 0.4170\n",
            "Epoch 16: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 16: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 16: accuracy did not improve from 0.53125\n",
            " 45/121 [==========>...................] - ETA: 0s - loss: 2.7785 - accuracy: 0.4181\n",
            "Epoch 16: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 16: accuracy did not improve from 0.53125\n",
            " 56/121 [============>.................] - ETA: 0s - loss: 2.7538 - accuracy: 0.4219\n",
            "Epoch 16: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 16: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 16: accuracy did not improve from 0.53125\n",
            " 72/121 [================>.............] - ETA: 0s - loss: 2.7332 - accuracy: 0.4284\n",
            "Epoch 16: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 16: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 16: accuracy did not improve from 0.53125\n",
            " 87/121 [====================>.........] - ETA: 0s - loss: 2.7269 - accuracy: 0.4278\n",
            "Epoch 16: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 16: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 16: accuracy did not improve from 0.53125\n",
            "103/121 [========================>.....] - ETA: 0s - loss: 2.7361 - accuracy: 0.4266\n",
            "Epoch 16: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 16: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 16: accuracy did not improve from 0.53125\n",
            "119/121 [============================>.] - ETA: 0s - loss: 2.7371 - accuracy: 0.4233\n",
            "Epoch 16: accuracy did not improve from 0.53125\n",
            "121/121 [==============================] - 0s 4ms/step - loss: 2.7364 - accuracy: 0.4233\n",
            "Epoch 17/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.8831 - accuracy: 0.3750\n",
            "Epoch 17: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 17: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 17: accuracy did not improve from 0.53125\n",
            " 18/121 [===>..........................] - ETA: 0s - loss: 2.6211 - accuracy: 0.4288\n",
            "Epoch 17: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 17: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 17: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 17: accuracy did not improve from 0.53125\n",
            " 35/121 [=======>......................] - ETA: 0s - loss: 2.7123 - accuracy: 0.4241\n",
            "Epoch 17: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 17: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 17: accuracy did not improve from 0.53125\n",
            " 49/121 [===========>..................] - ETA: 0s - loss: 2.7093 - accuracy: 0.4298\n",
            "Epoch 17: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 17: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 17: accuracy did not improve from 0.53125\n",
            " 66/121 [===============>..............] - ETA: 0s - loss: 2.7659 - accuracy: 0.4205\n",
            "Epoch 17: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 17: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 17: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 17: accuracy did not improve from 0.53125\n",
            " 84/121 [===================>..........] - ETA: 0s - loss: 2.7316 - accuracy: 0.4234\n",
            "Epoch 17: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 17: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 17: accuracy did not improve from 0.53125\n",
            "101/121 [========================>.....] - ETA: 0s - loss: 2.7229 - accuracy: 0.4226\n",
            "Epoch 17: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 17: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 17: accuracy did not improve from 0.53125\n",
            "114/121 [===========================>..] - ETA: 0s - loss: 2.7632 - accuracy: 0.4197\n",
            "Epoch 17: accuracy did not improve from 0.53125\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.7354 - accuracy: 0.4233\n",
            "Epoch 18/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 3.4591 - accuracy: 0.3750\n",
            "Epoch 18: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 18: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 18: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 18: accuracy did not improve from 0.53125\n",
            " 18/121 [===>..........................] - ETA: 0s - loss: 2.6292 - accuracy: 0.4410\n",
            "Epoch 18: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 18: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 18: accuracy did not improve from 0.53125\n",
            " 34/121 [=======>......................] - ETA: 0s - loss: 2.6844 - accuracy: 0.4283\n",
            "Epoch 18: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 18: accuracy did not improve from 0.53125\n",
            " 45/121 [==========>...................] - ETA: 0s - loss: 2.6527 - accuracy: 0.4396\n",
            "Epoch 18: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 18: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 18: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 18: accuracy did not improve from 0.53125\n",
            " 63/121 [==============>...............] - ETA: 0s - loss: 2.7343 - accuracy: 0.4281\n",
            "Epoch 18: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 18: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 18: accuracy did not improve from 0.53125\n",
            " 81/121 [===================>..........] - ETA: 0s - loss: 2.7310 - accuracy: 0.4267\n",
            "Epoch 18: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 18: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 18: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 18: accuracy did not improve from 0.53125\n",
            " 98/121 [=======================>......] - ETA: 0s - loss: 2.7416 - accuracy: 0.4254\n",
            "Epoch 18: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 18: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 18: accuracy did not improve from 0.53125\n",
            "113/121 [===========================>..] - ETA: 0s - loss: 2.7335 - accuracy: 0.4242\n",
            "Epoch 18: accuracy did not improve from 0.53125\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.7344 - accuracy: 0.4254\n",
            "Epoch 19/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 3.1758 - accuracy: 0.4375\n",
            "Epoch 19: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 19: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 19: accuracy did not improve from 0.53125\n",
            " 16/121 [==>...........................] - ETA: 0s - loss: 2.7104 - accuracy: 0.4160\n",
            "Epoch 19: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 19: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 19: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 19: accuracy did not improve from 0.53125\n",
            " 33/121 [=======>......................] - ETA: 0s - loss: 2.8047 - accuracy: 0.4081\n",
            "Epoch 19: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 19: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 19: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 19: accuracy did not improve from 0.53125\n",
            " 52/121 [===========>..................] - ETA: 0s - loss: 2.8094 - accuracy: 0.4008\n",
            "Epoch 19: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 19: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 19: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 19: accuracy did not improve from 0.53125\n",
            " 72/121 [================>.............] - ETA: 0s - loss: 2.7349 - accuracy: 0.4175\n",
            "Epoch 19: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 19: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 19: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 19: accuracy did not improve from 0.53125\n",
            " 92/121 [=====================>........] - ETA: 0s - loss: 2.7188 - accuracy: 0.4246\n",
            "Epoch 19: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 19: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 19: accuracy did not improve from 0.53125\n",
            "110/121 [==========================>...] - ETA: 0s - loss: 2.7356 - accuracy: 0.4250\n",
            "Epoch 19: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 19: accuracy did not improve from 0.53125\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.7335 - accuracy: 0.4257\n",
            "Epoch 20/100\n",
            "\n",
            "Epoch 20: accuracy did not improve from 0.53125\n",
            "  1/121 [..............................] - ETA: 0s - loss: 3.2653 - accuracy: 0.3750\n",
            "Epoch 20: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 20: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 20: accuracy did not improve from 0.53125\n",
            " 19/121 [===>..........................] - ETA: 0s - loss: 2.7450 - accuracy: 0.4112\n",
            "Epoch 20: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 20: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 20: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 20: accuracy did not improve from 0.53125\n",
            " 37/121 [========>.....................] - ETA: 0s - loss: 2.6660 - accuracy: 0.4265\n",
            "Epoch 20: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 20: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 20: accuracy did not improve from 0.53125\n",
            " 54/121 [============>.................] - ETA: 0s - loss: 2.6403 - accuracy: 0.4410\n",
            "Epoch 20: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 20: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 20: accuracy did not improve from 0.53125\n",
            " 69/121 [================>.............] - ETA: 0s - loss: 2.6863 - accuracy: 0.4307\n",
            "Epoch 20: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 20: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 20: accuracy did not improve from 0.53125\n",
            " 82/121 [===================>..........] - ETA: 0s - loss: 2.6801 - accuracy: 0.4318\n",
            "Epoch 20: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 20: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 20: accuracy did not improve from 0.53125\n",
            " 96/121 [======================>.......] - ETA: 0s - loss: 2.6779 - accuracy: 0.4352\n",
            "Epoch 20: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 20: accuracy did not improve from 0.53125\n",
            "110/121 [==========================>...] - ETA: 0s - loss: 2.7216 - accuracy: 0.4281\n",
            "Epoch 20: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 20: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 20: accuracy did not improve from 0.53125\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.7310 - accuracy: 0.4270\n",
            "Epoch 21/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.6909 - accuracy: 0.3438\n",
            "Epoch 21: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 21: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 21: accuracy did not improve from 0.53125\n",
            " 19/121 [===>..........................] - ETA: 0s - loss: 2.5894 - accuracy: 0.4062\n",
            "Epoch 21: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 21: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 21: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 21: accuracy did not improve from 0.53125\n",
            " 36/121 [=======>......................] - ETA: 0s - loss: 2.6104 - accuracy: 0.4288\n",
            "Epoch 21: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 21: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 21: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 21: accuracy did not improve from 0.53125\n",
            " 55/121 [============>.................] - ETA: 0s - loss: 2.6833 - accuracy: 0.4273\n",
            "Epoch 21: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 21: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 21: accuracy did not improve from 0.53125\n",
            " 73/121 [=================>............] - ETA: 0s - loss: 2.6806 - accuracy: 0.4289\n",
            "Epoch 21: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 21: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 21: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 21: accuracy did not improve from 0.53125\n",
            " 90/121 [=====================>........] - ETA: 0s - loss: 2.6982 - accuracy: 0.4240\n",
            "Epoch 21: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 21: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 21: accuracy did not improve from 0.53125\n",
            "105/121 [=========================>....] - ETA: 0s - loss: 2.6875 - accuracy: 0.4235\n",
            "Epoch 21: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 21: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 21: accuracy did not improve from 0.53125\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.7025 - accuracy: 0.4226\n",
            "Epoch 22/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.9750 - accuracy: 0.4375\n",
            "Epoch 22: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 22: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 22: accuracy did not improve from 0.53125\n",
            " 18/121 [===>..........................] - ETA: 0s - loss: 2.7035 - accuracy: 0.4306\n",
            "Epoch 22: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 22: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 22: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 22: accuracy did not improve from 0.53125\n",
            " 34/121 [=======>......................] - ETA: 0s - loss: 2.7625 - accuracy: 0.4136\n",
            "Epoch 22: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 22: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 22: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 22: accuracy did not improve from 0.53125\n",
            " 54/121 [============>.................] - ETA: 0s - loss: 2.7400 - accuracy: 0.4161\n",
            "Epoch 22: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 22: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 22: accuracy did not improve from 0.53125\n",
            " 72/121 [================>.............] - ETA: 0s - loss: 2.6914 - accuracy: 0.4158\n",
            "Epoch 22: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 22: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 22: accuracy did not improve from 0.53125\n",
            " 87/121 [====================>.........] - ETA: 0s - loss: 2.6934 - accuracy: 0.4203\n",
            "Epoch 22: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 22: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 22: accuracy did not improve from 0.53125\n",
            "101/121 [========================>.....] - ETA: 0s - loss: 2.6757 - accuracy: 0.4270\n",
            "Epoch 22: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 22: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 22: accuracy did not improve from 0.53125\n",
            "114/121 [===========================>..] - ETA: 0s - loss: 2.6907 - accuracy: 0.4238\n",
            "Epoch 22: accuracy did not improve from 0.53125\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.6873 - accuracy: 0.4231\n",
            "Epoch 23/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.4984 - accuracy: 0.4688\n",
            "Epoch 23: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 23: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 23: accuracy did not improve from 0.53125\n",
            " 13/121 [==>...........................] - ETA: 0s - loss: 2.6764 - accuracy: 0.4375\n",
            "Epoch 23: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 23: accuracy did not improve from 0.53125\n",
            " 25/121 [=====>........................] - ETA: 0s - loss: 2.7276 - accuracy: 0.4288\n",
            "Epoch 23: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 23: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 23: accuracy did not improve from 0.53125\n",
            " 38/121 [========>.....................] - ETA: 0s - loss: 2.6891 - accuracy: 0.4293\n",
            "Epoch 23: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 23: accuracy did not improve from 0.53125\n",
            " 51/121 [===========>..................] - ETA: 0s - loss: 2.6660 - accuracy: 0.4308\n",
            "Epoch 23: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 23: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 23: accuracy did not improve from 0.53125\n",
            " 63/121 [==============>...............] - ETA: 0s - loss: 2.6814 - accuracy: 0.4360\n",
            "Epoch 23: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 23: accuracy did not improve from 0.53125\n",
            " 75/121 [=================>............] - ETA: 0s - loss: 2.7000 - accuracy: 0.4258\n",
            "Epoch 23: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 23: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 23: accuracy did not improve from 0.53125\n",
            " 88/121 [====================>.........] - ETA: 0s - loss: 2.6828 - accuracy: 0.4308\n",
            "Epoch 23: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 23: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 23: accuracy did not improve from 0.53125\n",
            "103/121 [========================>.....] - ETA: 0s - loss: 2.6729 - accuracy: 0.4284\n",
            "Epoch 23: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 23: accuracy did not improve from 0.53125\n",
            "116/121 [===========================>..] - ETA: 0s - loss: 2.6726 - accuracy: 0.4278\n",
            "Epoch 23: accuracy did not improve from 0.53125\n",
            "121/121 [==============================] - 0s 4ms/step - loss: 2.6728 - accuracy: 0.4283\n",
            "Epoch 24/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.0208 - accuracy: 0.5000\n",
            "Epoch 24: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 24: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 24: accuracy did not improve from 0.53125\n",
            " 14/121 [==>...........................] - ETA: 0s - loss: 2.5356 - accuracy: 0.4464\n",
            "Epoch 24: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 24: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 24: accuracy did not improve from 0.53125\n",
            " 28/121 [=====>........................] - ETA: 0s - loss: 2.6685 - accuracy: 0.4152\n",
            "Epoch 24: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 24: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 24: accuracy did not improve from 0.53125\n",
            " 42/121 [=========>....................] - ETA: 0s - loss: 2.5907 - accuracy: 0.4382\n",
            "Epoch 24: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 24: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 24: accuracy did not improve from 0.53125\n",
            " 58/121 [=============>................] - ETA: 0s - loss: 2.6055 - accuracy: 0.4380\n",
            "Epoch 24: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 24: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 24: accuracy did not improve from 0.53125\n",
            " 73/121 [=================>............] - ETA: 0s - loss: 2.6525 - accuracy: 0.4311\n",
            "Epoch 24: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 24: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 24: accuracy did not improve from 0.53125\n",
            " 89/121 [=====================>........] - ETA: 0s - loss: 2.6448 - accuracy: 0.4315\n",
            "Epoch 24: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 24: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 24: accuracy did not improve from 0.53125\n",
            "103/121 [========================>.....] - ETA: 0s - loss: 2.6443 - accuracy: 0.4333\n",
            "Epoch 24: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 24: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 24: accuracy did not improve from 0.53125\n",
            "121/121 [==============================] - 0s 4ms/step - loss: 2.6675 - accuracy: 0.4293\n",
            "Epoch 25/100\n",
            "\n",
            "Epoch 25: accuracy did not improve from 0.53125\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.1107 - accuracy: 0.4688\n",
            "Epoch 25: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 25: accuracy did not improve from 0.53125\n",
            " 15/121 [==>...........................] - ETA: 0s - loss: 2.6859 - accuracy: 0.4229\n",
            "Epoch 25: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 25: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 25: accuracy did not improve from 0.53125\n",
            " 27/121 [=====>........................] - ETA: 0s - loss: 2.7829 - accuracy: 0.4097\n",
            "Epoch 25: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 25: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 25: accuracy did not improve from 0.53125\n",
            " 42/121 [=========>....................] - ETA: 0s - loss: 2.7262 - accuracy: 0.4249\n",
            "Epoch 25: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 25: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 25: accuracy did not improve from 0.53125\n",
            " 60/121 [=============>................] - ETA: 0s - loss: 2.7112 - accuracy: 0.4344\n",
            "Epoch 25: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 25: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 25: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 25: accuracy did not improve from 0.53125\n",
            " 77/121 [==================>...........] - ETA: 0s - loss: 2.6778 - accuracy: 0.4347\n",
            "Epoch 25: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 25: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 25: accuracy did not improve from 0.53125\n",
            " 91/121 [=====================>........] - ETA: 0s - loss: 2.6882 - accuracy: 0.4348\n",
            "Epoch 25: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 25: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 25: accuracy did not improve from 0.53125\n",
            "106/121 [=========================>....] - ETA: 0s - loss: 2.6701 - accuracy: 0.4357\n",
            "Epoch 25: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 25: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 25: accuracy did not improve from 0.53125\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.6656 - accuracy: 0.4356\n",
            "Epoch 26/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.1023 - accuracy: 0.5312\n",
            "Epoch 26: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 26: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 26: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 26: accuracy did not improve from 0.53125\n",
            " 20/121 [===>..........................] - ETA: 0s - loss: 2.6173 - accuracy: 0.4219\n",
            "Epoch 26: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 26: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 26: accuracy did not improve from 0.53125\n",
            " 37/121 [========>.....................] - ETA: 0s - loss: 2.5661 - accuracy: 0.4485\n",
            "Epoch 26: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 26: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 26: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 26: accuracy did not improve from 0.53125\n",
            " 55/121 [============>.................] - ETA: 0s - loss: 2.6174 - accuracy: 0.4460\n",
            "Epoch 26: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 26: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 26: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 26: accuracy did not improve from 0.53125\n",
            " 75/121 [=================>............] - ETA: 0s - loss: 2.6754 - accuracy: 0.4408\n",
            "Epoch 26: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 26: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 26: accuracy did not improve from 0.53125\n",
            " 94/121 [======================>.......] - ETA: 0s - loss: 2.6614 - accuracy: 0.4418\n",
            "Epoch 26: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 26: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 26: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 26: accuracy did not improve from 0.53125\n",
            "110/121 [==========================>...] - ETA: 0s - loss: 2.6682 - accuracy: 0.4395\n",
            "Epoch 26: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 26: accuracy did not improve from 0.53125\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.6644 - accuracy: 0.4381\n",
            "Epoch 27/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 1.9263 - accuracy: 0.5312\n",
            "Epoch 27: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 27: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 27: accuracy did not improve from 0.53125\n",
            " 16/121 [==>...........................] - ETA: 0s - loss: 2.7025 - accuracy: 0.4316\n",
            "Epoch 27: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 27: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 27: accuracy did not improve from 0.53125\n",
            " 29/121 [======>.......................] - ETA: 0s - loss: 2.7014 - accuracy: 0.4203\n",
            "Epoch 27: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 27: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 27: accuracy did not improve from 0.53125\n",
            " 44/121 [=========>....................] - ETA: 0s - loss: 2.7352 - accuracy: 0.4219\n",
            "Epoch 27: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 27: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 27: accuracy did not improve from 0.53125\n",
            " 59/121 [=============>................] - ETA: 0s - loss: 2.6982 - accuracy: 0.4274\n",
            "Epoch 27: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 27: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 27: accuracy did not improve from 0.53125\n",
            " 74/121 [=================>............] - ETA: 0s - loss: 2.6809 - accuracy: 0.4299\n",
            "Epoch 27: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 27: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 27: accuracy did not improve from 0.53125\n",
            " 89/121 [=====================>........] - ETA: 0s - loss: 2.6872 - accuracy: 0.4294\n",
            "Epoch 27: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 27: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 27: accuracy did not improve from 0.53125\n",
            "107/121 [=========================>....] - ETA: 0s - loss: 2.6830 - accuracy: 0.4349\n",
            "Epoch 27: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 27: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 27: accuracy did not improve from 0.53125\n",
            "121/121 [==============================] - 0s 4ms/step - loss: 2.6637 - accuracy: 0.4397\n",
            "Epoch 28/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.2280 - accuracy: 0.4375\n",
            "Epoch 28: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 28: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 28: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 28: accuracy did not improve from 0.53125\n",
            " 20/121 [===>..........................] - ETA: 0s - loss: 2.7696 - accuracy: 0.4219\n",
            "Epoch 28: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 28: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 28: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 28: accuracy did not improve from 0.53125\n",
            " 40/121 [========>.....................] - ETA: 0s - loss: 2.7549 - accuracy: 0.4164\n",
            "Epoch 28: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 28: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 28: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 28: accuracy did not improve from 0.53125\n",
            " 59/121 [=============>................] - ETA: 0s - loss: 2.7700 - accuracy: 0.4200\n",
            "Epoch 28: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 28: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 28: accuracy did not improve from 0.53125\n",
            " 74/121 [=================>............] - ETA: 0s - loss: 2.6934 - accuracy: 0.4337\n",
            "Epoch 28: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 28: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 28: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 28: accuracy did not improve from 0.53125\n",
            " 93/121 [======================>.......] - ETA: 0s - loss: 2.6285 - accuracy: 0.4429\n",
            "Epoch 28: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 28: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 28: accuracy did not improve from 0.53125\n",
            "112/121 [==========================>...] - ETA: 0s - loss: 2.6752 - accuracy: 0.4375\n",
            "Epoch 28: accuracy did not improve from 0.53125\n",
            "\n",
            "Epoch 28: accuracy did not improve from 0.53125\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.6631 - accuracy: 0.4400\n",
            "Epoch 29/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.5806 - accuracy: 0.5312\n",
            "Epoch 29: accuracy improved from 0.53125 to 0.64062, saving model to best_model.hdf5\n",
            "\n",
            "Epoch 29: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 29: accuracy did not improve from 0.64062\n",
            " 15/121 [==>...........................] - ETA: 0s - loss: 2.4984 - accuracy: 0.4708\n",
            "Epoch 29: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 29: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 29: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 29: accuracy did not improve from 0.64062\n",
            " 32/121 [======>.......................] - ETA: 0s - loss: 2.5740 - accuracy: 0.4600\n",
            "Epoch 29: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 29: accuracy did not improve from 0.64062\n",
            " 44/121 [=========>....................] - ETA: 0s - loss: 2.5402 - accuracy: 0.4581\n",
            "Epoch 29: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 29: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 29: accuracy did not improve from 0.64062\n",
            " 57/121 [=============>................] - ETA: 0s - loss: 2.5115 - accuracy: 0.4594\n",
            "Epoch 29: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 29: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 29: accuracy did not improve from 0.64062\n",
            " 75/121 [=================>............] - ETA: 0s - loss: 2.5875 - accuracy: 0.4479\n",
            "Epoch 29: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 29: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 29: accuracy did not improve from 0.64062\n",
            " 90/121 [=====================>........] - ETA: 0s - loss: 2.6211 - accuracy: 0.4476\n",
            "Epoch 29: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 29: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 29: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 29: accuracy did not improve from 0.64062\n",
            "108/121 [=========================>....] - ETA: 0s - loss: 2.6505 - accuracy: 0.4450\n",
            "Epoch 29: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 29: accuracy did not improve from 0.64062\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.6624 - accuracy: 0.4402\n",
            "Epoch 30/100\n",
            "\n",
            "Epoch 30: accuracy did not improve from 0.64062\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.7780 - accuracy: 0.5000\n",
            "Epoch 30: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 30: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 30: accuracy did not improve from 0.64062\n",
            " 17/121 [===>..........................] - ETA: 0s - loss: 2.8019 - accuracy: 0.4301\n",
            "Epoch 30: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 30: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 30: accuracy did not improve from 0.64062\n",
            " 34/121 [=======>......................] - ETA: 0s - loss: 2.7574 - accuracy: 0.4357\n",
            "Epoch 30: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 30: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 30: accuracy did not improve from 0.64062\n",
            " 48/121 [==========>...................] - ETA: 0s - loss: 2.7619 - accuracy: 0.4329\n",
            "Epoch 30: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 30: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 30: accuracy did not improve from 0.64062\n",
            " 62/121 [==============>...............] - ETA: 0s - loss: 2.7180 - accuracy: 0.4415\n",
            "Epoch 30: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 30: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 30: accuracy did not improve from 0.64062\n",
            " 78/121 [==================>...........] - ETA: 0s - loss: 2.6580 - accuracy: 0.4479\n",
            "Epoch 30: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 30: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 30: accuracy did not improve from 0.64062\n",
            " 93/121 [======================>.......] - ETA: 0s - loss: 2.6184 - accuracy: 0.4479\n",
            "Epoch 30: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 30: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 30: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 30: accuracy did not improve from 0.64062\n",
            "111/121 [==========================>...] - ETA: 0s - loss: 2.6442 - accuracy: 0.4454\n",
            "Epoch 30: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 30: accuracy did not improve from 0.64062\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.6618 - accuracy: 0.4418\n",
            "Epoch 31/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 3.0643 - accuracy: 0.4375\n",
            "Epoch 31: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 31: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 31: accuracy did not improve from 0.64062\n",
            " 18/121 [===>..........................] - ETA: 0s - loss: 2.5670 - accuracy: 0.4566\n",
            "Epoch 31: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 31: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 31: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 31: accuracy did not improve from 0.64062\n",
            " 35/121 [=======>......................] - ETA: 0s - loss: 2.6273 - accuracy: 0.4527\n",
            "Epoch 31: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 31: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 31: accuracy did not improve from 0.64062\n",
            " 51/121 [===========>..................] - ETA: 0s - loss: 2.6632 - accuracy: 0.4498\n",
            "Epoch 31: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 31: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 31: accuracy did not improve from 0.64062\n",
            " 68/121 [===============>..............] - ETA: 0s - loss: 2.6643 - accuracy: 0.4504\n",
            "Epoch 31: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 31: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 31: accuracy did not improve from 0.64062\n",
            " 84/121 [===================>..........] - ETA: 0s - loss: 2.6465 - accuracy: 0.4479\n",
            "Epoch 31: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 31: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 31: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 31: accuracy did not improve from 0.64062\n",
            "101/121 [========================>.....] - ETA: 0s - loss: 2.6592 - accuracy: 0.4459\n",
            "Epoch 31: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 31: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 31: accuracy did not improve from 0.64062\n",
            "119/121 [============================>.] - ETA: 0s - loss: 2.6658 - accuracy: 0.4428\n",
            "Epoch 31: accuracy did not improve from 0.64062\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.6613 - accuracy: 0.4431\n",
            "Epoch 32/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.6734 - accuracy: 0.4375\n",
            "Epoch 32: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 32: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 32: accuracy did not improve from 0.64062\n",
            " 18/121 [===>..........................] - ETA: 0s - loss: 2.6894 - accuracy: 0.4427\n",
            "Epoch 32: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 32: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 32: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 32: accuracy did not improve from 0.64062\n",
            " 34/121 [=======>......................] - ETA: 0s - loss: 2.6863 - accuracy: 0.4329\n",
            "Epoch 32: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 32: accuracy did not improve from 0.64062\n",
            " 48/121 [==========>...................] - ETA: 0s - loss: 2.7234 - accuracy: 0.4264\n",
            "Epoch 32: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 32: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 32: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 32: accuracy did not improve from 0.64062\n",
            " 66/121 [===============>..............] - ETA: 0s - loss: 2.7036 - accuracy: 0.4366\n",
            "Epoch 32: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 32: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 32: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 32: accuracy did not improve from 0.64062\n",
            " 85/121 [====================>.........] - ETA: 0s - loss: 2.7038 - accuracy: 0.4360\n",
            "Epoch 32: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 32: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 32: accuracy did not improve from 0.64062\n",
            "100/121 [=======================>......] - ETA: 0s - loss: 2.6575 - accuracy: 0.4425\n",
            "Epoch 32: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 32: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 32: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 32: accuracy did not improve from 0.64062\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.6607 - accuracy: 0.4441\n",
            "Epoch 33/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.5801 - accuracy: 0.4375\n",
            "Epoch 33: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 33: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 33: accuracy did not improve from 0.64062\n",
            " 16/121 [==>...........................] - ETA: 0s - loss: 2.6307 - accuracy: 0.4258\n",
            "Epoch 33: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 33: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 33: accuracy did not improve from 0.64062\n",
            " 32/121 [======>.......................] - ETA: 0s - loss: 2.6602 - accuracy: 0.4375\n",
            "Epoch 33: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 33: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 33: accuracy did not improve from 0.64062\n",
            " 45/121 [==========>...................] - ETA: 0s - loss: 2.6938 - accuracy: 0.4424\n",
            "Epoch 33: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 33: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 33: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 33: accuracy did not improve from 0.64062\n",
            " 63/121 [==============>...............] - ETA: 0s - loss: 2.7006 - accuracy: 0.4400\n",
            "Epoch 33: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 33: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 33: accuracy did not improve from 0.64062\n",
            " 82/121 [===================>..........] - ETA: 0s - loss: 2.6291 - accuracy: 0.4482\n",
            "Epoch 33: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 33: accuracy did not improve from 0.64062\n",
            " 91/121 [=====================>........] - ETA: 0s - loss: 2.6470 - accuracy: 0.4444\n",
            "Epoch 33: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 33: accuracy did not improve from 0.64062\n",
            " 99/121 [=======================>......] - ETA: 0s - loss: 2.6815 - accuracy: 0.4422\n",
            "Epoch 33: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 33: accuracy did not improve from 0.64062\n",
            "108/121 [=========================>....] - ETA: 0s - loss: 2.6710 - accuracy: 0.4413\n",
            "Epoch 33: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 33: accuracy did not improve from 0.64062\n",
            "121/121 [==============================] - 1s 5ms/step - loss: 2.6602 - accuracy: 0.4446\n",
            "Epoch 34/100\n",
            "  1/121 [..............................] - ETA: 2s - loss: 2.4879 - accuracy: 0.3750\n",
            "Epoch 34: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 34: accuracy did not improve from 0.64062\n",
            " 10/121 [=>............................] - ETA: 0s - loss: 2.7454 - accuracy: 0.4437\n",
            "Epoch 34: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 34: accuracy did not improve from 0.64062\n",
            " 19/121 [===>..........................] - ETA: 0s - loss: 2.6949 - accuracy: 0.4539\n",
            "Epoch 34: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 34: accuracy did not improve from 0.64062\n",
            " 28/121 [=====>........................] - ETA: 0s - loss: 2.7222 - accuracy: 0.4487\n",
            "Epoch 34: accuracy did not improve from 0.64062\n",
            " 35/121 [=======>......................] - ETA: 0s - loss: 2.7304 - accuracy: 0.4429\n",
            "Epoch 34: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 34: accuracy did not improve from 0.64062\n",
            " 43/121 [=========>....................] - ETA: 0s - loss: 2.7503 - accuracy: 0.4397\n",
            "Epoch 34: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 34: accuracy did not improve from 0.64062\n",
            " 53/121 [============>.................] - ETA: 0s - loss: 2.6669 - accuracy: 0.4463\n",
            "Epoch 34: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 34: accuracy did not improve from 0.64062\n",
            " 66/121 [===============>..............] - ETA: 0s - loss: 2.6831 - accuracy: 0.4432\n",
            "Epoch 34: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 34: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 34: accuracy did not improve from 0.64062\n",
            " 77/121 [==================>...........] - ETA: 0s - loss: 2.6571 - accuracy: 0.4452\n",
            "Epoch 34: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 34: accuracy did not improve from 0.64062\n",
            " 88/121 [====================>.........] - ETA: 0s - loss: 2.6636 - accuracy: 0.4471\n",
            "Epoch 34: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 34: accuracy did not improve from 0.64062\n",
            "101/121 [========================>.....] - ETA: 0s - loss: 2.6582 - accuracy: 0.4465\n",
            "Epoch 34: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 34: accuracy did not improve from 0.64062\n",
            "111/121 [==========================>...] - ETA: 0s - loss: 2.6716 - accuracy: 0.4445\n",
            "Epoch 34: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 34: accuracy did not improve from 0.64062\n",
            "121/121 [==============================] - 1s 5ms/step - loss: 2.6597 - accuracy: 0.4459\n",
            "Epoch 35/100\n",
            "\n",
            "Epoch 35: accuracy did not improve from 0.64062\n",
            "  1/121 [..............................] - ETA: 1s - loss: 3.1585 - accuracy: 0.2812\n",
            "Epoch 35: accuracy did not improve from 0.64062\n",
            "  9/121 [=>............................] - ETA: 0s - loss: 2.7678 - accuracy: 0.4236\n",
            "Epoch 35: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 35: accuracy did not improve from 0.64062\n",
            " 19/121 [===>..........................] - ETA: 0s - loss: 2.5807 - accuracy: 0.4638\n",
            "Epoch 35: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 35: accuracy did not improve from 0.64062\n",
            " 26/121 [=====>........................] - ETA: 0s - loss: 2.5973 - accuracy: 0.4639\n",
            "Epoch 35: accuracy did not improve from 0.64062\n",
            " 34/121 [=======>......................] - ETA: 0s - loss: 2.6652 - accuracy: 0.4522\n",
            "Epoch 35: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 35: accuracy did not improve from 0.64062\n",
            " 41/121 [=========>....................] - ETA: 0s - loss: 2.6121 - accuracy: 0.4588\n",
            "Epoch 35: accuracy did not improve from 0.64062\n",
            " 49/121 [===========>..................] - ETA: 0s - loss: 2.5982 - accuracy: 0.4579\n",
            "Epoch 35: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 35: accuracy did not improve from 0.64062\n",
            " 56/121 [============>.................] - ETA: 0s - loss: 2.6412 - accuracy: 0.4515\n",
            "Epoch 35: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 35: accuracy did not improve from 0.64062\n",
            " 67/121 [===============>..............] - ETA: 0s - loss: 2.6834 - accuracy: 0.4473\n",
            "Epoch 35: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 35: accuracy did not improve from 0.64062\n",
            " 76/121 [=================>............] - ETA: 0s - loss: 2.6918 - accuracy: 0.4453\n",
            "Epoch 35: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 35: accuracy did not improve from 0.64062\n",
            " 88/121 [====================>.........] - ETA: 0s - loss: 2.6742 - accuracy: 0.4453\n",
            "Epoch 35: accuracy did not improve from 0.64062\n",
            " 95/121 [======================>.......] - ETA: 0s - loss: 2.6636 - accuracy: 0.4480\n",
            "Epoch 35: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 35: accuracy did not improve from 0.64062\n",
            "102/121 [========================>.....] - ETA: 0s - loss: 2.6789 - accuracy: 0.4498\n",
            "Epoch 35: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 35: accuracy did not improve from 0.64062\n",
            "115/121 [===========================>..] - ETA: 0s - loss: 2.6657 - accuracy: 0.4484\n",
            "Epoch 35: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 35: accuracy did not improve from 0.64062\n",
            "121/121 [==============================] - 1s 6ms/step - loss: 2.6593 - accuracy: 0.4470\n",
            "Epoch 36/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 3.6411 - accuracy: 0.3125\n",
            "Epoch 36: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 36: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 36: accuracy did not improve from 0.64062\n",
            " 15/121 [==>...........................] - ETA: 0s - loss: 2.7840 - accuracy: 0.4479\n",
            "Epoch 36: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 36: accuracy did not improve from 0.64062\n",
            " 27/121 [=====>........................] - ETA: 0s - loss: 2.6536 - accuracy: 0.4514\n",
            "Epoch 36: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 36: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 36: accuracy did not improve from 0.64062\n",
            " 40/121 [========>.....................] - ETA: 0s - loss: 2.6287 - accuracy: 0.4602\n",
            "Epoch 36: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 36: accuracy did not improve from 0.64062\n",
            " 51/121 [===========>..................] - ETA: 0s - loss: 2.6380 - accuracy: 0.4528\n",
            "Epoch 36: accuracy did not improve from 0.64062\n",
            " 59/121 [=============>................] - ETA: 0s - loss: 2.6470 - accuracy: 0.4502\n",
            "Epoch 36: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 36: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 36: accuracy did not improve from 0.64062\n",
            " 70/121 [================>.............] - ETA: 0s - loss: 2.6547 - accuracy: 0.4464\n",
            "Epoch 36: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 36: accuracy did not improve from 0.64062\n",
            " 81/121 [===================>..........] - ETA: 0s - loss: 2.6573 - accuracy: 0.4483\n",
            "Epoch 36: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 36: accuracy did not improve from 0.64062\n",
            " 90/121 [=====================>........] - ETA: 0s - loss: 2.6417 - accuracy: 0.4517\n",
            "Epoch 36: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 36: accuracy did not improve from 0.64062\n",
            "101/121 [========================>.....] - ETA: 0s - loss: 2.6632 - accuracy: 0.4465\n",
            "Epoch 36: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 36: accuracy did not improve from 0.64062\n",
            "111/121 [==========================>...] - ETA: 0s - loss: 2.6768 - accuracy: 0.4459\n",
            "Epoch 36: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 36: accuracy did not improve from 0.64062\n",
            "121/121 [==============================] - 1s 5ms/step - loss: 2.6588 - accuracy: 0.4504\n",
            "Epoch 37/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.3973 - accuracy: 0.4688\n",
            "Epoch 37: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 37: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 37: accuracy did not improve from 0.64062\n",
            " 14/121 [==>...........................] - ETA: 0s - loss: 2.8584 - accuracy: 0.4174\n",
            "Epoch 37: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 37: accuracy did not improve from 0.64062\n",
            " 24/121 [====>.........................] - ETA: 0s - loss: 2.8252 - accuracy: 0.4141\n",
            "Epoch 37: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 37: accuracy did not improve from 0.64062\n",
            " 36/121 [=======>......................] - ETA: 0s - loss: 2.6922 - accuracy: 0.4462\n",
            "Epoch 37: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 37: accuracy did not improve from 0.64062\n",
            " 45/121 [==========>...................] - ETA: 0s - loss: 2.7071 - accuracy: 0.4465\n",
            "Epoch 37: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 37: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 37: accuracy did not improve from 0.64062\n",
            " 59/121 [=============>................] - ETA: 0s - loss: 2.7090 - accuracy: 0.4481\n",
            "Epoch 37: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 37: accuracy did not improve from 0.64062\n",
            " 69/121 [================>.............] - ETA: 0s - loss: 2.6782 - accuracy: 0.4520\n",
            "Epoch 37: accuracy did not improve from 0.64062\n",
            " 77/121 [==================>...........] - ETA: 0s - loss: 2.7008 - accuracy: 0.4489\n",
            "Epoch 37: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 37: accuracy did not improve from 0.64062\n",
            " 84/121 [===================>..........] - ETA: 0s - loss: 2.7106 - accuracy: 0.4479\n",
            "Epoch 37: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 37: accuracy did not improve from 0.64062\n",
            " 97/121 [=======================>......] - ETA: 0s - loss: 2.7075 - accuracy: 0.4465\n",
            "Epoch 37: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 37: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 37: accuracy did not improve from 0.64062\n",
            "109/121 [==========================>...] - ETA: 0s - loss: 2.6702 - accuracy: 0.4530\n",
            "Epoch 37: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 37: accuracy did not improve from 0.64062\n",
            "121/121 [==============================] - 1s 5ms/step - loss: 2.6584 - accuracy: 0.4537\n",
            "Epoch 38/100\n",
            "  1/121 [..............................] - ETA: 1s - loss: 2.1049 - accuracy: 0.5625\n",
            "Epoch 38: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 38: accuracy did not improve from 0.64062\n",
            "  9/121 [=>............................] - ETA: 0s - loss: 2.7133 - accuracy: 0.4340\n",
            "Epoch 38: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 38: accuracy did not improve from 0.64062\n",
            " 18/121 [===>..........................] - ETA: 0s - loss: 2.7010 - accuracy: 0.4358\n",
            "Epoch 38: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 38: accuracy did not improve from 0.64062\n",
            " 30/121 [======>.......................] - ETA: 0s - loss: 2.6828 - accuracy: 0.4302\n",
            "Epoch 38: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 38: accuracy did not improve from 0.64062\n",
            " 41/121 [=========>....................] - ETA: 0s - loss: 2.5977 - accuracy: 0.4520\n",
            "Epoch 38: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 38: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 38: accuracy did not improve from 0.64062\n",
            " 53/121 [============>.................] - ETA: 0s - loss: 2.6546 - accuracy: 0.4499\n",
            "Epoch 38: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 38: accuracy did not improve from 0.64062\n",
            " 64/121 [==============>...............] - ETA: 0s - loss: 2.6441 - accuracy: 0.4531\n",
            "Epoch 38: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 38: accuracy did not improve from 0.64062\n",
            " 76/121 [=================>............] - ETA: 0s - loss: 2.6100 - accuracy: 0.4605\n",
            "Epoch 38: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 38: accuracy did not improve from 0.64062\n",
            " 83/121 [===================>..........] - ETA: 0s - loss: 2.6020 - accuracy: 0.4631\n",
            "Epoch 38: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 38: accuracy did not improve from 0.64062\n",
            " 97/121 [=======================>......] - ETA: 0s - loss: 2.6400 - accuracy: 0.4559\n",
            "Epoch 38: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 38: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 38: accuracy did not improve from 0.64062\n",
            "108/121 [=========================>....] - ETA: 0s - loss: 2.6619 - accuracy: 0.4528\n",
            "Epoch 38: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 38: accuracy did not improve from 0.64062\n",
            "121/121 [==============================] - 1s 5ms/step - loss: 2.6580 - accuracy: 0.4561\n",
            "Epoch 39/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.2988 - accuracy: 0.4688\n",
            "Epoch 39: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 39: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 39: accuracy did not improve from 0.64062\n",
            " 14/121 [==>...........................] - ETA: 0s - loss: 2.7888 - accuracy: 0.4554\n",
            "Epoch 39: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 39: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 39: accuracy did not improve from 0.64062\n",
            " 28/121 [=====>........................] - ETA: 0s - loss: 2.7690 - accuracy: 0.4576\n",
            "Epoch 39: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 39: accuracy did not improve from 0.64062\n",
            " 41/121 [=========>....................] - ETA: 0s - loss: 2.6706 - accuracy: 0.4741\n",
            "Epoch 39: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 39: accuracy did not improve from 0.64062\n",
            " 50/121 [===========>..................] - ETA: 0s - loss: 2.6721 - accuracy: 0.4688\n",
            "Epoch 39: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 39: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 39: accuracy did not improve from 0.64062\n",
            " 62/121 [==============>...............] - ETA: 0s - loss: 2.6967 - accuracy: 0.4617\n",
            "Epoch 39: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 39: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 39: accuracy did not improve from 0.64062\n",
            " 77/121 [==================>...........] - ETA: 0s - loss: 2.6997 - accuracy: 0.4554\n",
            "Epoch 39: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 39: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 39: accuracy did not improve from 0.64062\n",
            " 92/121 [=====================>........] - ETA: 0s - loss: 2.6933 - accuracy: 0.4558\n",
            "Epoch 39: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 39: accuracy did not improve from 0.64062\n",
            "103/121 [========================>.....] - ETA: 0s - loss: 2.6697 - accuracy: 0.4584\n",
            "Epoch 39: accuracy did not improve from 0.64062\n",
            "111/121 [==========================>...] - ETA: 0s - loss: 2.6593 - accuracy: 0.4578\n",
            "Epoch 39: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 39: accuracy did not improve from 0.64062\n",
            "121/121 [==============================] - 1s 5ms/step - loss: 2.6577 - accuracy: 0.4569\n",
            "Epoch 40/100\n",
            "\n",
            "Epoch 40: accuracy did not improve from 0.64062\n",
            "  1/121 [..............................] - ETA: 0s - loss: 3.9250 - accuracy: 0.1875\n",
            "Epoch 40: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 40: accuracy did not improve from 0.64062\n",
            " 12/121 [=>............................] - ETA: 0s - loss: 2.8142 - accuracy: 0.4297\n",
            "Epoch 40: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 40: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 40: accuracy did not improve from 0.64062\n",
            " 26/121 [=====>........................] - ETA: 0s - loss: 2.7129 - accuracy: 0.4447\n",
            "Epoch 40: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 40: accuracy did not improve from 0.64062\n",
            " 37/121 [========>.....................] - ETA: 0s - loss: 2.7436 - accuracy: 0.4468\n",
            "Epoch 40: accuracy did not improve from 0.64062\n",
            " 44/121 [=========>....................] - ETA: 0s - loss: 2.7399 - accuracy: 0.4482\n",
            "Epoch 40: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 40: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 40: accuracy did not improve from 0.64062\n",
            " 56/121 [============>.................] - ETA: 0s - loss: 2.6998 - accuracy: 0.4520\n",
            "Epoch 40: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 40: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 40: accuracy did not improve from 0.64062\n",
            " 72/121 [================>.............] - ETA: 0s - loss: 2.6728 - accuracy: 0.4531\n",
            "Epoch 40: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 40: accuracy did not improve from 0.64062\n",
            " 83/121 [===================>..........] - ETA: 0s - loss: 2.6795 - accuracy: 0.4552\n",
            "Epoch 40: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 40: accuracy did not improve from 0.64062\n",
            " 95/121 [======================>.......] - ETA: 0s - loss: 2.6383 - accuracy: 0.4586\n",
            "Epoch 40: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 40: accuracy did not improve from 0.64062\n",
            "104/121 [========================>.....] - ETA: 0s - loss: 2.6546 - accuracy: 0.4582\n",
            "Epoch 40: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 40: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 40: accuracy did not improve from 0.64062\n",
            "119/121 [============================>.] - ETA: 0s - loss: 2.6563 - accuracy: 0.4588\n",
            "Epoch 40: accuracy did not improve from 0.64062\n",
            "121/121 [==============================] - 1s 5ms/step - loss: 2.6573 - accuracy: 0.4579\n",
            "Epoch 41/100\n",
            "  1/121 [..............................] - ETA: 1s - loss: 2.3002 - accuracy: 0.5312\n",
            "Epoch 41: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 41: accuracy did not improve from 0.64062\n",
            " 14/121 [==>...........................] - ETA: 0s - loss: 2.6912 - accuracy: 0.4621\n",
            "Epoch 41: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 41: accuracy did not improve from 0.64062\n",
            " 22/121 [====>.........................] - ETA: 0s - loss: 2.6747 - accuracy: 0.4616\n",
            "Epoch 41: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 41: accuracy did not improve from 0.64062\n",
            " 33/121 [=======>......................] - ETA: 0s - loss: 2.7110 - accuracy: 0.4555\n",
            "Epoch 41: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 41: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 41: accuracy did not improve from 0.64062\n",
            " 45/121 [==========>...................] - ETA: 0s - loss: 2.6768 - accuracy: 0.4597\n",
            "Epoch 41: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 41: accuracy did not improve from 0.64062\n",
            " 57/121 [=============>................] - ETA: 0s - loss: 2.6908 - accuracy: 0.4572\n",
            "Epoch 41: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 41: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 41: accuracy did not improve from 0.64062\n",
            " 70/121 [================>.............] - ETA: 0s - loss: 2.7054 - accuracy: 0.4527\n",
            "Epoch 41: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 41: accuracy did not improve from 0.64062\n",
            " 83/121 [===================>..........] - ETA: 0s - loss: 2.6806 - accuracy: 0.4575\n",
            "Epoch 41: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 41: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 41: accuracy did not improve from 0.64062\n",
            " 95/121 [======================>.......] - ETA: 0s - loss: 2.6854 - accuracy: 0.4559\n",
            "Epoch 41: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 41: accuracy did not improve from 0.64062\n",
            "106/121 [=========================>....] - ETA: 0s - loss: 2.6883 - accuracy: 0.4578\n",
            "Epoch 41: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 41: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 41: accuracy did not improve from 0.64062\n",
            "121/121 [==============================] - 1s 5ms/step - loss: 2.6570 - accuracy: 0.4602\n",
            "Epoch 42/100\n",
            "  1/121 [..............................] - ETA: 1s - loss: 2.6785 - accuracy: 0.3125\n",
            "Epoch 42: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 42: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 42: accuracy did not improve from 0.64062\n",
            " 15/121 [==>...........................] - ETA: 0s - loss: 2.7117 - accuracy: 0.4187\n",
            "Epoch 42: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 42: accuracy did not improve from 0.64062\n",
            " 24/121 [====>.........................] - ETA: 0s - loss: 2.6035 - accuracy: 0.4557\n",
            "Epoch 42: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 42: accuracy did not improve from 0.64062\n",
            " 37/121 [========>.....................] - ETA: 0s - loss: 2.5292 - accuracy: 0.4688\n",
            "Epoch 42: accuracy did not improve from 0.64062\n",
            " 43/121 [=========>....................] - ETA: 0s - loss: 2.5946 - accuracy: 0.4571\n",
            "Epoch 42: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 42: accuracy did not improve from 0.64062\n",
            " 53/121 [============>.................] - ETA: 0s - loss: 2.5961 - accuracy: 0.4575\n",
            "Epoch 42: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 42: accuracy did not improve from 0.64062\n",
            " 62/121 [==============>...............] - ETA: 0s - loss: 2.6264 - accuracy: 0.4556\n",
            "Epoch 42: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 42: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 42: accuracy did not improve from 0.64062\n",
            " 74/121 [=================>............] - ETA: 0s - loss: 2.6286 - accuracy: 0.4590\n",
            "Epoch 42: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 42: accuracy did not improve from 0.64062\n",
            " 87/121 [====================>.........] - ETA: 0s - loss: 2.6164 - accuracy: 0.4637\n",
            "Epoch 42: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 42: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 42: accuracy did not improve from 0.64062\n",
            " 99/121 [=======================>......] - ETA: 0s - loss: 2.6259 - accuracy: 0.4602\n",
            "Epoch 42: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 42: accuracy did not improve from 0.64062\n",
            "113/121 [===========================>..] - ETA: 0s - loss: 2.6552 - accuracy: 0.4593\n",
            "Epoch 42: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 42: accuracy did not improve from 0.64062\n",
            "121/121 [==============================] - 1s 5ms/step - loss: 2.6567 - accuracy: 0.4615\n",
            "Epoch 43/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.2971 - accuracy: 0.5625\n",
            "Epoch 43: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 43: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 43: accuracy did not improve from 0.64062\n",
            " 17/121 [===>..........................] - ETA: 0s - loss: 2.5839 - accuracy: 0.4596\n",
            "Epoch 43: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 43: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 43: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 43: accuracy did not improve from 0.64062\n",
            " 33/121 [=======>......................] - ETA: 0s - loss: 2.6530 - accuracy: 0.4489\n",
            "Epoch 43: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 43: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 43: accuracy did not improve from 0.64062\n",
            " 49/121 [===========>..................] - ETA: 0s - loss: 2.6439 - accuracy: 0.4547\n",
            "Epoch 43: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 43: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 43: accuracy did not improve from 0.64062\n",
            " 67/121 [===============>..............] - ETA: 0s - loss: 2.6688 - accuracy: 0.4557\n",
            "Epoch 43: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 43: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 43: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 43: accuracy did not improve from 0.64062\n",
            " 87/121 [====================>.........] - ETA: 0s - loss: 2.6932 - accuracy: 0.4612\n",
            "Epoch 43: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 43: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 43: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 43: accuracy did not improve from 0.64062\n",
            "107/121 [=========================>....] - ETA: 0s - loss: 2.6367 - accuracy: 0.4652\n",
            "Epoch 43: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 43: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 43: accuracy did not improve from 0.64062\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.6558 - accuracy: 0.4631\n",
            "Epoch 44/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 3.8283 - accuracy: 0.2812\n",
            "Epoch 44: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 44: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 44: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 44: accuracy did not improve from 0.64062\n",
            " 19/121 [===>..........................] - ETA: 0s - loss: 2.7484 - accuracy: 0.4572\n",
            "Epoch 44: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 44: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 44: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 44: accuracy did not improve from 0.64062\n",
            " 38/121 [========>.....................] - ETA: 0s - loss: 2.6527 - accuracy: 0.4762\n",
            "Epoch 44: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 44: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 44: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 44: accuracy did not improve from 0.64062\n",
            " 58/121 [=============>................] - ETA: 0s - loss: 2.6515 - accuracy: 0.4784\n",
            "Epoch 44: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 44: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 44: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 44: accuracy did not improve from 0.64062\n",
            " 79/121 [==================>...........] - ETA: 0s - loss: 2.6271 - accuracy: 0.4755\n",
            "Epoch 44: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 44: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 44: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 44: accuracy did not improve from 0.64062\n",
            " 98/121 [=======================>......] - ETA: 0s - loss: 2.6645 - accuracy: 0.4672\n",
            "Epoch 44: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 44: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 44: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 44: accuracy did not improve from 0.64062\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.6554 - accuracy: 0.4660\n",
            "Epoch 45/100\n",
            "\n",
            "Epoch 45: accuracy did not improve from 0.64062\n",
            "  1/121 [..............................] - ETA: 1s - loss: 2.3937 - accuracy: 0.4688\n",
            "Epoch 45: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 45: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 45: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 45: accuracy did not improve from 0.64062\n",
            " 21/121 [====>.........................] - ETA: 0s - loss: 2.6281 - accuracy: 0.4717\n",
            "Epoch 45: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 45: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 45: accuracy did not improve from 0.64062\n",
            " 40/121 [========>.....................] - ETA: 0s - loss: 2.6373 - accuracy: 0.4711\n",
            "Epoch 45: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 45: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 45: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 45: accuracy did not improve from 0.64062\n",
            " 58/121 [=============>................] - ETA: 0s - loss: 2.6422 - accuracy: 0.4666\n",
            "Epoch 45: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 45: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 45: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 45: accuracy did not improve from 0.64062\n",
            " 76/121 [=================>............] - ETA: 0s - loss: 2.6831 - accuracy: 0.4576\n",
            "Epoch 45: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 45: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 45: accuracy did not improve from 0.64062\n",
            " 95/121 [======================>.......] - ETA: 0s - loss: 2.6723 - accuracy: 0.4638\n",
            "Epoch 45: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 45: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 45: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 45: accuracy did not improve from 0.64062\n",
            "112/121 [==========================>...] - ETA: 0s - loss: 2.6621 - accuracy: 0.4671\n",
            "Epoch 45: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 45: accuracy did not improve from 0.64062\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.6552 - accuracy: 0.4670\n",
            "Epoch 46/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.6752 - accuracy: 0.4688\n",
            "Epoch 46: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 46: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 46: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 46: accuracy did not improve from 0.64062\n",
            " 20/121 [===>..........................] - ETA: 0s - loss: 2.7835 - accuracy: 0.4453\n",
            "Epoch 46: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 46: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 46: accuracy did not improve from 0.64062\n",
            " 38/121 [========>.....................] - ETA: 0s - loss: 2.8093 - accuracy: 0.4367\n",
            "Epoch 46: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 46: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 46: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 46: accuracy did not improve from 0.64062\n",
            " 56/121 [============>.................] - ETA: 0s - loss: 2.6901 - accuracy: 0.4593\n",
            "Epoch 46: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 46: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 46: accuracy did not improve from 0.64062\n",
            " 72/121 [================>.............] - ETA: 0s - loss: 2.6675 - accuracy: 0.4622\n",
            "Epoch 46: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 46: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 46: accuracy did not improve from 0.64062\n",
            " 89/121 [=====================>........] - ETA: 0s - loss: 2.6514 - accuracy: 0.4617\n",
            "Epoch 46: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 46: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 46: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 46: accuracy did not improve from 0.64062\n",
            "107/121 [=========================>....] - ETA: 0s - loss: 2.6416 - accuracy: 0.4650\n",
            "Epoch 46: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 46: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 46: accuracy did not improve from 0.64062\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.6550 - accuracy: 0.4688\n",
            "Epoch 47/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.7721 - accuracy: 0.5312\n",
            "Epoch 47: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 47: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 47: accuracy did not improve from 0.64062\n",
            " 16/121 [==>...........................] - ETA: 0s - loss: 2.5106 - accuracy: 0.4961\n",
            "Epoch 47: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 47: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 47: accuracy did not improve from 0.64062\n",
            " 32/121 [======>.......................] - ETA: 0s - loss: 2.5910 - accuracy: 0.4824\n",
            "Epoch 47: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 47: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 47: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 47: accuracy did not improve from 0.64062\n",
            " 50/121 [===========>..................] - ETA: 0s - loss: 2.6072 - accuracy: 0.4725\n",
            "Epoch 47: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 47: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 47: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 47: accuracy did not improve from 0.64062\n",
            " 70/121 [================>.............] - ETA: 0s - loss: 2.5904 - accuracy: 0.4763\n",
            "Epoch 47: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 47: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 47: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 47: accuracy did not improve from 0.64062\n",
            " 89/121 [=====================>........] - ETA: 0s - loss: 2.5931 - accuracy: 0.4733\n",
            "Epoch 47: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 47: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 47: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 47: accuracy did not improve from 0.64062\n",
            "109/121 [==========================>...] - ETA: 0s - loss: 2.6342 - accuracy: 0.4702\n",
            "Epoch 47: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 47: accuracy did not improve from 0.64062\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.6549 - accuracy: 0.4688\n",
            "Epoch 48/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 3.0607 - accuracy: 0.4062\n",
            "Epoch 48: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 48: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 48: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 48: accuracy did not improve from 0.64062\n",
            " 18/121 [===>..........................] - ETA: 0s - loss: 2.6625 - accuracy: 0.4705\n",
            "Epoch 48: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 48: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 48: accuracy did not improve from 0.64062\n",
            " 37/121 [========>.....................] - ETA: 0s - loss: 2.5832 - accuracy: 0.4780\n",
            "Epoch 48: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 48: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 48: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 48: accuracy did not improve from 0.64062\n",
            " 55/121 [============>.................] - ETA: 0s - loss: 2.6383 - accuracy: 0.4727\n",
            "Epoch 48: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 48: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 48: accuracy did not improve from 0.64062\n",
            " 69/121 [================>.............] - ETA: 0s - loss: 2.6134 - accuracy: 0.4783\n",
            "Epoch 48: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 48: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 48: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 48: accuracy did not improve from 0.64062\n",
            " 88/121 [====================>.........] - ETA: 0s - loss: 2.6228 - accuracy: 0.4751\n",
            "Epoch 48: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 48: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 48: accuracy did not improve from 0.64062\n",
            "105/121 [=========================>....] - ETA: 0s - loss: 2.6117 - accuracy: 0.4759\n",
            "Epoch 48: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 48: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 48: accuracy did not improve from 0.64062\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.6548 - accuracy: 0.4704\n",
            "Epoch 49/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.0123 - accuracy: 0.5938\n",
            "Epoch 49: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 49: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 49: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 49: accuracy did not improve from 0.64062\n",
            " 18/121 [===>..........................] - ETA: 0s - loss: 2.5872 - accuracy: 0.4792\n",
            "Epoch 49: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 49: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 49: accuracy did not improve from 0.64062\n",
            " 36/121 [=======>......................] - ETA: 0s - loss: 2.5986 - accuracy: 0.4722\n",
            "Epoch 49: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 49: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 49: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 49: accuracy did not improve from 0.64062\n",
            " 52/121 [===========>..................] - ETA: 0s - loss: 2.5990 - accuracy: 0.4748\n",
            "Epoch 49: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 49: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 49: accuracy did not improve from 0.64062\n",
            " 67/121 [===============>..............] - ETA: 0s - loss: 2.6234 - accuracy: 0.4688\n",
            "Epoch 49: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 49: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 49: accuracy did not improve from 0.64062\n",
            " 86/121 [====================>.........] - ETA: 0s - loss: 2.6655 - accuracy: 0.4709\n",
            "Epoch 49: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 49: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 49: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 49: accuracy did not improve from 0.64062\n",
            "102/121 [========================>.....] - ETA: 0s - loss: 2.6666 - accuracy: 0.4709\n",
            "Epoch 49: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 49: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 49: accuracy did not improve from 0.64062\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.6548 - accuracy: 0.4712\n",
            "Epoch 50/100\n",
            "\n",
            "Epoch 50: accuracy did not improve from 0.64062\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.2918 - accuracy: 0.5938\n",
            "Epoch 50: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 50: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 50: accuracy did not improve from 0.64062\n",
            " 20/121 [===>..........................] - ETA: 0s - loss: 2.6814 - accuracy: 0.4641\n",
            "Epoch 50: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 50: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 50: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 50: accuracy did not improve from 0.64062\n",
            " 39/121 [========>.....................] - ETA: 0s - loss: 2.5794 - accuracy: 0.4856\n",
            "Epoch 50: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 50: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 50: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 50: accuracy did not improve from 0.64062\n",
            " 56/121 [============>.................] - ETA: 0s - loss: 2.6638 - accuracy: 0.4682\n",
            "Epoch 50: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 50: accuracy did not improve from 0.64062\n",
            " 69/121 [================>.............] - ETA: 0s - loss: 2.6707 - accuracy: 0.4656\n",
            "Epoch 50: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 50: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 50: accuracy did not improve from 0.64062\n",
            " 85/121 [====================>.........] - ETA: 0s - loss: 2.6600 - accuracy: 0.4665\n",
            "Epoch 50: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 50: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 50: accuracy did not improve from 0.64062\n",
            "100/121 [=======================>......] - ETA: 0s - loss: 2.6349 - accuracy: 0.4731\n",
            "Epoch 50: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 50: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 50: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 50: accuracy did not improve from 0.64062\n",
            "116/121 [===========================>..] - ETA: 0s - loss: 2.6464 - accuracy: 0.4725\n",
            "Epoch 50: accuracy did not improve from 0.64062\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.6547 - accuracy: 0.4719\n",
            "Epoch 51/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.2940 - accuracy: 0.4688\n",
            "Epoch 51: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 51: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 51: accuracy did not improve from 0.64062\n",
            " 18/121 [===>..........................] - ETA: 0s - loss: 2.6993 - accuracy: 0.4688\n",
            "Epoch 51: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 51: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 51: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 51: accuracy did not improve from 0.64062\n",
            " 35/121 [=======>......................] - ETA: 0s - loss: 2.6639 - accuracy: 0.4670\n",
            "Epoch 51: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 51: accuracy did not improve from 0.64062\n",
            " 48/121 [==========>...................] - ETA: 0s - loss: 2.6539 - accuracy: 0.4681\n",
            "Epoch 51: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 51: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 51: accuracy did not improve from 0.64062\n",
            " 62/121 [==============>...............] - ETA: 0s - loss: 2.6765 - accuracy: 0.4642\n",
            "Epoch 51: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 51: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 51: accuracy did not improve from 0.64062\n",
            " 75/121 [=================>............] - ETA: 0s - loss: 2.6626 - accuracy: 0.4679\n",
            "Epoch 51: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 51: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 51: accuracy did not improve from 0.64062\n",
            " 93/121 [======================>.......] - ETA: 0s - loss: 2.6389 - accuracy: 0.4724\n",
            "Epoch 51: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 51: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 51: accuracy did not improve from 0.64062\n",
            "108/121 [=========================>....] - ETA: 0s - loss: 2.6442 - accuracy: 0.4708\n",
            "Epoch 51: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 51: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 51: accuracy did not improve from 0.64062\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.6547 - accuracy: 0.4722\n",
            "Epoch 52/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.3915 - accuracy: 0.5312\n",
            "Epoch 52: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 52: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 52: accuracy did not improve from 0.64062\n",
            " 16/121 [==>...........................] - ETA: 0s - loss: 2.6478 - accuracy: 0.4844\n",
            "Epoch 52: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 52: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 52: accuracy did not improve from 0.64062\n",
            " 30/121 [======>.......................] - ETA: 0s - loss: 2.6494 - accuracy: 0.4812\n",
            "Epoch 52: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 52: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 52: accuracy did not improve from 0.64062\n",
            " 44/121 [=========>....................] - ETA: 0s - loss: 2.5713 - accuracy: 0.4957\n",
            "Epoch 52: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 52: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 52: accuracy did not improve from 0.64062\n",
            " 59/121 [=============>................] - ETA: 0s - loss: 2.5707 - accuracy: 0.4910\n",
            "Epoch 52: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 52: accuracy did not improve from 0.64062\n",
            " 73/121 [=================>............] - ETA: 0s - loss: 2.6123 - accuracy: 0.4782\n",
            "Epoch 52: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 52: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 52: accuracy did not improve from 0.64062\n",
            " 87/121 [====================>.........] - ETA: 0s - loss: 2.6285 - accuracy: 0.4784\n",
            "Epoch 52: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 52: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 52: accuracy did not improve from 0.64062\n",
            " 99/121 [=======================>......] - ETA: 0s - loss: 2.6246 - accuracy: 0.4785\n",
            "Epoch 52: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 52: accuracy did not improve from 0.64062\n",
            "112/121 [==========================>...] - ETA: 0s - loss: 2.6419 - accuracy: 0.4749\n",
            "Epoch 52: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 52: accuracy did not improve from 0.64062\n",
            "121/121 [==============================] - 0s 4ms/step - loss: 2.6546 - accuracy: 0.4732\n",
            "Epoch 53/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.2009 - accuracy: 0.5312\n",
            "Epoch 53: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 53: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 53: accuracy did not improve from 0.64062\n",
            " 15/121 [==>...........................] - ETA: 0s - loss: 2.7595 - accuracy: 0.4542\n",
            "Epoch 53: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 53: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 53: accuracy did not improve from 0.64062\n",
            " 31/121 [======>.......................] - ETA: 0s - loss: 2.7294 - accuracy: 0.4577\n",
            "Epoch 53: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 53: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 53: accuracy did not improve from 0.64062\n",
            " 43/121 [=========>....................] - ETA: 0s - loss: 2.7775 - accuracy: 0.4491\n",
            "Epoch 53: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 53: accuracy did not improve from 0.64062\n",
            " 57/121 [=============>................] - ETA: 0s - loss: 2.7078 - accuracy: 0.4583\n",
            "Epoch 53: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 53: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 53: accuracy did not improve from 0.64062\n",
            " 72/121 [================>.............] - ETA: 0s - loss: 2.6762 - accuracy: 0.4688\n",
            "Epoch 53: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 53: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 53: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 53: accuracy did not improve from 0.64062\n",
            " 90/121 [=====================>........] - ETA: 0s - loss: 2.6404 - accuracy: 0.4753\n",
            "Epoch 53: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 53: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 53: accuracy did not improve from 0.64062\n",
            "106/121 [=========================>....] - ETA: 0s - loss: 2.6344 - accuracy: 0.4755\n",
            "Epoch 53: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 53: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 53: accuracy did not improve from 0.64062\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.6546 - accuracy: 0.4738\n",
            "Epoch 54/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.8658 - accuracy: 0.3125\n",
            "Epoch 54: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 54: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 54: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 54: accuracy did not improve from 0.64062\n",
            " 17/121 [===>..........................] - ETA: 0s - loss: 2.6147 - accuracy: 0.4724\n",
            "Epoch 54: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 54: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 54: accuracy did not improve from 0.64062\n",
            " 36/121 [=======>......................] - ETA: 0s - loss: 2.6325 - accuracy: 0.4783\n",
            "Epoch 54: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 54: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 54: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 54: accuracy did not improve from 0.64062\n",
            " 55/121 [============>.................] - ETA: 0s - loss: 2.6408 - accuracy: 0.4750\n",
            "Epoch 54: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 54: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 54: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 54: accuracy did not improve from 0.64062\n",
            " 73/121 [=================>............] - ETA: 0s - loss: 2.6423 - accuracy: 0.4756\n",
            "Epoch 54: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 54: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 54: accuracy did not improve from 0.64062\n",
            " 91/121 [=====================>........] - ETA: 0s - loss: 2.6681 - accuracy: 0.4698\n",
            "Epoch 54: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 54: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 54: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 54: accuracy did not improve from 0.64062\n",
            "110/121 [==========================>...] - ETA: 0s - loss: 2.6671 - accuracy: 0.4724\n",
            "Epoch 54: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 54: accuracy did not improve from 0.64062\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.6546 - accuracy: 0.4743\n",
            "Epoch 55/100\n",
            "\n",
            "Epoch 55: accuracy did not improve from 0.64062\n",
            "  1/121 [..............................] - ETA: 1s - loss: 2.9589 - accuracy: 0.5312\n",
            "Epoch 55: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 55: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 55: accuracy did not improve from 0.64062\n",
            " 16/121 [==>...........................] - ETA: 0s - loss: 2.7853 - accuracy: 0.4570\n",
            "Epoch 55: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 55: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 55: accuracy did not improve from 0.64062\n",
            " 34/121 [=======>......................] - ETA: 0s - loss: 2.7312 - accuracy: 0.4807\n",
            "Epoch 55: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 55: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 55: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 55: accuracy did not improve from 0.64062\n",
            " 53/121 [============>.................] - ETA: 0s - loss: 2.6340 - accuracy: 0.4870\n",
            "Epoch 55: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 55: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 55: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 55: accuracy did not improve from 0.64062\n",
            " 71/121 [================>.............] - ETA: 0s - loss: 2.6625 - accuracy: 0.4793\n",
            "Epoch 55: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 55: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 55: accuracy did not improve from 0.64062\n",
            " 87/121 [====================>.........] - ETA: 0s - loss: 2.6688 - accuracy: 0.4745\n",
            "Epoch 55: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 55: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 55: accuracy did not improve from 0.64062\n",
            "103/121 [========================>.....] - ETA: 0s - loss: 2.6303 - accuracy: 0.4824\n",
            "Epoch 55: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 55: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 55: accuracy did not improve from 0.64062\n",
            "118/121 [============================>.] - ETA: 0s - loss: 2.6565 - accuracy: 0.4740\n",
            "Epoch 55: accuracy did not improve from 0.64062\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.6546 - accuracy: 0.4743\n",
            "Epoch 56/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 3.2485 - accuracy: 0.3125\n",
            "Epoch 56: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 56: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 56: accuracy did not improve from 0.64062\n",
            " 19/121 [===>..........................] - ETA: 0s - loss: 2.6316 - accuracy: 0.4671\n",
            "Epoch 56: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 56: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 56: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 56: accuracy did not improve from 0.64062\n",
            " 36/121 [=======>......................] - ETA: 0s - loss: 2.6032 - accuracy: 0.4688\n",
            "Epoch 56: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 56: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 56: accuracy did not improve from 0.64062\n",
            " 50/121 [===========>..................] - ETA: 0s - loss: 2.6923 - accuracy: 0.4650\n",
            "Epoch 56: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 56: accuracy did not improve from 0.64062\n",
            " 61/121 [==============>...............] - ETA: 0s - loss: 2.6552 - accuracy: 0.4759\n",
            "Epoch 56: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 56: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 56: accuracy did not improve from 0.64062\n",
            " 75/121 [=================>............] - ETA: 0s - loss: 2.6249 - accuracy: 0.4796\n",
            "Epoch 56: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 56: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 56: accuracy did not improve from 0.64062\n",
            " 90/121 [=====================>........] - ETA: 0s - loss: 2.6317 - accuracy: 0.4792\n",
            "Epoch 56: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 56: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 56: accuracy did not improve from 0.64062\n",
            "105/121 [=========================>....] - ETA: 0s - loss: 2.6621 - accuracy: 0.4729\n",
            "Epoch 56: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 56: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 56: accuracy did not improve from 0.64062\n",
            "121/121 [==============================] - 0s 4ms/step - loss: 2.6545 - accuracy: 0.4748\n",
            "Epoch 57/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 3.7258 - accuracy: 0.3125\n",
            "Epoch 57: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 57: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 57: accuracy did not improve from 0.64062\n",
            " 14/121 [==>...........................] - ETA: 0s - loss: 2.5261 - accuracy: 0.4531\n",
            "Epoch 57: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 57: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 57: accuracy did not improve from 0.64062\n",
            " 29/121 [======>.......................] - ETA: 0s - loss: 2.6112 - accuracy: 0.4580\n",
            "Epoch 57: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 57: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 57: accuracy did not improve from 0.64062\n",
            " 45/121 [==========>...................] - ETA: 0s - loss: 2.7006 - accuracy: 0.4611\n",
            "Epoch 57: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 57: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 57: accuracy did not improve from 0.64062\n",
            " 59/121 [=============>................] - ETA: 0s - loss: 2.7291 - accuracy: 0.4539\n",
            "Epoch 57: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 57: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 57: accuracy did not improve from 0.64062\n",
            " 76/121 [=================>............] - ETA: 0s - loss: 2.6612 - accuracy: 0.4667\n",
            "Epoch 57: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 57: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 57: accuracy did not improve from 0.64062\n",
            " 93/121 [======================>.......] - ETA: 0s - loss: 2.6704 - accuracy: 0.4671\n",
            "Epoch 57: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 57: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 57: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 57: accuracy did not improve from 0.64062\n",
            "109/121 [==========================>...] - ETA: 0s - loss: 2.6565 - accuracy: 0.4733\n",
            "Epoch 57: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 57: accuracy did not improve from 0.64062\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.6545 - accuracy: 0.4753\n",
            "Epoch 58/100\n",
            "  1/121 [..............................] - ETA: 1s - loss: 2.2952 - accuracy: 0.5000\n",
            "Epoch 58: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 58: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 58: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 58: accuracy did not improve from 0.64062\n",
            " 18/121 [===>..........................] - ETA: 0s - loss: 2.6196 - accuracy: 0.4792\n",
            "Epoch 58: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 58: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 58: accuracy did not improve from 0.64062\n",
            " 35/121 [=======>......................] - ETA: 0s - loss: 2.6072 - accuracy: 0.4723\n",
            "Epoch 58: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 58: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 58: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 58: accuracy did not improve from 0.64062\n",
            " 56/121 [============>.................] - ETA: 0s - loss: 2.6504 - accuracy: 0.4788\n",
            "Epoch 58: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 58: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 58: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 58: accuracy did not improve from 0.64062\n",
            " 75/121 [=================>............] - ETA: 0s - loss: 2.6661 - accuracy: 0.4733\n",
            "Epoch 58: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 58: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 58: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 58: accuracy did not improve from 0.64062\n",
            " 96/121 [======================>.......] - ETA: 0s - loss: 2.6776 - accuracy: 0.4704\n",
            "Epoch 58: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 58: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 58: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 58: accuracy did not improve from 0.64062\n",
            "117/121 [============================>.] - ETA: 0s - loss: 2.6604 - accuracy: 0.4746\n",
            "Epoch 58: accuracy did not improve from 0.64062\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.6545 - accuracy: 0.4758\n",
            "Epoch 59/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.3871 - accuracy: 0.5625\n",
            "Epoch 59: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 59: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 59: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 59: accuracy did not improve from 0.64062\n",
            " 21/121 [====>.........................] - ETA: 0s - loss: 2.5272 - accuracy: 0.4940\n",
            "Epoch 59: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 59: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 59: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 59: accuracy did not improve from 0.64062\n",
            " 39/121 [========>.....................] - ETA: 0s - loss: 2.5619 - accuracy: 0.4816\n",
            "Epoch 59: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 59: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 59: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 59: accuracy did not improve from 0.64062\n",
            " 57/121 [=============>................] - ETA: 0s - loss: 2.6007 - accuracy: 0.4688\n",
            "Epoch 59: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 59: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 59: accuracy did not improve from 0.64062\n",
            " 73/121 [=================>............] - ETA: 0s - loss: 2.6400 - accuracy: 0.4700\n",
            "Epoch 59: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 59: accuracy did not improve from 0.64062\n",
            " 85/121 [====================>.........] - ETA: 0s - loss: 2.6497 - accuracy: 0.4717\n",
            "Epoch 59: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 59: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 59: accuracy did not improve from 0.64062\n",
            "101/121 [========================>.....] - ETA: 0s - loss: 2.6520 - accuracy: 0.4746\n",
            "Epoch 59: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 59: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 59: accuracy did not improve from 0.64062\n",
            "116/121 [===========================>..] - ETA: 0s - loss: 2.6447 - accuracy: 0.4758\n",
            "Epoch 59: accuracy did not improve from 0.64062\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.6545 - accuracy: 0.4764\n",
            "Epoch 60/100\n",
            "\n",
            "Epoch 60: accuracy did not improve from 0.64062\n",
            "  1/121 [..............................] - ETA: 0s - loss: 3.2558 - accuracy: 0.3750\n",
            "Epoch 60: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 60: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 60: accuracy did not improve from 0.64062\n",
            " 16/121 [==>...........................] - ETA: 0s - loss: 2.6171 - accuracy: 0.4727\n",
            "Epoch 60: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 60: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 60: accuracy did not improve from 0.64062\n",
            " 32/121 [======>.......................] - ETA: 0s - loss: 2.6711 - accuracy: 0.4678\n",
            "Epoch 60: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 60: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 60: accuracy did not improve from 0.64062\n",
            " 47/121 [==========>...................] - ETA: 0s - loss: 2.6223 - accuracy: 0.4781\n",
            "Epoch 60: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 60: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 60: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 60: accuracy did not improve from 0.64062\n",
            " 67/121 [===============>..............] - ETA: 0s - loss: 2.6446 - accuracy: 0.4767\n",
            "Epoch 60: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 60: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 60: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 60: accuracy did not improve from 0.64062\n",
            " 90/121 [=====================>........] - ETA: 0s - loss: 2.6330 - accuracy: 0.4792\n",
            "Epoch 60: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 60: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 60: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 60: accuracy did not improve from 0.64062\n",
            "110/121 [==========================>...] - ETA: 0s - loss: 2.6429 - accuracy: 0.4795\n",
            "Epoch 60: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 60: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 60: accuracy did not improve from 0.64062\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.6545 - accuracy: 0.4766\n",
            "Epoch 61/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 1.7287 - accuracy: 0.6250\n",
            "Epoch 61: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 61: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 61: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 61: accuracy did not improve from 0.64062\n",
            " 21/121 [====>.........................] - ETA: 0s - loss: 2.6190 - accuracy: 0.4792\n",
            "Epoch 61: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 61: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 61: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 61: accuracy did not improve from 0.64062\n",
            " 43/121 [=========>....................] - ETA: 0s - loss: 2.6066 - accuracy: 0.4847\n",
            "Epoch 61: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 61: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 61: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 61: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 61: accuracy did not improve from 0.64062\n",
            " 65/121 [===============>..............] - ETA: 0s - loss: 2.6318 - accuracy: 0.4764\n",
            "Epoch 61: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 61: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 61: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 61: accuracy did not improve from 0.64062\n",
            " 86/121 [====================>.........] - ETA: 0s - loss: 2.6597 - accuracy: 0.4720\n",
            "Epoch 61: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 61: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 61: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 61: accuracy did not improve from 0.64062\n",
            "105/121 [=========================>....] - ETA: 0s - loss: 2.6363 - accuracy: 0.4774\n",
            "Epoch 61: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 61: accuracy did not improve from 0.64062\n",
            "117/121 [============================>.] - ETA: 0s - loss: 2.6546 - accuracy: 0.4765\n",
            "Epoch 61: accuracy did not improve from 0.64062\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.6545 - accuracy: 0.4771\n",
            "Epoch 62/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.2995 - accuracy: 0.5625\n",
            "Epoch 62: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 62: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 62: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 62: accuracy did not improve from 0.64062\n",
            " 22/121 [====>.........................] - ETA: 0s - loss: 2.8731 - accuracy: 0.4460\n",
            "Epoch 62: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 62: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 62: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 62: accuracy did not improve from 0.64062\n",
            " 39/121 [========>.....................] - ETA: 0s - loss: 2.7338 - accuracy: 0.4744\n",
            "Epoch 62: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 62: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 62: accuracy did not improve from 0.64062\n",
            " 54/121 [============>.................] - ETA: 0s - loss: 2.6562 - accuracy: 0.4855\n",
            "Epoch 62: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 62: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 62: accuracy did not improve from 0.64062\n",
            " 69/121 [================>.............] - ETA: 0s - loss: 2.6303 - accuracy: 0.4896\n",
            "Epoch 62: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 62: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 62: accuracy did not improve from 0.64062\n",
            " 87/121 [====================>.........] - ETA: 0s - loss: 2.6523 - accuracy: 0.4828\n",
            "Epoch 62: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 62: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 62: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 62: accuracy did not improve from 0.64062\n",
            "105/121 [=========================>....] - ETA: 0s - loss: 2.6449 - accuracy: 0.4795\n",
            "Epoch 62: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 62: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 62: accuracy did not improve from 0.64062\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.6545 - accuracy: 0.4777\n",
            "Epoch 63/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 3.3479 - accuracy: 0.3750\n",
            "Epoch 63: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 63: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 63: accuracy did not improve from 0.64062\n",
            " 14/121 [==>...........................] - ETA: 0s - loss: 2.7119 - accuracy: 0.4598\n",
            "Epoch 63: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 63: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 63: accuracy did not improve from 0.64062\n",
            " 28/121 [=====>........................] - ETA: 0s - loss: 2.7468 - accuracy: 0.4587\n",
            "Epoch 63: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 63: accuracy did not improve from 0.64062\n",
            " 41/121 [=========>....................] - ETA: 0s - loss: 2.6968 - accuracy: 0.4688\n",
            "Epoch 63: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 63: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 63: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 63: accuracy did not improve from 0.64062\n",
            " 58/121 [=============>................] - ETA: 0s - loss: 2.6681 - accuracy: 0.4693\n",
            "Epoch 63: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 63: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 63: accuracy did not improve from 0.64062\n",
            " 75/121 [=================>............] - ETA: 0s - loss: 2.6563 - accuracy: 0.4737\n",
            "Epoch 63: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 63: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 63: accuracy did not improve from 0.64062\n",
            " 88/121 [====================>.........] - ETA: 0s - loss: 2.6519 - accuracy: 0.4755\n",
            "Epoch 63: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 63: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 63: accuracy did not improve from 0.64062\n",
            "103/121 [========================>.....] - ETA: 0s - loss: 2.6611 - accuracy: 0.4718\n",
            "Epoch 63: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 63: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 63: accuracy did not improve from 0.64062\n",
            "121/121 [==============================] - 0s 4ms/step - loss: 2.6545 - accuracy: 0.4777\n",
            "Epoch 64/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 1.9116 - accuracy: 0.5625\n",
            "Epoch 64: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 64: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 64: accuracy did not improve from 0.64062\n",
            " 13/121 [==>...........................] - ETA: 0s - loss: 2.6328 - accuracy: 0.4784\n",
            "Epoch 64: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 64: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 64: accuracy did not improve from 0.64062\n",
            " 29/121 [======>.......................] - ETA: 0s - loss: 2.6222 - accuracy: 0.4838\n",
            "Epoch 64: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 64: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 64: accuracy did not improve from 0.64062\n",
            " 45/121 [==========>...................] - ETA: 0s - loss: 2.7140 - accuracy: 0.4785\n",
            "Epoch 64: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 64: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 64: accuracy did not improve from 0.64062\n",
            " 61/121 [==============>...............] - ETA: 0s - loss: 2.6917 - accuracy: 0.4759\n",
            "Epoch 64: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 64: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 64: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 64: accuracy did not improve from 0.64062\n",
            " 77/121 [==================>...........] - ETA: 0s - loss: 2.7050 - accuracy: 0.4716\n",
            "Epoch 64: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 64: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 64: accuracy did not improve from 0.64062\n",
            " 95/121 [======================>.......] - ETA: 0s - loss: 2.6867 - accuracy: 0.4740\n",
            "Epoch 64: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 64: accuracy did not improve from 0.64062\n",
            "106/121 [=========================>....] - ETA: 0s - loss: 2.6649 - accuracy: 0.4764\n",
            "Epoch 64: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 64: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 64: accuracy did not improve from 0.64062\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.6544 - accuracy: 0.4777\n",
            "Epoch 65/100\n",
            "\n",
            "Epoch 65: accuracy did not improve from 0.64062\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.8627 - accuracy: 0.4062\n",
            "Epoch 65: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 65: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 65: accuracy did not improve from 0.64062\n",
            " 16/121 [==>...........................] - ETA: 0s - loss: 2.5145 - accuracy: 0.5117\n",
            "Epoch 65: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 65: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 65: accuracy did not improve from 0.64062\n",
            " 31/121 [======>.......................] - ETA: 0s - loss: 2.6796 - accuracy: 0.4879\n",
            "Epoch 65: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 65: accuracy did not improve from 0.64062\n",
            " 41/121 [=========>....................] - ETA: 0s - loss: 2.6792 - accuracy: 0.4817\n",
            "Epoch 65: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 65: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 65: accuracy did not improve from 0.64062\n",
            " 57/121 [=============>................] - ETA: 0s - loss: 2.6705 - accuracy: 0.4781\n",
            "Epoch 65: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 65: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 65: accuracy did not improve from 0.64062\n",
            " 74/121 [=================>............] - ETA: 0s - loss: 2.6604 - accuracy: 0.4755\n",
            "Epoch 65: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 65: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 65: accuracy did not improve from 0.64062\n",
            " 88/121 [====================>.........] - ETA: 0s - loss: 2.6502 - accuracy: 0.4776\n",
            "Epoch 65: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 65: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 65: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 65: accuracy did not improve from 0.64062\n",
            "106/121 [=========================>....] - ETA: 0s - loss: 2.6503 - accuracy: 0.4770\n",
            "Epoch 65: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 65: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 65: accuracy did not improve from 0.64062\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.6544 - accuracy: 0.4779\n",
            "Epoch 66/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.0990 - accuracy: 0.5938\n",
            "Epoch 66: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 66: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 66: accuracy did not improve from 0.64062\n",
            " 15/121 [==>...........................] - ETA: 0s - loss: 2.6150 - accuracy: 0.4979\n",
            "Epoch 66: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 66: accuracy did not improve from 0.64062\n",
            " 29/121 [======>.......................] - ETA: 0s - loss: 2.6515 - accuracy: 0.4860\n",
            "Epoch 66: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 66: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 66: accuracy did not improve from 0.64062\n",
            " 42/121 [=========>....................] - ETA: 0s - loss: 2.5867 - accuracy: 0.4903\n",
            "Epoch 66: accuracy did not improve from 0.64062\n",
            " 46/121 [==========>...................] - ETA: 0s - loss: 2.6027 - accuracy: 0.4878\n",
            "Epoch 66: accuracy did not improve from 0.64062\n",
            " 52/121 [===========>..................] - ETA: 0s - loss: 2.5930 - accuracy: 0.4892\n",
            "Epoch 66: accuracy did not improve from 0.64062\n",
            " 57/121 [=============>................] - ETA: 0s - loss: 2.5905 - accuracy: 0.4896\n",
            "Epoch 66: accuracy did not improve from 0.64062\n",
            " 63/121 [==============>...............] - ETA: 0s - loss: 2.5623 - accuracy: 0.4936\n",
            "Epoch 66: accuracy did not improve from 0.64062\n",
            " 66/121 [===============>..............] - ETA: 0s - loss: 2.5804 - accuracy: 0.4901\n",
            "Epoch 66: accuracy did not improve from 0.64062\n",
            " 74/121 [=================>............] - ETA: 0s - loss: 2.5871 - accuracy: 0.4852\n",
            "Epoch 66: accuracy did not improve from 0.64062\n",
            " 78/121 [==================>...........] - ETA: 0s - loss: 2.5917 - accuracy: 0.4828\n",
            "Epoch 66: accuracy did not improve from 0.64062\n",
            " 82/121 [===================>..........] - ETA: 0s - loss: 2.5807 - accuracy: 0.4867\n",
            "Epoch 66: accuracy did not improve from 0.64062\n",
            " 88/121 [====================>.........] - ETA: 0s - loss: 2.6024 - accuracy: 0.4833\n",
            "Epoch 66: accuracy did not improve from 0.64062\n",
            " 94/121 [======================>.......] - ETA: 0s - loss: 2.6234 - accuracy: 0.4794\n",
            "Epoch 66: accuracy did not improve from 0.64062\n",
            " 98/121 [=======================>......] - ETA: 0s - loss: 2.6276 - accuracy: 0.4790\n",
            "Epoch 66: accuracy did not improve from 0.64062\n",
            "102/121 [========================>.....] - ETA: 0s - loss: 2.6259 - accuracy: 0.4807\n",
            "Epoch 66: accuracy did not improve from 0.64062\n",
            "107/121 [=========================>....] - ETA: 0s - loss: 2.6398 - accuracy: 0.4787\n",
            "Epoch 66: accuracy did not improve from 0.64062\n",
            "111/121 [==========================>...] - ETA: 0s - loss: 2.6317 - accuracy: 0.4806\n",
            "Epoch 66: accuracy did not improve from 0.64062\n",
            "115/121 [===========================>..] - ETA: 0s - loss: 2.6409 - accuracy: 0.4788\n",
            "Epoch 66: accuracy did not improve from 0.64062\n",
            "121/121 [==============================] - 1s 9ms/step - loss: 2.6544 - accuracy: 0.4782\n",
            "Epoch 67/100\n",
            "  1/121 [..............................] - ETA: 1s - loss: 2.7694 - accuracy: 0.4375\n",
            "Epoch 67: accuracy did not improve from 0.64062\n",
            "  4/121 [..............................] - ETA: 2s - loss: 2.7980 - accuracy: 0.4766\n",
            "Epoch 67: accuracy did not improve from 0.64062\n",
            "  9/121 [=>............................] - ETA: 1s - loss: 2.8054 - accuracy: 0.4340\n",
            "Epoch 67: accuracy did not improve from 0.64062\n",
            " 15/121 [==>...........................] - ETA: 1s - loss: 2.7924 - accuracy: 0.4333\n",
            "Epoch 67: accuracy did not improve from 0.64062\n",
            " 19/121 [===>..........................] - ETA: 1s - loss: 2.7583 - accuracy: 0.4457\n",
            "Epoch 67: accuracy did not improve from 0.64062\n",
            " 24/121 [====>.........................] - ETA: 1s - loss: 2.7538 - accuracy: 0.4518\n",
            "Epoch 67: accuracy did not improve from 0.64062\n",
            " 29/121 [======>.......................] - ETA: 1s - loss: 2.7207 - accuracy: 0.4601\n",
            "Epoch 67: accuracy did not improve from 0.64062\n",
            " 37/121 [========>.....................] - ETA: 0s - loss: 2.7529 - accuracy: 0.4552\n",
            "Epoch 67: accuracy did not improve from 0.64062\n",
            " 43/121 [=========>....................] - ETA: 0s - loss: 2.7311 - accuracy: 0.4629\n",
            "Epoch 67: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 67: accuracy did not improve from 0.64062\n",
            " 49/121 [===========>..................] - ETA: 0s - loss: 2.6639 - accuracy: 0.4713\n",
            "Epoch 67: accuracy did not improve from 0.64062\n",
            " 57/121 [=============>................] - ETA: 0s - loss: 2.6506 - accuracy: 0.4753\n",
            "Epoch 67: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 67: accuracy did not improve from 0.64062\n",
            " 64/121 [==============>...............] - ETA: 0s - loss: 2.6716 - accuracy: 0.4722\n",
            "Epoch 67: accuracy did not improve from 0.64062\n",
            " 69/121 [================>.............] - ETA: 0s - loss: 2.6776 - accuracy: 0.4688\n",
            "Epoch 67: accuracy did not improve from 0.64062\n",
            " 74/121 [=================>............] - ETA: 0s - loss: 2.6967 - accuracy: 0.4704\n",
            "Epoch 67: accuracy did not improve from 0.64062\n",
            " 81/121 [===================>..........] - ETA: 0s - loss: 2.6867 - accuracy: 0.4730\n",
            "Epoch 67: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 67: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 67: accuracy did not improve from 0.64062\n",
            " 95/121 [======================>.......] - ETA: 0s - loss: 2.6532 - accuracy: 0.4799\n",
            "Epoch 67: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 67: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 67: accuracy did not improve from 0.64062\n",
            "111/121 [==========================>...] - ETA: 0s - loss: 2.6576 - accuracy: 0.4797\n",
            "Epoch 67: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 67: accuracy did not improve from 0.64062\n",
            "121/121 [==============================] - 1s 8ms/step - loss: 2.6544 - accuracy: 0.4782\n",
            "Epoch 68/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 1.9105 - accuracy: 0.6250\n",
            "Epoch 68: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 68: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 68: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 68: accuracy did not improve from 0.64062\n",
            " 19/121 [===>..........................] - ETA: 0s - loss: 2.6263 - accuracy: 0.4803\n",
            "Epoch 68: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 68: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 68: accuracy did not improve from 0.64062\n",
            " 36/121 [=======>......................] - ETA: 0s - loss: 2.6877 - accuracy: 0.4766\n",
            "Epoch 68: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 68: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 68: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 68: accuracy did not improve from 0.64062\n",
            " 53/121 [============>.................] - ETA: 0s - loss: 2.6536 - accuracy: 0.4776\n",
            "Epoch 68: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 68: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 68: accuracy did not improve from 0.64062\n",
            " 68/121 [===============>..............] - ETA: 0s - loss: 2.6771 - accuracy: 0.4729\n",
            "Epoch 68: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 68: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 68: accuracy did not improve from 0.64062\n",
            " 83/121 [===================>..........] - ETA: 0s - loss: 2.6876 - accuracy: 0.4710\n",
            "Epoch 68: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 68: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 68: accuracy did not improve from 0.64062\n",
            "102/121 [========================>.....] - ETA: 0s - loss: 2.6802 - accuracy: 0.4743\n",
            "Epoch 68: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 68: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 68: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 68: accuracy did not improve from 0.64062\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.6544 - accuracy: 0.4782\n",
            "Epoch 69/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.8680 - accuracy: 0.5000\n",
            "Epoch 69: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 69: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 69: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 69: accuracy did not improve from 0.64062\n",
            " 17/121 [===>..........................] - ETA: 0s - loss: 2.7113 - accuracy: 0.4688\n",
            "Epoch 69: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 69: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 69: accuracy did not improve from 0.64062\n",
            " 36/121 [=======>......................] - ETA: 0s - loss: 2.6530 - accuracy: 0.4826\n",
            "Epoch 69: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 69: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 69: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 69: accuracy did not improve from 0.64062\n",
            " 55/121 [============>.................] - ETA: 0s - loss: 2.6617 - accuracy: 0.4795\n",
            "Epoch 69: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 69: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 69: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 69: accuracy did not improve from 0.64062\n",
            " 73/121 [=================>............] - ETA: 0s - loss: 2.6356 - accuracy: 0.4756\n",
            "Epoch 69: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 69: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 69: accuracy did not improve from 0.64062\n",
            " 88/121 [====================>.........] - ETA: 0s - loss: 2.6408 - accuracy: 0.4776\n",
            "Epoch 69: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 69: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 69: accuracy did not improve from 0.64062\n",
            "106/121 [=========================>....] - ETA: 0s - loss: 2.6334 - accuracy: 0.4811\n",
            "Epoch 69: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 69: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 69: accuracy did not improve from 0.64062\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.6544 - accuracy: 0.4784\n",
            "Epoch 70/100\n",
            "\n",
            "Epoch 70: accuracy did not improve from 0.64062\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.6763 - accuracy: 0.4062\n",
            "Epoch 70: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 70: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 70: accuracy did not improve from 0.64062\n",
            " 20/121 [===>..........................] - ETA: 0s - loss: 2.6289 - accuracy: 0.4688\n",
            "Epoch 70: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 70: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 70: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 70: accuracy did not improve from 0.64062\n",
            " 37/121 [========>.....................] - ETA: 0s - loss: 2.7471 - accuracy: 0.4578\n",
            "Epoch 70: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 70: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 70: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 70: accuracy did not improve from 0.64062\n",
            " 56/121 [============>.................] - ETA: 0s - loss: 2.7370 - accuracy: 0.4660\n",
            "Epoch 70: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 70: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 70: accuracy did not improve from 0.64062\n",
            " 75/121 [=================>............] - ETA: 0s - loss: 2.6851 - accuracy: 0.4767\n",
            "Epoch 70: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 70: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 70: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 70: accuracy did not improve from 0.64062\n",
            " 95/121 [======================>.......] - ETA: 0s - loss: 2.6524 - accuracy: 0.4789\n",
            "Epoch 70: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 70: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 70: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 70: accuracy did not improve from 0.64062\n",
            "113/121 [===========================>..] - ETA: 0s - loss: 2.6504 - accuracy: 0.4795\n",
            "Epoch 70: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 70: accuracy did not improve from 0.64062\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.6544 - accuracy: 0.4787\n",
            "Epoch 71/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.7716 - accuracy: 0.5000\n",
            "Epoch 71: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 71: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 71: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 71: accuracy did not improve from 0.64062\n",
            " 20/121 [===>..........................] - ETA: 0s - loss: 2.5729 - accuracy: 0.4938\n",
            "Epoch 71: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 71: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 71: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 71: accuracy did not improve from 0.64062\n",
            " 40/121 [========>.....................] - ETA: 0s - loss: 2.6162 - accuracy: 0.4891\n",
            "Epoch 71: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 71: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 71: accuracy did not improve from 0.64062\n",
            " 59/121 [=============>................] - ETA: 0s - loss: 2.6292 - accuracy: 0.4889\n",
            "Epoch 71: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 71: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 71: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 71: accuracy did not improve from 0.64062\n",
            " 76/121 [=================>............] - ETA: 0s - loss: 2.6376 - accuracy: 0.4877\n",
            "Epoch 71: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 71: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 71: accuracy did not improve from 0.64062\n",
            " 93/121 [======================>.......] - ETA: 0s - loss: 2.6594 - accuracy: 0.4792\n",
            "Epoch 71: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 71: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 71: accuracy did not improve from 0.64062\n",
            "106/121 [=========================>....] - ETA: 0s - loss: 2.6668 - accuracy: 0.4797\n",
            "Epoch 71: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 71: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 71: accuracy did not improve from 0.64062\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.6544 - accuracy: 0.4790\n",
            "Epoch 72/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.3970 - accuracy: 0.4375\n",
            "Epoch 72: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 72: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 72: accuracy did not improve from 0.64062\n",
            " 18/121 [===>..........................] - ETA: 0s - loss: 2.6033 - accuracy: 0.4931\n",
            "Epoch 72: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 72: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 72: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 72: accuracy did not improve from 0.64062\n",
            " 35/121 [=======>......................] - ETA: 0s - loss: 2.6201 - accuracy: 0.4911\n",
            "Epoch 72: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 72: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 72: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 72: accuracy did not improve from 0.64062\n",
            " 54/121 [============>.................] - ETA: 0s - loss: 2.6100 - accuracy: 0.4838\n",
            "Epoch 72: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 72: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 72: accuracy did not improve from 0.64062\n",
            " 71/121 [================>.............] - ETA: 0s - loss: 2.6006 - accuracy: 0.4855\n",
            "Epoch 72: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 72: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 72: accuracy did not improve from 0.64062\n",
            " 87/121 [====================>.........] - ETA: 0s - loss: 2.6037 - accuracy: 0.4835\n",
            "Epoch 72: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 72: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 72: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 72: accuracy did not improve from 0.64062\n",
            "105/121 [=========================>....] - ETA: 0s - loss: 2.6219 - accuracy: 0.4824\n",
            "Epoch 72: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 72: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 72: accuracy did not improve from 0.64062\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.6544 - accuracy: 0.4792\n",
            "Epoch 73/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 3.2482 - accuracy: 0.4375\n",
            "Epoch 73: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 73: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 73: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 73: accuracy did not improve from 0.64062\n",
            " 20/121 [===>..........................] - ETA: 0s - loss: 2.6433 - accuracy: 0.4891\n",
            "Epoch 73: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 73: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 73: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 73: accuracy did not improve from 0.64062\n",
            " 38/121 [========>.....................] - ETA: 0s - loss: 2.6450 - accuracy: 0.4942\n",
            "Epoch 73: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 73: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 73: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 73: accuracy did not improve from 0.64062\n",
            " 58/121 [=============>................] - ETA: 0s - loss: 2.6807 - accuracy: 0.4844\n",
            "Epoch 73: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 73: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 73: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 73: accuracy did not improve from 0.64062\n",
            " 78/121 [==================>...........] - ETA: 0s - loss: 2.6528 - accuracy: 0.4840\n",
            "Epoch 73: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 73: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 73: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 73: accuracy did not improve from 0.64062\n",
            " 99/121 [=======================>......] - ETA: 0s - loss: 2.6764 - accuracy: 0.4789\n",
            "Epoch 73: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 73: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 73: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 73: accuracy did not improve from 0.64062\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.6544 - accuracy: 0.4792\n",
            "Epoch 74/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.3981 - accuracy: 0.4688\n",
            "Epoch 74: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 74: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 74: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 74: accuracy did not improve from 0.64062\n",
            " 21/121 [====>.........................] - ETA: 0s - loss: 2.6544 - accuracy: 0.4792\n",
            "Epoch 74: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 74: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 74: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 74: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 74: accuracy did not improve from 0.64062\n",
            " 42/121 [=========>....................] - ETA: 0s - loss: 2.6159 - accuracy: 0.4881\n",
            "Epoch 74: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 74: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 74: accuracy did not improve from 0.64062\n",
            " 61/121 [==============>...............] - ETA: 0s - loss: 2.6273 - accuracy: 0.4846\n",
            "Epoch 74: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 74: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 74: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 74: accuracy did not improve from 0.64062\n",
            " 79/121 [==================>...........] - ETA: 0s - loss: 2.6702 - accuracy: 0.4846\n",
            "Epoch 74: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 74: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 74: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 74: accuracy did not improve from 0.64062\n",
            "100/121 [=======================>......] - ETA: 0s - loss: 2.6651 - accuracy: 0.4812\n",
            "Epoch 74: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 74: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 74: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 74: accuracy did not improve from 0.64062\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.6544 - accuracy: 0.4792\n",
            "Epoch 75/100\n",
            "\n",
            "Epoch 75: accuracy did not improve from 0.64062\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.6785 - accuracy: 0.5000\n",
            "Epoch 75: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 75: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 75: accuracy did not improve from 0.64062\n",
            " 20/121 [===>..........................] - ETA: 0s - loss: 2.9599 - accuracy: 0.4516\n",
            "Epoch 75: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 75: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 75: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 75: accuracy did not improve from 0.64062\n",
            " 37/121 [========>.....................] - ETA: 0s - loss: 2.8430 - accuracy: 0.4519\n",
            "Epoch 75: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 75: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 75: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 75: accuracy did not improve from 0.64062\n",
            " 56/121 [============>.................] - ETA: 0s - loss: 2.7597 - accuracy: 0.4609\n",
            "Epoch 75: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 75: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 75: accuracy did not improve from 0.64062\n",
            " 73/121 [=================>............] - ETA: 0s - loss: 2.7173 - accuracy: 0.4666\n",
            "Epoch 75: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 75: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 75: accuracy did not improve from 0.64062\n",
            " 87/121 [====================>.........] - ETA: 0s - loss: 2.7019 - accuracy: 0.4691\n",
            "Epoch 75: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 75: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 75: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 75: accuracy did not improve from 0.64062\n",
            "106/121 [=========================>....] - ETA: 0s - loss: 2.6443 - accuracy: 0.4776\n",
            "Epoch 75: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 75: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 75: accuracy did not improve from 0.64062\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.6544 - accuracy: 0.4792\n",
            "Epoch 76/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.0091 - accuracy: 0.5625\n",
            "Epoch 76: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 76: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 76: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 76: accuracy did not improve from 0.64062\n",
            " 20/121 [===>..........................] - ETA: 0s - loss: 2.6771 - accuracy: 0.4953\n",
            "Epoch 76: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 76: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 76: accuracy did not improve from 0.64062\n",
            " 38/121 [========>.....................] - ETA: 0s - loss: 2.6546 - accuracy: 0.4885\n",
            "Epoch 76: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 76: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 76: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 76: accuracy did not improve from 0.64062\n",
            " 56/121 [============>.................] - ETA: 0s - loss: 2.6449 - accuracy: 0.4888\n",
            "Epoch 76: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 76: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 76: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 76: accuracy did not improve from 0.64062\n",
            " 75/121 [=================>............] - ETA: 0s - loss: 2.6520 - accuracy: 0.4858\n",
            "Epoch 76: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 76: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 76: accuracy did not improve from 0.64062\n",
            " 93/121 [======================>.......] - ETA: 0s - loss: 2.6670 - accuracy: 0.4802\n",
            "Epoch 76: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 76: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 76: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 76: accuracy did not improve from 0.64062\n",
            "113/121 [===========================>..] - ETA: 0s - loss: 2.6588 - accuracy: 0.4779\n",
            "Epoch 76: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 76: accuracy did not improve from 0.64062\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.6544 - accuracy: 0.4792\n",
            "Epoch 77/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.6697 - accuracy: 0.5000\n",
            "Epoch 77: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 77: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 77: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 77: accuracy did not improve from 0.64062\n",
            " 21/121 [====>.........................] - ETA: 0s - loss: 2.6417 - accuracy: 0.4702\n",
            "Epoch 77: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 77: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 77: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 77: accuracy did not improve from 0.64062\n",
            " 39/121 [========>.....................] - ETA: 0s - loss: 2.7244 - accuracy: 0.4559\n",
            "Epoch 77: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 77: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 77: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 77: accuracy did not improve from 0.64062\n",
            " 59/121 [=============>................] - ETA: 0s - loss: 2.6957 - accuracy: 0.4709\n",
            "Epoch 77: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 77: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 77: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 77: accuracy did not improve from 0.64062\n",
            " 79/121 [==================>...........] - ETA: 0s - loss: 2.7057 - accuracy: 0.4703\n",
            "Epoch 77: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 77: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 77: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 77: accuracy did not improve from 0.64062\n",
            " 99/121 [=======================>......] - ETA: 0s - loss: 2.6284 - accuracy: 0.4804\n",
            "Epoch 77: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 77: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 77: accuracy did not improve from 0.64062\n",
            "116/121 [===========================>..] - ETA: 0s - loss: 2.6421 - accuracy: 0.4809\n",
            "Epoch 77: accuracy did not improve from 0.64062\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.6544 - accuracy: 0.4792\n",
            "Epoch 78/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.3849 - accuracy: 0.5625\n",
            "Epoch 78: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 78: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 78: accuracy did not improve from 0.64062\n",
            " 17/121 [===>..........................] - ETA: 0s - loss: 2.5541 - accuracy: 0.4945\n",
            "Epoch 78: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 78: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 78: accuracy did not improve from 0.64062\n",
            " 30/121 [======>.......................] - ETA: 0s - loss: 2.6146 - accuracy: 0.4740\n",
            "Epoch 78: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 78: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 78: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 78: accuracy did not improve from 0.64062\n",
            " 48/121 [==========>...................] - ETA: 0s - loss: 2.6639 - accuracy: 0.4753\n",
            "Epoch 78: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 78: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 78: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 78: accuracy did not improve from 0.64062\n",
            " 68/121 [===============>..............] - ETA: 0s - loss: 2.6693 - accuracy: 0.4697\n",
            "Epoch 78: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 78: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 78: accuracy did not improve from 0.64062\n",
            " 87/121 [====================>.........] - ETA: 0s - loss: 2.6930 - accuracy: 0.4727\n",
            "Epoch 78: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 78: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 78: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 78: accuracy did not improve from 0.64062\n",
            "105/121 [=========================>....] - ETA: 0s - loss: 2.6657 - accuracy: 0.4774\n",
            "Epoch 78: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 78: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 78: accuracy did not improve from 0.64062\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.6544 - accuracy: 0.4795\n",
            "Epoch 79/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.4813 - accuracy: 0.4375\n",
            "Epoch 79: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 79: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 79: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 79: accuracy did not improve from 0.64062\n",
            " 19/121 [===>..........................] - ETA: 0s - loss: 2.7520 - accuracy: 0.4507\n",
            "Epoch 79: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 79: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 79: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 79: accuracy did not improve from 0.64062\n",
            " 37/121 [========>.....................] - ETA: 0s - loss: 2.6975 - accuracy: 0.4654\n",
            "Epoch 79: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 79: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 79: accuracy did not improve from 0.64062\n",
            " 53/121 [============>.................] - ETA: 0s - loss: 2.6574 - accuracy: 0.4741\n",
            "Epoch 79: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 79: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 79: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 79: accuracy did not improve from 0.64062\n",
            " 73/121 [=================>............] - ETA: 0s - loss: 2.6540 - accuracy: 0.4730\n",
            "Epoch 79: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 79: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 79: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 79: accuracy did not improve from 0.64062\n",
            " 93/121 [======================>.......] - ETA: 0s - loss: 2.6867 - accuracy: 0.4761\n",
            "Epoch 79: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 79: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 79: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 79: accuracy did not improve from 0.64062\n",
            "113/121 [===========================>..] - ETA: 0s - loss: 2.6571 - accuracy: 0.4795\n",
            "Epoch 79: accuracy did not improve from 0.64062\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.6544 - accuracy: 0.4795\n",
            "Epoch 80/100\n",
            "\n",
            "Epoch 80: accuracy did not improve from 0.64062\n",
            "  1/121 [..............................] - ETA: 1s - loss: 2.2973 - accuracy: 0.5000\n",
            "Epoch 80: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 80: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 80: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 80: accuracy did not improve from 0.64062\n",
            " 21/121 [====>.........................] - ETA: 0s - loss: 2.7588 - accuracy: 0.4792\n",
            "Epoch 80: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 80: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 80: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 80: accuracy did not improve from 0.64062\n",
            " 41/121 [=========>....................] - ETA: 0s - loss: 2.7260 - accuracy: 0.4718\n",
            "Epoch 80: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 80: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 80: accuracy did not improve from 0.64062\n",
            " 60/121 [=============>................] - ETA: 0s - loss: 2.6532 - accuracy: 0.4760\n",
            "Epoch 80: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 80: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 80: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 80: accuracy did not improve from 0.64062\n",
            " 78/121 [==================>...........] - ETA: 0s - loss: 2.6784 - accuracy: 0.4736\n",
            "Epoch 80: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 80: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 80: accuracy did not improve from 0.64062\n",
            " 95/121 [======================>.......] - ETA: 0s - loss: 2.6632 - accuracy: 0.4793\n",
            "Epoch 80: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 80: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 80: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 80: accuracy did not improve from 0.64062\n",
            "112/121 [==========================>...] - ETA: 0s - loss: 2.6722 - accuracy: 0.4774\n",
            "Epoch 80: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 80: accuracy did not improve from 0.64062\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.6544 - accuracy: 0.4797\n",
            "Epoch 81/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.3871 - accuracy: 0.5625\n",
            "Epoch 81: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 81: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 81: accuracy did not improve from 0.64062\n",
            " 19/121 [===>..........................] - ETA: 0s - loss: 2.6623 - accuracy: 0.4655\n",
            "Epoch 81: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 81: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 81: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 81: accuracy did not improve from 0.64062\n",
            " 36/121 [=======>......................] - ETA: 0s - loss: 2.6166 - accuracy: 0.4688\n",
            "Epoch 81: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 81: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 81: accuracy did not improve from 0.64062\n",
            " 54/121 [============>.................] - ETA: 0s - loss: 2.6671 - accuracy: 0.4688\n",
            "Epoch 81: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 81: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 81: accuracy did not improve from 0.64062\n",
            " 67/121 [===============>..............] - ETA: 0s - loss: 2.6606 - accuracy: 0.4757\n",
            "Epoch 81: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 81: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 81: accuracy did not improve from 0.64062\n",
            " 83/121 [===================>..........] - ETA: 0s - loss: 2.6648 - accuracy: 0.4774\n",
            "Epoch 81: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 81: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 81: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 81: accuracy did not improve from 0.64062\n",
            "100/121 [=======================>......] - ETA: 0s - loss: 2.6717 - accuracy: 0.4762\n",
            "Epoch 81: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 81: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 81: accuracy did not improve from 0.64062\n",
            "118/121 [============================>.] - ETA: 0s - loss: 2.6515 - accuracy: 0.4791\n",
            "Epoch 81: accuracy did not improve from 0.64062\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.6544 - accuracy: 0.4797\n",
            "Epoch 82/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.3893 - accuracy: 0.5000\n",
            "Epoch 82: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 82: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 82: accuracy did not improve from 0.64062\n",
            " 17/121 [===>..........................] - ETA: 0s - loss: 2.7274 - accuracy: 0.4724\n",
            "Epoch 82: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 82: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 82: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 82: accuracy did not improve from 0.64062\n",
            " 34/121 [=======>......................] - ETA: 0s - loss: 2.6689 - accuracy: 0.4761\n",
            "Epoch 82: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 82: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 82: accuracy did not improve from 0.64062\n",
            " 52/121 [===========>..................] - ETA: 0s - loss: 2.6992 - accuracy: 0.4724\n",
            "Epoch 82: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 82: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 82: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 82: accuracy did not improve from 0.64062\n",
            " 70/121 [================>.............] - ETA: 0s - loss: 2.6718 - accuracy: 0.4759\n",
            "Epoch 82: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 82: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 82: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 82: accuracy did not improve from 0.64062\n",
            " 89/121 [=====================>........] - ETA: 0s - loss: 2.6666 - accuracy: 0.4740\n",
            "Epoch 82: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 82: accuracy did not improve from 0.64062\n",
            "103/121 [========================>.....] - ETA: 0s - loss: 2.6495 - accuracy: 0.4766\n",
            "Epoch 82: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 82: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 82: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 82: accuracy did not improve from 0.64062\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.6544 - accuracy: 0.4797\n",
            "Epoch 83/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 1.9171 - accuracy: 0.5000\n",
            "Epoch 83: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 83: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 83: accuracy did not improve from 0.64062\n",
            " 17/121 [===>..........................] - ETA: 0s - loss: 2.6272 - accuracy: 0.4890\n",
            "Epoch 83: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 83: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 83: accuracy did not improve from 0.64062\n",
            " 29/121 [======>.......................] - ETA: 0s - loss: 2.6411 - accuracy: 0.4935\n",
            "Epoch 83: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 83: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 83: accuracy did not improve from 0.64062\n",
            " 43/121 [=========>....................] - ETA: 0s - loss: 2.6799 - accuracy: 0.4782\n",
            "Epoch 83: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 83: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 83: accuracy did not improve from 0.64062\n",
            " 60/121 [=============>................] - ETA: 0s - loss: 2.6505 - accuracy: 0.4797\n",
            "Epoch 83: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 83: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 83: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 83: accuracy did not improve from 0.64062\n",
            " 78/121 [==================>...........] - ETA: 0s - loss: 2.6946 - accuracy: 0.4740\n",
            "Epoch 83: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 83: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 83: accuracy did not improve from 0.64062\n",
            " 96/121 [======================>.......] - ETA: 0s - loss: 2.6813 - accuracy: 0.4785\n",
            "Epoch 83: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 83: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 83: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 83: accuracy did not improve from 0.64062\n",
            "115/121 [===========================>..] - ETA: 0s - loss: 2.6724 - accuracy: 0.4783\n",
            "Epoch 83: accuracy did not improve from 0.64062\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.6544 - accuracy: 0.4797\n",
            "Epoch 84/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 3.2547 - accuracy: 0.3438\n",
            "Epoch 84: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 84: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 84: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 84: accuracy did not improve from 0.64062\n",
            " 18/121 [===>..........................] - ETA: 0s - loss: 2.5280 - accuracy: 0.4757\n",
            "Epoch 84: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 84: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 84: accuracy did not improve from 0.64062\n",
            " 33/121 [=======>......................] - ETA: 0s - loss: 2.6341 - accuracy: 0.4612\n",
            "Epoch 84: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 84: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 84: accuracy did not improve from 0.64062\n",
            " 50/121 [===========>..................] - ETA: 0s - loss: 2.6605 - accuracy: 0.4644\n",
            "Epoch 84: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 84: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 84: accuracy did not improve from 0.64062\n",
            " 63/121 [==============>...............] - ETA: 0s - loss: 2.6110 - accuracy: 0.4692\n",
            "Epoch 84: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 84: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 84: accuracy did not improve from 0.64062\n",
            " 78/121 [==================>...........] - ETA: 0s - loss: 2.5881 - accuracy: 0.4808\n",
            "Epoch 84: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 84: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 84: accuracy did not improve from 0.64062\n",
            " 96/121 [======================>.......] - ETA: 0s - loss: 2.6476 - accuracy: 0.4753\n",
            "Epoch 84: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 84: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 84: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 84: accuracy did not improve from 0.64062\n",
            "113/121 [===========================>..] - ETA: 0s - loss: 2.6370 - accuracy: 0.4820\n",
            "Epoch 84: accuracy did not improve from 0.64062\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.6544 - accuracy: 0.4797\n",
            "Epoch 85/100\n",
            "\n",
            "Epoch 85: accuracy did not improve from 0.64062\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.3937 - accuracy: 0.5938\n",
            "Epoch 85: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 85: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 85: accuracy did not improve from 0.64062\n",
            " 20/121 [===>..........................] - ETA: 0s - loss: 2.7957 - accuracy: 0.4656\n",
            "Epoch 85: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 85: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 85: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 85: accuracy did not improve from 0.64062\n",
            " 39/121 [========>.....................] - ETA: 0s - loss: 2.6814 - accuracy: 0.4936\n",
            "Epoch 85: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 85: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 85: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 85: accuracy did not improve from 0.64062\n",
            " 57/121 [=============>................] - ETA: 0s - loss: 2.6602 - accuracy: 0.4929\n",
            "Epoch 85: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 85: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 85: accuracy did not improve from 0.64062\n",
            " 75/121 [=================>............] - ETA: 0s - loss: 2.6300 - accuracy: 0.4892\n",
            "Epoch 85: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 85: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 85: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 85: accuracy did not improve from 0.64062\n",
            " 92/121 [=====================>........] - ETA: 0s - loss: 2.6338 - accuracy: 0.4830\n",
            "Epoch 85: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 85: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 85: accuracy did not improve from 0.64062\n",
            "110/121 [==========================>...] - ETA: 0s - loss: 2.6592 - accuracy: 0.4784\n",
            "Epoch 85: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 85: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 85: accuracy did not improve from 0.64062\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.6544 - accuracy: 0.4797\n",
            "Epoch 86/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.8636 - accuracy: 0.4688\n",
            "Epoch 86: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 86: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 86: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 86: accuracy did not improve from 0.64062\n",
            " 20/121 [===>..........................] - ETA: 0s - loss: 2.7253 - accuracy: 0.4750\n",
            "Epoch 86: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 86: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 86: accuracy did not improve from 0.64062\n",
            " 39/121 [========>.....................] - ETA: 0s - loss: 2.6504 - accuracy: 0.4792\n",
            "Epoch 86: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 86: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 86: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 86: accuracy did not improve from 0.64062\n",
            " 56/121 [============>.................] - ETA: 0s - loss: 2.6636 - accuracy: 0.4794\n",
            "Epoch 86: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 86: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 86: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 86: accuracy did not improve from 0.64062\n",
            " 75/121 [=================>............] - ETA: 0s - loss: 2.6595 - accuracy: 0.4808\n",
            "Epoch 86: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 86: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 86: accuracy did not improve from 0.64062\n",
            " 93/121 [======================>.......] - ETA: 0s - loss: 2.6630 - accuracy: 0.4782\n",
            "Epoch 86: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 86: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 86: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 86: accuracy did not improve from 0.64062\n",
            "110/121 [==========================>...] - ETA: 0s - loss: 2.6559 - accuracy: 0.4776\n",
            "Epoch 86: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 86: accuracy did not improve from 0.64062\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.6544 - accuracy: 0.4797\n",
            "Epoch 87/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.8713 - accuracy: 0.4062\n",
            "Epoch 87: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 87: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 87: accuracy did not improve from 0.64062\n",
            " 15/121 [==>...........................] - ETA: 0s - loss: 2.5128 - accuracy: 0.5125\n",
            "Epoch 87: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 87: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 87: accuracy did not improve from 0.64062\n",
            " 33/121 [=======>......................] - ETA: 0s - loss: 2.5096 - accuracy: 0.5057\n",
            "Epoch 87: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 87: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 87: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 87: accuracy did not improve from 0.64062\n",
            " 52/121 [===========>..................] - ETA: 0s - loss: 2.6352 - accuracy: 0.4778\n",
            "Epoch 87: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 87: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 87: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 87: accuracy did not improve from 0.64062\n",
            " 70/121 [================>.............] - ETA: 0s - loss: 2.6297 - accuracy: 0.4763\n",
            "Epoch 87: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 87: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 87: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 87: accuracy did not improve from 0.64062\n",
            " 89/121 [=====================>........] - ETA: 0s - loss: 2.6516 - accuracy: 0.4772\n",
            "Epoch 87: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 87: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 87: accuracy did not improve from 0.64062\n",
            "107/121 [=========================>....] - ETA: 0s - loss: 2.6362 - accuracy: 0.4845\n",
            "Epoch 87: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 87: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 87: accuracy did not improve from 0.64062\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.6544 - accuracy: 0.4797\n",
            "Epoch 88/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 3.2438 - accuracy: 0.5312\n",
            "Epoch 88: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 88: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 88: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 88: accuracy did not improve from 0.64062\n",
            " 19/121 [===>..........................] - ETA: 0s - loss: 2.6472 - accuracy: 0.4951\n",
            "Epoch 88: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 88: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 88: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 88: accuracy did not improve from 0.64062\n",
            " 38/121 [========>.....................] - ETA: 0s - loss: 2.6172 - accuracy: 0.4860\n",
            "Epoch 88: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 88: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 88: accuracy did not improve from 0.64062\n",
            " 57/121 [=============>................] - ETA: 0s - loss: 2.5952 - accuracy: 0.4896\n",
            "Epoch 88: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 88: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 88: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 88: accuracy did not improve from 0.64062\n",
            " 74/121 [=================>............] - ETA: 0s - loss: 2.6347 - accuracy: 0.4823\n",
            "Epoch 88: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 88: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 88: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 88: accuracy did not improve from 0.64062\n",
            " 93/121 [======================>.......] - ETA: 0s - loss: 2.6774 - accuracy: 0.4761\n",
            "Epoch 88: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 88: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 88: accuracy did not improve from 0.64062\n",
            "112/121 [==========================>...] - ETA: 0s - loss: 2.6637 - accuracy: 0.4799\n",
            "Epoch 88: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 88: accuracy did not improve from 0.64062\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.6544 - accuracy: 0.4797\n",
            "Epoch 89/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.8691 - accuracy: 0.4062\n",
            "Epoch 89: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 89: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 89: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 89: accuracy did not improve from 0.64062\n",
            " 18/121 [===>..........................] - ETA: 0s - loss: 2.6553 - accuracy: 0.4705\n",
            "Epoch 89: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 89: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 89: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 89: accuracy did not improve from 0.64062\n",
            " 37/121 [========>.....................] - ETA: 0s - loss: 2.5973 - accuracy: 0.4924\n",
            "Epoch 89: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 89: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 89: accuracy did not improve from 0.64062\n",
            " 55/121 [============>.................] - ETA: 0s - loss: 2.6426 - accuracy: 0.4795\n",
            "Epoch 89: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 89: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 89: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 89: accuracy did not improve from 0.64062\n",
            " 72/121 [================>.............] - ETA: 0s - loss: 2.6497 - accuracy: 0.4709\n",
            "Epoch 89: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 89: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 89: accuracy did not improve from 0.64062\n",
            " 89/121 [=====================>........] - ETA: 0s - loss: 2.6699 - accuracy: 0.4751\n",
            "Epoch 89: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 89: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 89: accuracy did not improve from 0.64062\n",
            "105/121 [=========================>....] - ETA: 0s - loss: 2.6546 - accuracy: 0.4798\n",
            "Epoch 89: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 89: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 89: accuracy did not improve from 0.64062\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.6544 - accuracy: 0.4797\n",
            "Epoch 90/100\n",
            "\n",
            "Epoch 90: accuracy did not improve from 0.64062\n",
            "  1/121 [..............................] - ETA: 1s - loss: 2.6730 - accuracy: 0.5000\n",
            "Epoch 90: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 90: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 90: accuracy did not improve from 0.64062\n",
            " 18/121 [===>..........................] - ETA: 0s - loss: 2.7781 - accuracy: 0.4583\n",
            "Epoch 90: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 90: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 90: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 90: accuracy did not improve from 0.64062\n",
            " 36/121 [=======>......................] - ETA: 0s - loss: 2.6936 - accuracy: 0.4688\n",
            "Epoch 90: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 90: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 90: accuracy did not improve from 0.64062\n",
            " 51/121 [===========>..................] - ETA: 0s - loss: 2.6362 - accuracy: 0.4810\n",
            "Epoch 90: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 90: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 90: accuracy did not improve from 0.64062\n",
            " 69/121 [================>.............] - ETA: 0s - loss: 2.6512 - accuracy: 0.4764\n",
            "Epoch 90: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 90: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 90: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 90: accuracy did not improve from 0.64062\n",
            " 88/121 [====================>.........] - ETA: 0s - loss: 2.6580 - accuracy: 0.4780\n",
            "Epoch 90: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 90: accuracy did not improve from 0.64062\n",
            "100/121 [=======================>......] - ETA: 0s - loss: 2.6775 - accuracy: 0.4775\n",
            "Epoch 90: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 90: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 90: accuracy did not improve from 0.64062\n",
            "112/121 [==========================>...] - ETA: 0s - loss: 2.6672 - accuracy: 0.4777\n",
            "Epoch 90: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 90: accuracy did not improve from 0.64062\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.6544 - accuracy: 0.4797\n",
            "Epoch 91/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.5865 - accuracy: 0.5312\n",
            "Epoch 91: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 91: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 91: accuracy did not improve from 0.64062\n",
            " 16/121 [==>...........................] - ETA: 0s - loss: 2.7496 - accuracy: 0.4570\n",
            "Epoch 91: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 91: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 91: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 91: accuracy did not improve from 0.64062\n",
            " 35/121 [=======>......................] - ETA: 0s - loss: 2.7374 - accuracy: 0.4696\n",
            "Epoch 91: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 91: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 91: accuracy did not improve from 0.64062\n",
            " 53/121 [============>.................] - ETA: 0s - loss: 2.7627 - accuracy: 0.4593\n",
            "Epoch 91: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 91: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 91: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 91: accuracy did not improve from 0.64062\n",
            " 70/121 [================>.............] - ETA: 0s - loss: 2.7268 - accuracy: 0.4688\n",
            "Epoch 91: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 91: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 91: accuracy did not improve from 0.64062\n",
            " 89/121 [=====================>........] - ETA: 0s - loss: 2.7009 - accuracy: 0.4712\n",
            "Epoch 91: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 91: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 91: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 91: accuracy did not improve from 0.64062\n",
            "106/121 [=========================>....] - ETA: 0s - loss: 2.6693 - accuracy: 0.4770\n",
            "Epoch 91: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 91: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 91: accuracy did not improve from 0.64062\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.6544 - accuracy: 0.4797\n",
            "Epoch 92/100\n",
            "  1/121 [..............................] - ETA: 1s - loss: 4.0128 - accuracy: 0.2500\n",
            "Epoch 92: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 92: accuracy did not improve from 0.64062\n",
            " 11/121 [=>............................] - ETA: 0s - loss: 2.7655 - accuracy: 0.4602\n",
            "Epoch 92: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 92: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 92: accuracy did not improve from 0.64062\n",
            " 25/121 [=====>........................] - ETA: 0s - loss: 2.6207 - accuracy: 0.4787\n",
            "Epoch 92: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 92: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 92: accuracy did not improve from 0.64062\n",
            " 41/121 [=========>....................] - ETA: 0s - loss: 2.5425 - accuracy: 0.4893\n",
            "Epoch 92: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 92: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 92: accuracy did not improve from 0.64062\n",
            " 58/121 [=============>................] - ETA: 0s - loss: 2.6130 - accuracy: 0.4855\n",
            "Epoch 92: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 92: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 92: accuracy did not improve from 0.64062\n",
            " 73/121 [=================>............] - ETA: 0s - loss: 2.6092 - accuracy: 0.4859\n",
            "Epoch 92: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 92: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 92: accuracy did not improve from 0.64062\n",
            " 88/121 [====================>.........] - ETA: 0s - loss: 2.6741 - accuracy: 0.4783\n",
            "Epoch 92: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 92: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 92: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 92: accuracy did not improve from 0.64062\n",
            "104/121 [========================>.....] - ETA: 0s - loss: 2.6589 - accuracy: 0.4829\n",
            "Epoch 92: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 92: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 92: accuracy did not improve from 0.64062\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.6544 - accuracy: 0.4797\n",
            "Epoch 93/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.9622 - accuracy: 0.5312\n",
            "Epoch 93: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 93: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 93: accuracy did not improve from 0.64062\n",
            " 14/121 [==>...........................] - ETA: 0s - loss: 2.7168 - accuracy: 0.4754\n",
            "Epoch 93: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 93: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 93: accuracy did not improve from 0.64062\n",
            " 29/121 [======>.......................] - ETA: 0s - loss: 2.7227 - accuracy: 0.4741\n",
            "Epoch 93: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 93: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 93: accuracy did not improve from 0.64062\n",
            " 44/121 [=========>....................] - ETA: 0s - loss: 2.6937 - accuracy: 0.4751\n",
            "Epoch 93: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 93: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 93: accuracy did not improve from 0.64062\n",
            " 59/121 [=============>................] - ETA: 0s - loss: 2.6851 - accuracy: 0.4756\n",
            "Epoch 93: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 93: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 93: accuracy did not improve from 0.64062\n",
            " 74/121 [=================>............] - ETA: 0s - loss: 2.7019 - accuracy: 0.4709\n",
            "Epoch 93: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 93: accuracy did not improve from 0.64062\n",
            " 85/121 [====================>.........] - ETA: 0s - loss: 2.6807 - accuracy: 0.4779\n",
            "Epoch 93: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 93: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 93: accuracy did not improve from 0.64062\n",
            " 98/121 [=======================>......] - ETA: 0s - loss: 2.6422 - accuracy: 0.4821\n",
            "Epoch 93: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 93: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 93: accuracy did not improve from 0.64062\n",
            "114/121 [===========================>..] - ETA: 0s - loss: 2.6364 - accuracy: 0.4816\n",
            "Epoch 93: accuracy did not improve from 0.64062\n",
            "121/121 [==============================] - 0s 4ms/step - loss: 2.6544 - accuracy: 0.4797\n",
            "Epoch 94/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 3.3489 - accuracy: 0.4688\n",
            "Epoch 94: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 94: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 94: accuracy did not improve from 0.64062\n",
            " 16/121 [==>...........................] - ETA: 0s - loss: 2.8334 - accuracy: 0.4453\n",
            "Epoch 94: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 94: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 94: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 94: accuracy did not improve from 0.64062\n",
            " 33/121 [=======>......................] - ETA: 0s - loss: 2.8162 - accuracy: 0.4489\n",
            "Epoch 94: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 94: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 94: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 94: accuracy did not improve from 0.64062\n",
            " 55/121 [============>.................] - ETA: 0s - loss: 2.7398 - accuracy: 0.4648\n",
            "Epoch 94: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 94: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 94: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 94: accuracy did not improve from 0.64062\n",
            " 76/121 [=================>............] - ETA: 0s - loss: 2.6687 - accuracy: 0.4782\n",
            "Epoch 94: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 94: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 94: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 94: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 94: accuracy did not improve from 0.64062\n",
            " 97/121 [=======================>......] - ETA: 0s - loss: 2.6489 - accuracy: 0.4800\n",
            "Epoch 94: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 94: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 94: accuracy did not improve from 0.64062\n",
            "116/121 [===========================>..] - ETA: 0s - loss: 2.6528 - accuracy: 0.4806\n",
            "Epoch 94: accuracy did not improve from 0.64062\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.6544 - accuracy: 0.4797\n",
            "Epoch 95/100\n",
            "\n",
            "Epoch 95: accuracy did not improve from 0.64062\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.2064 - accuracy: 0.5000\n",
            "Epoch 95: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 95: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 95: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 95: accuracy did not improve from 0.64062\n",
            " 22/121 [====>.........................] - ETA: 0s - loss: 2.7470 - accuracy: 0.4474\n",
            "Epoch 95: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 95: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 95: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 95: accuracy did not improve from 0.64062\n",
            " 41/121 [=========>....................] - ETA: 0s - loss: 2.7034 - accuracy: 0.4550\n",
            "Epoch 95: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 95: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 95: accuracy did not improve from 0.64062\n",
            " 59/121 [=============>................] - ETA: 0s - loss: 2.6828 - accuracy: 0.4635\n",
            "Epoch 95: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 95: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 95: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 95: accuracy did not improve from 0.64062\n",
            " 80/121 [==================>...........] - ETA: 0s - loss: 2.6661 - accuracy: 0.4691\n",
            "Epoch 95: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 95: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 95: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 95: accuracy did not improve from 0.64062\n",
            " 96/121 [======================>.......] - ETA: 0s - loss: 2.6599 - accuracy: 0.4697\n",
            "Epoch 95: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 95: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 95: accuracy did not improve from 0.64062\n",
            "112/121 [==========================>...] - ETA: 0s - loss: 2.6571 - accuracy: 0.4771\n",
            "Epoch 95: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 95: accuracy did not improve from 0.64062\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.6544 - accuracy: 0.4797\n",
            "Epoch 96/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.1976 - accuracy: 0.5000\n",
            "Epoch 96: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 96: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 96: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 96: accuracy did not improve from 0.64062\n",
            " 21/121 [====>.........................] - ETA: 0s - loss: 2.6730 - accuracy: 0.4673\n",
            "Epoch 96: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 96: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 96: accuracy did not improve from 0.64062\n",
            " 38/121 [========>.....................] - ETA: 0s - loss: 2.7001 - accuracy: 0.4646\n",
            "Epoch 96: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 96: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 96: accuracy did not improve from 0.64062\n",
            " 51/121 [===========>..................] - ETA: 0s - loss: 2.7056 - accuracy: 0.4681\n",
            "Epoch 96: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 96: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 96: accuracy did not improve from 0.64062\n",
            " 68/121 [===============>..............] - ETA: 0s - loss: 2.7210 - accuracy: 0.4655\n",
            "Epoch 96: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 96: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 96: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 96: accuracy did not improve from 0.64062\n",
            " 89/121 [=====================>........] - ETA: 0s - loss: 2.6796 - accuracy: 0.4740\n",
            "Epoch 96: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 96: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 96: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 96: accuracy did not improve from 0.64062\n",
            "105/121 [=========================>....] - ETA: 0s - loss: 2.6666 - accuracy: 0.4753\n",
            "Epoch 96: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 96: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 96: accuracy did not improve from 0.64062\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.6544 - accuracy: 0.4797\n",
            "Epoch 97/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 1.4329 - accuracy: 0.6250\n",
            "Epoch 97: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 97: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 97: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 97: accuracy did not improve from 0.64062\n",
            " 19/121 [===>..........................] - ETA: 0s - loss: 2.5665 - accuracy: 0.4786\n",
            "Epoch 97: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 97: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 97: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 97: accuracy did not improve from 0.64062\n",
            " 39/121 [========>.....................] - ETA: 0s - loss: 2.6020 - accuracy: 0.4824\n",
            "Epoch 97: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 97: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 97: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 97: accuracy did not improve from 0.64062\n",
            " 59/121 [=============>................] - ETA: 0s - loss: 2.6290 - accuracy: 0.4857\n",
            "Epoch 97: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 97: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 97: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 97: accuracy did not improve from 0.64062\n",
            " 79/121 [==================>...........] - ETA: 0s - loss: 2.6472 - accuracy: 0.4822\n",
            "Epoch 97: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 97: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 97: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 97: accuracy did not improve from 0.64062\n",
            "100/121 [=======================>......] - ETA: 0s - loss: 2.6239 - accuracy: 0.4844\n",
            "Epoch 97: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 97: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 97: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 97: accuracy did not improve from 0.64062\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.6544 - accuracy: 0.4797\n",
            "Epoch 98/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 3.0597 - accuracy: 0.4375\n",
            "Epoch 98: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 98: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 98: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 98: accuracy did not improve from 0.64062\n",
            " 21/121 [====>.........................] - ETA: 0s - loss: 2.7042 - accuracy: 0.4688\n",
            "Epoch 98: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 98: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 98: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 98: accuracy did not improve from 0.64062\n",
            " 41/121 [=========>....................] - ETA: 0s - loss: 2.7001 - accuracy: 0.4741\n",
            "Epoch 98: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 98: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 98: accuracy did not improve from 0.64062\n",
            " 55/121 [============>.................] - ETA: 0s - loss: 2.7257 - accuracy: 0.4722\n",
            "Epoch 98: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 98: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 98: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 98: accuracy did not improve from 0.64062\n",
            " 73/121 [=================>............] - ETA: 0s - loss: 2.7162 - accuracy: 0.4756\n",
            "Epoch 98: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 98: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 98: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 98: accuracy did not improve from 0.64062\n",
            " 93/121 [======================>.......] - ETA: 0s - loss: 2.7049 - accuracy: 0.4741\n",
            "Epoch 98: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 98: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 98: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 98: accuracy did not improve from 0.64062\n",
            "113/121 [===========================>..] - ETA: 0s - loss: 2.6781 - accuracy: 0.4757\n",
            "Epoch 98: accuracy did not improve from 0.64062\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.6544 - accuracy: 0.4797\n",
            "Epoch 99/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 3.0630 - accuracy: 0.3750\n",
            "Epoch 99: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 99: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 99: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 99: accuracy did not improve from 0.64062\n",
            " 19/121 [===>..........................] - ETA: 0s - loss: 2.6310 - accuracy: 0.4885\n",
            "Epoch 99: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 99: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 99: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 99: accuracy did not improve from 0.64062\n",
            " 38/121 [========>.....................] - ETA: 0s - loss: 2.5861 - accuracy: 0.4934\n",
            "Epoch 99: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 99: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 99: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 99: accuracy did not improve from 0.64062\n",
            " 57/121 [=============>................] - ETA: 0s - loss: 2.6501 - accuracy: 0.4814\n",
            "Epoch 99: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 99: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 99: accuracy did not improve from 0.64062\n",
            " 75/121 [=================>............] - ETA: 0s - loss: 2.6570 - accuracy: 0.4796\n",
            "Epoch 99: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 99: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 99: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 99: accuracy did not improve from 0.64062\n",
            " 94/121 [======================>.......] - ETA: 0s - loss: 2.6580 - accuracy: 0.4784\n",
            "Epoch 99: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 99: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 99: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 99: accuracy did not improve from 0.64062\n",
            "113/121 [===========================>..] - ETA: 0s - loss: 2.6469 - accuracy: 0.4809\n",
            "Epoch 99: accuracy did not improve from 0.64062\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.6544 - accuracy: 0.4797\n",
            "Epoch 100/100\n",
            "\n",
            "Epoch 100: accuracy did not improve from 0.64062\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.5843 - accuracy: 0.5938\n",
            "Epoch 100: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 100: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 100: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 100: accuracy did not improve from 0.64062\n",
            " 21/121 [====>.........................] - ETA: 0s - loss: 2.6922 - accuracy: 0.4524\n",
            "Epoch 100: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 100: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 100: accuracy did not improve from 0.64062\n",
            " 40/121 [========>.....................] - ETA: 0s - loss: 2.6135 - accuracy: 0.4641\n",
            "Epoch 100: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 100: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 100: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 100: accuracy did not improve from 0.64062\n",
            " 58/121 [=============>................] - ETA: 0s - loss: 2.6336 - accuracy: 0.4682\n",
            "Epoch 100: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 100: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 100: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 100: accuracy did not improve from 0.64062\n",
            " 76/121 [=================>............] - ETA: 0s - loss: 2.6903 - accuracy: 0.4663\n",
            "Epoch 100: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 100: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 100: accuracy did not improve from 0.64062\n",
            " 91/121 [=====================>........] - ETA: 0s - loss: 2.6870 - accuracy: 0.4688\n",
            "Epoch 100: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 100: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 100: accuracy did not improve from 0.64062\n",
            "107/121 [=========================>....] - ETA: 0s - loss: 2.6605 - accuracy: 0.4758\n",
            "Epoch 100: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 100: accuracy did not improve from 0.64062\n",
            "\n",
            "Epoch 100: accuracy did not improve from 0.64062\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.6544 - accuracy: 0.4797\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model using the test data\n",
        "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=1)\n",
        "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ScXOhixnu_nu",
        "outputId": "aec15287-f46c-40c9-ba34-8b422e01da9d"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "41/41 [==============================] - 0s 1ms/step - loss: 2.5198 - accuracy: 0.4801\n",
            "Loss: 2.519768238067627, Accuracy: 0.48012471199035645\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JkscMHgdu_tq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#NN Dropping Only Computer Science\n",
        "\n",
        "summary of model\n",
        "41/41 [==============================] - \n",
        "\n",
        "Loss: 2.330411672592163, \n",
        "\n",
        "Accuracy: 0.6297739744186401"
      ],
      "metadata": {
        "id": "EKp1dEYTwjgF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "comp_data = cat_data.copy()\n",
        "comp_data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352
        },
        "id": "eIZ1au1YwoH6",
        "outputId": "819fda95-80cd-4912-f92d-08dd755d9ca4"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Grade  Section_Grade  Course_AP Research (Capstone Year 2)  \\\n",
              "0      9          96.67                                     0   \n",
              "1      9          87.92                                     0   \n",
              "2      9          86.02                                     0   \n",
              "3      9          88.89                                     0   \n",
              "4      9          88.49                                     0   \n",
              "\n",
              "   Course_AP Seminar (Capstone Year 1)  Course_Algebra II  \\\n",
              "0                                    0                  0   \n",
              "1                                    0                  0   \n",
              "2                                    0                  0   \n",
              "3                                    0                  0   \n",
              "4                                    0                  0   \n",
              "\n",
              "   Course_Algebra II Honors  Course_Anatomy and Physiology Honors  \\\n",
              "0                         0                                     0   \n",
              "1                         0                                     0   \n",
              "2                         0                                     0   \n",
              "3                         0                                     0   \n",
              "4                         0                                     0   \n",
              "\n",
              "   Course_Art History AP  Course_Artificial Intelligence Post-AP  \\\n",
              "0                      0                                       0   \n",
              "1                      0                                       0   \n",
              "2                      0                                       0   \n",
              "3                      0                                       0   \n",
              "4                      0                                       0   \n",
              "\n",
              "   Course_Astronomy Honors  ...  Course_Type_Computer Science  \\\n",
              "0                        0  ...                             0   \n",
              "1                        0  ...                             0   \n",
              "2                        0  ...                             0   \n",
              "3                        0  ...                             0   \n",
              "4                        0  ...                             0   \n",
              "\n",
              "   Course_Type_English  Course_Type_Entrepreneurship  \\\n",
              "0                    1                             0   \n",
              "1                    0                             0   \n",
              "2                    0                             0   \n",
              "3                    0                             0   \n",
              "4                    0                             0   \n",
              "\n",
              "   Course_Type_Foreign Language  Course_Type_Humanities  \\\n",
              "0                             0                       0   \n",
              "1                             1                       0   \n",
              "2                             0                       0   \n",
              "3                             0                       0   \n",
              "4                             0                       1   \n",
              "\n",
              "   Course_Type_Law and Politics  Course_Type_Math  Course_Type_Psychology  \\\n",
              "0                             0                 0                       0   \n",
              "1                             0                 0                       0   \n",
              "2                             0                 0                       0   \n",
              "3                             0                 0                       0   \n",
              "4                             0                 0                       0   \n",
              "\n",
              "   Course_Type_Research  Course_Type_Science  \n",
              "0                     0                    0  \n",
              "1                     0                    0  \n",
              "2                     0                    1  \n",
              "3                     0                    1  \n",
              "4                     0                    0  \n",
              "\n",
              "[5 rows x 118 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f2e24ed2-1cd8-4799-adcf-531c568e94ed\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Grade</th>\n",
              "      <th>Section_Grade</th>\n",
              "      <th>Course_AP Research (Capstone Year 2)</th>\n",
              "      <th>Course_AP Seminar (Capstone Year 1)</th>\n",
              "      <th>Course_Algebra II</th>\n",
              "      <th>Course_Algebra II Honors</th>\n",
              "      <th>Course_Anatomy and Physiology Honors</th>\n",
              "      <th>Course_Art History AP</th>\n",
              "      <th>Course_Artificial Intelligence Post-AP</th>\n",
              "      <th>Course_Astronomy Honors</th>\n",
              "      <th>...</th>\n",
              "      <th>Course_Type_Computer Science</th>\n",
              "      <th>Course_Type_English</th>\n",
              "      <th>Course_Type_Entrepreneurship</th>\n",
              "      <th>Course_Type_Foreign Language</th>\n",
              "      <th>Course_Type_Humanities</th>\n",
              "      <th>Course_Type_Law and Politics</th>\n",
              "      <th>Course_Type_Math</th>\n",
              "      <th>Course_Type_Psychology</th>\n",
              "      <th>Course_Type_Research</th>\n",
              "      <th>Course_Type_Science</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>9</td>\n",
              "      <td>96.67</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>9</td>\n",
              "      <td>87.92</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>9</td>\n",
              "      <td>86.02</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9</td>\n",
              "      <td>88.89</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9</td>\n",
              "      <td>88.49</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 118 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f2e24ed2-1cd8-4799-adcf-531c568e94ed')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f2e24ed2-1cd8-4799-adcf-531c568e94ed button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f2e24ed2-1cd8-4799-adcf-531c568e94ed');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split our preprocessed data into our features and target arrays\n",
        "X = comp_data.drop('Course_Type_Computer Science', axis=1).values\n",
        "y = comp_data['Course_Type_Computer Science'].values\n",
        "\n",
        "# Split the preprocessed data into a training and testing dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=13)"
      ],
      "metadata": {
        "id": "2QHnLYwFxCQW"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a StandardScaler instances\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit the StandardScaler\n",
        "X_scaler = scaler.fit(X_train)\n",
        "\n",
        "# Scale the data\n",
        "X_train_scaled = X_scaler.transform(X_train)\n",
        "X_test_scaled = X_scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "arK13hL8xCpU"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
        "input = X_train_scaled.shape[1]\n",
        "nn = tf.keras.models.Sequential()\n",
        "\n",
        "# First hidden layer\n",
        "nn.add(tf.keras.layers.Dense(units=5, activation=\"relu\", input_dim=input))\n",
        "\n",
        "# Check the structure of the model\n",
        "nn.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DCU_Iq_rxCx9",
        "outputId": "7838084a-9860-4bb9-f6f8-2c5f4c3b8b39"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_2 (Dense)             (None, 5)                 590       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 590\n",
            "Trainable params: 590\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Compile the model\n",
        "nn.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "fHcziaIpxVCd"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "checkpoint = ModelCheckpoint(\"best_model.hdf5\", monitor='accuracy', verbose=1,\n",
        "    save_best_only=True, mode='auto', save_freq=5)\n",
        "\n",
        "fit_model = nn.fit(X_train_scaled, y_train, epochs=100, verbose=1, callbacks=[checkpoint])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JHTvDs2OxYs9",
        "outputId": "2d5dd44c-a568-44e3-e739-f7d1da00747d"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Epoch 1: accuracy improved from 0.20395 to 0.20562, saving model to best_model.hdf5\n",
            "\n",
            "Epoch 1: accuracy did not improve from 0.20562\n",
            "\n",
            "Epoch 1: accuracy did not improve from 0.20562\n",
            "111/121 [==========================>...] - ETA: 0s - loss: 3.0217 - accuracy: 0.2052\n",
            "Epoch 1: accuracy improved from 0.20562 to 0.20679, saving model to best_model.hdf5\n",
            "\n",
            "Epoch 1: accuracy improved from 0.20679 to 0.20937, saving model to best_model.hdf5\n",
            "121/121 [==============================] - 1s 4ms/step - loss: 3.0229 - accuracy: 0.2092\n",
            "Epoch 2/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.8517 - accuracy: 0.1875\n",
            "Epoch 2: accuracy improved from 0.20937 to 0.23438, saving model to best_model.hdf5\n",
            "\n",
            "Epoch 2: accuracy improved from 0.23438 to 0.25694, saving model to best_model.hdf5\n",
            "\n",
            "Epoch 2: accuracy did not improve from 0.25694\n",
            " 14/121 [==>...........................] - ETA: 0s - loss: 2.9562 - accuracy: 0.2522\n",
            "Epoch 2: accuracy improved from 0.25694 to 0.25822, saving model to best_model.hdf5\n",
            "\n",
            "Epoch 2: accuracy improved from 0.25822 to 0.25911, saving model to best_model.hdf5\n",
            " 26/121 [=====>........................] - ETA: 0s - loss: 2.8702 - accuracy: 0.2524\n",
            "Epoch 2: accuracy did not improve from 0.25911\n",
            "\n",
            "Epoch 2: accuracy did not improve from 0.25911\n",
            "\n",
            "Epoch 2: accuracy did not improve from 0.25911\n",
            "\n",
            "Epoch 2: accuracy did not improve from 0.25911\n",
            " 45/121 [==========>...................] - ETA: 0s - loss: 2.8238 - accuracy: 0.2528\n",
            "Epoch 2: accuracy did not improve from 0.25911\n",
            "\n",
            "Epoch 2: accuracy did not improve from 0.25911\n",
            "\n",
            "Epoch 2: accuracy did not improve from 0.25911\n",
            "\n",
            "Epoch 2: accuracy did not improve from 0.25911\n",
            " 64/121 [==============>...............] - ETA: 0s - loss: 2.7487 - accuracy: 0.2583\n",
            "Epoch 2: accuracy did not improve from 0.25911\n",
            "\n",
            "Epoch 2: accuracy did not improve from 0.25911\n",
            "\n",
            "Epoch 2: accuracy improved from 0.25911 to 0.26187, saving model to best_model.hdf5\n",
            " 79/121 [==================>...........] - ETA: 0s - loss: 2.7080 - accuracy: 0.2619\n",
            "Epoch 2: accuracy improved from 0.26187 to 0.26302, saving model to best_model.hdf5\n",
            "\n",
            "Epoch 2: accuracy improved from 0.26302 to 0.26475, saving model to best_model.hdf5\n",
            " 89/121 [=====================>........] - ETA: 0s - loss: 2.7151 - accuracy: 0.2647\n",
            "Epoch 2: accuracy improved from 0.26475 to 0.26762, saving model to best_model.hdf5\n",
            "\n",
            "Epoch 2: accuracy improved from 0.26762 to 0.27367, saving model to best_model.hdf5\n",
            " 99/121 [=======================>......] - ETA: 0s - loss: 2.7059 - accuracy: 0.2737\n",
            "Epoch 2: accuracy improved from 0.27367 to 0.27614, saving model to best_model.hdf5\n",
            "\n",
            "Epoch 2: accuracy improved from 0.27614 to 0.27924, saving model to best_model.hdf5\n",
            "110/121 [==========================>...] - ETA: 0s - loss: 2.6787 - accuracy: 0.2804\n",
            "Epoch 2: accuracy improved from 0.27924 to 0.28043, saving model to best_model.hdf5\n",
            "\n",
            "Epoch 2: accuracy improved from 0.28043 to 0.28072, saving model to best_model.hdf5\n",
            "121/121 [==============================] - 0s 4ms/step - loss: 2.6658 - accuracy: 0.2796\n",
            "Epoch 3/100\n",
            "  1/121 [..............................] - ETA: 1s - loss: 3.1192 - accuracy: 0.2188\n",
            "Epoch 3: accuracy improved from 0.28072 to 0.34375, saving model to best_model.hdf5\n",
            "\n",
            "Epoch 3: accuracy did not improve from 0.34375\n",
            "\n",
            "Epoch 3: accuracy did not improve from 0.34375\n",
            " 15/121 [==>...........................] - ETA: 0s - loss: 2.6480 - accuracy: 0.3521\n",
            "Epoch 3: accuracy improved from 0.34375 to 0.36111, saving model to best_model.hdf5\n",
            "\n",
            "Epoch 3: accuracy improved from 0.36111 to 0.36685, saving model to best_model.hdf5\n",
            " 27/121 [=====>........................] - ETA: 0s - loss: 2.4382 - accuracy: 0.3657\n",
            "Epoch 3: accuracy improved from 0.36685 to 0.36719, saving model to best_model.hdf5\n",
            "\n",
            "Epoch 3: accuracy did not improve from 0.36719\n",
            "\n",
            "Epoch 3: accuracy did not improve from 0.36719\n",
            "\n",
            "Epoch 3: accuracy did not improve from 0.36719\n",
            " 43/121 [=========>....................] - ETA: 0s - loss: 2.4345 - accuracy: 0.3648\n",
            "Epoch 3: accuracy improved from 0.36719 to 0.36914, saving model to best_model.hdf5\n",
            "\n",
            "Epoch 3: accuracy did not improve from 0.36914\n",
            "\n",
            "Epoch 3: accuracy improved from 0.36914 to 0.37392, saving model to best_model.hdf5\n",
            " 58/121 [=============>................] - ETA: 0s - loss: 2.4122 - accuracy: 0.3739\n",
            "Epoch 3: accuracy improved from 0.37392 to 0.37798, saving model to best_model.hdf5\n",
            "\n",
            "Epoch 3: accuracy improved from 0.37798 to 0.37822, saving model to best_model.hdf5\n",
            " 70/121 [================>.............] - ETA: 0s - loss: 2.4079 - accuracy: 0.3777\n",
            "Epoch 3: accuracy did not improve from 0.37822\n",
            "\n",
            "Epoch 3: accuracy did not improve from 0.37822\n",
            "\n",
            "Epoch 3: accuracy did not improve from 0.37822\n",
            "\n",
            "Epoch 3: accuracy did not improve from 0.37822\n",
            " 88/121 [====================>.........] - ETA: 0s - loss: 2.4379 - accuracy: 0.3722\n",
            "Epoch 3: accuracy did not improve from 0.37822\n",
            "\n",
            "Epoch 3: accuracy did not improve from 0.37822\n",
            "\n",
            "Epoch 3: accuracy did not improve from 0.37822\n",
            "104/121 [========================>.....] - ETA: 0s - loss: 2.4304 - accuracy: 0.3765\n",
            "Epoch 3: accuracy improved from 0.37822 to 0.37876, saving model to best_model.hdf5\n",
            "\n",
            "Epoch 3: accuracy improved from 0.37876 to 0.38164, saving model to best_model.hdf5\n",
            "114/121 [===========================>..] - ETA: 0s - loss: 2.4434 - accuracy: 0.3821\n",
            "Epoch 3: accuracy improved from 0.38164 to 0.38427, saving model to best_model.hdf5\n",
            "121/121 [==============================] - 0s 4ms/step - loss: 2.4486 - accuracy: 0.3844\n",
            "Epoch 4/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.7921 - accuracy: 0.3750\n",
            "Epoch 4: accuracy did not improve from 0.38427\n",
            "\n",
            "Epoch 4: accuracy improved from 0.38427 to 0.45982, saving model to best_model.hdf5\n",
            "\n",
            "Epoch 4: accuracy did not improve from 0.45982\n",
            " 12/121 [=>............................] - ETA: 0s - loss: 2.6369 - accuracy: 0.4193\n",
            "Epoch 4: accuracy did not improve from 0.45982\n",
            "\n",
            "Epoch 4: accuracy did not improve from 0.45982\n",
            "\n",
            "Epoch 4: accuracy did not improve from 0.45982\n",
            " 29/121 [======>.......................] - ETA: 0s - loss: 2.5189 - accuracy: 0.4084\n",
            "Epoch 4: accuracy did not improve from 0.45982\n",
            "\n",
            "Epoch 4: accuracy did not improve from 0.45982\n",
            "\n",
            "Epoch 4: accuracy did not improve from 0.45982\n",
            "\n",
            "Epoch 4: accuracy did not improve from 0.45982\n",
            " 48/121 [==========>...................] - ETA: 0s - loss: 2.4447 - accuracy: 0.4147\n",
            "Epoch 4: accuracy did not improve from 0.45982\n",
            "\n",
            "Epoch 4: accuracy did not improve from 0.45982\n",
            "\n",
            "Epoch 4: accuracy did not improve from 0.45982\n",
            "\n",
            "Epoch 4: accuracy did not improve from 0.45982\n",
            " 67/121 [===============>..............] - ETA: 0s - loss: 2.4256 - accuracy: 0.4226\n",
            "Epoch 4: accuracy did not improve from 0.45982\n",
            "\n",
            "Epoch 4: accuracy did not improve from 0.45982\n",
            "\n",
            "Epoch 4: accuracy did not improve from 0.45982\n",
            "\n",
            "Epoch 4: accuracy did not improve from 0.45982\n",
            " 87/121 [====================>.........] - ETA: 0s - loss: 2.4266 - accuracy: 0.4260\n",
            "Epoch 4: accuracy did not improve from 0.45982\n",
            "\n",
            "Epoch 4: accuracy did not improve from 0.45982\n",
            "\n",
            "Epoch 4: accuracy did not improve from 0.45982\n",
            "102/121 [========================>.....] - ETA: 0s - loss: 2.4304 - accuracy: 0.4277\n",
            "Epoch 4: accuracy did not improve from 0.45982\n",
            "\n",
            "Epoch 4: accuracy did not improve from 0.45982\n",
            "\n",
            "Epoch 4: accuracy did not improve from 0.45982\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.4055 - accuracy: 0.4374\n",
            "Epoch 5/100\n",
            "\n",
            "Epoch 5: accuracy did not improve from 0.45982\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.1231 - accuracy: 0.3438\n",
            "Epoch 5: accuracy did not improve from 0.45982\n",
            "\n",
            "Epoch 5: accuracy did not improve from 0.45982\n",
            " 13/121 [==>...........................] - ETA: 0s - loss: 2.4233 - accuracy: 0.4423\n",
            "Epoch 5: accuracy did not improve from 0.45982\n",
            "\n",
            "Epoch 5: accuracy did not improve from 0.45982\n",
            "\n",
            "Epoch 5: accuracy improved from 0.45982 to 0.47596, saving model to best_model.hdf5\n",
            " 26/121 [=====>........................] - ETA: 0s - loss: 2.4751 - accuracy: 0.4760\n",
            "Epoch 5: accuracy improved from 0.47596 to 0.47782, saving model to best_model.hdf5\n",
            "\n",
            "Epoch 5: accuracy improved from 0.47782 to 0.48785, saving model to best_model.hdf5\n",
            " 36/121 [=======>......................] - ETA: 0s - loss: 2.4661 - accuracy: 0.4878\n",
            "Epoch 5: accuracy did not improve from 0.48785\n",
            "\n",
            "Epoch 5: accuracy improved from 0.48785 to 0.49117, saving model to best_model.hdf5\n",
            " 50/121 [===========>..................] - ETA: 0s - loss: 2.4270 - accuracy: 0.4944\n",
            "Epoch 5: accuracy improved from 0.49117 to 0.49387, saving model to best_model.hdf5\n",
            "\n",
            "Epoch 5: accuracy did not improve from 0.49387\n",
            " 58/121 [=============>................] - ETA: 0s - loss: 2.4426 - accuracy: 0.4919\n",
            "Epoch 5: accuracy did not improve from 0.49387\n",
            "\n",
            "Epoch 5: accuracy improved from 0.49387 to 0.49621, saving model to best_model.hdf5\n",
            " 70/121 [================>.............] - ETA: 0s - loss: 2.4061 - accuracy: 0.4973\n",
            "Epoch 5: accuracy improved from 0.49621 to 0.49692, saving model to best_model.hdf5\n",
            "\n",
            "Epoch 5: accuracy did not improve from 0.49692\n",
            "\n",
            "Epoch 5: accuracy did not improve from 0.49692\n",
            " 81/121 [===================>..........] - ETA: 0s - loss: 2.4064 - accuracy: 0.4946\n",
            "Epoch 5: accuracy did not improve from 0.49692\n",
            "\n",
            "Epoch 5: accuracy improved from 0.49692 to 0.49966, saving model to best_model.hdf5\n",
            " 91/121 [=====================>........] - ETA: 0s - loss: 2.3934 - accuracy: 0.4997\n",
            "Epoch 5: accuracy improved from 0.49966 to 0.50130, saving model to best_model.hdf5\n",
            "\n",
            "Epoch 5: accuracy improved from 0.50130 to 0.50340, saving model to best_model.hdf5\n",
            "101/121 [========================>.....] - ETA: 0s - loss: 2.4114 - accuracy: 0.5034\n",
            "Epoch 5: accuracy improved from 0.50340 to 0.50796, saving model to best_model.hdf5\n",
            "\n",
            "Epoch 5: accuracy improved from 0.50796 to 0.50873, saving model to best_model.hdf5\n",
            "111/121 [==========================>...] - ETA: 0s - loss: 2.3878 - accuracy: 0.5087\n",
            "Epoch 5: accuracy improved from 0.50873 to 0.50916, saving model to best_model.hdf5\n",
            "\n",
            "Epoch 5: accuracy improved from 0.50916 to 0.51039, saving model to best_model.hdf5\n",
            "121/121 [==============================] - 1s 5ms/step - loss: 2.3958 - accuracy: 0.5104\n",
            "Epoch 6/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 3.3411 - accuracy: 0.4688\n",
            "Epoch 6: accuracy did not improve from 0.51039\n",
            "\n",
            "Epoch 6: accuracy improved from 0.51039 to 0.51875, saving model to best_model.hdf5\n",
            " 14/121 [==>...........................] - ETA: 0s - loss: 2.4361 - accuracy: 0.5424\n",
            "Epoch 6: accuracy improved from 0.51875 to 0.53958, saving model to best_model.hdf5\n",
            "\n",
            "Epoch 6: accuracy did not improve from 0.53958\n",
            "\n",
            "Epoch 6: accuracy improved from 0.53958 to 0.54375, saving model to best_model.hdf5\n",
            " 25/121 [=====>........................] - ETA: 0s - loss: 2.4593 - accuracy: 0.5437\n",
            "Epoch 6: accuracy improved from 0.54375 to 0.54479, saving model to best_model.hdf5\n",
            "\n",
            "Epoch 6: accuracy improved from 0.54479 to 0.54821, saving model to best_model.hdf5\n",
            " 35/121 [=======>......................] - ETA: 0s - loss: 2.4180 - accuracy: 0.5482\n",
            "Epoch 6: accuracy improved from 0.54821 to 0.55625, saving model to best_model.hdf5\n",
            "\n",
            "Epoch 6: accuracy did not improve from 0.55625\n",
            " 49/121 [===========>..................] - ETA: 0s - loss: 2.4030 - accuracy: 0.5472\n",
            "Epoch 6: accuracy did not improve from 0.55625\n",
            "\n",
            "Epoch 6: accuracy did not improve from 0.55625\n",
            "\n",
            "Epoch 6: accuracy did not improve from 0.55625\n",
            "\n",
            "Epoch 6: accuracy did not improve from 0.55625\n",
            " 67/121 [===============>..............] - ETA: 0s - loss: 2.3815 - accuracy: 0.5424\n",
            "Epoch 6: accuracy did not improve from 0.55625\n",
            "\n",
            "Epoch 6: accuracy did not improve from 0.55625\n",
            "\n",
            "Epoch 6: accuracy did not improve from 0.55625\n",
            "\n",
            "Epoch 6: accuracy did not improve from 0.55625\n",
            " 85/121 [====================>.........] - ETA: 0s - loss: 2.4088 - accuracy: 0.5401\n",
            "Epoch 6: accuracy did not improve from 0.55625\n",
            "\n",
            "Epoch 6: accuracy did not improve from 0.55625\n",
            "\n",
            "Epoch 6: accuracy did not improve from 0.55625\n",
            "\n",
            "Epoch 6: accuracy did not improve from 0.55625\n",
            "105/121 [=========================>....] - ETA: 0s - loss: 2.3869 - accuracy: 0.5393\n",
            "Epoch 6: accuracy did not improve from 0.55625\n",
            "\n",
            "Epoch 6: accuracy did not improve from 0.55625\n",
            "\n",
            "Epoch 6: accuracy did not improve from 0.55625\n",
            "121/121 [==============================] - 0s 4ms/step - loss: 2.3914 - accuracy: 0.5377\n",
            "Epoch 7/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.7698 - accuracy: 0.5000\n",
            "Epoch 7: accuracy did not improve from 0.55625\n",
            "\n",
            "Epoch 7: accuracy did not improve from 0.55625\n",
            "\n",
            "Epoch 7: accuracy did not improve from 0.55625\n",
            " 15/121 [==>...........................] - ETA: 0s - loss: 2.5282 - accuracy: 0.5229\n",
            "Epoch 7: accuracy did not improve from 0.55625\n",
            "\n",
            "Epoch 7: accuracy did not improve from 0.55625\n",
            "\n",
            "Epoch 7: accuracy did not improve from 0.55625\n",
            "\n",
            "Epoch 7: accuracy did not improve from 0.55625\n",
            " 36/121 [=======>......................] - ETA: 0s - loss: 2.4505 - accuracy: 0.5286\n",
            "Epoch 7: accuracy did not improve from 0.55625\n",
            "\n",
            "Epoch 7: accuracy did not improve from 0.55625\n",
            "\n",
            "Epoch 7: accuracy did not improve from 0.55625\n",
            " 49/121 [===========>..................] - ETA: 0s - loss: 2.4225 - accuracy: 0.5395\n",
            "Epoch 7: accuracy did not improve from 0.55625\n",
            "\n",
            "Epoch 7: accuracy did not improve from 0.55625\n",
            "\n",
            "Epoch 7: accuracy did not improve from 0.55625\n",
            " 65/121 [===============>..............] - ETA: 0s - loss: 2.4817 - accuracy: 0.5389\n",
            "Epoch 7: accuracy did not improve from 0.55625\n",
            "\n",
            "Epoch 7: accuracy did not improve from 0.55625\n",
            "\n",
            "Epoch 7: accuracy did not improve from 0.55625\n",
            " 79/121 [==================>...........] - ETA: 0s - loss: 2.4171 - accuracy: 0.5451\n",
            "Epoch 7: accuracy did not improve from 0.55625\n",
            "\n",
            "Epoch 7: accuracy did not improve from 0.55625\n",
            "\n",
            "Epoch 7: accuracy did not improve from 0.55625\n",
            " 94/121 [======================>.......] - ETA: 0s - loss: 2.3969 - accuracy: 0.5442\n",
            "Epoch 7: accuracy did not improve from 0.55625\n",
            "\n",
            "Epoch 7: accuracy did not improve from 0.55625\n",
            "\n",
            "Epoch 7: accuracy did not improve from 0.55625\n",
            "109/121 [==========================>...] - ETA: 0s - loss: 2.3985 - accuracy: 0.5407\n",
            "Epoch 7: accuracy did not improve from 0.55625\n",
            "\n",
            "Epoch 7: accuracy did not improve from 0.55625\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.3886 - accuracy: 0.5465\n",
            "Epoch 8/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.4862 - accuracy: 0.6250\n",
            "Epoch 8: accuracy did not improve from 0.55625\n",
            "\n",
            "Epoch 8: accuracy did not improve from 0.55625\n",
            "\n",
            "Epoch 8: accuracy improved from 0.55625 to 0.56731, saving model to best_model.hdf5\n",
            " 13/121 [==>...........................] - ETA: 0s - loss: 2.1770 - accuracy: 0.5673\n",
            "Epoch 8: accuracy did not improve from 0.56731\n",
            "\n",
            "Epoch 8: accuracy did not improve from 0.56731\n",
            "\n",
            "Epoch 8: accuracy did not improve from 0.56731\n",
            " 29/121 [======>.......................] - ETA: 0s - loss: 2.3030 - accuracy: 0.5636\n",
            "Epoch 8: accuracy did not improve from 0.56731\n",
            "\n",
            "Epoch 8: accuracy did not improve from 0.56731\n",
            "\n",
            "Epoch 8: accuracy did not improve from 0.56731\n",
            " 44/121 [=========>....................] - ETA: 0s - loss: 2.3356 - accuracy: 0.5533\n",
            "Epoch 8: accuracy did not improve from 0.56731\n",
            "\n",
            "Epoch 8: accuracy did not improve from 0.56731\n",
            "\n",
            "Epoch 8: accuracy did not improve from 0.56731\n",
            " 62/121 [==============>...............] - ETA: 0s - loss: 2.3255 - accuracy: 0.5464\n",
            "Epoch 8: accuracy did not improve from 0.56731\n",
            "\n",
            "Epoch 8: accuracy did not improve from 0.56731\n",
            "\n",
            "Epoch 8: accuracy did not improve from 0.56731\n",
            "\n",
            "Epoch 8: accuracy did not improve from 0.56731\n",
            " 78/121 [==================>...........] - ETA: 0s - loss: 2.3609 - accuracy: 0.5473\n",
            "Epoch 8: accuracy did not improve from 0.56731\n",
            "\n",
            "Epoch 8: accuracy did not improve from 0.56731\n",
            "\n",
            "Epoch 8: accuracy did not improve from 0.56731\n",
            " 94/121 [======================>.......] - ETA: 0s - loss: 2.3775 - accuracy: 0.5449\n",
            "Epoch 8: accuracy did not improve from 0.56731\n",
            "\n",
            "Epoch 8: accuracy did not improve from 0.56731\n",
            "\n",
            "Epoch 8: accuracy did not improve from 0.56731\n",
            "112/121 [==========================>...] - ETA: 0s - loss: 2.3920 - accuracy: 0.5483\n",
            "Epoch 8: accuracy did not improve from 0.56731\n",
            "\n",
            "Epoch 8: accuracy did not improve from 0.56731\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.3868 - accuracy: 0.5509\n",
            "Epoch 9/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.9567 - accuracy: 0.6875\n",
            "Epoch 9: accuracy improved from 0.56731 to 0.57812, saving model to best_model.hdf5\n",
            "\n",
            "Epoch 9: accuracy did not improve from 0.57812\n",
            "\n",
            "Epoch 9: accuracy did not improve from 0.57812\n",
            " 13/121 [==>...........................] - ETA: 0s - loss: 2.4112 - accuracy: 0.5312\n",
            "Epoch 9: accuracy did not improve from 0.57812\n",
            "\n",
            "Epoch 9: accuracy did not improve from 0.57812\n",
            "\n",
            "Epoch 9: accuracy did not improve from 0.57812\n",
            " 30/121 [======>.......................] - ETA: 0s - loss: 2.4202 - accuracy: 0.5406\n",
            "Epoch 9: accuracy did not improve from 0.57812\n",
            "\n",
            "Epoch 9: accuracy did not improve from 0.57812\n",
            "\n",
            "Epoch 9: accuracy did not improve from 0.57812\n",
            "\n",
            "Epoch 9: accuracy did not improve from 0.57812\n",
            " 47/121 [==========>...................] - ETA: 0s - loss: 2.3211 - accuracy: 0.5532\n",
            "Epoch 9: accuracy did not improve from 0.57812\n",
            "\n",
            "Epoch 9: accuracy did not improve from 0.57812\n",
            "\n",
            "Epoch 9: accuracy did not improve from 0.57812\n",
            " 64/121 [==============>...............] - ETA: 0s - loss: 2.3445 - accuracy: 0.5571\n",
            "Epoch 9: accuracy did not improve from 0.57812\n",
            "\n",
            "Epoch 9: accuracy did not improve from 0.57812\n",
            "\n",
            "Epoch 9: accuracy did not improve from 0.57812\n",
            " 77/121 [==================>...........] - ETA: 0s - loss: 2.3331 - accuracy: 0.5605\n",
            "Epoch 9: accuracy did not improve from 0.57812\n",
            "\n",
            "Epoch 9: accuracy did not improve from 0.57812\n",
            "\n",
            "Epoch 9: accuracy did not improve from 0.57812\n",
            " 92/121 [=====================>........] - ETA: 0s - loss: 2.3412 - accuracy: 0.5567\n",
            "Epoch 9: accuracy did not improve from 0.57812\n",
            "\n",
            "Epoch 9: accuracy did not improve from 0.57812\n",
            "\n",
            "Epoch 9: accuracy did not improve from 0.57812\n",
            "110/121 [==========================>...] - ETA: 0s - loss: 2.3818 - accuracy: 0.5568\n",
            "Epoch 9: accuracy did not improve from 0.57812\n",
            "\n",
            "Epoch 9: accuracy did not improve from 0.57812\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.3853 - accuracy: 0.5564\n",
            "Epoch 10/100\n",
            "\n",
            "Epoch 10: accuracy did not improve from 0.57812\n",
            "  1/121 [..............................] - ETA: 1s - loss: 2.3976 - accuracy: 0.5625\n",
            "Epoch 10: accuracy did not improve from 0.57812\n",
            "\n",
            "Epoch 10: accuracy did not improve from 0.57812\n",
            " 13/121 [==>...........................] - ETA: 0s - loss: 2.5341 - accuracy: 0.5409\n",
            "Epoch 10: accuracy did not improve from 0.57812\n",
            "\n",
            "Epoch 10: accuracy did not improve from 0.57812\n",
            "\n",
            "Epoch 10: accuracy did not improve from 0.57812\n",
            " 26/121 [=====>........................] - ETA: 0s - loss: 2.4319 - accuracy: 0.5337\n",
            "Epoch 10: accuracy did not improve from 0.57812\n",
            "\n",
            "Epoch 10: accuracy did not improve from 0.57812\n",
            "\n",
            "Epoch 10: accuracy did not improve from 0.57812\n",
            " 41/121 [=========>....................] - ETA: 0s - loss: 2.4314 - accuracy: 0.5396\n",
            "Epoch 10: accuracy did not improve from 0.57812\n",
            "\n",
            "Epoch 10: accuracy did not improve from 0.57812\n",
            " 52/121 [===========>..................] - ETA: 0s - loss: 2.3981 - accuracy: 0.5553\n",
            "Epoch 10: accuracy did not improve from 0.57812\n",
            "\n",
            "Epoch 10: accuracy did not improve from 0.57812\n",
            "\n",
            "Epoch 10: accuracy did not improve from 0.57812\n",
            " 68/121 [===============>..............] - ETA: 0s - loss: 2.3912 - accuracy: 0.5630\n",
            "Epoch 10: accuracy did not improve from 0.57812\n",
            "\n",
            "Epoch 10: accuracy did not improve from 0.57812\n",
            "\n",
            "Epoch 10: accuracy did not improve from 0.57812\n",
            " 82/121 [===================>..........] - ETA: 0s - loss: 2.3847 - accuracy: 0.5675\n",
            "Epoch 10: accuracy did not improve from 0.57812\n",
            "\n",
            "Epoch 10: accuracy did not improve from 0.57812\n",
            "\n",
            "Epoch 10: accuracy did not improve from 0.57812\n",
            " 96/121 [======================>.......] - ETA: 0s - loss: 2.3841 - accuracy: 0.5710\n",
            "Epoch 10: accuracy did not improve from 0.57812\n",
            "\n",
            "Epoch 10: accuracy did not improve from 0.57812\n",
            "\n",
            "Epoch 10: accuracy did not improve from 0.57812\n",
            "112/121 [==========================>...] - ETA: 0s - loss: 2.3732 - accuracy: 0.5770\n",
            "Epoch 10: accuracy did not improve from 0.57812\n",
            "\n",
            "Epoch 10: accuracy did not improve from 0.57812\n",
            "121/121 [==============================] - 0s 4ms/step - loss: 2.3841 - accuracy: 0.5764\n",
            "Epoch 11/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.1017 - accuracy: 0.5625\n",
            "Epoch 11: accuracy did not improve from 0.57812\n",
            "\n",
            "Epoch 11: accuracy improved from 0.57812 to 0.61875, saving model to best_model.hdf5\n",
            " 14/121 [==>...........................] - ETA: 0s - loss: 2.1487 - accuracy: 0.6272\n",
            "Epoch 11: accuracy improved from 0.61875 to 0.63125, saving model to best_model.hdf5\n",
            "\n",
            "Epoch 11: accuracy did not improve from 0.63125\n",
            "\n",
            "Epoch 11: accuracy did not improve from 0.63125\n",
            " 26/121 [=====>........................] - ETA: 0s - loss: 2.2395 - accuracy: 0.6130\n",
            "Epoch 11: accuracy did not improve from 0.63125\n",
            "\n",
            "Epoch 11: accuracy did not improve from 0.63125\n",
            "\n",
            "Epoch 11: accuracy did not improve from 0.63125\n",
            " 43/121 [=========>....................] - ETA: 0s - loss: 2.2848 - accuracy: 0.5959\n",
            "Epoch 11: accuracy did not improve from 0.63125\n",
            "\n",
            "Epoch 11: accuracy did not improve from 0.63125\n",
            "\n",
            "Epoch 11: accuracy did not improve from 0.63125\n",
            " 57/121 [=============>................] - ETA: 0s - loss: 2.3128 - accuracy: 0.5987\n",
            "Epoch 11: accuracy did not improve from 0.63125\n",
            "\n",
            "Epoch 11: accuracy did not improve from 0.63125\n",
            "\n",
            "Epoch 11: accuracy did not improve from 0.63125\n",
            " 70/121 [================>.............] - ETA: 0s - loss: 2.3630 - accuracy: 0.6000\n",
            "Epoch 11: accuracy did not improve from 0.63125\n",
            "\n",
            "Epoch 11: accuracy did not improve from 0.63125\n",
            "\n",
            "Epoch 11: accuracy did not improve from 0.63125\n",
            "\n",
            "Epoch 11: accuracy did not improve from 0.63125\n",
            " 90/121 [=====================>........] - ETA: 0s - loss: 2.4156 - accuracy: 0.5910\n",
            "Epoch 11: accuracy did not improve from 0.63125\n",
            "\n",
            "Epoch 11: accuracy did not improve from 0.63125\n",
            "\n",
            "Epoch 11: accuracy did not improve from 0.63125\n",
            "109/121 [==========================>...] - ETA: 0s - loss: 2.3876 - accuracy: 0.5909\n",
            "Epoch 11: accuracy did not improve from 0.63125\n",
            "\n",
            "Epoch 11: accuracy did not improve from 0.63125\n",
            "\n",
            "Epoch 11: accuracy did not improve from 0.63125\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.3833 - accuracy: 0.5881\n",
            "Epoch 12/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.1958 - accuracy: 0.5312\n",
            "Epoch 12: accuracy did not improve from 0.63125\n",
            "\n",
            "Epoch 12: accuracy did not improve from 0.63125\n",
            "\n",
            "Epoch 12: accuracy did not improve from 0.63125\n",
            " 16/121 [==>...........................] - ETA: 0s - loss: 2.3739 - accuracy: 0.5840\n",
            "Epoch 12: accuracy did not improve from 0.63125\n",
            "\n",
            "Epoch 12: accuracy did not improve from 0.63125\n",
            "\n",
            "Epoch 12: accuracy did not improve from 0.63125\n",
            "\n",
            "Epoch 12: accuracy did not improve from 0.63125\n",
            " 34/121 [=======>......................] - ETA: 0s - loss: 2.4785 - accuracy: 0.5671\n",
            "Epoch 12: accuracy did not improve from 0.63125\n",
            "\n",
            "Epoch 12: accuracy did not improve from 0.63125\n",
            "\n",
            "Epoch 12: accuracy did not improve from 0.63125\n",
            " 53/121 [============>.................] - ETA: 0s - loss: 2.3931 - accuracy: 0.5849\n",
            "Epoch 12: accuracy did not improve from 0.63125\n",
            "\n",
            "Epoch 12: accuracy did not improve from 0.63125\n",
            "\n",
            "Epoch 12: accuracy did not improve from 0.63125\n",
            "\n",
            "Epoch 12: accuracy did not improve from 0.63125\n",
            " 72/121 [================>.............] - ETA: 0s - loss: 2.4081 - accuracy: 0.5855\n",
            "Epoch 12: accuracy did not improve from 0.63125\n",
            "\n",
            "Epoch 12: accuracy did not improve from 0.63125\n",
            "\n",
            "Epoch 12: accuracy did not improve from 0.63125\n",
            "\n",
            "Epoch 12: accuracy did not improve from 0.63125\n",
            " 89/121 [=====================>........] - ETA: 0s - loss: 2.3908 - accuracy: 0.5888\n",
            "Epoch 12: accuracy did not improve from 0.63125\n",
            "\n",
            "Epoch 12: accuracy did not improve from 0.63125\n",
            "\n",
            "Epoch 12: accuracy did not improve from 0.63125\n",
            "108/121 [=========================>....] - ETA: 0s - loss: 2.3765 - accuracy: 0.5932\n",
            "Epoch 12: accuracy did not improve from 0.63125\n",
            "\n",
            "Epoch 12: accuracy did not improve from 0.63125\n",
            "\n",
            "Epoch 12: accuracy did not improve from 0.63125\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.3827 - accuracy: 0.5917\n",
            "Epoch 13/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 3.1479 - accuracy: 0.5312\n",
            "Epoch 13: accuracy did not improve from 0.63125\n",
            "\n",
            "Epoch 13: accuracy did not improve from 0.63125\n",
            "\n",
            "Epoch 13: accuracy did not improve from 0.63125\n",
            "\n",
            "Epoch 13: accuracy did not improve from 0.63125\n",
            " 18/121 [===>..........................] - ETA: 0s - loss: 2.7608 - accuracy: 0.5694\n",
            "Epoch 13: accuracy did not improve from 0.63125\n",
            "\n",
            "Epoch 13: accuracy did not improve from 0.63125\n",
            "\n",
            "Epoch 13: accuracy did not improve from 0.63125\n",
            " 36/121 [=======>......................] - ETA: 0s - loss: 2.5015 - accuracy: 0.5738\n",
            "Epoch 13: accuracy did not improve from 0.63125\n",
            "\n",
            "Epoch 13: accuracy did not improve from 0.63125\n",
            "\n",
            "Epoch 13: accuracy did not improve from 0.63125\n",
            "\n",
            "Epoch 13: accuracy did not improve from 0.63125\n",
            " 54/121 [============>.................] - ETA: 0s - loss: 2.4997 - accuracy: 0.5799\n",
            "Epoch 13: accuracy did not improve from 0.63125\n",
            "\n",
            "Epoch 13: accuracy did not improve from 0.63125\n",
            "\n",
            "Epoch 13: accuracy did not improve from 0.63125\n",
            " 72/121 [================>.............] - ETA: 0s - loss: 2.4566 - accuracy: 0.5842\n",
            "Epoch 13: accuracy did not improve from 0.63125\n",
            "\n",
            "Epoch 13: accuracy did not improve from 0.63125\n",
            "\n",
            "Epoch 13: accuracy did not improve from 0.63125\n",
            "\n",
            "Epoch 13: accuracy did not improve from 0.63125\n",
            " 88/121 [====================>.........] - ETA: 0s - loss: 2.4142 - accuracy: 0.5895\n",
            "Epoch 13: accuracy did not improve from 0.63125\n",
            "\n",
            "Epoch 13: accuracy did not improve from 0.63125\n",
            "\n",
            "Epoch 13: accuracy did not improve from 0.63125\n",
            "103/121 [========================>.....] - ETA: 0s - loss: 2.3996 - accuracy: 0.5941\n",
            "Epoch 13: accuracy did not improve from 0.63125\n",
            "\n",
            "Epoch 13: accuracy did not improve from 0.63125\n",
            "\n",
            "Epoch 13: accuracy did not improve from 0.63125\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.3821 - accuracy: 0.5969\n",
            "Epoch 14/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 1.6214 - accuracy: 0.6562\n",
            "Epoch 14: accuracy did not improve from 0.63125\n",
            "\n",
            "Epoch 14: accuracy improved from 0.63125 to 0.65625, saving model to best_model.hdf5\n",
            " 11/121 [=>............................] - ETA: 0s - loss: 2.1851 - accuracy: 0.6335\n",
            "Epoch 14: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 14: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 14: accuracy did not improve from 0.65625\n",
            " 25/121 [=====>........................] - ETA: 0s - loss: 2.3539 - accuracy: 0.5913\n",
            "Epoch 14: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 14: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 14: accuracy did not improve from 0.65625\n",
            " 38/121 [========>.....................] - ETA: 0s - loss: 2.4118 - accuracy: 0.5987\n",
            "Epoch 14: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 14: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 14: accuracy did not improve from 0.65625\n",
            " 52/121 [===========>..................] - ETA: 0s - loss: 2.4338 - accuracy: 0.5962\n",
            "Epoch 14: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 14: accuracy did not improve from 0.65625\n",
            " 65/121 [===============>..............] - ETA: 0s - loss: 2.4240 - accuracy: 0.5986\n",
            "Epoch 14: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 14: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 14: accuracy did not improve from 0.65625\n",
            " 77/121 [==================>...........] - ETA: 0s - loss: 2.3966 - accuracy: 0.5978\n",
            "Epoch 14: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 14: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 14: accuracy did not improve from 0.65625\n",
            " 92/121 [=====================>........] - ETA: 0s - loss: 2.3802 - accuracy: 0.5978\n",
            "Epoch 14: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 14: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 14: accuracy did not improve from 0.65625\n",
            "111/121 [==========================>...] - ETA: 0s - loss: 2.3722 - accuracy: 0.6033\n",
            "Epoch 14: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 14: accuracy did not improve from 0.65625\n",
            "121/121 [==============================] - 0s 4ms/step - loss: 2.3817 - accuracy: 0.6014\n",
            "Epoch 15/100\n",
            "\n",
            "Epoch 15: accuracy did not improve from 0.65625\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.1928 - accuracy: 0.6562\n",
            "Epoch 15: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 15: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 15: accuracy did not improve from 0.65625\n",
            " 17/121 [===>..........................] - ETA: 0s - loss: 2.3732 - accuracy: 0.6176\n",
            "Epoch 15: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 15: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 15: accuracy did not improve from 0.65625\n",
            " 32/121 [======>.......................] - ETA: 0s - loss: 2.4054 - accuracy: 0.6035\n",
            "Epoch 15: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 15: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 15: accuracy did not improve from 0.65625\n",
            " 47/121 [==========>...................] - ETA: 0s - loss: 2.4146 - accuracy: 0.6051\n",
            "Epoch 15: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 15: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 15: accuracy did not improve from 0.65625\n",
            " 63/121 [==============>...............] - ETA: 0s - loss: 2.3961 - accuracy: 0.6062\n",
            "Epoch 15: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 15: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 15: accuracy did not improve from 0.65625\n",
            " 80/121 [==================>...........] - ETA: 0s - loss: 2.4339 - accuracy: 0.6066\n",
            "Epoch 15: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 15: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 15: accuracy did not improve from 0.65625\n",
            " 92/121 [=====================>........] - ETA: 0s - loss: 2.3942 - accuracy: 0.6084\n",
            "Epoch 15: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 15: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 15: accuracy did not improve from 0.65625\n",
            "106/121 [=========================>....] - ETA: 0s - loss: 2.3678 - accuracy: 0.6085\n",
            "Epoch 15: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 15: accuracy did not improve from 0.65625\n",
            "120/121 [============================>.] - ETA: 0s - loss: 2.3840 - accuracy: 0.6070\n",
            "Epoch 15: accuracy did not improve from 0.65625\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.3815 - accuracy: 0.6071\n",
            "Epoch 16/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 1.4296 - accuracy: 0.7812\n",
            "Epoch 16: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 16: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 16: accuracy did not improve from 0.65625\n",
            " 19/121 [===>..........................] - ETA: 0s - loss: 2.4245 - accuracy: 0.6036\n",
            "Epoch 16: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 16: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 16: accuracy did not improve from 0.65625\n",
            " 33/121 [=======>......................] - ETA: 0s - loss: 2.3380 - accuracy: 0.6080\n",
            "Epoch 16: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 16: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 16: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 16: accuracy did not improve from 0.65625\n",
            " 51/121 [===========>..................] - ETA: 0s - loss: 2.4383 - accuracy: 0.6029\n",
            "Epoch 16: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 16: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 16: accuracy did not improve from 0.65625\n",
            " 67/121 [===============>..............] - ETA: 0s - loss: 2.4382 - accuracy: 0.6031\n",
            "Epoch 16: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 16: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 16: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 16: accuracy did not improve from 0.65625\n",
            " 87/121 [====================>.........] - ETA: 0s - loss: 2.4158 - accuracy: 0.6045\n",
            "Epoch 16: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 16: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 16: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 16: accuracy did not improve from 0.65625\n",
            "106/121 [=========================>....] - ETA: 0s - loss: 2.3848 - accuracy: 0.6088\n",
            "Epoch 16: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 16: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 16: accuracy did not improve from 0.65625\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.3813 - accuracy: 0.6110\n",
            "Epoch 17/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.1921 - accuracy: 0.5938\n",
            "Epoch 17: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 17: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 17: accuracy did not improve from 0.65625\n",
            " 15/121 [==>...........................] - ETA: 0s - loss: 2.2943 - accuracy: 0.6125\n",
            "Epoch 17: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 17: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 17: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 17: accuracy did not improve from 0.65625\n",
            " 34/121 [=======>......................] - ETA: 0s - loss: 2.3499 - accuracy: 0.6296\n",
            "Epoch 17: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 17: accuracy did not improve from 0.65625\n",
            " 47/121 [==========>...................] - ETA: 0s - loss: 2.3555 - accuracy: 0.6243\n",
            "Epoch 17: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 17: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 17: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 17: accuracy did not improve from 0.65625\n",
            " 66/121 [===============>..............] - ETA: 0s - loss: 2.3881 - accuracy: 0.6184\n",
            "Epoch 17: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 17: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 17: accuracy did not improve from 0.65625\n",
            " 79/121 [==================>...........] - ETA: 0s - loss: 2.3887 - accuracy: 0.6147\n",
            "Epoch 17: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 17: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 17: accuracy did not improve from 0.65625\n",
            " 94/121 [======================>.......] - ETA: 0s - loss: 2.3706 - accuracy: 0.6180\n",
            "Epoch 17: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 17: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 17: accuracy did not improve from 0.65625\n",
            "110/121 [==========================>...] - ETA: 0s - loss: 2.3690 - accuracy: 0.6142\n",
            "Epoch 17: accuracy did not improve from 0.65625\n",
            "\n",
            "Epoch 17: accuracy did not improve from 0.65625\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.3811 - accuracy: 0.6143\n",
            "Epoch 18/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 1.8108 - accuracy: 0.7188\n",
            "Epoch 18: accuracy improved from 0.65625 to 0.72917, saving model to best_model.hdf5\n",
            "\n",
            "Epoch 18: accuracy did not improve from 0.72917\n",
            " 11/121 [=>............................] - ETA: 0s - loss: 2.3228 - accuracy: 0.6562\n",
            "Epoch 18: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 18: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 18: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 18: accuracy did not improve from 0.72917\n",
            " 28/121 [=====>........................] - ETA: 0s - loss: 2.5232 - accuracy: 0.6161\n",
            "Epoch 18: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 18: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 18: accuracy did not improve from 0.72917\n",
            " 44/121 [=========>....................] - ETA: 0s - loss: 2.3966 - accuracy: 0.6222\n",
            "Epoch 18: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 18: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 18: accuracy did not improve from 0.72917\n",
            " 61/121 [==============>...............] - ETA: 0s - loss: 2.4041 - accuracy: 0.6240\n",
            "Epoch 18: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 18: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 18: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 18: accuracy did not improve from 0.72917\n",
            " 78/121 [==================>...........] - ETA: 0s - loss: 2.3630 - accuracy: 0.6226\n",
            "Epoch 18: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 18: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 18: accuracy did not improve from 0.72917\n",
            " 94/121 [======================>.......] - ETA: 0s - loss: 2.3826 - accuracy: 0.6177\n",
            "Epoch 18: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 18: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 18: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 18: accuracy did not improve from 0.72917\n",
            "113/121 [===========================>..] - ETA: 0s - loss: 2.3718 - accuracy: 0.6173\n",
            "Epoch 18: accuracy did not improve from 0.72917\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.3810 - accuracy: 0.6175\n",
            "Epoch 19/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.9593 - accuracy: 0.6250\n",
            "Epoch 19: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 19: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 19: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 19: accuracy did not improve from 0.72917\n",
            " 17/121 [===>..........................] - ETA: 0s - loss: 2.4962 - accuracy: 0.5919\n",
            "Epoch 19: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 19: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 19: accuracy did not improve from 0.72917\n",
            " 35/121 [=======>......................] - ETA: 0s - loss: 2.4900 - accuracy: 0.6089\n",
            "Epoch 19: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 19: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 19: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 19: accuracy did not improve from 0.72917\n",
            " 52/121 [===========>..................] - ETA: 0s - loss: 2.4258 - accuracy: 0.6118\n",
            "Epoch 19: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 19: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 19: accuracy did not improve from 0.72917\n",
            " 67/121 [===============>..............] - ETA: 0s - loss: 2.4278 - accuracy: 0.6124\n",
            "Epoch 19: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 19: accuracy did not improve from 0.72917\n",
            " 78/121 [==================>...........] - ETA: 0s - loss: 2.3824 - accuracy: 0.6194\n",
            "Epoch 19: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 19: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 19: accuracy did not improve from 0.72917\n",
            " 93/121 [======================>.......] - ETA: 0s - loss: 2.4052 - accuracy: 0.6200\n",
            "Epoch 19: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 19: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 19: accuracy did not improve from 0.72917\n",
            "108/121 [=========================>....] - ETA: 0s - loss: 2.3986 - accuracy: 0.6195\n",
            "Epoch 19: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 19: accuracy did not improve from 0.72917\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.3810 - accuracy: 0.6214\n",
            "Epoch 20/100\n",
            "\n",
            "Epoch 20: accuracy did not improve from 0.72917\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.5777 - accuracy: 0.5312\n",
            "Epoch 20: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 20: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 20: accuracy did not improve from 0.72917\n",
            " 16/121 [==>...........................] - ETA: 0s - loss: 2.2460 - accuracy: 0.6270\n",
            "Epoch 20: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 20: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 20: accuracy did not improve from 0.72917\n",
            " 33/121 [=======>......................] - ETA: 0s - loss: 2.4008 - accuracy: 0.6241\n",
            "Epoch 20: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 20: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 20: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 20: accuracy did not improve from 0.72917\n",
            " 51/121 [===========>..................] - ETA: 0s - loss: 2.3947 - accuracy: 0.6256\n",
            "Epoch 20: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 20: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 20: accuracy did not improve from 0.72917\n",
            " 66/121 [===============>..............] - ETA: 0s - loss: 2.3793 - accuracy: 0.6217\n",
            "Epoch 20: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 20: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 20: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 20: accuracy did not improve from 0.72917\n",
            " 86/121 [====================>.........] - ETA: 0s - loss: 2.3869 - accuracy: 0.6239\n",
            "Epoch 20: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 20: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 20: accuracy did not improve from 0.72917\n",
            "102/121 [========================>.....] - ETA: 0s - loss: 2.3892 - accuracy: 0.6250\n",
            "Epoch 20: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 20: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 20: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 20: accuracy did not improve from 0.72917\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.3809 - accuracy: 0.6221\n",
            "Epoch 21/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 3.1452 - accuracy: 0.4688\n",
            "Epoch 21: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 21: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 21: accuracy did not improve from 0.72917\n",
            " 17/121 [===>..........................] - ETA: 0s - loss: 2.4618 - accuracy: 0.5993\n",
            "Epoch 21: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 21: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 21: accuracy did not improve from 0.72917\n",
            " 34/121 [=======>......................] - ETA: 0s - loss: 2.3188 - accuracy: 0.6140\n",
            "Epoch 21: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 21: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 21: accuracy did not improve from 0.72917\n",
            " 48/121 [==========>...................] - ETA: 0s - loss: 2.3616 - accuracy: 0.6191\n",
            "Epoch 21: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 21: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 21: accuracy did not improve from 0.72917\n",
            " 64/121 [==============>...............] - ETA: 0s - loss: 2.3716 - accuracy: 0.6147\n",
            "Epoch 21: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 21: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 21: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 21: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 21: accuracy did not improve from 0.72917\n",
            " 85/121 [====================>.........] - ETA: 0s - loss: 2.3857 - accuracy: 0.6151\n",
            "Epoch 21: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 21: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 21: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 21: accuracy did not improve from 0.72917\n",
            "105/121 [=========================>....] - ETA: 0s - loss: 2.3790 - accuracy: 0.6223\n",
            "Epoch 21: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 21: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 21: accuracy did not improve from 0.72917\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.3809 - accuracy: 0.6229\n",
            "Epoch 22/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.0968 - accuracy: 0.6875\n",
            "Epoch 22: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 22: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 22: accuracy did not improve from 0.72917\n",
            " 14/121 [==>...........................] - ETA: 0s - loss: 2.2065 - accuracy: 0.6540\n",
            "Epoch 22: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 22: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 22: accuracy did not improve from 0.72917\n",
            " 29/121 [======>.......................] - ETA: 0s - loss: 2.3015 - accuracy: 0.6282\n",
            "Epoch 22: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 22: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 22: accuracy did not improve from 0.72917\n",
            " 44/121 [=========>....................] - ETA: 0s - loss: 2.3662 - accuracy: 0.6236\n",
            "Epoch 22: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 22: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 22: accuracy did not improve from 0.72917\n",
            " 62/121 [==============>...............] - ETA: 0s - loss: 2.3805 - accuracy: 0.6255\n",
            "Epoch 22: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 22: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 22: accuracy did not improve from 0.72917\n",
            " 74/121 [=================>............] - ETA: 0s - loss: 2.4080 - accuracy: 0.6208\n",
            "Epoch 22: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 22: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 22: accuracy did not improve from 0.72917\n",
            " 90/121 [=====================>........] - ETA: 0s - loss: 2.4132 - accuracy: 0.6174\n",
            "Epoch 22: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 22: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 22: accuracy did not improve from 0.72917\n",
            "106/121 [=========================>....] - ETA: 0s - loss: 2.3987 - accuracy: 0.6226\n",
            "Epoch 22: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 22: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 22: accuracy did not improve from 0.72917\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.3809 - accuracy: 0.6242\n",
            "Epoch 23/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.0015 - accuracy: 0.5312\n",
            "Epoch 23: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 23: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 23: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 23: accuracy did not improve from 0.72917\n",
            " 18/121 [===>..........................] - ETA: 0s - loss: 2.4417 - accuracy: 0.6354\n",
            "Epoch 23: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 23: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 23: accuracy did not improve from 0.72917\n",
            " 34/121 [=======>......................] - ETA: 0s - loss: 2.3639 - accuracy: 0.6250\n",
            "Epoch 23: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 23: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 23: accuracy did not improve from 0.72917\n",
            " 52/121 [===========>..................] - ETA: 0s - loss: 2.3304 - accuracy: 0.6274\n",
            "Epoch 23: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 23: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 23: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 23: accuracy did not improve from 0.72917\n",
            " 71/121 [================>.............] - ETA: 0s - loss: 2.3392 - accuracy: 0.6338\n",
            "Epoch 23: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 23: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 23: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 23: accuracy did not improve from 0.72917\n",
            " 92/121 [=====================>........] - ETA: 0s - loss: 2.3576 - accuracy: 0.6267\n",
            "Epoch 23: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 23: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 23: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 23: accuracy did not improve from 0.72917\n",
            "109/121 [==========================>...] - ETA: 0s - loss: 2.3738 - accuracy: 0.6241\n",
            "Epoch 23: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 23: accuracy did not improve from 0.72917\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.3809 - accuracy: 0.6242\n",
            "Epoch 24/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 1.4296 - accuracy: 0.7188\n",
            "Epoch 24: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 24: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 24: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 24: accuracy did not improve from 0.72917\n",
            " 18/121 [===>..........................] - ETA: 0s - loss: 2.4204 - accuracy: 0.6094\n",
            "Epoch 24: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 24: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 24: accuracy did not improve from 0.72917\n",
            " 36/121 [=======>......................] - ETA: 0s - loss: 2.3781 - accuracy: 0.6155\n",
            "Epoch 24: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 24: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 24: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 24: accuracy did not improve from 0.72917\n",
            " 52/121 [===========>..................] - ETA: 0s - loss: 2.3597 - accuracy: 0.6238\n",
            "Epoch 24: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 24: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 24: accuracy did not improve from 0.72917\n",
            " 70/121 [================>.............] - ETA: 0s - loss: 2.3699 - accuracy: 0.6223\n",
            "Epoch 24: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 24: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 24: accuracy did not improve from 0.72917\n",
            " 85/121 [====================>.........] - ETA: 0s - loss: 2.3812 - accuracy: 0.6210\n",
            "Epoch 24: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 24: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 24: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 24: accuracy did not improve from 0.72917\n",
            "102/121 [========================>.....] - ETA: 0s - loss: 2.3657 - accuracy: 0.6244\n",
            "Epoch 24: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 24: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 24: accuracy did not improve from 0.72917\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.3809 - accuracy: 0.6247\n",
            "Epoch 25/100\n",
            "\n",
            "Epoch 25: accuracy did not improve from 0.72917\n",
            "  1/121 [..............................] - ETA: 0s - loss: 1.8143 - accuracy: 0.6562\n",
            "Epoch 25: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 25: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 25: accuracy did not improve from 0.72917\n",
            " 18/121 [===>..........................] - ETA: 0s - loss: 2.2244 - accuracy: 0.6528\n",
            "Epoch 25: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 25: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 25: accuracy did not improve from 0.72917\n",
            " 35/121 [=======>......................] - ETA: 0s - loss: 2.4052 - accuracy: 0.6179\n",
            "Epoch 25: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 25: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 25: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 25: accuracy did not improve from 0.72917\n",
            " 51/121 [===========>..................] - ETA: 0s - loss: 2.4245 - accuracy: 0.6158\n",
            "Epoch 25: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 25: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 25: accuracy did not improve from 0.72917\n",
            " 69/121 [================>.............] - ETA: 0s - loss: 2.3861 - accuracy: 0.6241\n",
            "Epoch 25: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 25: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 25: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 25: accuracy did not improve from 0.72917\n",
            " 86/121 [====================>.........] - ETA: 0s - loss: 2.3812 - accuracy: 0.6232\n",
            "Epoch 25: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 25: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 25: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 25: accuracy did not improve from 0.72917\n",
            "106/121 [=========================>....] - ETA: 0s - loss: 2.3843 - accuracy: 0.6212\n",
            "Epoch 25: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 25: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 25: accuracy did not improve from 0.72917\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.3809 - accuracy: 0.6253\n",
            "Epoch 26/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 1.1437 - accuracy: 0.8438\n",
            "Epoch 26: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 26: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 26: accuracy did not improve from 0.72917\n",
            " 18/121 [===>..........................] - ETA: 0s - loss: 2.5949 - accuracy: 0.6128\n",
            "Epoch 26: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 26: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 26: accuracy did not improve from 0.72917\n",
            " 34/121 [=======>......................] - ETA: 0s - loss: 2.5261 - accuracy: 0.6131\n",
            "Epoch 26: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 26: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 26: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 26: accuracy did not improve from 0.72917\n",
            " 51/121 [===========>..................] - ETA: 0s - loss: 2.5031 - accuracy: 0.6158\n",
            "Epoch 26: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 26: accuracy did not improve from 0.72917\n",
            " 64/121 [==============>...............] - ETA: 0s - loss: 2.4461 - accuracy: 0.6211\n",
            "Epoch 26: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 26: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 26: accuracy did not improve from 0.72917\n",
            " 78/121 [==================>...........] - ETA: 0s - loss: 2.4642 - accuracy: 0.6174\n",
            "Epoch 26: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 26: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 26: accuracy did not improve from 0.72917\n",
            " 93/121 [======================>.......] - ETA: 0s - loss: 2.4152 - accuracy: 0.6233\n",
            "Epoch 26: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 26: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 26: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 26: accuracy did not improve from 0.72917\n",
            "110/121 [==========================>...] - ETA: 0s - loss: 2.3886 - accuracy: 0.6244\n",
            "Epoch 26: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 26: accuracy did not improve from 0.72917\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.3808 - accuracy: 0.6258\n",
            "Epoch 27/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.3827 - accuracy: 0.5312\n",
            "Epoch 27: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 27: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 27: accuracy did not improve from 0.72917\n",
            " 17/121 [===>..........................] - ETA: 0s - loss: 2.4113 - accuracy: 0.5974\n",
            "Epoch 27: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 27: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 27: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 27: accuracy did not improve from 0.72917\n",
            " 34/121 [=======>......................] - ETA: 0s - loss: 2.4197 - accuracy: 0.6131\n",
            "Epoch 27: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 27: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 27: accuracy did not improve from 0.72917\n",
            " 50/121 [===========>..................] - ETA: 0s - loss: 2.3205 - accuracy: 0.6269\n",
            "Epoch 27: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 27: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 27: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 27: accuracy did not improve from 0.72917\n",
            " 69/121 [================>.............] - ETA: 0s - loss: 2.3447 - accuracy: 0.6277\n",
            "Epoch 27: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 27: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 27: accuracy did not improve from 0.72917\n",
            " 84/121 [===================>..........] - ETA: 0s - loss: 2.3459 - accuracy: 0.6295\n",
            "Epoch 27: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 27: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 27: accuracy did not improve from 0.72917\n",
            "100/121 [=======================>......] - ETA: 0s - loss: 2.3624 - accuracy: 0.6288\n",
            "Epoch 27: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 27: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 27: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 27: accuracy did not improve from 0.72917\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.3808 - accuracy: 0.6258\n",
            "Epoch 28/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.4780 - accuracy: 0.7188\n",
            "Epoch 28: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 28: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 28: accuracy did not improve from 0.72917\n",
            " 15/121 [==>...........................] - ETA: 0s - loss: 2.5488 - accuracy: 0.6250\n",
            "Epoch 28: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 28: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 28: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 28: accuracy did not improve from 0.72917\n",
            " 36/121 [=======>......................] - ETA: 0s - loss: 2.4018 - accuracy: 0.6311\n",
            "Epoch 28: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 28: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 28: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 28: accuracy did not improve from 0.72917\n",
            " 56/121 [============>.................] - ETA: 0s - loss: 2.4038 - accuracy: 0.6161\n",
            "Epoch 28: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 28: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 28: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 28: accuracy did not improve from 0.72917\n",
            " 76/121 [=================>............] - ETA: 0s - loss: 2.4035 - accuracy: 0.6205\n",
            "Epoch 28: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 28: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 28: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 28: accuracy did not improve from 0.72917\n",
            " 93/121 [======================>.......] - ETA: 0s - loss: 2.3957 - accuracy: 0.6223\n",
            "Epoch 28: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 28: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 28: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 28: accuracy did not improve from 0.72917\n",
            "113/121 [===========================>..] - ETA: 0s - loss: 2.3851 - accuracy: 0.6261\n",
            "Epoch 28: accuracy did not improve from 0.72917\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.3808 - accuracy: 0.6260\n",
            "Epoch 29/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 1.8108 - accuracy: 0.7812\n",
            "Epoch 29: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 29: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 29: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 29: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 29: accuracy did not improve from 0.72917\n",
            " 22/121 [====>.........................] - ETA: 0s - loss: 2.3793 - accuracy: 0.6179\n",
            "Epoch 29: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 29: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 29: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 29: accuracy did not improve from 0.72917\n",
            " 42/121 [=========>....................] - ETA: 0s - loss: 2.3063 - accuracy: 0.6310\n",
            "Epoch 29: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 29: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 29: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 29: accuracy did not improve from 0.72917\n",
            " 62/121 [==============>...............] - ETA: 0s - loss: 2.3141 - accuracy: 0.6295\n",
            "Epoch 29: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 29: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 29: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 29: accuracy did not improve from 0.72917\n",
            " 82/121 [===================>..........] - ETA: 0s - loss: 2.3437 - accuracy: 0.6311\n",
            "Epoch 29: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 29: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 29: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 29: accuracy did not improve from 0.72917\n",
            "102/121 [========================>.....] - ETA: 0s - loss: 2.3890 - accuracy: 0.6238\n",
            "Epoch 29: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 29: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 29: accuracy did not improve from 0.72917\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.3808 - accuracy: 0.6263\n",
            "Epoch 30/100\n",
            "\n",
            "Epoch 30: accuracy did not improve from 0.72917\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.8592 - accuracy: 0.5938\n",
            "Epoch 30: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 30: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 30: accuracy did not improve from 0.72917\n",
            " 20/121 [===>..........................] - ETA: 0s - loss: 2.3264 - accuracy: 0.6203\n",
            "Epoch 30: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 30: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 30: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 30: accuracy did not improve from 0.72917\n",
            " 38/121 [========>.....................] - ETA: 0s - loss: 2.3761 - accuracy: 0.6184\n",
            "Epoch 30: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 30: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 30: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 30: accuracy did not improve from 0.72917\n",
            " 57/121 [=============>................] - ETA: 0s - loss: 2.3769 - accuracy: 0.6228\n",
            "Epoch 30: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 30: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 30: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 30: accuracy did not improve from 0.72917\n",
            " 76/121 [=================>............] - ETA: 0s - loss: 2.3960 - accuracy: 0.6238\n",
            "Epoch 30: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 30: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 30: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 30: accuracy did not improve from 0.72917\n",
            " 96/121 [======================>.......] - ETA: 0s - loss: 2.3814 - accuracy: 0.6260\n",
            "Epoch 30: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 30: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 30: accuracy did not improve from 0.72917\n",
            "112/121 [==========================>...] - ETA: 0s - loss: 2.3766 - accuracy: 0.6275\n",
            "Epoch 30: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 30: accuracy did not improve from 0.72917\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.3808 - accuracy: 0.6263\n",
            "Epoch 31/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.4780 - accuracy: 0.6250\n",
            "Epoch 31: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 31: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 31: accuracy did not improve from 0.72917\n",
            " 15/121 [==>...........................] - ETA: 0s - loss: 2.3007 - accuracy: 0.6375\n",
            "Epoch 31: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 31: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 31: accuracy did not improve from 0.72917\n",
            " 30/121 [======>.......................] - ETA: 0s - loss: 2.3325 - accuracy: 0.6260\n",
            "Epoch 31: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 31: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 31: accuracy did not improve from 0.72917\n",
            " 46/121 [==========>...................] - ETA: 0s - loss: 2.2755 - accuracy: 0.6345\n",
            "Epoch 31: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 31: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 31: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 31: accuracy did not improve from 0.72917\n",
            " 65/121 [===============>..............] - ETA: 0s - loss: 2.3143 - accuracy: 0.6341\n",
            "Epoch 31: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 31: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 31: accuracy did not improve from 0.72917\n",
            " 82/121 [===================>..........] - ETA: 0s - loss: 2.3683 - accuracy: 0.6319\n",
            "Epoch 31: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 31: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 31: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 31: accuracy did not improve from 0.72917\n",
            "104/121 [========================>.....] - ETA: 0s - loss: 2.3953 - accuracy: 0.6235\n",
            "Epoch 31: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 31: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 31: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 31: accuracy did not improve from 0.72917\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.3808 - accuracy: 0.6263\n",
            "Epoch 32/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.1943 - accuracy: 0.5312\n",
            "Epoch 32: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 32: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 32: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 32: accuracy did not improve from 0.72917\n",
            " 21/121 [====>.........................] - ETA: 0s - loss: 2.2882 - accuracy: 0.6280\n",
            "Epoch 32: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 32: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 32: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 32: accuracy did not improve from 0.72917\n",
            " 41/121 [=========>....................] - ETA: 0s - loss: 2.4019 - accuracy: 0.6113\n",
            "Epoch 32: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 32: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 32: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 32: accuracy did not improve from 0.72917\n",
            " 59/121 [=============>................] - ETA: 0s - loss: 2.4092 - accuracy: 0.6197\n",
            "Epoch 32: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 32: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 32: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 32: accuracy did not improve from 0.72917\n",
            " 79/121 [==================>...........] - ETA: 0s - loss: 2.4015 - accuracy: 0.6250\n",
            "Epoch 32: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 32: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 32: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 32: accuracy did not improve from 0.72917\n",
            "100/121 [=======================>......] - ETA: 0s - loss: 2.3910 - accuracy: 0.6263\n",
            "Epoch 32: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 32: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 32: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 32: accuracy did not improve from 0.72917\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.3808 - accuracy: 0.6263\n",
            "Epoch 33/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.7639 - accuracy: 0.5938\n",
            "Epoch 33: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 33: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 33: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 33: accuracy did not improve from 0.72917\n",
            " 21/121 [====>.........................] - ETA: 0s - loss: 2.4649 - accuracy: 0.6161\n",
            "Epoch 33: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 33: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 33: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 33: accuracy did not improve from 0.72917\n",
            " 42/121 [=========>....................] - ETA: 0s - loss: 2.3517 - accuracy: 0.6280\n",
            "Epoch 33: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 33: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 33: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 33: accuracy did not improve from 0.72917\n",
            " 62/121 [==============>...............] - ETA: 0s - loss: 2.3434 - accuracy: 0.6295\n",
            "Epoch 33: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 33: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 33: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 33: accuracy did not improve from 0.72917\n",
            " 81/121 [===================>..........] - ETA: 0s - loss: 2.3858 - accuracy: 0.6265\n",
            "Epoch 33: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 33: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 33: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 33: accuracy did not improve from 0.72917\n",
            "102/121 [========================>.....] - ETA: 0s - loss: 2.3928 - accuracy: 0.6259\n",
            "Epoch 33: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 33: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 33: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 33: accuracy did not improve from 0.72917\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.3808 - accuracy: 0.6263\n",
            "Epoch 34/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 1.9062 - accuracy: 0.6562\n",
            "Epoch 34: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 34: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 34: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 34: accuracy did not improve from 0.72917\n",
            " 20/121 [===>..........................] - ETA: 0s - loss: 2.3457 - accuracy: 0.6219\n",
            "Epoch 34: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 34: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 34: accuracy did not improve from 0.72917\n",
            " 36/121 [=======>......................] - ETA: 0s - loss: 2.4235 - accuracy: 0.6146\n",
            "Epoch 34: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 34: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 34: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 34: accuracy did not improve from 0.72917\n",
            " 54/121 [============>.................] - ETA: 0s - loss: 2.3536 - accuracy: 0.6302\n",
            "Epoch 34: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 34: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 34: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 34: accuracy did not improve from 0.72917\n",
            " 75/121 [=================>............] - ETA: 0s - loss: 2.3657 - accuracy: 0.6204\n",
            "Epoch 34: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 34: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 34: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 34: accuracy did not improve from 0.72917\n",
            " 95/121 [======================>.......] - ETA: 0s - loss: 2.3564 - accuracy: 0.6243\n",
            "Epoch 34: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 34: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 34: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 34: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 34: accuracy did not improve from 0.72917\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.3808 - accuracy: 0.6266\n",
            "Epoch 35/100\n",
            "\n",
            "Epoch 35: accuracy did not improve from 0.72917\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.4802 - accuracy: 0.6562\n",
            "Epoch 35: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 35: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 35: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 35: accuracy did not improve from 0.72917\n",
            " 21/121 [====>.........................] - ETA: 0s - loss: 2.2878 - accuracy: 0.6443\n",
            "Epoch 35: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 35: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 35: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 35: accuracy did not improve from 0.72917\n",
            " 42/121 [=========>....................] - ETA: 0s - loss: 2.3357 - accuracy: 0.6324\n",
            "Epoch 35: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 35: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 35: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 35: accuracy did not improve from 0.72917\n",
            " 61/121 [==============>...............] - ETA: 0s - loss: 2.3912 - accuracy: 0.6270\n",
            "Epoch 35: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 35: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 35: accuracy did not improve from 0.72917\n",
            " 78/121 [==================>...........] - ETA: 0s - loss: 2.4079 - accuracy: 0.6246\n",
            "Epoch 35: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 35: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 35: accuracy did not improve from 0.72917\n",
            " 94/121 [======================>.......] - ETA: 0s - loss: 2.4200 - accuracy: 0.6233\n",
            "Epoch 35: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 35: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 35: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 35: accuracy did not improve from 0.72917\n",
            "111/121 [==========================>...] - ETA: 0s - loss: 2.3757 - accuracy: 0.6273\n",
            "Epoch 35: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 35: accuracy did not improve from 0.72917\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.3808 - accuracy: 0.6266\n",
            "Epoch 36/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.6708 - accuracy: 0.5000\n",
            "Epoch 36: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 36: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 36: accuracy did not improve from 0.72917\n",
            " 17/121 [===>..........................] - ETA: 0s - loss: 2.3952 - accuracy: 0.6140\n",
            "Epoch 36: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 36: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 36: accuracy did not improve from 0.72917\n",
            " 32/121 [======>.......................] - ETA: 0s - loss: 2.4463 - accuracy: 0.6270\n",
            "Epoch 36: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 36: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 36: accuracy did not improve from 0.72917\n",
            " 48/121 [==========>...................] - ETA: 0s - loss: 2.4572 - accuracy: 0.6204\n",
            "Epoch 36: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 36: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 36: accuracy did not improve from 0.72917\n",
            " 64/121 [==============>...............] - ETA: 0s - loss: 2.3836 - accuracy: 0.6250\n",
            "Epoch 36: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 36: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 36: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 36: accuracy did not improve from 0.72917\n",
            " 80/121 [==================>...........] - ETA: 0s - loss: 2.3991 - accuracy: 0.6203\n",
            "Epoch 36: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 36: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 36: accuracy did not improve from 0.72917\n",
            " 96/121 [======================>.......] - ETA: 0s - loss: 2.3786 - accuracy: 0.6198\n",
            "Epoch 36: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 36: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 36: accuracy did not improve from 0.72917\n",
            "112/121 [==========================>...] - ETA: 0s - loss: 2.3817 - accuracy: 0.6275\n",
            "Epoch 36: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 36: accuracy did not improve from 0.72917\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.3808 - accuracy: 0.6266\n",
            "Epoch 37/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 1.8108 - accuracy: 0.6875\n",
            "Epoch 37: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 37: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 37: accuracy did not improve from 0.72917\n",
            " 17/121 [===>..........................] - ETA: 0s - loss: 2.4837 - accuracy: 0.5938\n",
            "Epoch 37: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 37: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 37: accuracy did not improve from 0.72917\n",
            " 32/121 [======>.......................] - ETA: 0s - loss: 2.3145 - accuracy: 0.6201\n",
            "Epoch 37: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 37: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 37: accuracy did not improve from 0.72917\n",
            " 48/121 [==========>...................] - ETA: 0s - loss: 2.3931 - accuracy: 0.6204\n",
            "Epoch 37: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 37: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 37: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 37: accuracy did not improve from 0.72917\n",
            " 64/121 [==============>...............] - ETA: 0s - loss: 2.3908 - accuracy: 0.6216\n",
            "Epoch 37: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 37: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 37: accuracy did not improve from 0.72917\n",
            " 81/121 [===================>..........] - ETA: 0s - loss: 2.3456 - accuracy: 0.6327\n",
            "Epoch 37: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 37: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 37: accuracy did not improve from 0.72917\n",
            " 98/121 [=======================>......] - ETA: 0s - loss: 2.3813 - accuracy: 0.6298\n",
            "Epoch 37: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 37: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 37: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 37: accuracy did not improve from 0.72917\n",
            "114/121 [===========================>..] - ETA: 0s - loss: 2.3884 - accuracy: 0.6255\n",
            "Epoch 37: accuracy did not improve from 0.72917\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.3808 - accuracy: 0.6268\n",
            "Epoch 38/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.4780 - accuracy: 0.6250\n",
            "Epoch 38: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 38: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 38: accuracy did not improve from 0.72917\n",
            " 16/121 [==>...........................] - ETA: 0s - loss: 2.4068 - accuracy: 0.6055\n",
            "Epoch 38: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 38: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 38: accuracy did not improve from 0.72917\n",
            " 30/121 [======>.......................] - ETA: 0s - loss: 2.3674 - accuracy: 0.6281\n",
            "Epoch 38: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 38: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 38: accuracy did not improve from 0.72917\n",
            " 46/121 [==========>...................] - ETA: 0s - loss: 2.3875 - accuracy: 0.6175\n",
            "Epoch 38: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 38: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 38: accuracy did not improve from 0.72917\n",
            " 59/121 [=============>................] - ETA: 0s - loss: 2.4269 - accuracy: 0.6149\n",
            "Epoch 38: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 38: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 38: accuracy did not improve from 0.72917\n",
            " 77/121 [==================>...........] - ETA: 0s - loss: 2.3809 - accuracy: 0.6266\n",
            "Epoch 38: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 38: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 38: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 38: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 38: accuracy did not improve from 0.72917\n",
            " 98/121 [=======================>......] - ETA: 0s - loss: 2.3551 - accuracy: 0.6291\n",
            "Epoch 38: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 38: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 38: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 38: accuracy did not improve from 0.72917\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.3808 - accuracy: 0.6266\n",
            "Epoch 39/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.8592 - accuracy: 0.5938\n",
            "Epoch 39: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 39: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 39: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 39: accuracy did not improve from 0.72917\n",
            " 20/121 [===>..........................] - ETA: 0s - loss: 2.5118 - accuracy: 0.6234\n",
            "Epoch 39: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 39: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 39: accuracy did not improve from 0.72917\n",
            " 34/121 [=======>......................] - ETA: 0s - loss: 2.4672 - accuracy: 0.6094\n",
            "Epoch 39: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 39: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 39: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 39: accuracy did not improve from 0.72917\n",
            " 54/121 [============>.................] - ETA: 0s - loss: 2.4256 - accuracy: 0.6088\n",
            "Epoch 39: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 39: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 39: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 39: accuracy did not improve from 0.72917\n",
            " 75/121 [=================>............] - ETA: 0s - loss: 2.4442 - accuracy: 0.6104\n",
            "Epoch 39: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 39: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 39: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 39: accuracy did not improve from 0.72917\n",
            " 95/121 [======================>.......] - ETA: 0s - loss: 2.4054 - accuracy: 0.6237\n",
            "Epoch 39: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 39: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 39: accuracy did not improve from 0.72917\n",
            "107/121 [=========================>....] - ETA: 0s - loss: 2.3950 - accuracy: 0.6221\n",
            "Epoch 39: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 39: accuracy did not improve from 0.72917\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.3808 - accuracy: 0.6268\n",
            "Epoch 40/100\n",
            "\n",
            "Epoch 40: accuracy did not improve from 0.72917\n",
            "  1/121 [..............................] - ETA: 1s - loss: 2.3849 - accuracy: 0.6562\n",
            "Epoch 40: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 40: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 40: accuracy did not improve from 0.72917\n",
            " 16/121 [==>...........................] - ETA: 0s - loss: 2.4615 - accuracy: 0.6348\n",
            "Epoch 40: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 40: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 40: accuracy did not improve from 0.72917\n",
            " 35/121 [=======>......................] - ETA: 0s - loss: 2.3890 - accuracy: 0.6420\n",
            "Epoch 40: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 40: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 40: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 40: accuracy did not improve from 0.72917\n",
            " 54/121 [============>.................] - ETA: 0s - loss: 2.3994 - accuracy: 0.6354\n",
            "Epoch 40: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 40: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 40: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 40: accuracy did not improve from 0.72917\n",
            " 71/121 [================>.............] - ETA: 0s - loss: 2.3740 - accuracy: 0.6312\n",
            "Epoch 40: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 40: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 40: accuracy did not improve from 0.72917\n",
            " 89/121 [=====================>........] - ETA: 0s - loss: 2.3502 - accuracy: 0.6282\n",
            "Epoch 40: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 40: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 40: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 40: accuracy did not improve from 0.72917\n",
            "106/121 [=========================>....] - ETA: 0s - loss: 2.3673 - accuracy: 0.6256\n",
            "Epoch 40: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 40: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 40: accuracy did not improve from 0.72917\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.3808 - accuracy: 0.6268\n",
            "Epoch 41/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 3.2427 - accuracy: 0.5625\n",
            "Epoch 41: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 41: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 41: accuracy did not improve from 0.72917\n",
            " 19/121 [===>..........................] - ETA: 0s - loss: 2.6643 - accuracy: 0.6053\n",
            "Epoch 41: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 41: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 41: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 41: accuracy did not improve from 0.72917\n",
            " 35/121 [=======>......................] - ETA: 0s - loss: 2.5249 - accuracy: 0.6134\n",
            "Epoch 41: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 41: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 41: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 41: accuracy did not improve from 0.72917\n",
            " 55/121 [============>.................] - ETA: 0s - loss: 2.4874 - accuracy: 0.6239\n",
            "Epoch 41: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 41: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 41: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 41: accuracy did not improve from 0.72917\n",
            " 75/121 [=================>............] - ETA: 0s - loss: 2.4087 - accuracy: 0.6263\n",
            "Epoch 41: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 41: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 41: accuracy did not improve from 0.72917\n",
            " 90/121 [=====================>........] - ETA: 0s - loss: 2.3876 - accuracy: 0.6302\n",
            "Epoch 41: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 41: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 41: accuracy did not improve from 0.72917\n",
            "108/121 [=========================>....] - ETA: 0s - loss: 2.3675 - accuracy: 0.6296\n",
            "Epoch 41: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 41: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 41: accuracy did not improve from 0.72917\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.3808 - accuracy: 0.6266\n",
            "Epoch 42/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.9567 - accuracy: 0.5938\n",
            "Epoch 42: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 42: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 42: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 42: accuracy did not improve from 0.72917\n",
            " 19/121 [===>..........................] - ETA: 0s - loss: 2.5688 - accuracy: 0.6020\n",
            "Epoch 42: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 42: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 42: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 42: accuracy did not improve from 0.72917\n",
            " 39/121 [========>.....................] - ETA: 0s - loss: 2.3760 - accuracy: 0.6250\n",
            "Epoch 42: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 42: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 42: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 42: accuracy did not improve from 0.72917\n",
            " 59/121 [=============>................] - ETA: 0s - loss: 2.4092 - accuracy: 0.6276\n",
            "Epoch 42: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 42: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 42: accuracy did not improve from 0.72917\n",
            " 76/121 [=================>............] - ETA: 0s - loss: 2.3921 - accuracy: 0.6266\n",
            "Epoch 42: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 42: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 42: accuracy did not improve from 0.72917\n",
            " 92/121 [=====================>........] - ETA: 0s - loss: 2.3730 - accuracy: 0.6318\n",
            "Epoch 42: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 42: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 42: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 42: accuracy did not improve from 0.72917\n",
            "111/121 [==========================>...] - ETA: 0s - loss: 2.3731 - accuracy: 0.6281\n",
            "Epoch 42: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 42: accuracy did not improve from 0.72917\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.3808 - accuracy: 0.6268\n",
            "Epoch 43/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.7639 - accuracy: 0.6250\n",
            "Epoch 43: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 43: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 43: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 43: accuracy did not improve from 0.72917\n",
            " 18/121 [===>..........................] - ETA: 0s - loss: 2.3310 - accuracy: 0.6389\n",
            "Epoch 43: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 43: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 43: accuracy did not improve from 0.72917\n",
            " 33/121 [=======>......................] - ETA: 0s - loss: 2.3433 - accuracy: 0.6222\n",
            "Epoch 43: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 43: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 43: accuracy did not improve from 0.72917\n",
            " 48/121 [==========>...................] - ETA: 0s - loss: 2.3878 - accuracy: 0.6283\n",
            "Epoch 43: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 43: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 43: accuracy did not improve from 0.72917\n",
            " 63/121 [==============>...............] - ETA: 0s - loss: 2.3957 - accuracy: 0.6215\n",
            "Epoch 43: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 43: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 43: accuracy did not improve from 0.72917\n",
            " 78/121 [==================>...........] - ETA: 0s - loss: 2.3944 - accuracy: 0.6226\n",
            "Epoch 43: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 43: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 43: accuracy did not improve from 0.72917\n",
            " 95/121 [======================>.......] - ETA: 0s - loss: 2.3965 - accuracy: 0.6220\n",
            "Epoch 43: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 43: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 43: accuracy did not improve from 0.72917\n",
            "112/121 [==========================>...] - ETA: 0s - loss: 2.3766 - accuracy: 0.6278\n",
            "Epoch 43: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 43: accuracy did not improve from 0.72917\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.3808 - accuracy: 0.6268\n",
            "Epoch 44/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.6708 - accuracy: 0.4688\n",
            "Epoch 44: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 44: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 44: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 44: accuracy did not improve from 0.72917\n",
            " 18/121 [===>..........................] - ETA: 0s - loss: 2.4258 - accuracy: 0.6302\n",
            "Epoch 44: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 44: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 44: accuracy did not improve from 0.72917\n",
            " 35/121 [=======>......................] - ETA: 0s - loss: 2.3534 - accuracy: 0.6250\n",
            "Epoch 44: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 44: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 44: accuracy did not improve from 0.72917\n",
            " 49/121 [===========>..................] - ETA: 0s - loss: 2.3192 - accuracy: 0.6327\n",
            "Epoch 44: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 44: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 44: accuracy did not improve from 0.72917\n",
            " 66/121 [===============>..............] - ETA: 0s - loss: 2.3271 - accuracy: 0.6364\n",
            "Epoch 44: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 44: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 44: accuracy did not improve from 0.72917\n",
            " 80/121 [==================>...........] - ETA: 0s - loss: 2.3501 - accuracy: 0.6313\n",
            "Epoch 44: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 44: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 44: accuracy did not improve from 0.72917\n",
            " 95/121 [======================>.......] - ETA: 0s - loss: 2.3804 - accuracy: 0.6293\n",
            "Epoch 44: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 44: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 44: accuracy did not improve from 0.72917\n",
            "109/121 [==========================>...] - ETA: 0s - loss: 2.3817 - accuracy: 0.6299\n",
            "Epoch 44: accuracy did not improve from 0.72917\n",
            "\n",
            "Epoch 44: accuracy did not improve from 0.72917\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.3808 - accuracy: 0.6268\n",
            "Epoch 45/100\n",
            "\n",
            "Epoch 45: accuracy improved from 0.72917 to 0.75000, saving model to best_model.hdf5\n",
            "  1/121 [..............................] - ETA: 2s - loss: 1.8108 - accuracy: 0.7500\n",
            "Epoch 45: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 45: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 45: accuracy did not improve from 0.75000\n",
            " 16/121 [==>...........................] - ETA: 0s - loss: 2.3359 - accuracy: 0.6309\n",
            "Epoch 45: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 45: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 45: accuracy did not improve from 0.75000\n",
            " 31/121 [======>.......................] - ETA: 0s - loss: 2.4267 - accuracy: 0.6421\n",
            "Epoch 45: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 45: accuracy did not improve from 0.75000\n",
            " 44/121 [=========>....................] - ETA: 0s - loss: 2.4140 - accuracy: 0.6371\n",
            "Epoch 45: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 45: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 45: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 45: accuracy did not improve from 0.75000\n",
            " 61/121 [==============>...............] - ETA: 0s - loss: 2.4115 - accuracy: 0.6270\n",
            "Epoch 45: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 45: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 45: accuracy did not improve from 0.75000\n",
            " 78/121 [==================>...........] - ETA: 0s - loss: 2.3883 - accuracy: 0.6278\n",
            "Epoch 45: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 45: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 45: accuracy did not improve from 0.75000\n",
            " 93/121 [======================>.......] - ETA: 0s - loss: 2.3813 - accuracy: 0.6280\n",
            "Epoch 45: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 45: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 45: accuracy did not improve from 0.75000\n",
            "109/121 [==========================>...] - ETA: 0s - loss: 2.3921 - accuracy: 0.6236\n",
            "Epoch 45: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 45: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 45: accuracy did not improve from 0.75000\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.3808 - accuracy: 0.6268\n",
            "Epoch 46/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.6686 - accuracy: 0.5625\n",
            "Epoch 46: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 46: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 46: accuracy did not improve from 0.75000\n",
            " 15/121 [==>...........................] - ETA: 0s - loss: 2.2688 - accuracy: 0.6146\n",
            "Epoch 46: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 46: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 46: accuracy did not improve from 0.75000\n",
            " 33/121 [=======>......................] - ETA: 0s - loss: 2.2850 - accuracy: 0.6222\n",
            "Epoch 46: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 46: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 46: accuracy did not improve from 0.75000\n",
            " 48/121 [==========>...................] - ETA: 0s - loss: 2.3615 - accuracy: 0.6185\n",
            "Epoch 46: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 46: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 46: accuracy did not improve from 0.75000\n",
            " 63/121 [==============>...............] - ETA: 0s - loss: 2.3516 - accuracy: 0.6230\n",
            "Epoch 46: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 46: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 46: accuracy did not improve from 0.75000\n",
            " 77/121 [==================>...........] - ETA: 0s - loss: 2.3413 - accuracy: 0.6250\n",
            "Epoch 46: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 46: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 46: accuracy did not improve from 0.75000\n",
            " 93/121 [======================>.......] - ETA: 0s - loss: 2.3681 - accuracy: 0.6274\n",
            "Epoch 46: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 46: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 46: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 46: accuracy did not improve from 0.75000\n",
            "112/121 [==========================>...] - ETA: 0s - loss: 2.3970 - accuracy: 0.6242\n",
            "Epoch 46: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 46: accuracy did not improve from 0.75000\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.3808 - accuracy: 0.6268\n",
            "Epoch 47/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.7639 - accuracy: 0.6562\n",
            "Epoch 47: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 47: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 47: accuracy did not improve from 0.75000\n",
            " 16/121 [==>...........................] - ETA: 0s - loss: 2.4195 - accuracy: 0.6523\n",
            "Epoch 47: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 47: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 47: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 47: accuracy did not improve from 0.75000\n",
            " 34/121 [=======>......................] - ETA: 0s - loss: 2.3840 - accuracy: 0.6379\n",
            "Epoch 47: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 47: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 47: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 47: accuracy did not improve from 0.75000\n",
            " 54/121 [============>.................] - ETA: 0s - loss: 2.3360 - accuracy: 0.6400\n",
            "Epoch 47: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 47: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 47: accuracy did not improve from 0.75000\n",
            " 69/121 [================>.............] - ETA: 0s - loss: 2.3753 - accuracy: 0.6291\n",
            "Epoch 47: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 47: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 47: accuracy did not improve from 0.75000\n",
            " 86/121 [====================>.........] - ETA: 0s - loss: 2.3414 - accuracy: 0.6330\n",
            "Epoch 47: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 47: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 47: accuracy did not improve from 0.75000\n",
            "102/121 [========================>.....] - ETA: 0s - loss: 2.3732 - accuracy: 0.6281\n",
            "Epoch 47: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 47: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 47: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 47: accuracy did not improve from 0.75000\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.3808 - accuracy: 0.6268\n",
            "Epoch 48/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.1943 - accuracy: 0.5625\n",
            "Epoch 48: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 48: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 48: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 48: accuracy did not improve from 0.75000\n",
            " 20/121 [===>..........................] - ETA: 0s - loss: 2.4073 - accuracy: 0.6234\n",
            "Epoch 48: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 48: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 48: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 48: accuracy did not improve from 0.75000\n",
            " 40/121 [========>.....................] - ETA: 0s - loss: 2.3689 - accuracy: 0.6211\n",
            "Epoch 48: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 48: accuracy did not improve from 0.75000\n",
            " 51/121 [===========>..................] - ETA: 0s - loss: 2.3776 - accuracy: 0.6250\n",
            "Epoch 48: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 48: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 48: accuracy did not improve from 0.75000\n",
            " 63/121 [==============>...............] - ETA: 0s - loss: 2.3393 - accuracy: 0.6245\n",
            "Epoch 48: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 48: accuracy did not improve from 0.75000\n",
            " 77/121 [==================>...........] - ETA: 0s - loss: 2.3845 - accuracy: 0.6282\n",
            "Epoch 48: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 48: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 48: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 48: accuracy did not improve from 0.75000\n",
            " 93/121 [======================>.......] - ETA: 0s - loss: 2.3649 - accuracy: 0.6294\n",
            "Epoch 48: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 48: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 48: accuracy did not improve from 0.75000\n",
            "111/121 [==========================>...] - ETA: 0s - loss: 2.3757 - accuracy: 0.6284\n",
            "Epoch 48: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 48: accuracy did not improve from 0.75000\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.3808 - accuracy: 0.6268\n",
            "Epoch 49/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 1.5249 - accuracy: 0.7812\n",
            "Epoch 49: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 49: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 49: accuracy did not improve from 0.75000\n",
            " 14/121 [==>...........................] - ETA: 0s - loss: 2.3564 - accuracy: 0.6362\n",
            "Epoch 49: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 49: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 49: accuracy did not improve from 0.75000\n",
            " 28/121 [=====>........................] - ETA: 0s - loss: 2.3155 - accuracy: 0.6328\n",
            "Epoch 49: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 49: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 49: accuracy did not improve from 0.75000\n",
            " 42/121 [=========>....................] - ETA: 0s - loss: 2.3290 - accuracy: 0.6302\n",
            "Epoch 49: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 49: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 49: accuracy did not improve from 0.75000\n",
            " 57/121 [=============>................] - ETA: 0s - loss: 2.3081 - accuracy: 0.6371\n",
            "Epoch 49: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 49: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 49: accuracy did not improve from 0.75000\n",
            " 72/121 [================>.............] - ETA: 0s - loss: 2.3211 - accuracy: 0.6393\n",
            "Epoch 49: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 49: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 49: accuracy did not improve from 0.75000\n",
            " 89/121 [=====================>........] - ETA: 0s - loss: 2.3663 - accuracy: 0.6303\n",
            "Epoch 49: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 49: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 49: accuracy did not improve from 0.75000\n",
            "104/121 [========================>.....] - ETA: 0s - loss: 2.3816 - accuracy: 0.6268\n",
            "Epoch 49: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 49: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 49: accuracy did not improve from 0.75000\n",
            "121/121 [==============================] - 0s 4ms/step - loss: 2.3808 - accuracy: 0.6268\n",
            "Epoch 50/100\n",
            "\n",
            "Epoch 50: accuracy did not improve from 0.75000\n",
            "  1/121 [..............................] - ETA: 1s - loss: 2.6686 - accuracy: 0.6250\n",
            "Epoch 50: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 50: accuracy did not improve from 0.75000\n",
            " 15/121 [==>...........................] - ETA: 0s - loss: 2.5418 - accuracy: 0.6375\n",
            "Epoch 50: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 50: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 50: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 50: accuracy did not improve from 0.75000\n",
            " 34/121 [=======>......................] - ETA: 0s - loss: 2.4167 - accuracy: 0.6250\n",
            "Epoch 50: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 50: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 50: accuracy did not improve from 0.75000\n",
            " 49/121 [===========>..................] - ETA: 0s - loss: 2.3695 - accuracy: 0.6288\n",
            "Epoch 50: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 50: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 50: accuracy did not improve from 0.75000\n",
            " 64/121 [==============>...............] - ETA: 0s - loss: 2.3340 - accuracy: 0.6309\n",
            "Epoch 50: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 50: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 50: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 50: accuracy did not improve from 0.75000\n",
            " 82/121 [===================>..........] - ETA: 0s - loss: 2.3508 - accuracy: 0.6273\n",
            "Epoch 50: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 50: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 50: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 50: accuracy did not improve from 0.75000\n",
            "101/121 [========================>.....] - ETA: 0s - loss: 2.3843 - accuracy: 0.6259\n",
            "Epoch 50: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 50: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 50: accuracy did not improve from 0.75000\n",
            "117/121 [============================>.] - ETA: 0s - loss: 2.3883 - accuracy: 0.6239\n",
            "Epoch 50: accuracy did not improve from 0.75000\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.3808 - accuracy: 0.6268\n",
            "Epoch 51/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.2874 - accuracy: 0.6875\n",
            "Epoch 51: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 51: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 51: accuracy did not improve from 0.75000\n",
            " 15/121 [==>...........................] - ETA: 0s - loss: 2.5040 - accuracy: 0.6083\n",
            "Epoch 51: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 51: accuracy did not improve from 0.75000\n",
            " 28/121 [=====>........................] - ETA: 0s - loss: 2.5126 - accuracy: 0.6217\n",
            "Epoch 51: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 51: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 51: accuracy did not improve from 0.75000\n",
            " 42/121 [=========>....................] - ETA: 0s - loss: 2.4355 - accuracy: 0.6220\n",
            "Epoch 51: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 51: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 51: accuracy did not improve from 0.75000\n",
            " 55/121 [============>.................] - ETA: 0s - loss: 2.4006 - accuracy: 0.6250\n",
            "Epoch 51: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 51: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 51: accuracy did not improve from 0.75000\n",
            " 71/121 [================>.............] - ETA: 0s - loss: 2.3832 - accuracy: 0.6250\n",
            "Epoch 51: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 51: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 51: accuracy did not improve from 0.75000\n",
            " 87/121 [====================>.........] - ETA: 0s - loss: 2.3767 - accuracy: 0.6261\n",
            "Epoch 51: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 51: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 51: accuracy did not improve from 0.75000\n",
            "101/121 [========================>.....] - ETA: 0s - loss: 2.3777 - accuracy: 0.6290\n",
            "Epoch 51: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 51: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 51: accuracy did not improve from 0.75000\n",
            "118/121 [============================>.] - ETA: 0s - loss: 2.3745 - accuracy: 0.6271\n",
            "Epoch 51: accuracy did not improve from 0.75000\n",
            "121/121 [==============================] - 0s 4ms/step - loss: 2.3808 - accuracy: 0.6268\n",
            "Epoch 52/100\n",
            "  1/121 [..............................] - ETA: 1s - loss: 1.7155 - accuracy: 0.7500\n",
            "Epoch 52: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 52: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 52: accuracy did not improve from 0.75000\n",
            " 16/121 [==>...........................] - ETA: 0s - loss: 2.3356 - accuracy: 0.6074\n",
            "Epoch 52: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 52: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 52: accuracy did not improve from 0.75000\n",
            " 31/121 [======>.......................] - ETA: 0s - loss: 2.3986 - accuracy: 0.6149\n",
            "Epoch 52: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 52: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 52: accuracy did not improve from 0.75000\n",
            " 45/121 [==========>...................] - ETA: 0s - loss: 2.3599 - accuracy: 0.6201\n",
            "Epoch 52: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 52: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 52: accuracy did not improve from 0.75000\n",
            " 60/121 [=============>................] - ETA: 0s - loss: 2.3658 - accuracy: 0.6245\n",
            "Epoch 52: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 52: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 52: accuracy did not improve from 0.75000\n",
            " 74/121 [=================>............] - ETA: 0s - loss: 2.3640 - accuracy: 0.6292\n",
            "Epoch 52: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 52: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 52: accuracy did not improve from 0.75000\n",
            " 89/121 [=====================>........] - ETA: 0s - loss: 2.3695 - accuracy: 0.6275\n",
            "Epoch 52: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 52: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 52: accuracy did not improve from 0.75000\n",
            "104/121 [========================>.....] - ETA: 0s - loss: 2.3623 - accuracy: 0.6289\n",
            "Epoch 52: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 52: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 52: accuracy did not improve from 0.75000\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.3808 - accuracy: 0.6268\n",
            "Epoch 53/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.7639 - accuracy: 0.5625\n",
            "Epoch 53: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 53: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 53: accuracy did not improve from 0.75000\n",
            " 17/121 [===>..........................] - ETA: 0s - loss: 2.5125 - accuracy: 0.5938\n",
            "Epoch 53: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 53: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 53: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 53: accuracy did not improve from 0.75000\n",
            " 33/121 [=======>......................] - ETA: 0s - loss: 2.4960 - accuracy: 0.6127\n",
            "Epoch 53: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 53: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 53: accuracy did not improve from 0.75000\n",
            " 48/121 [==========>...................] - ETA: 0s - loss: 2.4589 - accuracy: 0.6204\n",
            "Epoch 53: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 53: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 53: accuracy did not improve from 0.75000\n",
            " 63/121 [==============>...............] - ETA: 0s - loss: 2.4772 - accuracy: 0.6141\n",
            "Epoch 53: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 53: accuracy did not improve from 0.75000\n",
            " 76/121 [=================>............] - ETA: 0s - loss: 2.4361 - accuracy: 0.6225\n",
            "Epoch 53: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 53: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 53: accuracy did not improve from 0.75000\n",
            " 90/121 [=====================>........] - ETA: 0s - loss: 2.4130 - accuracy: 0.6236\n",
            "Epoch 53: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 53: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 53: accuracy did not improve from 0.75000\n",
            "103/121 [========================>.....] - ETA: 0s - loss: 2.3852 - accuracy: 0.6253\n",
            "Epoch 53: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 53: accuracy did not improve from 0.75000\n",
            "117/121 [============================>.] - ETA: 0s - loss: 2.3818 - accuracy: 0.6274\n",
            "Epoch 53: accuracy did not improve from 0.75000\n",
            "121/121 [==============================] - 0s 4ms/step - loss: 2.3808 - accuracy: 0.6268\n",
            "Epoch 54/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.5733 - accuracy: 0.5312\n",
            "Epoch 54: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 54: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 54: accuracy did not improve from 0.75000\n",
            " 13/121 [==>...........................] - ETA: 0s - loss: 2.2657 - accuracy: 0.6370\n",
            "Epoch 54: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 54: accuracy did not improve from 0.75000\n",
            " 26/121 [=====>........................] - ETA: 0s - loss: 2.2844 - accuracy: 0.6478\n",
            "Epoch 54: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 54: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 54: accuracy did not improve from 0.75000\n",
            " 41/121 [=========>....................] - ETA: 0s - loss: 2.3416 - accuracy: 0.6357\n",
            "Epoch 54: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 54: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 54: accuracy did not improve from 0.75000\n",
            " 56/121 [============>.................] - ETA: 0s - loss: 2.3648 - accuracy: 0.6367\n",
            "Epoch 54: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 54: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 54: accuracy did not improve from 0.75000\n",
            " 70/121 [================>.............] - ETA: 0s - loss: 2.3536 - accuracy: 0.6357\n",
            "Epoch 54: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 54: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 54: accuracy did not improve from 0.75000\n",
            " 84/121 [===================>..........] - ETA: 0s - loss: 2.3766 - accuracy: 0.6388\n",
            "Epoch 54: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 54: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 54: accuracy did not improve from 0.75000\n",
            " 98/121 [=======================>......] - ETA: 0s - loss: 2.4000 - accuracy: 0.6304\n",
            "Epoch 54: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 54: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 54: accuracy did not improve from 0.75000\n",
            "114/121 [===========================>..] - ETA: 0s - loss: 2.3868 - accuracy: 0.6272\n",
            "Epoch 54: accuracy did not improve from 0.75000\n",
            "121/121 [==============================] - 0s 4ms/step - loss: 2.3808 - accuracy: 0.6268\n",
            "Epoch 55/100\n",
            "\n",
            "Epoch 55: accuracy did not improve from 0.75000\n",
            "  1/121 [..............................] - ETA: 1s - loss: 3.1452 - accuracy: 0.5938\n",
            "Epoch 55: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 55: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 55: accuracy did not improve from 0.75000\n",
            " 16/121 [==>...........................] - ETA: 0s - loss: 2.4370 - accuracy: 0.6074\n",
            "Epoch 55: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 55: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 55: accuracy did not improve from 0.75000\n",
            " 31/121 [======>.......................] - ETA: 0s - loss: 2.4479 - accuracy: 0.6119\n",
            "Epoch 55: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 55: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 55: accuracy did not improve from 0.75000\n",
            " 49/121 [===========>..................] - ETA: 0s - loss: 2.4030 - accuracy: 0.6250\n",
            "Epoch 55: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 55: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 55: accuracy did not improve from 0.75000\n",
            " 61/121 [==============>...............] - ETA: 0s - loss: 2.4116 - accuracy: 0.6250\n",
            "Epoch 55: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 55: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 55: accuracy did not improve from 0.75000\n",
            " 78/121 [==================>...........] - ETA: 0s - loss: 2.4311 - accuracy: 0.6194\n",
            "Epoch 55: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 55: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 55: accuracy did not improve from 0.75000\n",
            " 93/121 [======================>.......] - ETA: 0s - loss: 2.3885 - accuracy: 0.6226\n",
            "Epoch 55: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 55: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 55: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 55: accuracy did not improve from 0.75000\n",
            "111/121 [==========================>...] - ETA: 0s - loss: 2.4006 - accuracy: 0.6244\n",
            "Epoch 55: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 55: accuracy did not improve from 0.75000\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.3808 - accuracy: 0.6268\n",
            "Epoch 56/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.8592 - accuracy: 0.6250\n",
            "Epoch 56: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 56: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 56: accuracy did not improve from 0.75000\n",
            " 19/121 [===>..........................] - ETA: 0s - loss: 2.2628 - accuracy: 0.6562\n",
            "Epoch 56: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 56: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 56: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 56: accuracy did not improve from 0.75000\n",
            " 36/121 [=======>......................] - ETA: 0s - loss: 2.3437 - accuracy: 0.6337\n",
            "Epoch 56: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 56: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 56: accuracy did not improve from 0.75000\n",
            " 52/121 [===========>..................] - ETA: 0s - loss: 2.3173 - accuracy: 0.6334\n",
            "Epoch 56: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 56: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 56: accuracy did not improve from 0.75000\n",
            " 66/121 [===============>..............] - ETA: 0s - loss: 2.3761 - accuracy: 0.6231\n",
            "Epoch 56: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 56: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 56: accuracy did not improve from 0.75000\n",
            " 84/121 [===================>..........] - ETA: 0s - loss: 2.4027 - accuracy: 0.6243\n",
            "Epoch 56: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 56: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 56: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 56: accuracy did not improve from 0.75000\n",
            "103/121 [========================>.....] - ETA: 0s - loss: 2.3760 - accuracy: 0.6296\n",
            "Epoch 56: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 56: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 56: accuracy did not improve from 0.75000\n",
            "117/121 [============================>.] - ETA: 0s - loss: 2.3801 - accuracy: 0.6266\n",
            "Epoch 56: accuracy did not improve from 0.75000\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.3808 - accuracy: 0.6268\n",
            "Epoch 57/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 1.7155 - accuracy: 0.7188\n",
            "Epoch 57: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 57: accuracy did not improve from 0.75000\n",
            " 11/121 [=>............................] - ETA: 0s - loss: 2.3311 - accuracy: 0.6335\n",
            "Epoch 57: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 57: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 57: accuracy did not improve from 0.75000\n",
            " 24/121 [====>.........................] - ETA: 0s - loss: 2.3954 - accuracy: 0.6393\n",
            "Epoch 57: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 57: accuracy did not improve from 0.75000\n",
            " 38/121 [========>.....................] - ETA: 0s - loss: 2.4010 - accuracy: 0.6357\n",
            "Epoch 57: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 57: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 57: accuracy did not improve from 0.75000\n",
            " 51/121 [===========>..................] - ETA: 0s - loss: 2.3517 - accuracy: 0.6422\n",
            "Epoch 57: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 57: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 57: accuracy did not improve from 0.75000\n",
            " 68/121 [===============>..............] - ETA: 0s - loss: 2.3833 - accuracy: 0.6347\n",
            "Epoch 57: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 57: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 57: accuracy did not improve from 0.75000\n",
            " 83/121 [===================>..........] - ETA: 0s - loss: 2.3948 - accuracy: 0.6284\n",
            "Epoch 57: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 57: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 57: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 57: accuracy did not improve from 0.75000\n",
            "100/121 [=======================>......] - ETA: 0s - loss: 2.3786 - accuracy: 0.6319\n",
            "Epoch 57: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 57: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 57: accuracy did not improve from 0.75000\n",
            "114/121 [===========================>..] - ETA: 0s - loss: 2.3750 - accuracy: 0.6297\n",
            "Epoch 57: accuracy did not improve from 0.75000\n",
            "121/121 [==============================] - 0s 4ms/step - loss: 2.3808 - accuracy: 0.6268\n",
            "Epoch 58/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.5733 - accuracy: 0.5312\n",
            "Epoch 58: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 58: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 58: accuracy did not improve from 0.75000\n",
            " 14/121 [==>...........................] - ETA: 0s - loss: 2.2606 - accuracy: 0.6183\n",
            "Epoch 58: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 58: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 58: accuracy did not improve from 0.75000\n",
            " 28/121 [=====>........................] - ETA: 0s - loss: 2.2506 - accuracy: 0.6295\n",
            "Epoch 58: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 58: accuracy did not improve from 0.75000\n",
            " 42/121 [=========>....................] - ETA: 0s - loss: 2.2584 - accuracy: 0.6287\n",
            "Epoch 58: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 58: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 58: accuracy did not improve from 0.75000\n",
            " 57/121 [=============>................] - ETA: 0s - loss: 2.2696 - accuracy: 0.6327\n",
            "Epoch 58: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 58: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 58: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 58: accuracy did not improve from 0.75000\n",
            " 75/121 [=================>............] - ETA: 0s - loss: 2.3121 - accuracy: 0.6333\n",
            "Epoch 58: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 58: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 58: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 58: accuracy did not improve from 0.75000\n",
            " 93/121 [======================>.......] - ETA: 0s - loss: 2.3649 - accuracy: 0.6267\n",
            "Epoch 58: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 58: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 58: accuracy did not improve from 0.75000\n",
            "112/121 [==========================>...] - ETA: 0s - loss: 2.3706 - accuracy: 0.6270\n",
            "Epoch 58: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 58: accuracy did not improve from 0.75000\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.3808 - accuracy: 0.6268\n",
            "Epoch 59/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 3.8123 - accuracy: 0.5625\n",
            "Epoch 59: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 59: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 59: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 59: accuracy did not improve from 0.75000\n",
            " 19/121 [===>..........................] - ETA: 0s - loss: 2.3433 - accuracy: 0.6365\n",
            "Epoch 59: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 59: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 59: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 59: accuracy did not improve from 0.75000\n",
            " 38/121 [========>.....................] - ETA: 0s - loss: 2.3358 - accuracy: 0.6291\n",
            "Epoch 59: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 59: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 59: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 59: accuracy did not improve from 0.75000\n",
            " 57/121 [=============>................] - ETA: 0s - loss: 2.3900 - accuracy: 0.6250\n",
            "Epoch 59: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 59: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 59: accuracy did not improve from 0.75000\n",
            " 76/121 [=================>............] - ETA: 0s - loss: 2.4059 - accuracy: 0.6229\n",
            "Epoch 59: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 59: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 59: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 59: accuracy did not improve from 0.75000\n",
            " 95/121 [======================>.......] - ETA: 0s - loss: 2.4105 - accuracy: 0.6234\n",
            "Epoch 59: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 59: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 59: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 59: accuracy did not improve from 0.75000\n",
            "113/121 [===========================>..] - ETA: 0s - loss: 2.4003 - accuracy: 0.6231\n",
            "Epoch 59: accuracy did not improve from 0.75000\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.3808 - accuracy: 0.6268\n",
            "Epoch 60/100\n",
            "\n",
            "Epoch 60: accuracy did not improve from 0.75000\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.7639 - accuracy: 0.6250\n",
            "Epoch 60: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 60: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 60: accuracy did not improve from 0.75000\n",
            " 19/121 [===>..........................] - ETA: 0s - loss: 2.5033 - accuracy: 0.6069\n",
            "Epoch 60: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 60: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 60: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 60: accuracy did not improve from 0.75000\n",
            " 38/121 [========>.....................] - ETA: 0s - loss: 2.4155 - accuracy: 0.6209\n",
            "Epoch 60: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 60: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 60: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 60: accuracy did not improve from 0.75000\n",
            " 56/121 [============>.................] - ETA: 0s - loss: 2.4257 - accuracy: 0.6099\n",
            "Epoch 60: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 60: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 60: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 60: accuracy did not improve from 0.75000\n",
            " 76/121 [=================>............] - ETA: 0s - loss: 2.3959 - accuracy: 0.6205\n",
            "Epoch 60: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 60: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 60: accuracy did not improve from 0.75000\n",
            " 94/121 [======================>.......] - ETA: 0s - loss: 2.3824 - accuracy: 0.6233\n",
            "Epoch 60: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 60: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 60: accuracy did not improve from 0.75000\n",
            "109/121 [==========================>...] - ETA: 0s - loss: 2.3860 - accuracy: 0.6287\n",
            "Epoch 60: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 60: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 60: accuracy did not improve from 0.75000\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.3808 - accuracy: 0.6268\n",
            "Epoch 61/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.5733 - accuracy: 0.5938\n",
            "Epoch 61: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 61: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 61: accuracy did not improve from 0.75000\n",
            " 19/121 [===>..........................] - ETA: 0s - loss: 2.2929 - accuracy: 0.6612\n",
            "Epoch 61: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 61: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 61: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 61: accuracy did not improve from 0.75000\n",
            " 37/121 [========>.....................] - ETA: 0s - loss: 2.3833 - accuracy: 0.6436\n",
            "Epoch 61: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 61: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 61: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 61: accuracy did not improve from 0.75000\n",
            " 57/121 [=============>................] - ETA: 0s - loss: 2.3231 - accuracy: 0.6464\n",
            "Epoch 61: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 61: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 61: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 61: accuracy did not improve from 0.75000\n",
            " 76/121 [=================>............] - ETA: 0s - loss: 2.3470 - accuracy: 0.6373\n",
            "Epoch 61: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 61: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 61: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 61: accuracy did not improve from 0.75000\n",
            " 95/121 [======================>.......] - ETA: 0s - loss: 2.3513 - accuracy: 0.6293\n",
            "Epoch 61: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 61: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 61: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 61: accuracy did not improve from 0.75000\n",
            "115/121 [===========================>..] - ETA: 0s - loss: 2.3850 - accuracy: 0.6264\n",
            "Epoch 61: accuracy did not improve from 0.75000\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.3808 - accuracy: 0.6268\n",
            "Epoch 62/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.0968 - accuracy: 0.6250\n",
            "Epoch 62: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 62: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 62: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 62: accuracy did not improve from 0.75000\n",
            " 20/121 [===>..........................] - ETA: 0s - loss: 2.2356 - accuracy: 0.6438\n",
            "Epoch 62: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 62: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 62: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 62: accuracy did not improve from 0.75000\n",
            " 39/121 [========>.....................] - ETA: 0s - loss: 2.3493 - accuracy: 0.6234\n",
            "Epoch 62: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 62: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 62: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 62: accuracy did not improve from 0.75000\n",
            " 59/121 [=============>................] - ETA: 0s - loss: 2.3885 - accuracy: 0.6298\n",
            "Epoch 62: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 62: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 62: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 62: accuracy did not improve from 0.75000\n",
            " 80/121 [==================>...........] - ETA: 0s - loss: 2.3990 - accuracy: 0.6258\n",
            "Epoch 62: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 62: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 62: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 62: accuracy did not improve from 0.75000\n",
            "100/121 [=======================>......] - ETA: 0s - loss: 2.3939 - accuracy: 0.6256\n",
            "Epoch 62: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 62: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 62: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 62: accuracy did not improve from 0.75000\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.3808 - accuracy: 0.6268\n",
            "Epoch 63/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 1.6224 - accuracy: 0.7188\n",
            "Epoch 63: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 63: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 63: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 63: accuracy did not improve from 0.75000\n",
            " 21/121 [====>.........................] - ETA: 0s - loss: 2.3879 - accuracy: 0.6176\n",
            "Epoch 63: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 63: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 63: accuracy did not improve from 0.75000\n",
            " 35/121 [=======>......................] - ETA: 0s - loss: 2.3995 - accuracy: 0.6161\n",
            "Epoch 63: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 63: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 63: accuracy did not improve from 0.75000\n",
            " 49/121 [===========>..................] - ETA: 0s - loss: 2.4087 - accuracy: 0.6263\n",
            "Epoch 63: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 63: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 63: accuracy did not improve from 0.75000\n",
            " 63/121 [==============>...............] - ETA: 0s - loss: 2.3774 - accuracy: 0.6329\n",
            "Epoch 63: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 63: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 63: accuracy did not improve from 0.75000\n",
            " 78/121 [==================>...........] - ETA: 0s - loss: 2.4189 - accuracy: 0.6258\n",
            "Epoch 63: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 63: accuracy did not improve from 0.75000\n",
            " 91/121 [=====================>........] - ETA: 0s - loss: 2.3908 - accuracy: 0.6295\n",
            "Epoch 63: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 63: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 63: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 63: accuracy did not improve from 0.75000\n",
            "108/121 [=========================>....] - ETA: 0s - loss: 2.3710 - accuracy: 0.6302\n",
            "Epoch 63: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 63: accuracy did not improve from 0.75000\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.3808 - accuracy: 0.6268\n",
            "Epoch 64/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 1.8130 - accuracy: 0.7188\n",
            "Epoch 64: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 64: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 64: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 64: accuracy did not improve from 0.75000\n",
            " 19/121 [===>..........................] - ETA: 0s - loss: 2.4488 - accuracy: 0.6365\n",
            "Epoch 64: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 64: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 64: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 64: accuracy did not improve from 0.75000\n",
            " 37/121 [========>.....................] - ETA: 0s - loss: 2.4429 - accuracy: 0.6292\n",
            "Epoch 64: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 64: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 64: accuracy did not improve from 0.75000\n",
            " 55/121 [============>.................] - ETA: 0s - loss: 2.3801 - accuracy: 0.6375\n",
            "Epoch 64: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 64: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 64: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 64: accuracy did not improve from 0.75000\n",
            " 72/121 [================>.............] - ETA: 0s - loss: 2.3981 - accuracy: 0.6298\n",
            "Epoch 64: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 64: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 64: accuracy did not improve from 0.75000\n",
            " 88/121 [====================>.........] - ETA: 0s - loss: 2.3933 - accuracy: 0.6261\n",
            "Epoch 64: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 64: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 64: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 64: accuracy did not improve from 0.75000\n",
            "107/121 [=========================>....] - ETA: 0s - loss: 2.3567 - accuracy: 0.6308\n",
            "Epoch 64: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 64: accuracy did not improve from 0.75000\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.3808 - accuracy: 0.6268\n",
            "Epoch 65/100\n",
            "\n",
            "Epoch 65: accuracy did not improve from 0.75000\n",
            "  1/121 [..............................] - ETA: 1s - loss: 2.2874 - accuracy: 0.6875\n",
            "Epoch 65: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 65: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 65: accuracy did not improve from 0.75000\n",
            " 16/121 [==>...........................] - ETA: 0s - loss: 2.3953 - accuracy: 0.6172\n",
            "Epoch 65: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 65: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 65: accuracy did not improve from 0.75000\n",
            " 31/121 [======>.......................] - ETA: 0s - loss: 2.3467 - accuracy: 0.6250\n",
            "Epoch 65: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 65: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 65: accuracy did not improve from 0.75000\n",
            " 46/121 [==========>...................] - ETA: 0s - loss: 2.4229 - accuracy: 0.6338\n",
            "Epoch 65: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 65: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 65: accuracy did not improve from 0.75000\n",
            " 61/121 [==============>...............] - ETA: 0s - loss: 2.4148 - accuracy: 0.6296\n",
            "Epoch 65: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 65: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 65: accuracy did not improve from 0.75000\n",
            " 76/121 [=================>............] - ETA: 0s - loss: 2.4086 - accuracy: 0.6229\n",
            "Epoch 65: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 65: accuracy did not improve from 0.75000\n",
            " 90/121 [=====================>........] - ETA: 0s - loss: 2.4205 - accuracy: 0.6240\n",
            "Epoch 65: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 65: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 65: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 65: accuracy did not improve from 0.75000\n",
            "106/121 [=========================>....] - ETA: 0s - loss: 2.4077 - accuracy: 0.6244\n",
            "Epoch 65: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 65: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 65: accuracy did not improve from 0.75000\n",
            "121/121 [==============================] - 0s 4ms/step - loss: 2.3808 - accuracy: 0.6268\n",
            "Epoch 66/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.2874 - accuracy: 0.6562\n",
            "Epoch 66: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 66: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 66: accuracy did not improve from 0.75000\n",
            " 16/121 [==>...........................] - ETA: 0s - loss: 2.3597 - accuracy: 0.6230\n",
            "Epoch 66: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 66: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 66: accuracy did not improve from 0.75000\n",
            " 30/121 [======>.......................] - ETA: 0s - loss: 2.2914 - accuracy: 0.6208\n",
            "Epoch 66: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 66: accuracy did not improve from 0.75000\n",
            " 43/121 [=========>....................] - ETA: 0s - loss: 2.3082 - accuracy: 0.6206\n",
            "Epoch 66: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 66: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 66: accuracy did not improve from 0.75000\n",
            " 57/121 [=============>................] - ETA: 0s - loss: 2.3150 - accuracy: 0.6250\n",
            "Epoch 66: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 66: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 66: accuracy did not improve from 0.75000\n",
            " 72/121 [================>.............] - ETA: 0s - loss: 2.2988 - accuracy: 0.6254\n",
            "Epoch 66: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 66: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 66: accuracy did not improve from 0.75000\n",
            " 88/121 [====================>.........] - ETA: 0s - loss: 2.3391 - accuracy: 0.6303\n",
            "Epoch 66: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 66: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 66: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 66: accuracy did not improve from 0.75000\n",
            "105/121 [=========================>....] - ETA: 0s - loss: 2.3426 - accuracy: 0.6313\n",
            "Epoch 66: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 66: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 66: accuracy did not improve from 0.75000\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.3808 - accuracy: 0.6268\n",
            "Epoch 67/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 1.7177 - accuracy: 0.7500\n",
            "Epoch 67: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 67: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 67: accuracy did not improve from 0.75000\n",
            " 18/121 [===>..........................] - ETA: 0s - loss: 2.2831 - accuracy: 0.6285\n",
            "Epoch 67: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 67: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 67: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 67: accuracy did not improve from 0.75000\n",
            " 34/121 [=======>......................] - ETA: 0s - loss: 2.4060 - accuracy: 0.6222\n",
            "Epoch 67: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 67: accuracy did not improve from 0.75000\n",
            " 46/121 [==========>...................] - ETA: 0s - loss: 2.3815 - accuracy: 0.6168\n",
            "Epoch 67: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 67: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 67: accuracy did not improve from 0.75000\n",
            " 61/121 [==============>...............] - ETA: 0s - loss: 2.4054 - accuracy: 0.6173\n",
            "Epoch 67: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 67: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 67: accuracy did not improve from 0.75000\n",
            " 76/121 [=================>............] - ETA: 0s - loss: 2.3872 - accuracy: 0.6197\n",
            "Epoch 67: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 67: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 67: accuracy did not improve from 0.75000\n",
            " 91/121 [=====================>........] - ETA: 0s - loss: 2.3782 - accuracy: 0.6257\n",
            "Epoch 67: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 67: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 67: accuracy did not improve from 0.75000\n",
            "108/121 [=========================>....] - ETA: 0s - loss: 2.3816 - accuracy: 0.6317\n",
            "Epoch 67: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 67: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 67: accuracy did not improve from 0.75000\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.3808 - accuracy: 0.6268\n",
            "Epoch 68/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.4780 - accuracy: 0.6250\n",
            "Epoch 68: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 68: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 68: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 68: accuracy did not improve from 0.75000\n",
            " 18/121 [===>..........................] - ETA: 0s - loss: 2.4365 - accuracy: 0.6128\n",
            "Epoch 68: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 68: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 68: accuracy did not improve from 0.75000\n",
            " 36/121 [=======>......................] - ETA: 0s - loss: 2.4338 - accuracy: 0.6198\n",
            "Epoch 68: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 68: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 68: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 68: accuracy did not improve from 0.75000\n",
            " 53/121 [============>.................] - ETA: 0s - loss: 2.4087 - accuracy: 0.6268\n",
            "Epoch 68: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 68: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 68: accuracy did not improve from 0.75000\n",
            " 70/121 [================>.............] - ETA: 0s - loss: 2.3930 - accuracy: 0.6250\n",
            "Epoch 68: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 68: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 68: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 68: accuracy did not improve from 0.75000\n",
            " 88/121 [====================>.........] - ETA: 0s - loss: 2.3704 - accuracy: 0.6243\n",
            "Epoch 68: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 68: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 68: accuracy did not improve from 0.75000\n",
            "104/121 [========================>.....] - ETA: 0s - loss: 2.3779 - accuracy: 0.6262\n",
            "Epoch 68: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 68: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 68: accuracy did not improve from 0.75000\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.3808 - accuracy: 0.6268\n",
            "Epoch 69/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 1.9084 - accuracy: 0.6875\n",
            "Epoch 69: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 69: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 69: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 69: accuracy did not improve from 0.75000\n",
            " 19/121 [===>..........................] - ETA: 0s - loss: 2.5294 - accuracy: 0.5970\n",
            "Epoch 69: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 69: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 69: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 69: accuracy did not improve from 0.75000\n",
            " 38/121 [========>.....................] - ETA: 0s - loss: 2.4137 - accuracy: 0.6176\n",
            "Epoch 69: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 69: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 69: accuracy did not improve from 0.75000\n",
            " 56/121 [============>.................] - ETA: 0s - loss: 2.3836 - accuracy: 0.6272\n",
            "Epoch 69: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 69: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 69: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 69: accuracy did not improve from 0.75000\n",
            " 74/121 [=================>............] - ETA: 0s - loss: 2.3514 - accuracy: 0.6309\n",
            "Epoch 69: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 69: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 69: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 69: accuracy did not improve from 0.75000\n",
            " 92/121 [=====================>........] - ETA: 0s - loss: 2.3597 - accuracy: 0.6311\n",
            "Epoch 69: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 69: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 69: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 69: accuracy did not improve from 0.75000\n",
            "112/121 [==========================>...] - ETA: 0s - loss: 2.3562 - accuracy: 0.6289\n",
            "Epoch 69: accuracy did not improve from 0.75000\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.3808 - accuracy: 0.6268\n",
            "Epoch 70/100\n",
            "\n",
            "Epoch 70: accuracy did not improve from 0.75000\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.7639 - accuracy: 0.6250\n",
            "Epoch 70: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 70: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 70: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 70: accuracy did not improve from 0.75000\n",
            " 21/121 [====>.........................] - ETA: 0s - loss: 2.4018 - accuracy: 0.6414\n",
            "Epoch 70: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 70: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 70: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 70: accuracy did not improve from 0.75000\n",
            " 41/121 [=========>....................] - ETA: 0s - loss: 2.3021 - accuracy: 0.6303\n",
            "Epoch 70: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 70: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 70: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 70: accuracy did not improve from 0.75000\n",
            " 61/121 [==============>...............] - ETA: 0s - loss: 2.3210 - accuracy: 0.6265\n",
            "Epoch 70: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 70: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 70: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 70: accuracy did not improve from 0.75000\n",
            " 81/121 [===================>..........] - ETA: 0s - loss: 2.2574 - accuracy: 0.6385\n",
            "Epoch 70: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 70: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 70: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 70: accuracy did not improve from 0.75000\n",
            "101/121 [========================>.....] - ETA: 0s - loss: 2.3211 - accuracy: 0.6346\n",
            "Epoch 70: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 70: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 70: accuracy did not improve from 0.75000\n",
            "120/121 [============================>.] - ETA: 0s - loss: 2.3834 - accuracy: 0.6266\n",
            "Epoch 70: accuracy did not improve from 0.75000\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.3808 - accuracy: 0.6268\n",
            "Epoch 71/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 3.5308 - accuracy: 0.4062\n",
            "Epoch 71: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 71: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 71: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 71: accuracy did not improve from 0.75000\n",
            " 20/121 [===>..........................] - ETA: 0s - loss: 2.2453 - accuracy: 0.6687\n",
            "Epoch 71: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 71: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 71: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 71: accuracy did not improve from 0.75000\n",
            " 40/121 [========>.....................] - ETA: 0s - loss: 2.3502 - accuracy: 0.6523\n",
            "Epoch 71: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 71: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 71: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 71: accuracy did not improve from 0.75000\n",
            " 61/121 [==============>...............] - ETA: 0s - loss: 2.3678 - accuracy: 0.6434\n",
            "Epoch 71: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 71: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 71: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 71: accuracy did not improve from 0.75000\n",
            " 80/121 [==================>...........] - ETA: 0s - loss: 2.4013 - accuracy: 0.6289\n",
            "Epoch 71: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 71: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 71: accuracy did not improve from 0.75000\n",
            " 99/121 [=======================>......] - ETA: 0s - loss: 2.3776 - accuracy: 0.6301\n",
            "Epoch 71: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 71: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 71: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 71: accuracy did not improve from 0.75000\n",
            "115/121 [===========================>..] - ETA: 0s - loss: 2.3875 - accuracy: 0.6255\n",
            "Epoch 71: accuracy did not improve from 0.75000\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.3808 - accuracy: 0.6268\n",
            "Epoch 72/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 3.0498 - accuracy: 0.5312\n",
            "Epoch 72: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 72: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 72: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 72: accuracy did not improve from 0.75000\n",
            " 19/121 [===>..........................] - ETA: 0s - loss: 2.2831 - accuracy: 0.6234\n",
            "Epoch 72: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 72: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 72: accuracy did not improve from 0.75000\n",
            " 37/121 [========>.....................] - ETA: 0s - loss: 2.3137 - accuracy: 0.6334\n",
            "Epoch 72: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 72: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 72: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 72: accuracy did not improve from 0.75000\n",
            " 55/121 [============>.................] - ETA: 0s - loss: 2.2621 - accuracy: 0.6409\n",
            "Epoch 72: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 72: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 72: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 72: accuracy did not improve from 0.75000\n",
            " 74/121 [=================>............] - ETA: 0s - loss: 2.2893 - accuracy: 0.6377\n",
            "Epoch 72: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 72: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 72: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 72: accuracy did not improve from 0.75000\n",
            " 94/121 [======================>.......] - ETA: 0s - loss: 2.3641 - accuracy: 0.6267\n",
            "Epoch 72: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 72: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 72: accuracy did not improve from 0.75000\n",
            "113/121 [===========================>..] - ETA: 0s - loss: 2.3657 - accuracy: 0.6278\n",
            "Epoch 72: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 72: accuracy did not improve from 0.75000\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.3808 - accuracy: 0.6268\n",
            "Epoch 73/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 3.0520 - accuracy: 0.6562\n",
            "Epoch 73: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 73: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 73: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 73: accuracy did not improve from 0.75000\n",
            " 20/121 [===>..........................] - ETA: 0s - loss: 2.3597 - accuracy: 0.6547\n",
            "Epoch 73: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 73: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 73: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 73: accuracy did not improve from 0.75000\n",
            " 38/121 [========>.....................] - ETA: 0s - loss: 2.4209 - accuracy: 0.6250\n",
            "Epoch 73: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 73: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 73: accuracy did not improve from 0.75000\n",
            " 56/121 [============>.................] - ETA: 0s - loss: 2.3544 - accuracy: 0.6300\n",
            "Epoch 73: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 73: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 73: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 73: accuracy did not improve from 0.75000\n",
            " 74/121 [=================>............] - ETA: 0s - loss: 2.3305 - accuracy: 0.6309\n",
            "Epoch 73: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 73: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 73: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 73: accuracy did not improve from 0.75000\n",
            " 94/121 [======================>.......] - ETA: 0s - loss: 2.3590 - accuracy: 0.6287\n",
            "Epoch 73: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 73: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 73: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 73: accuracy did not improve from 0.75000\n",
            "113/121 [===========================>..] - ETA: 0s - loss: 2.3691 - accuracy: 0.6275\n",
            "Epoch 73: accuracy did not improve from 0.75000\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.3808 - accuracy: 0.6268\n",
            "Epoch 74/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.7639 - accuracy: 0.6562\n",
            "Epoch 74: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 74: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 74: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 74: accuracy did not improve from 0.75000\n",
            " 21/121 [====>.........................] - ETA: 0s - loss: 2.4835 - accuracy: 0.6101\n",
            "Epoch 74: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 74: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 74: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 74: accuracy did not improve from 0.75000\n",
            " 40/121 [========>.....................] - ETA: 0s - loss: 2.3740 - accuracy: 0.6219\n",
            "Epoch 74: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 74: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 74: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 74: accuracy did not improve from 0.75000\n",
            " 59/121 [=============>................] - ETA: 0s - loss: 2.3640 - accuracy: 0.6382\n",
            "Epoch 74: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 74: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 74: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 74: accuracy did not improve from 0.75000\n",
            " 79/121 [==================>...........] - ETA: 0s - loss: 2.4051 - accuracy: 0.6286\n",
            "Epoch 74: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 74: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 74: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 74: accuracy did not improve from 0.75000\n",
            " 97/121 [=======================>......] - ETA: 0s - loss: 2.4149 - accuracy: 0.6250\n",
            "Epoch 74: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 74: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 74: accuracy did not improve from 0.75000\n",
            "115/121 [===========================>..] - ETA: 0s - loss: 2.3867 - accuracy: 0.6274\n",
            "Epoch 74: accuracy did not improve from 0.75000\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.3808 - accuracy: 0.6268\n",
            "Epoch 75/100\n",
            "\n",
            "Epoch 75: accuracy did not improve from 0.75000\n",
            "  1/121 [..............................] - ETA: 0s - loss: 3.0498 - accuracy: 0.5312\n",
            "Epoch 75: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 75: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 75: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 75: accuracy did not improve from 0.75000\n",
            " 21/121 [====>.........................] - ETA: 0s - loss: 2.3792 - accuracy: 0.6533\n",
            "Epoch 75: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 75: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 75: accuracy did not improve from 0.75000\n",
            " 38/121 [========>.....................] - ETA: 0s - loss: 2.3759 - accuracy: 0.6398\n",
            "Epoch 75: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 75: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 75: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 75: accuracy did not improve from 0.75000\n",
            " 57/121 [=============>................] - ETA: 0s - loss: 2.3583 - accuracy: 0.6332\n",
            "Epoch 75: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 75: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 75: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 75: accuracy did not improve from 0.75000\n",
            " 76/121 [=================>............] - ETA: 0s - loss: 2.3872 - accuracy: 0.6266\n",
            "Epoch 75: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 75: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 75: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 75: accuracy did not improve from 0.75000\n",
            " 96/121 [======================>.......] - ETA: 0s - loss: 2.3646 - accuracy: 0.6257\n",
            "Epoch 75: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 75: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 75: accuracy did not improve from 0.75000\n",
            "113/121 [===========================>..] - ETA: 0s - loss: 2.3707 - accuracy: 0.6267\n",
            "Epoch 75: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 75: accuracy did not improve from 0.75000\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.3808 - accuracy: 0.6268\n",
            "Epoch 76/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 1.3343 - accuracy: 0.8125\n",
            "Epoch 76: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 76: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 76: accuracy did not improve from 0.75000\n",
            " 19/121 [===>..........................] - ETA: 0s - loss: 2.5189 - accuracy: 0.6201\n",
            "Epoch 76: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 76: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 76: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 76: accuracy did not improve from 0.75000\n",
            " 36/121 [=======>......................] - ETA: 0s - loss: 2.4601 - accuracy: 0.6285\n",
            "Epoch 76: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 76: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 76: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 76: accuracy did not improve from 0.75000\n",
            " 55/121 [============>.................] - ETA: 0s - loss: 2.4544 - accuracy: 0.6233\n",
            "Epoch 76: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 76: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 76: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 76: accuracy did not improve from 0.75000\n",
            " 75/121 [=================>............] - ETA: 0s - loss: 2.4418 - accuracy: 0.6229\n",
            "Epoch 76: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 76: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 76: accuracy did not improve from 0.75000\n",
            " 94/121 [======================>.......] - ETA: 0s - loss: 2.4007 - accuracy: 0.6237\n",
            "Epoch 76: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 76: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 76: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 76: accuracy did not improve from 0.75000\n",
            "111/121 [==========================>...] - ETA: 0s - loss: 2.3809 - accuracy: 0.6281\n",
            "Epoch 76: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 76: accuracy did not improve from 0.75000\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.3808 - accuracy: 0.6268\n",
            "Epoch 77/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.3827 - accuracy: 0.6875\n",
            "Epoch 77: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 77: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 77: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 77: accuracy did not improve from 0.75000\n",
            " 20/121 [===>..........................] - ETA: 0s - loss: 2.4164 - accuracy: 0.6359\n",
            "Epoch 77: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 77: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 77: accuracy did not improve from 0.75000\n",
            " 38/121 [========>.....................] - ETA: 0s - loss: 2.3481 - accuracy: 0.6398\n",
            "Epoch 77: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 77: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 77: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 77: accuracy did not improve from 0.75000\n",
            " 54/121 [============>.................] - ETA: 0s - loss: 2.4326 - accuracy: 0.6279\n",
            "Epoch 77: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 77: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 77: accuracy did not improve from 0.75000\n",
            " 70/121 [================>.............] - ETA: 0s - loss: 2.4362 - accuracy: 0.6272\n",
            "Epoch 77: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 77: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 77: accuracy did not improve from 0.75000\n",
            " 87/121 [====================>.........] - ETA: 0s - loss: 2.3569 - accuracy: 0.6336\n",
            "Epoch 77: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 77: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 77: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 77: accuracy did not improve from 0.75000\n",
            "104/121 [========================>.....] - ETA: 0s - loss: 2.3906 - accuracy: 0.6256\n",
            "Epoch 77: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 77: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 77: accuracy did not improve from 0.75000\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.3808 - accuracy: 0.6268\n",
            "Epoch 78/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.1921 - accuracy: 0.7500\n",
            "Epoch 78: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 78: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 78: accuracy did not improve from 0.75000\n",
            " 17/121 [===>..........................] - ETA: 0s - loss: 2.3552 - accuracy: 0.6507\n",
            "Epoch 78: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 78: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 78: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 78: accuracy did not improve from 0.75000\n",
            " 34/121 [=======>......................] - ETA: 0s - loss: 2.3973 - accuracy: 0.6369\n",
            "Epoch 78: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 78: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 78: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 78: accuracy did not improve from 0.75000\n",
            " 53/121 [============>.................] - ETA: 0s - loss: 2.3600 - accuracy: 0.6362\n",
            "Epoch 78: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 78: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 78: accuracy did not improve from 0.75000\n",
            " 72/121 [================>.............] - ETA: 0s - loss: 2.3754 - accuracy: 0.6280\n",
            "Epoch 78: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 78: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 78: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 78: accuracy did not improve from 0.75000\n",
            " 88/121 [====================>.........] - ETA: 0s - loss: 2.3996 - accuracy: 0.6243\n",
            "Epoch 78: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 78: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 78: accuracy did not improve from 0.75000\n",
            "106/121 [=========================>....] - ETA: 0s - loss: 2.3816 - accuracy: 0.6262\n",
            "Epoch 78: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 78: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 78: accuracy did not improve from 0.75000\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.3808 - accuracy: 0.6268\n",
            "Epoch 79/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.3849 - accuracy: 0.6562\n",
            "Epoch 79: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 79: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 79: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 79: accuracy did not improve from 0.75000\n",
            " 17/121 [===>..........................] - ETA: 0s - loss: 2.3107 - accuracy: 0.6618\n",
            "Epoch 79: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 79: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 79: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 79: accuracy did not improve from 0.75000\n",
            " 37/121 [========>.....................] - ETA: 0s - loss: 2.3294 - accuracy: 0.6613\n",
            "Epoch 79: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 79: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 79: accuracy did not improve from 0.75000\n",
            " 56/121 [============>.................] - ETA: 0s - loss: 2.3358 - accuracy: 0.6518\n",
            "Epoch 79: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 79: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 79: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 79: accuracy did not improve from 0.75000\n",
            " 72/121 [================>.............] - ETA: 0s - loss: 2.3437 - accuracy: 0.6454\n",
            "Epoch 79: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 79: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 79: accuracy did not improve from 0.75000\n",
            " 90/121 [=====================>........] - ETA: 0s - loss: 2.3759 - accuracy: 0.6365\n",
            "Epoch 79: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 79: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 79: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 79: accuracy did not improve from 0.75000\n",
            "107/121 [=========================>....] - ETA: 0s - loss: 2.3735 - accuracy: 0.6311\n",
            "Epoch 79: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 79: accuracy did not improve from 0.75000\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.3808 - accuracy: 0.6268\n",
            "Epoch 80/100\n",
            "\n",
            "Epoch 80: accuracy did not improve from 0.75000\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.0968 - accuracy: 0.5625\n",
            "Epoch 80: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 80: accuracy did not improve from 0.75000\n",
            " 14/121 [==>...........................] - ETA: 0s - loss: 2.1580 - accuracy: 0.6696\n",
            "Epoch 80: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 80: accuracy did not improve from 0.75000\n",
            " 21/121 [====>.........................] - ETA: 0s - loss: 2.2104 - accuracy: 0.6607\n",
            "Epoch 80: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 80: accuracy did not improve from 0.75000\n",
            " 32/121 [======>.......................] - ETA: 0s - loss: 2.1747 - accuracy: 0.6465\n",
            "Epoch 80: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 80: accuracy did not improve from 0.75000\n",
            " 42/121 [=========>....................] - ETA: 0s - loss: 2.2628 - accuracy: 0.6421\n",
            "Epoch 80: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 80: accuracy did not improve from 0.75000\n",
            " 51/121 [===========>..................] - ETA: 0s - loss: 2.3553 - accuracy: 0.6330\n",
            "Epoch 80: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 80: accuracy did not improve from 0.75000\n",
            " 61/121 [==============>...............] - ETA: 0s - loss: 2.3474 - accuracy: 0.6306\n",
            "Epoch 80: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 80: accuracy did not improve from 0.75000\n",
            " 71/121 [================>.............] - ETA: 0s - loss: 2.3605 - accuracy: 0.6325\n",
            "Epoch 80: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 80: accuracy did not improve from 0.75000\n",
            " 81/121 [===================>..........] - ETA: 0s - loss: 2.3410 - accuracy: 0.6358\n",
            "Epoch 80: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 80: accuracy did not improve from 0.75000\n",
            " 91/121 [=====================>........] - ETA: 0s - loss: 2.3404 - accuracy: 0.6326\n",
            "Epoch 80: accuracy did not improve from 0.75000\n",
            "100/121 [=======================>......] - ETA: 0s - loss: 2.3472 - accuracy: 0.6303\n",
            "Epoch 80: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 80: accuracy did not improve from 0.75000\n",
            "110/121 [==========================>...] - ETA: 0s - loss: 2.3783 - accuracy: 0.6264\n",
            "Epoch 80: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 80: accuracy did not improve from 0.75000\n",
            "120/121 [============================>.] - ETA: 0s - loss: 2.3850 - accuracy: 0.6263\n",
            "Epoch 80: accuracy did not improve from 0.75000\n",
            "121/121 [==============================] - 1s 5ms/step - loss: 2.3808 - accuracy: 0.6268\n",
            "Epoch 81/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.3871 - accuracy: 0.7500\n",
            "Epoch 81: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 81: accuracy did not improve from 0.75000\n",
            " 10/121 [=>............................] - ETA: 0s - loss: 2.2690 - accuracy: 0.6438\n",
            "Epoch 81: accuracy did not improve from 0.75000\n",
            " 17/121 [===>..........................] - ETA: 0s - loss: 2.3049 - accuracy: 0.6599\n",
            "Epoch 81: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 81: accuracy did not improve from 0.75000\n",
            " 25/121 [=====>........................] - ETA: 0s - loss: 2.4215 - accuracy: 0.6350\n",
            "Epoch 81: accuracy did not improve from 0.75000\n",
            " 34/121 [=======>......................] - ETA: 0s - loss: 2.4030 - accuracy: 0.6360\n",
            "Epoch 81: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 81: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 81: accuracy did not improve from 0.75000\n",
            " 45/121 [==========>...................] - ETA: 0s - loss: 2.4151 - accuracy: 0.6319\n",
            "Epoch 81: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 81: accuracy did not improve from 0.75000\n",
            " 56/121 [============>.................] - ETA: 0s - loss: 2.3935 - accuracy: 0.6311\n",
            "Epoch 81: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 81: accuracy did not improve from 0.75000\n",
            " 65/121 [===============>..............] - ETA: 0s - loss: 2.4302 - accuracy: 0.6250\n",
            "Epoch 81: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 81: accuracy did not improve from 0.75000\n",
            " 77/121 [==================>...........] - ETA: 0s - loss: 2.4081 - accuracy: 0.6303\n",
            "Epoch 81: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 81: accuracy did not improve from 0.75000\n",
            " 88/121 [====================>.........] - ETA: 0s - loss: 2.4039 - accuracy: 0.6293\n",
            "Epoch 81: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 81: accuracy did not improve from 0.75000\n",
            " 99/121 [=======================>......] - ETA: 0s - loss: 2.4151 - accuracy: 0.6278\n",
            "Epoch 81: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 81: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 81: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 81: accuracy did not improve from 0.75000\n",
            "115/121 [===========================>..] - ETA: 0s - loss: 2.3759 - accuracy: 0.6280\n",
            "Epoch 81: accuracy did not improve from 0.75000\n",
            "121/121 [==============================] - 1s 5ms/step - loss: 2.3808 - accuracy: 0.6268\n",
            "Epoch 82/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.6686 - accuracy: 0.5312\n",
            "Epoch 82: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 82: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 82: accuracy did not improve from 0.75000\n",
            " 14/121 [==>...........................] - ETA: 0s - loss: 2.3493 - accuracy: 0.5871\n",
            "Epoch 82: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 82: accuracy did not improve from 0.75000\n",
            " 28/121 [=====>........................] - ETA: 0s - loss: 2.4005 - accuracy: 0.6004\n",
            "Epoch 82: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 82: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 82: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 82: accuracy did not improve from 0.75000\n",
            " 46/121 [==========>...................] - ETA: 0s - loss: 2.4602 - accuracy: 0.6114\n",
            "Epoch 82: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 82: accuracy did not improve from 0.75000\n",
            " 57/121 [=============>................] - ETA: 0s - loss: 2.4570 - accuracy: 0.6151\n",
            "Epoch 82: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 82: accuracy did not improve from 0.75000\n",
            " 65/121 [===============>..............] - ETA: 0s - loss: 2.4229 - accuracy: 0.6154\n",
            "Epoch 82: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 82: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 82: accuracy did not improve from 0.75000\n",
            " 79/121 [==================>...........] - ETA: 0s - loss: 2.4485 - accuracy: 0.6147\n",
            "Epoch 82: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 82: accuracy did not improve from 0.75000\n",
            " 89/121 [=====================>........] - ETA: 0s - loss: 2.4444 - accuracy: 0.6180\n",
            "Epoch 82: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 82: accuracy did not improve from 0.75000\n",
            " 99/121 [=======================>......] - ETA: 0s - loss: 2.4248 - accuracy: 0.6212\n",
            "Epoch 82: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 82: accuracy did not improve from 0.75000\n",
            "109/121 [==========================>...] - ETA: 0s - loss: 2.4035 - accuracy: 0.6239\n",
            "Epoch 82: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 82: accuracy did not improve from 0.75000\n",
            "121/121 [==============================] - 1s 5ms/step - loss: 2.3808 - accuracy: 0.6268\n",
            "Epoch 83/100\n",
            "  1/121 [..............................] - ETA: 1s - loss: 2.0968 - accuracy: 0.6875\n",
            "Epoch 83: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 83: accuracy did not improve from 0.75000\n",
            " 10/121 [=>............................] - ETA: 0s - loss: 2.4403 - accuracy: 0.6156\n",
            "Epoch 83: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 83: accuracy did not improve from 0.75000\n",
            " 19/121 [===>..........................] - ETA: 0s - loss: 2.3633 - accuracy: 0.6332\n",
            "Epoch 83: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 83: accuracy did not improve from 0.75000\n",
            " 29/121 [======>.......................] - ETA: 0s - loss: 2.4032 - accuracy: 0.6272\n",
            "Epoch 83: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 83: accuracy did not improve from 0.75000\n",
            " 39/121 [========>.....................] - ETA: 0s - loss: 2.3614 - accuracy: 0.6282\n",
            "Epoch 83: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 83: accuracy did not improve from 0.75000\n",
            " 48/121 [==========>...................] - ETA: 0s - loss: 2.3774 - accuracy: 0.6250\n",
            "Epoch 83: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 83: accuracy did not improve from 0.75000\n",
            " 58/121 [=============>................] - ETA: 0s - loss: 2.3867 - accuracy: 0.6234\n",
            "Epoch 83: accuracy did not improve from 0.75000\n",
            " 67/121 [===============>..............] - ETA: 0s - loss: 2.3692 - accuracy: 0.6269\n",
            "Epoch 83: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 83: accuracy did not improve from 0.75000\n",
            " 74/121 [=================>............] - ETA: 0s - loss: 2.3744 - accuracy: 0.6284\n",
            "Epoch 83: accuracy did not improve from 0.75000\n",
            " 80/121 [==================>...........] - ETA: 0s - loss: 2.3858 - accuracy: 0.6258\n",
            "Epoch 83: accuracy did not improve from 0.75000\n",
            " 87/121 [====================>.........] - ETA: 0s - loss: 2.3965 - accuracy: 0.6254\n",
            "Epoch 83: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 83: accuracy did not improve from 0.75000\n",
            " 94/121 [======================>.......] - ETA: 0s - loss: 2.3916 - accuracy: 0.6277\n",
            "Epoch 83: accuracy did not improve from 0.75000\n",
            "102/121 [========================>.....] - ETA: 0s - loss: 2.3937 - accuracy: 0.6293\n",
            "Epoch 83: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 83: accuracy did not improve from 0.75000\n",
            "108/121 [=========================>....] - ETA: 0s - loss: 2.3913 - accuracy: 0.6296\n",
            "Epoch 83: accuracy did not improve from 0.75000\n",
            "115/121 [===========================>..] - ETA: 0s - loss: 2.3917 - accuracy: 0.6258\n",
            "Epoch 83: accuracy did not improve from 0.75000\n",
            "121/121 [==============================] - 1s 7ms/step - loss: 2.3808 - accuracy: 0.6268\n",
            "Epoch 84/100\n",
            "  1/121 [..............................] - ETA: 1s - loss: 2.9567 - accuracy: 0.5000\n",
            "Epoch 84: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 84: accuracy did not improve from 0.75000\n",
            "  8/121 [>.............................] - ETA: 0s - loss: 2.6451 - accuracy: 0.5938\n",
            "Epoch 84: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 84: accuracy did not improve from 0.75000\n",
            " 17/121 [===>..........................] - ETA: 0s - loss: 2.5120 - accuracy: 0.6140\n",
            "Epoch 84: accuracy did not improve from 0.75000\n",
            " 24/121 [====>.........................] - ETA: 0s - loss: 2.5221 - accuracy: 0.6120\n",
            "Epoch 84: accuracy did not improve from 0.75000\n",
            " 30/121 [======>.......................] - ETA: 0s - loss: 2.4531 - accuracy: 0.6187\n",
            "Epoch 84: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 84: accuracy did not improve from 0.75000\n",
            " 37/121 [========>.....................] - ETA: 0s - loss: 2.4219 - accuracy: 0.6191\n",
            "Epoch 84: accuracy did not improve from 0.75000\n",
            " 44/121 [=========>....................] - ETA: 0s - loss: 2.4354 - accuracy: 0.6172\n",
            "Epoch 84: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 84: accuracy did not improve from 0.75000\n",
            " 52/121 [===========>..................] - ETA: 0s - loss: 2.4550 - accuracy: 0.6190\n",
            "Epoch 84: accuracy did not improve from 0.75000\n",
            " 61/121 [==============>...............] - ETA: 0s - loss: 2.4132 - accuracy: 0.6265\n",
            "Epoch 84: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 84: accuracy did not improve from 0.75000\n",
            " 70/121 [================>.............] - ETA: 0s - loss: 2.4189 - accuracy: 0.6237\n",
            "Epoch 84: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 84: accuracy did not improve from 0.75000\n",
            " 77/121 [==================>...........] - ETA: 0s - loss: 2.4181 - accuracy: 0.6218\n",
            "Epoch 84: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 84: accuracy did not improve from 0.75000\n",
            " 87/121 [====================>.........] - ETA: 0s - loss: 2.4119 - accuracy: 0.6218\n",
            "Epoch 84: accuracy did not improve from 0.75000\n",
            " 95/121 [======================>.......] - ETA: 0s - loss: 2.3894 - accuracy: 0.6263\n",
            "Epoch 84: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 84: accuracy did not improve from 0.75000\n",
            "104/121 [========================>.....] - ETA: 0s - loss: 2.3834 - accuracy: 0.6271\n",
            "Epoch 84: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 84: accuracy did not improve from 0.75000\n",
            "112/121 [==========================>...] - ETA: 0s - loss: 2.3783 - accuracy: 0.6281\n",
            "Epoch 84: accuracy did not improve from 0.75000\n",
            "121/121 [==============================] - 1s 7ms/step - loss: 2.3808 - accuracy: 0.6268\n",
            "Epoch 85/100\n",
            "\n",
            "Epoch 85: accuracy did not improve from 0.75000\n",
            "  1/121 [..............................] - ETA: 1s - loss: 1.8108 - accuracy: 0.7188\n",
            "Epoch 85: accuracy did not improve from 0.75000\n",
            " 10/121 [=>............................] - ETA: 0s - loss: 2.1451 - accuracy: 0.6594\n",
            "Epoch 85: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 85: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 85: accuracy did not improve from 0.75000\n",
            " 21/121 [====>.........................] - ETA: 0s - loss: 2.4017 - accuracy: 0.6220\n",
            "Epoch 85: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 85: accuracy did not improve from 0.75000\n",
            " 32/121 [======>.......................] - ETA: 0s - loss: 2.3986 - accuracy: 0.6250\n",
            "Epoch 85: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 85: accuracy did not improve from 0.75000\n",
            " 41/121 [=========>....................] - ETA: 0s - loss: 2.4673 - accuracy: 0.6197\n",
            "Epoch 85: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 85: accuracy did not improve from 0.75000\n",
            " 53/121 [============>.................] - ETA: 0s - loss: 2.4087 - accuracy: 0.6179\n",
            "Epoch 85: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 85: accuracy did not improve from 0.75000\n",
            " 61/121 [==============>...............] - ETA: 0s - loss: 2.3819 - accuracy: 0.6260\n",
            "Epoch 85: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 85: accuracy did not improve from 0.75000\n",
            " 71/121 [================>.............] - ETA: 0s - loss: 2.3995 - accuracy: 0.6246\n",
            "Epoch 85: accuracy did not improve from 0.75000\n",
            " 80/121 [==================>...........] - ETA: 0s - loss: 2.3655 - accuracy: 0.6266\n",
            "Epoch 85: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 85: accuracy did not improve from 0.75000\n",
            " 88/121 [====================>.........] - ETA: 0s - loss: 2.3433 - accuracy: 0.6307\n",
            "Epoch 85: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 85: accuracy did not improve from 0.75000\n",
            " 97/121 [=======================>......] - ETA: 0s - loss: 2.3362 - accuracy: 0.6311\n",
            "Epoch 85: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 85: accuracy did not improve from 0.75000\n",
            "107/121 [=========================>....] - ETA: 0s - loss: 2.3477 - accuracy: 0.6308\n",
            "Epoch 85: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 85: accuracy did not improve from 0.75000\n",
            "117/121 [============================>.] - ETA: 0s - loss: 2.3663 - accuracy: 0.6301\n",
            "Epoch 85: accuracy did not improve from 0.75000\n",
            "121/121 [==============================] - 1s 6ms/step - loss: 2.3808 - accuracy: 0.6268\n",
            "Epoch 86/100\n",
            "  1/121 [..............................] - ETA: 1s - loss: 1.1437 - accuracy: 0.8125\n",
            "Epoch 86: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 86: accuracy did not improve from 0.75000\n",
            " 10/121 [=>............................] - ETA: 0s - loss: 1.9354 - accuracy: 0.6625\n",
            "Epoch 86: accuracy did not improve from 0.75000\n",
            " 19/121 [===>..........................] - ETA: 0s - loss: 2.1728 - accuracy: 0.6398\n",
            "Epoch 86: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 86: accuracy did not improve from 0.75000\n",
            " 28/121 [=====>........................] - ETA: 0s - loss: 2.3631 - accuracy: 0.6217\n",
            "Epoch 86: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 86: accuracy did not improve from 0.75000\n",
            " 36/121 [=======>......................] - ETA: 0s - loss: 2.4100 - accuracy: 0.6189\n",
            "Epoch 86: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 86: accuracy did not improve from 0.75000\n",
            " 46/121 [==========>...................] - ETA: 0s - loss: 2.4644 - accuracy: 0.6223\n",
            "Epoch 86: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 86: accuracy did not improve from 0.75000\n",
            " 55/121 [============>.................] - ETA: 0s - loss: 2.3991 - accuracy: 0.6273\n",
            "Epoch 86: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 86: accuracy did not improve from 0.75000\n",
            " 65/121 [===============>..............] - ETA: 0s - loss: 2.3982 - accuracy: 0.6240\n",
            "Epoch 86: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 86: accuracy did not improve from 0.75000\n",
            " 75/121 [=================>............] - ETA: 0s - loss: 2.3835 - accuracy: 0.6263\n",
            "Epoch 86: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 86: accuracy did not improve from 0.75000\n",
            " 86/121 [====================>.........] - ETA: 0s - loss: 2.3658 - accuracy: 0.6257\n",
            "Epoch 86: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 86: accuracy did not improve from 0.75000\n",
            " 95/121 [======================>.......] - ETA: 0s - loss: 2.3644 - accuracy: 0.6257\n",
            "Epoch 86: accuracy did not improve from 0.75000\n",
            "102/121 [========================>.....] - ETA: 0s - loss: 2.3526 - accuracy: 0.6302\n",
            "Epoch 86: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 86: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 86: accuracy did not improve from 0.75000\n",
            "115/121 [===========================>..] - ETA: 0s - loss: 2.3768 - accuracy: 0.6261\n",
            "Epoch 86: accuracy did not improve from 0.75000\n",
            "121/121 [==============================] - 1s 6ms/step - loss: 2.3808 - accuracy: 0.6268\n",
            "Epoch 87/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.0968 - accuracy: 0.6875\n",
            "Epoch 87: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 87: accuracy did not improve from 0.75000\n",
            " 10/121 [=>............................] - ETA: 0s - loss: 2.3641 - accuracy: 0.6656\n",
            "Epoch 87: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 87: accuracy did not improve from 0.75000\n",
            " 19/121 [===>..........................] - ETA: 0s - loss: 2.3181 - accuracy: 0.6628\n",
            "Epoch 87: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 87: accuracy did not improve from 0.75000\n",
            " 29/121 [======>.......................] - ETA: 0s - loss: 2.3767 - accuracy: 0.6466\n",
            "Epoch 87: accuracy did not improve from 0.75000\n",
            " 38/121 [========>.....................] - ETA: 0s - loss: 2.3907 - accuracy: 0.6431\n",
            "Epoch 87: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 87: accuracy did not improve from 0.75000\n",
            " 44/121 [=========>....................] - ETA: 0s - loss: 2.3856 - accuracy: 0.6428\n",
            "Epoch 87: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 87: accuracy did not improve from 0.75000\n",
            " 54/121 [============>.................] - ETA: 0s - loss: 2.3975 - accuracy: 0.6412\n",
            "Epoch 87: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 87: accuracy did not improve from 0.75000\n",
            " 64/121 [==============>...............] - ETA: 0s - loss: 2.3968 - accuracy: 0.6377\n",
            "Epoch 87: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 87: accuracy did not improve from 0.75000\n",
            " 74/121 [=================>............] - ETA: 0s - loss: 2.3434 - accuracy: 0.6368\n",
            "Epoch 87: accuracy did not improve from 0.75000\n",
            " 83/121 [===================>..........] - ETA: 0s - loss: 2.3179 - accuracy: 0.6401\n",
            "Epoch 87: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 87: accuracy did not improve from 0.75000\n",
            " 93/121 [======================>.......] - ETA: 0s - loss: 2.3486 - accuracy: 0.6327\n",
            "Epoch 87: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 87: accuracy did not improve from 0.75000\n",
            "101/121 [========================>.....] - ETA: 0s - loss: 2.3513 - accuracy: 0.6321\n",
            "Epoch 87: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 87: accuracy did not improve from 0.75000\n",
            "109/121 [==========================>...] - ETA: 0s - loss: 2.3676 - accuracy: 0.6293\n",
            "Epoch 87: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 87: accuracy did not improve from 0.75000\n",
            "121/121 [==============================] - 1s 6ms/step - loss: 2.3808 - accuracy: 0.6268\n",
            "Epoch 88/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.1921 - accuracy: 0.5938\n",
            "Epoch 88: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 88: accuracy did not improve from 0.75000\n",
            " 10/121 [=>............................] - ETA: 0s - loss: 2.3452 - accuracy: 0.6094\n",
            "Epoch 88: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 88: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 88: accuracy did not improve from 0.75000\n",
            " 23/121 [====>.........................] - ETA: 0s - loss: 2.4538 - accuracy: 0.6223\n",
            "Epoch 88: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 88: accuracy did not improve from 0.75000\n",
            " 33/121 [=======>......................] - ETA: 0s - loss: 2.3604 - accuracy: 0.6297\n",
            "Epoch 88: accuracy did not improve from 0.75000\n",
            " 40/121 [========>.....................] - ETA: 0s - loss: 2.3501 - accuracy: 0.6320\n",
            "Epoch 88: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 88: accuracy did not improve from 0.75000\n",
            " 48/121 [==========>...................] - ETA: 0s - loss: 2.3716 - accuracy: 0.6270\n",
            "Epoch 88: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 88: accuracy did not improve from 0.75000\n",
            " 58/121 [=============>................] - ETA: 0s - loss: 2.3458 - accuracy: 0.6277\n",
            "Epoch 88: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 88: accuracy did not improve from 0.75000\n",
            " 68/121 [===============>..............] - ETA: 0s - loss: 2.3485 - accuracy: 0.6328\n",
            "Epoch 88: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 88: accuracy did not improve from 0.75000\n",
            " 78/121 [==================>...........] - ETA: 0s - loss: 2.3163 - accuracy: 0.6390\n",
            "Epoch 88: accuracy did not improve from 0.75000\n",
            " 86/121 [====================>.........] - ETA: 0s - loss: 2.3203 - accuracy: 0.6377\n",
            "Epoch 88: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 88: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 88: accuracy did not improve from 0.75000\n",
            " 98/121 [=======================>......] - ETA: 0s - loss: 2.3503 - accuracy: 0.6342\n",
            "Epoch 88: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 88: accuracy did not improve from 0.75000\n",
            "108/121 [=========================>....] - ETA: 0s - loss: 2.3702 - accuracy: 0.6305\n",
            "Epoch 88: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 88: accuracy did not improve from 0.75000\n",
            "121/121 [==============================] - 1s 6ms/step - loss: 2.3808 - accuracy: 0.6268\n",
            "Epoch 89/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.2874 - accuracy: 0.7500\n",
            "Epoch 89: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 89: accuracy did not improve from 0.75000\n",
            " 11/121 [=>............................] - ETA: 0s - loss: 1.9936 - accuracy: 0.6960\n",
            "Epoch 89: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 89: accuracy did not improve from 0.75000\n",
            " 20/121 [===>..........................] - ETA: 0s - loss: 2.2597 - accuracy: 0.6531\n",
            "Epoch 89: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 89: accuracy did not improve from 0.75000\n",
            " 29/121 [======>.......................] - ETA: 0s - loss: 2.3507 - accuracy: 0.6401\n",
            "Epoch 89: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 89: accuracy did not improve from 0.75000\n",
            " 40/121 [========>.....................] - ETA: 0s - loss: 2.3456 - accuracy: 0.6430\n",
            "Epoch 89: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 89: accuracy did not improve from 0.75000\n",
            " 51/121 [===========>..................] - ETA: 0s - loss: 2.3349 - accuracy: 0.6397\n",
            "Epoch 89: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 89: accuracy did not improve from 0.75000\n",
            " 58/121 [=============>................] - ETA: 0s - loss: 2.3162 - accuracy: 0.6336\n",
            "Epoch 89: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 89: accuracy did not improve from 0.75000\n",
            " 67/121 [===============>..............] - ETA: 0s - loss: 2.3394 - accuracy: 0.6320\n",
            "Epoch 89: accuracy did not improve from 0.75000\n",
            " 74/121 [=================>............] - ETA: 0s - loss: 2.3409 - accuracy: 0.6334\n",
            "Epoch 89: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 89: accuracy did not improve from 0.75000\n",
            " 83/121 [===================>..........] - ETA: 0s - loss: 2.3512 - accuracy: 0.6314\n",
            "Epoch 89: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 89: accuracy did not improve from 0.75000\n",
            " 92/121 [=====================>........] - ETA: 0s - loss: 2.3336 - accuracy: 0.6365\n",
            "Epoch 89: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 89: accuracy did not improve from 0.75000\n",
            "102/121 [========================>.....] - ETA: 0s - loss: 2.3712 - accuracy: 0.6271\n",
            "Epoch 89: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 89: accuracy did not improve from 0.75000\n",
            "112/121 [==========================>...] - ETA: 0s - loss: 2.3672 - accuracy: 0.6278\n",
            "Epoch 89: accuracy did not improve from 0.75000\n",
            "121/121 [==============================] - 1s 6ms/step - loss: 2.3808 - accuracy: 0.6268\n",
            "Epoch 90/100\n",
            "\n",
            "Epoch 90: accuracy did not improve from 0.75000\n",
            "  1/121 [..............................] - ETA: 1s - loss: 2.3827 - accuracy: 0.6875\n",
            "Epoch 90: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 90: accuracy did not improve from 0.75000\n",
            " 11/121 [=>............................] - ETA: 0s - loss: 2.1407 - accuracy: 0.6562\n",
            "Epoch 90: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 90: accuracy did not improve from 0.75000\n",
            " 22/121 [====>.........................] - ETA: 0s - loss: 2.3789 - accuracy: 0.6392\n",
            "Epoch 90: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 90: accuracy did not improve from 0.75000\n",
            " 33/121 [=======>......................] - ETA: 0s - loss: 2.3660 - accuracy: 0.6259\n",
            "Epoch 90: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 90: accuracy did not improve from 0.75000\n",
            " 42/121 [=========>....................] - ETA: 0s - loss: 2.3493 - accuracy: 0.6257\n",
            "Epoch 90: accuracy did not improve from 0.75000\n",
            " 49/121 [===========>..................] - ETA: 0s - loss: 2.3738 - accuracy: 0.6205\n",
            "Epoch 90: accuracy did not improve from 0.75000\n",
            " 55/121 [============>.................] - ETA: 0s - loss: 2.3887 - accuracy: 0.6216\n",
            "Epoch 90: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 90: accuracy did not improve from 0.75000\n",
            " 63/121 [==============>...............] - ETA: 0s - loss: 2.3698 - accuracy: 0.6235\n",
            "Epoch 90: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 90: accuracy did not improve from 0.75000\n",
            " 71/121 [================>.............] - ETA: 0s - loss: 2.3069 - accuracy: 0.6342\n",
            "Epoch 90: accuracy did not improve from 0.75000\n",
            " 79/121 [==================>...........] - ETA: 0s - loss: 2.3146 - accuracy: 0.6317\n",
            "Epoch 90: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 90: accuracy did not improve from 0.75000\n",
            " 86/121 [====================>.........] - ETA: 0s - loss: 2.3380 - accuracy: 0.6319\n",
            "Epoch 90: accuracy did not improve from 0.75000\n",
            " 94/121 [======================>.......] - ETA: 0s - loss: 2.3581 - accuracy: 0.6270\n",
            "Epoch 90: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 90: accuracy did not improve from 0.75000\n",
            "101/121 [========================>.....] - ETA: 0s - loss: 2.3664 - accuracy: 0.6247\n",
            "Epoch 90: accuracy did not improve from 0.75000\n",
            "109/121 [==========================>...] - ETA: 0s - loss: 2.3660 - accuracy: 0.6264\n",
            "Epoch 90: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 90: accuracy did not improve from 0.75000\n",
            "116/121 [===========================>..] - ETA: 0s - loss: 2.3826 - accuracy: 0.6269\n",
            "Epoch 90: accuracy did not improve from 0.75000\n",
            "121/121 [==============================] - 1s 7ms/step - loss: 2.3808 - accuracy: 0.6268\n",
            "Epoch 91/100\n",
            "  1/121 [..............................] - ETA: 1s - loss: 1.9062 - accuracy: 0.5625\n",
            "Epoch 91: accuracy did not improve from 0.75000\n",
            "  8/121 [>.............................] - ETA: 0s - loss: 2.0256 - accuracy: 0.6562\n",
            "Epoch 91: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 91: accuracy did not improve from 0.75000\n",
            " 18/121 [===>..........................] - ETA: 0s - loss: 2.2880 - accuracy: 0.6302\n",
            "Epoch 91: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 91: accuracy did not improve from 0.75000\n",
            " 27/121 [=====>........................] - ETA: 0s - loss: 2.3233 - accuracy: 0.6296\n",
            "Epoch 91: accuracy did not improve from 0.75000\n",
            " 34/121 [=======>......................] - ETA: 0s - loss: 2.3020 - accuracy: 0.6333\n",
            "Epoch 91: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 91: accuracy did not improve from 0.75000\n",
            " 43/121 [=========>....................] - ETA: 0s - loss: 2.3545 - accuracy: 0.6257\n",
            "Epoch 91: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 91: accuracy did not improve from 0.75000\n",
            " 51/121 [===========>..................] - ETA: 0s - loss: 2.3441 - accuracy: 0.6281\n",
            "Epoch 91: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 91: accuracy did not improve from 0.75000\n",
            " 61/121 [==============>...............] - ETA: 0s - loss: 2.3146 - accuracy: 0.6296\n",
            "Epoch 91: accuracy did not improve from 0.75000\n",
            " 69/121 [================>.............] - ETA: 0s - loss: 2.2700 - accuracy: 0.6377\n",
            "Epoch 91: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 91: accuracy did not improve from 0.75000\n",
            " 77/121 [==================>...........] - ETA: 0s - loss: 2.2980 - accuracy: 0.6319\n",
            "Epoch 91: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 91: accuracy did not improve from 0.75000\n",
            " 85/121 [====================>.........] - ETA: 0s - loss: 2.3027 - accuracy: 0.6324\n",
            "Epoch 91: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 91: accuracy did not improve from 0.75000\n",
            " 95/121 [======================>.......] - ETA: 0s - loss: 2.3313 - accuracy: 0.6296\n",
            "Epoch 91: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 91: accuracy did not improve from 0.75000\n",
            "105/121 [=========================>....] - ETA: 0s - loss: 2.3462 - accuracy: 0.6283\n",
            "Epoch 91: accuracy did not improve from 0.75000\n",
            "110/121 [==========================>...] - ETA: 0s - loss: 2.3644 - accuracy: 0.6287\n",
            "Epoch 91: accuracy did not improve from 0.75000\n",
            "119/121 [============================>.] - ETA: 0s - loss: 2.3754 - accuracy: 0.6282\n",
            "Epoch 91: accuracy did not improve from 0.75000\n",
            "121/121 [==============================] - 1s 6ms/step - loss: 2.3808 - accuracy: 0.6268\n",
            "Epoch 92/100\n",
            "  1/121 [..............................] - ETA: 1s - loss: 2.1921 - accuracy: 0.6250\n",
            "Epoch 92: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 92: accuracy did not improve from 0.75000\n",
            " 13/121 [==>...........................] - ETA: 0s - loss: 2.3170 - accuracy: 0.6418\n",
            "Epoch 92: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 92: accuracy did not improve from 0.75000\n",
            " 23/121 [====>.........................] - ETA: 0s - loss: 2.2296 - accuracy: 0.6495\n",
            "Epoch 92: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 92: accuracy did not improve from 0.75000\n",
            " 32/121 [======>.......................] - ETA: 0s - loss: 2.1654 - accuracy: 0.6611\n",
            "Epoch 92: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 92: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 92: accuracy did not improve from 0.75000\n",
            " 45/121 [==========>...................] - ETA: 0s - loss: 2.2646 - accuracy: 0.6549\n",
            "Epoch 92: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 92: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 92: accuracy did not improve from 0.75000\n",
            " 59/121 [=============>................] - ETA: 0s - loss: 2.3575 - accuracy: 0.6335\n",
            "Epoch 92: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 92: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 92: accuracy did not improve from 0.75000\n",
            " 77/121 [==================>...........] - ETA: 0s - loss: 2.3635 - accuracy: 0.6303\n",
            "Epoch 92: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 92: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 92: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 92: accuracy did not improve from 0.75000\n",
            " 95/121 [======================>.......] - ETA: 0s - loss: 2.3854 - accuracy: 0.6296\n",
            "Epoch 92: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 92: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 92: accuracy did not improve from 0.75000\n",
            "112/121 [==========================>...] - ETA: 0s - loss: 2.3911 - accuracy: 0.6261\n",
            "Epoch 92: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 92: accuracy did not improve from 0.75000\n",
            "121/121 [==============================] - 0s 4ms/step - loss: 2.3808 - accuracy: 0.6268\n",
            "Epoch 93/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 3.6239 - accuracy: 0.4375\n",
            "Epoch 93: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 93: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 93: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 93: accuracy did not improve from 0.75000\n",
            " 19/121 [===>..........................] - ETA: 0s - loss: 2.2782 - accuracy: 0.6003\n",
            "Epoch 93: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 93: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 93: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 93: accuracy did not improve from 0.75000\n",
            " 39/121 [========>.....................] - ETA: 0s - loss: 2.3933 - accuracy: 0.6146\n",
            "Epoch 93: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 93: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 93: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 93: accuracy did not improve from 0.75000\n",
            " 58/121 [=============>................] - ETA: 0s - loss: 2.3999 - accuracy: 0.6212\n",
            "Epoch 93: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 93: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 93: accuracy did not improve from 0.75000\n",
            " 77/121 [==================>...........] - ETA: 0s - loss: 2.4292 - accuracy: 0.6209\n",
            "Epoch 93: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 93: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 93: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 93: accuracy did not improve from 0.75000\n",
            " 96/121 [======================>.......] - ETA: 0s - loss: 2.4023 - accuracy: 0.6204\n",
            "Epoch 93: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 93: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 93: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 93: accuracy did not improve from 0.75000\n",
            "114/121 [===========================>..] - ETA: 0s - loss: 2.3926 - accuracy: 0.6247\n",
            "Epoch 93: accuracy did not improve from 0.75000\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.3808 - accuracy: 0.6268\n",
            "Epoch 94/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.4780 - accuracy: 0.5625\n",
            "Epoch 94: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 94: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 94: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 94: accuracy did not improve from 0.75000\n",
            " 18/121 [===>..........................] - ETA: 0s - loss: 2.3359 - accuracy: 0.6215\n",
            "Epoch 94: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 94: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 94: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 94: accuracy did not improve from 0.75000\n",
            " 37/121 [========>.....................] - ETA: 0s - loss: 2.3062 - accuracy: 0.6275\n",
            "Epoch 94: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 94: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 94: accuracy did not improve from 0.75000\n",
            " 55/121 [============>.................] - ETA: 0s - loss: 2.3853 - accuracy: 0.6239\n",
            "Epoch 94: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 94: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 94: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 94: accuracy did not improve from 0.75000\n",
            " 72/121 [================>.............] - ETA: 0s - loss: 2.3808 - accuracy: 0.6263\n",
            "Epoch 94: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 94: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 94: accuracy did not improve from 0.75000\n",
            " 90/121 [=====================>........] - ETA: 0s - loss: 2.4173 - accuracy: 0.6219\n",
            "Epoch 94: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 94: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 94: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 94: accuracy did not improve from 0.75000\n",
            "107/121 [=========================>....] - ETA: 0s - loss: 2.4120 - accuracy: 0.6256\n",
            "Epoch 94: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 94: accuracy did not improve from 0.75000\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.3808 - accuracy: 0.6268\n",
            "Epoch 95/100\n",
            "\n",
            "Epoch 95: accuracy did not improve from 0.75000\n",
            "  1/121 [..............................] - ETA: 0s - loss: 1.6202 - accuracy: 0.6875\n",
            "Epoch 95: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 95: accuracy did not improve from 0.75000\n",
            " 15/121 [==>...........................] - ETA: 0s - loss: 2.3075 - accuracy: 0.6187\n",
            "Epoch 95: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 95: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 95: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 95: accuracy did not improve from 0.75000\n",
            " 32/121 [======>.......................] - ETA: 0s - loss: 2.3418 - accuracy: 0.6191\n",
            "Epoch 95: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 95: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 95: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 95: accuracy did not improve from 0.75000\n",
            " 51/121 [===========>..................] - ETA: 0s - loss: 2.3609 - accuracy: 0.6201\n",
            "Epoch 95: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 95: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 95: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 95: accuracy did not improve from 0.75000\n",
            " 71/121 [================>.............] - ETA: 0s - loss: 2.3604 - accuracy: 0.6202\n",
            "Epoch 95: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 95: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 95: accuracy did not improve from 0.75000\n",
            " 88/121 [====================>.........] - ETA: 0s - loss: 2.3953 - accuracy: 0.6211\n",
            "Epoch 95: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 95: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 95: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 95: accuracy did not improve from 0.75000\n",
            "106/121 [=========================>....] - ETA: 0s - loss: 2.3879 - accuracy: 0.6271\n",
            "Epoch 95: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 95: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 95: accuracy did not improve from 0.75000\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.3808 - accuracy: 0.6268\n",
            "Epoch 96/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.6686 - accuracy: 0.4688\n",
            "Epoch 96: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 96: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 96: accuracy did not improve from 0.75000\n",
            " 19/121 [===>..........................] - ETA: 0s - loss: 2.5235 - accuracy: 0.6151\n",
            "Epoch 96: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 96: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 96: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 96: accuracy did not improve from 0.75000\n",
            " 35/121 [=======>......................] - ETA: 0s - loss: 2.4023 - accuracy: 0.6223\n",
            "Epoch 96: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 96: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 96: accuracy did not improve from 0.75000\n",
            " 53/121 [============>.................] - ETA: 0s - loss: 2.4230 - accuracy: 0.6167\n",
            "Epoch 96: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 96: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 96: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 96: accuracy did not improve from 0.75000\n",
            " 71/121 [================>.............] - ETA: 0s - loss: 2.4156 - accuracy: 0.6224\n",
            "Epoch 96: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 96: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 96: accuracy did not improve from 0.75000\n",
            " 89/121 [=====================>........] - ETA: 0s - loss: 2.3856 - accuracy: 0.6271\n",
            "Epoch 96: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 96: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 96: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 96: accuracy did not improve from 0.75000\n",
            "106/121 [=========================>....] - ETA: 0s - loss: 2.3735 - accuracy: 0.6309\n",
            "Epoch 96: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 96: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 96: accuracy did not improve from 0.75000\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.3808 - accuracy: 0.6268\n",
            "Epoch 97/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 1.7177 - accuracy: 0.6562\n",
            "Epoch 97: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 97: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 97: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 97: accuracy did not improve from 0.75000\n",
            " 19/121 [===>..........................] - ETA: 0s - loss: 2.2279 - accuracy: 0.6530\n",
            "Epoch 97: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 97: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 97: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 97: accuracy did not improve from 0.75000\n",
            " 39/121 [========>.....................] - ETA: 0s - loss: 2.3661 - accuracy: 0.6322\n",
            "Epoch 97: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 97: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 97: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 97: accuracy did not improve from 0.75000\n",
            " 59/121 [=============>................] - ETA: 0s - loss: 2.3380 - accuracy: 0.6372\n",
            "Epoch 97: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 97: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 97: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 97: accuracy did not improve from 0.75000\n",
            " 79/121 [==================>...........] - ETA: 0s - loss: 2.3556 - accuracy: 0.6309\n",
            "Epoch 97: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 97: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 97: accuracy did not improve from 0.75000\n",
            " 97/121 [=======================>......] - ETA: 0s - loss: 2.3352 - accuracy: 0.6372\n",
            "Epoch 97: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 97: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 97: accuracy did not improve from 0.75000\n",
            "111/121 [==========================>...] - ETA: 0s - loss: 2.3619 - accuracy: 0.6306\n",
            "Epoch 97: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 97: accuracy did not improve from 0.75000\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.3808 - accuracy: 0.6268\n",
            "Epoch 98/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.2918 - accuracy: 0.5625\n",
            "Epoch 98: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 98: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 98: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 98: accuracy did not improve from 0.75000\n",
            " 18/121 [===>..........................] - ETA: 0s - loss: 2.3099 - accuracy: 0.6441\n",
            "Epoch 98: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 98: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 98: accuracy did not improve from 0.75000\n",
            " 36/121 [=======>......................] - ETA: 0s - loss: 2.3704 - accuracy: 0.6337\n",
            "Epoch 98: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 98: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 98: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 98: accuracy did not improve from 0.75000\n",
            " 53/121 [============>.................] - ETA: 0s - loss: 2.3782 - accuracy: 0.6274\n",
            "Epoch 98: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 98: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 98: accuracy did not improve from 0.75000\n",
            " 69/121 [================>.............] - ETA: 0s - loss: 2.3710 - accuracy: 0.6300\n",
            "Epoch 98: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 98: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 98: accuracy did not improve from 0.75000\n",
            " 85/121 [====================>.........] - ETA: 0s - loss: 2.4025 - accuracy: 0.6257\n",
            "Epoch 98: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 98: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 98: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 98: accuracy did not improve from 0.75000\n",
            "103/121 [========================>.....] - ETA: 0s - loss: 2.4029 - accuracy: 0.6208\n",
            "Epoch 98: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 98: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 98: accuracy did not improve from 0.75000\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.3808 - accuracy: 0.6268\n",
            "Epoch 99/100\n",
            "  1/121 [..............................] - ETA: 0s - loss: 2.0990 - accuracy: 0.6250\n",
            "Epoch 99: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 99: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 99: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 99: accuracy did not improve from 0.75000\n",
            " 17/121 [===>..........................] - ETA: 0s - loss: 2.4227 - accuracy: 0.6305\n",
            "Epoch 99: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 99: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 99: accuracy did not improve from 0.75000\n",
            " 34/121 [=======>......................] - ETA: 0s - loss: 2.3833 - accuracy: 0.6379\n",
            "Epoch 99: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 99: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 99: accuracy did not improve from 0.75000\n",
            " 51/121 [===========>..................] - ETA: 0s - loss: 2.4002 - accuracy: 0.6336\n",
            "Epoch 99: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 99: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 99: accuracy did not improve from 0.75000\n",
            " 65/121 [===============>..............] - ETA: 0s - loss: 2.3703 - accuracy: 0.6341\n",
            "Epoch 99: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 99: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 99: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 99: accuracy did not improve from 0.75000\n",
            " 82/121 [===================>..........] - ETA: 0s - loss: 2.4078 - accuracy: 0.6300\n",
            "Epoch 99: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 99: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 99: accuracy did not improve from 0.75000\n",
            "101/121 [========================>.....] - ETA: 0s - loss: 2.4098 - accuracy: 0.6228\n",
            "Epoch 99: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 99: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 99: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 99: accuracy did not improve from 0.75000\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.3808 - accuracy: 0.6268\n",
            "Epoch 100/100\n",
            "\n",
            "Epoch 100: accuracy did not improve from 0.75000\n",
            "  1/121 [..............................] - ETA: 1s - loss: 2.3827 - accuracy: 0.6250\n",
            "Epoch 100: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 100: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 100: accuracy did not improve from 0.75000\n",
            " 18/121 [===>..........................] - ETA: 0s - loss: 2.2301 - accuracy: 0.6545\n",
            "Epoch 100: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 100: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 100: accuracy did not improve from 0.75000\n",
            " 35/121 [=======>......................] - ETA: 0s - loss: 2.2664 - accuracy: 0.6402\n",
            "Epoch 100: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 100: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 100: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 100: accuracy did not improve from 0.75000\n",
            " 51/121 [===========>..................] - ETA: 0s - loss: 2.3367 - accuracy: 0.6366\n",
            "Epoch 100: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 100: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 100: accuracy did not improve from 0.75000\n",
            " 67/121 [===============>..............] - ETA: 0s - loss: 2.3464 - accuracy: 0.6357\n",
            "Epoch 100: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 100: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 100: accuracy did not improve from 0.75000\n",
            " 82/121 [===================>..........] - ETA: 0s - loss: 2.3438 - accuracy: 0.6345\n",
            "Epoch 100: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 100: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 100: accuracy did not improve from 0.75000\n",
            " 97/121 [=======================>......] - ETA: 0s - loss: 2.3785 - accuracy: 0.6321\n",
            "Epoch 100: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 100: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 100: accuracy did not improve from 0.75000\n",
            "\n",
            "Epoch 100: accuracy did not improve from 0.75000\n",
            "116/121 [===========================>..] - ETA: 0s - loss: 2.3875 - accuracy: 0.6266\n",
            "Epoch 100: accuracy did not improve from 0.75000\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 2.3808 - accuracy: 0.6268\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model using the test data\n",
        "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=1)\n",
        "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Prv_UdaxhSC",
        "outputId": "b517d94a-0ea3-44c0-981c-b469b80a5704"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "41/41 [==============================] - 0s 1ms/step - loss: 2.3304 - accuracy: 0.6298\n",
            "Loss: 2.330411672592163, Accuracy: 0.6297739744186401\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Other Models"
      ],
      "metadata": {
        "id": "gw-wQNEBwZHm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "which students are capable/ with predictions--passsing.\n",
        "\n",
        "predicting grade/ability\n",
        "\n",
        "turn grade levels into\n",
        "\n",
        "look what has the greates amount of points."
      ],
      "metadata": {
        "id": "Cvu9k0LQYh4E"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "K5e0Eb3mu_zU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# One-hot encode the categorical variables\n",
        "encoder = OneHotEncoder()\n",
        "X = encoder.fit_transform(new_df[['Grade', 'Course_Type']])\n",
        "\n",
        "# Extract the target variable\n",
        "y = new_df['Section_Grade']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "mxX4_Kr-dubx"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Train the model\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "duZDrAZmdxp6",
        "outputId": "b1f1f6c3-4646-4d05-dabd-858ea1f09852"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearRegression()"
            ],
            "text/html": [
              "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate the mean absolute error\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "print('Mean Absolute Error:', mae)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0BG4aySveH4o",
        "outputId": "13b6f259-2f0f-4ed4-90c5-31d24b9e6d6e"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Absolute Error: 3.96020623868929\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " a MAE of 3.96020623868929 means that, on average, the model's predictions are off by approximately 3.96 units (in the same units as the target variable). This indicates that the model's performance may not be very accurate, and there may be room for improvement. However, the interpretation of the MAE also depends on the scale of the target variable and the context of the problem."
      ],
      "metadata": {
        "id": "YxEoUDfRUscX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create a scatter plot of the actual vs predicted grades\n",
        "plt.scatter(y_test, y_pred)\n",
        "plt.xlabel('Actual Grade')\n",
        "plt.ylabel('Predicted Grade')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "EObfSXjqePoJ",
        "outputId": "236c5cbe-d8a0-493b-a9d1-5deec3df3440"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "tXbTw0PCezUz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "\n",
        "\n",
        "# Select the features that you want to use for clustering\n",
        "X = new_df[['Grade', 'Section_Grade']]\n",
        "\n",
        "# Define the number of clusters you want to create\n",
        "num_clusters = 3\n",
        "\n",
        "# Create a k-means clustering model with the specified number of clusters\n",
        "kmeans = KMeans(n_clusters=3, n_init=10)\n",
        "\n",
        "# Fit the model to the data\n",
        "kmeans.fit(X)\n",
        "\n",
        "# Add a new column to the original DataFrame with the cluster labels for each data point\n",
        "new_df['Cluster'] = kmeans.labels_\n",
        "\n",
        "# Print the cluster centers\n",
        "print(kmeans.cluster_centers_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2V0qDdgQezdP",
        "outputId": "84b96d01-c64d-4597-fb26-dd94530cd622"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[10.4789916  90.53703548]\n",
            " [10.65844636 82.80541307]\n",
            " [10.55280073 96.16747934]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "lVZWQ2cyQNFD",
        "outputId": "8ffae573-c6a3-4eb6-c227-9639fdf7a05a"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  StudentID                          Course  Grade  Section_Grade  \\\n",
              "0    STU711                English I Honors      9          96.67   \n",
              "1    STU711                French II Honors      9          87.92   \n",
              "2    STU711  Computer Science Principles AP      9          86.02   \n",
              "3    STU711                       Chemistry      9          88.89   \n",
              "4    STU711              Human Geography AP      9          88.49   \n",
              "\n",
              "        Course_Type  Cluster  \n",
              "0           English        1  \n",
              "1  Foreign Language        2  \n",
              "2           Science        0  \n",
              "3           Science        2  \n",
              "4        Humanities        2  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2cfb3f6d-a735-4f42-a946-73b4749637d4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>StudentID</th>\n",
              "      <th>Course</th>\n",
              "      <th>Grade</th>\n",
              "      <th>Section_Grade</th>\n",
              "      <th>Course_Type</th>\n",
              "      <th>Cluster</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>STU711</td>\n",
              "      <td>English I Honors</td>\n",
              "      <td>9</td>\n",
              "      <td>96.67</td>\n",
              "      <td>English</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>STU711</td>\n",
              "      <td>French II Honors</td>\n",
              "      <td>9</td>\n",
              "      <td>87.92</td>\n",
              "      <td>Foreign Language</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>STU711</td>\n",
              "      <td>Computer Science Principles AP</td>\n",
              "      <td>9</td>\n",
              "      <td>86.02</td>\n",
              "      <td>Science</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>STU711</td>\n",
              "      <td>Chemistry</td>\n",
              "      <td>9</td>\n",
              "      <td>88.89</td>\n",
              "      <td>Science</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>STU711</td>\n",
              "      <td>Human Geography AP</td>\n",
              "      <td>9</td>\n",
              "      <td>88.49</td>\n",
              "      <td>Humanities</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2cfb3f6d-a735-4f42-a946-73b4749637d4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2cfb3f6d-a735-4f42-a946-73b4749637d4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2cfb3f6d-a735-4f42-a946-73b4749637d4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Plot the data points colored by their assigned clusters\n",
        "colors = ['r', 'g', 'b']\n",
        "for i in range(num_clusters):\n",
        "    plt.scatter(X[new_df['Cluster'] == i]['Grade'], X[new_df['Cluster'] == i]['Section_Grade'], c=colors[i])\n",
        "plt.xlabel('Grade')\n",
        "plt.ylabel('Section_Grade')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "wO-tF4bnU6DU",
        "outputId": "e9425a16-d560-4528-b114-31006e5241fc"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "# encode the categorical variable \"Course\" using label encoding\n",
        "le = LabelEncoder()\n",
        "new_df['Course_enc'] = le.fit_transform(new_df['Course'])\n",
        "\n",
        "# split the data into training and testing sets with a 80:20 ratio\n",
        "X_train, X_test, y_train, y_test = train_test_split(new_df.drop(['Grade'], axis=1), df['Grade'], test_size=0.2, random_state=42)\n",
        "\n",
        "# print the shapes of the training and testing sets\n",
        "print(\"Training set shape:\", X_train.shape, y_train.shape)\n",
        "print(\"Testing set shape:\", X_test.shape, y_test.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HT8aXjGJRi0I",
        "outputId": "a69e6337-0bc0-4a9a-8a19-c41b609a9015"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set shape: (4104, 6) (4104,)\n",
            "Testing set shape: (1027, 6) (1027,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "df = new_df.copy()\n",
        "\n",
        "# Encode the categorical variables\n",
        "le = LabelEncoder()\n",
        "df['Course_enc'] = le.fit_transform(df['Course'])\n",
        "df['Course_Type_enc'] = le.fit_transform(df['Course_Type'])\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(df[['Course_enc', 'Section_Grade', 'Course_Type_enc']], df['Grade'], test_size=0.2, random_state=42)\n",
        "\n",
        "# Train a random forest regressor on the training set\n",
        "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the testing set\n",
        "y_pred = rf.predict(X_test)\n",
        "\n",
        "# Evaluate the model's performance using mean squared error\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(\"Mean squared error:\", mse)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wf0SFjUaS7bj",
        "outputId": "75d59ab4-327e-4456-d9b5-c8d248079ad2"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean squared error: 0.2298913848612861\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The mean squared error (MSE) is a measure of how well a regression model fits the data. It measures the average squared difference between the predicted values and the actual values. The value of MSE ranges from 0 to infinity, with a lower value indicating a better fit of the model.\n",
        "\n",
        "In your case, the value of MSE is 0.2298, which means that on average, the predicted values are off by the square root of 0.2298. A lower value of MSE indicates a better fit of the model to the data."
      ],
      "metadata": {
        "id": "wCXN7aGL5TgC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "computer_df = new_df.copy()\n",
        "computer_df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_voLZ8af59_-",
        "outputId": "59533ea3-b60c-40ca-d702-7d83a6768f40"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['StudentID', 'Course', 'Grade', 'Section_Grade', 'Cluster',\n",
              "       'Course_enc', 'Course_Type_Arts', 'Course_Type_Computer Science',\n",
              "       'Course_Type_English', 'Course_Type_Entrepreneurship',\n",
              "       'Course_Type_Foreign Language', 'Course_Type_Humanities',\n",
              "       'Course_Type_Law and Politics', 'Course_Type_Math',\n",
              "       'Course_Type_Psychology', 'Course_Type_Research',\n",
              "       'Course_Type_Science'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "computer_df = pd.get_dummies(computer_df, columns=['Course_Type_Arts', 'Course_Type_Computer Science',\n",
        "       'Course_Type_English', 'Course_Type_Entrepreneurship',\n",
        "       'Course_Type_Foreign Language', 'Course_Type_Humanities',\n",
        "       'Course_Type_Law and Politics', 'Course_Type_Math',\n",
        "       'Course_Type_Psychology', 'Course_Type_Research',\n",
        "       'Course_Type_Science'])"
      ],
      "metadata": {
        "id": "5xYp1-Fb7iil"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "computer_df.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "id": "F1eR5hRq7qpu",
        "outputId": "80f5402a-f25c-4748-ec64-e925a6630b03"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             Grade  Section_Grade      Cluster   Course_enc  \\\n",
              "count  5131.000000    5131.000000  5131.000000  5131.000000   \n",
              "mean     10.538686      91.704987     1.005457    46.981875   \n",
              "std       1.106165       5.141133     0.917859    29.334560   \n",
              "min       9.000000      58.620000     0.000000     0.000000   \n",
              "25%      10.000000      88.980000     0.000000    26.000000   \n",
              "50%      11.000000      92.580000     1.000000    41.000000   \n",
              "75%      12.000000      95.395000     2.000000    71.000000   \n",
              "max      12.000000     103.700000     2.000000   104.000000   \n",
              "\n",
              "       Course_Type_Arts_0  Course_Type_Arts_1  Course_Type_Computer Science_0  \\\n",
              "count         5131.000000         5131.000000                     5131.000000   \n",
              "mean             0.981095            0.018905                        0.989671   \n",
              "std              0.136202            0.136202                        0.101117   \n",
              "min              0.000000            0.000000                        0.000000   \n",
              "25%              1.000000            0.000000                        1.000000   \n",
              "50%              1.000000            0.000000                        1.000000   \n",
              "75%              1.000000            0.000000                        1.000000   \n",
              "max              1.000000            1.000000                        1.000000   \n",
              "\n",
              "       Course_Type_Computer Science_1  Course_Type_English_0  \\\n",
              "count                     5131.000000            5131.000000   \n",
              "mean                         0.010329               0.828883   \n",
              "std                          0.101117               0.376648   \n",
              "min                          0.000000               0.000000   \n",
              "25%                          0.000000               1.000000   \n",
              "50%                          0.000000               1.000000   \n",
              "75%                          0.000000               1.000000   \n",
              "max                          1.000000               1.000000   \n",
              "\n",
              "       Course_Type_English_1  ...  Course_Type_Law and Politics_0  \\\n",
              "count            5131.000000  ...                     5131.000000   \n",
              "mean                0.171117  ...                        0.991035   \n",
              "std                 0.376648  ...                        0.094268   \n",
              "min                 0.000000  ...                        0.000000   \n",
              "25%                 0.000000  ...                        1.000000   \n",
              "50%                 0.000000  ...                        1.000000   \n",
              "75%                 0.000000  ...                        1.000000   \n",
              "max                 1.000000  ...                        1.000000   \n",
              "\n",
              "       Course_Type_Law and Politics_1  Course_Type_Math_0  Course_Type_Math_1  \\\n",
              "count                     5131.000000         5131.000000         5131.000000   \n",
              "mean                         0.008965            0.826739            0.173261   \n",
              "std                          0.094268            0.378509            0.378509   \n",
              "min                          0.000000            0.000000            0.000000   \n",
              "25%                          0.000000            1.000000            0.000000   \n",
              "50%                          0.000000            1.000000            0.000000   \n",
              "75%                          0.000000            1.000000            0.000000   \n",
              "max                          1.000000            1.000000            1.000000   \n",
              "\n",
              "       Course_Type_Psychology_0  Course_Type_Psychology_1  \\\n",
              "count               5131.000000               5131.000000   \n",
              "mean                   0.970571                  0.029429   \n",
              "std                    0.169022                  0.169022   \n",
              "min                    0.000000                  0.000000   \n",
              "25%                    1.000000                  0.000000   \n",
              "50%                    1.000000                  0.000000   \n",
              "75%                    1.000000                  0.000000   \n",
              "max                    1.000000                  1.000000   \n",
              "\n",
              "       Course_Type_Research_0  Course_Type_Research_1  Course_Type_Science_0  \\\n",
              "count              5131.00000              5131.00000            5131.000000   \n",
              "mean                  0.99006                 0.00994               0.767492   \n",
              "std                   0.09921                 0.09921               0.422472   \n",
              "min                   0.00000                 0.00000               0.000000   \n",
              "25%                   1.00000                 0.00000               1.000000   \n",
              "50%                   1.00000                 0.00000               1.000000   \n",
              "75%                   1.00000                 0.00000               1.000000   \n",
              "max                   1.00000                 1.00000               1.000000   \n",
              "\n",
              "       Course_Type_Science_1  \n",
              "count            5131.000000  \n",
              "mean                0.232508  \n",
              "std                 0.422472  \n",
              "min                 0.000000  \n",
              "25%                 0.000000  \n",
              "50%                 0.000000  \n",
              "75%                 0.000000  \n",
              "max                 1.000000  \n",
              "\n",
              "[8 rows x 26 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e2bb5389-775e-4143-bfa4-b197051e619f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Grade</th>\n",
              "      <th>Section_Grade</th>\n",
              "      <th>Cluster</th>\n",
              "      <th>Course_enc</th>\n",
              "      <th>Course_Type_Arts_0</th>\n",
              "      <th>Course_Type_Arts_1</th>\n",
              "      <th>Course_Type_Computer Science_0</th>\n",
              "      <th>Course_Type_Computer Science_1</th>\n",
              "      <th>Course_Type_English_0</th>\n",
              "      <th>Course_Type_English_1</th>\n",
              "      <th>...</th>\n",
              "      <th>Course_Type_Law and Politics_0</th>\n",
              "      <th>Course_Type_Law and Politics_1</th>\n",
              "      <th>Course_Type_Math_0</th>\n",
              "      <th>Course_Type_Math_1</th>\n",
              "      <th>Course_Type_Psychology_0</th>\n",
              "      <th>Course_Type_Psychology_1</th>\n",
              "      <th>Course_Type_Research_0</th>\n",
              "      <th>Course_Type_Research_1</th>\n",
              "      <th>Course_Type_Science_0</th>\n",
              "      <th>Course_Type_Science_1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>5131.000000</td>\n",
              "      <td>5131.000000</td>\n",
              "      <td>5131.000000</td>\n",
              "      <td>5131.000000</td>\n",
              "      <td>5131.000000</td>\n",
              "      <td>5131.000000</td>\n",
              "      <td>5131.000000</td>\n",
              "      <td>5131.000000</td>\n",
              "      <td>5131.000000</td>\n",
              "      <td>5131.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>5131.000000</td>\n",
              "      <td>5131.000000</td>\n",
              "      <td>5131.000000</td>\n",
              "      <td>5131.000000</td>\n",
              "      <td>5131.000000</td>\n",
              "      <td>5131.000000</td>\n",
              "      <td>5131.00000</td>\n",
              "      <td>5131.00000</td>\n",
              "      <td>5131.000000</td>\n",
              "      <td>5131.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>10.538686</td>\n",
              "      <td>91.704987</td>\n",
              "      <td>1.005457</td>\n",
              "      <td>46.981875</td>\n",
              "      <td>0.981095</td>\n",
              "      <td>0.018905</td>\n",
              "      <td>0.989671</td>\n",
              "      <td>0.010329</td>\n",
              "      <td>0.828883</td>\n",
              "      <td>0.171117</td>\n",
              "      <td>...</td>\n",
              "      <td>0.991035</td>\n",
              "      <td>0.008965</td>\n",
              "      <td>0.826739</td>\n",
              "      <td>0.173261</td>\n",
              "      <td>0.970571</td>\n",
              "      <td>0.029429</td>\n",
              "      <td>0.99006</td>\n",
              "      <td>0.00994</td>\n",
              "      <td>0.767492</td>\n",
              "      <td>0.232508</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.106165</td>\n",
              "      <td>5.141133</td>\n",
              "      <td>0.917859</td>\n",
              "      <td>29.334560</td>\n",
              "      <td>0.136202</td>\n",
              "      <td>0.136202</td>\n",
              "      <td>0.101117</td>\n",
              "      <td>0.101117</td>\n",
              "      <td>0.376648</td>\n",
              "      <td>0.376648</td>\n",
              "      <td>...</td>\n",
              "      <td>0.094268</td>\n",
              "      <td>0.094268</td>\n",
              "      <td>0.378509</td>\n",
              "      <td>0.378509</td>\n",
              "      <td>0.169022</td>\n",
              "      <td>0.169022</td>\n",
              "      <td>0.09921</td>\n",
              "      <td>0.09921</td>\n",
              "      <td>0.422472</td>\n",
              "      <td>0.422472</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>9.000000</td>\n",
              "      <td>58.620000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>10.000000</td>\n",
              "      <td>88.980000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>11.000000</td>\n",
              "      <td>92.580000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>41.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>12.000000</td>\n",
              "      <td>95.395000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>71.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>12.000000</td>\n",
              "      <td>103.700000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>104.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 26 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e2bb5389-775e-4143-bfa4-b197051e619f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e2bb5389-775e-4143-bfa4-b197051e619f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e2bb5389-775e-4143-bfa4-b197051e619f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3LYMzqgJ8GNa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "\n",
        "# Define features and target variable\n",
        "X = new_df.drop(['StudentID', 'Course', 'Grade', 'Section_Grade', 'Cluster'], axis=1)\n",
        "y = new_df['Course_Type_Computer Science'].values # Binary target variable: 1 if the course is a computer course, 0 otherwise\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train logistic regression model\n",
        "clf = LogisticRegression()\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Predict target variable on testing set\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Compute accuracy score\n",
        "acc_score = accuracy_score(y_test, y_pred)\n",
        "print('Accuracy score:', acc_score)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_leii-PV5uSG",
        "outputId": "6e520d78-cdb3-43ce-e0d8-f7188df77b8f"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy score: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "BRNQme4xX9wk"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TBVHQxPvX9R6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}